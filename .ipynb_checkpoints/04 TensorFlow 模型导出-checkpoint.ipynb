{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 第四部分：TensorFlow 模型导出  <br/>\n",
    "   &emsp; 4.1 使用 SavedModel 完整导出模型 <br/>\n",
    "   &emsp; 4.2 Keras 自有的模型导出格式（Jinpeng） <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_core.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "class MNISTLoader_my_download():\n",
    "    def __init__(self):\n",
    "        # 读取数据，预先已经下载了相应的数据直\n",
    "        mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "        self.train_data = mnist.train.images\n",
    "        self.train_label = mnist.train.labels\n",
    "        self.test_data = mnist.test.images\n",
    "        self.test_label = mnist.test.labels\n",
    "        \n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 784, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 784, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "        \n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)  # 第一层神经元的个数为100\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)   # 第二层神经元的个数为10,输出一个样本的维度为10\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "batch 0: loss 2.302373\n",
      "batch 1: loss 2.301860\n",
      "batch 2: loss 2.302287\n",
      "batch 3: loss 2.301741\n",
      "batch 4: loss 2.300363\n",
      "batch 5: loss 2.301181\n",
      "batch 6: loss 2.299425\n",
      "batch 7: loss 2.299812\n",
      "batch 8: loss 2.299053\n",
      "batch 9: loss 2.299538\n",
      "batch 10: loss 2.299464\n",
      "batch 11: loss 2.297844\n",
      "batch 12: loss 2.299219\n",
      "batch 13: loss 2.298136\n",
      "batch 14: loss 2.298450\n",
      "batch 15: loss 2.298048\n",
      "batch 16: loss 2.296398\n",
      "batch 17: loss 2.296257\n",
      "batch 18: loss 2.295099\n",
      "batch 19: loss 2.293093\n",
      "batch 20: loss 2.295893\n",
      "batch 21: loss 2.294977\n",
      "batch 22: loss 2.293833\n",
      "batch 23: loss 2.293553\n",
      "batch 24: loss 2.289703\n",
      "batch 25: loss 2.291344\n",
      "batch 26: loss 2.294388\n",
      "batch 27: loss 2.292542\n",
      "batch 28: loss 2.291328\n",
      "batch 29: loss 2.287314\n",
      "batch 30: loss 2.293865\n",
      "batch 31: loss 2.289235\n",
      "batch 32: loss 2.290250\n",
      "batch 33: loss 2.287432\n",
      "batch 34: loss 2.285551\n",
      "batch 35: loss 2.287399\n",
      "batch 36: loss 2.288785\n",
      "batch 37: loss 2.292027\n",
      "batch 38: loss 2.284811\n",
      "batch 39: loss 2.285136\n",
      "batch 40: loss 2.282796\n",
      "batch 41: loss 2.280499\n",
      "batch 42: loss 2.283396\n",
      "batch 43: loss 2.287360\n",
      "batch 44: loss 2.280006\n",
      "batch 45: loss 2.289540\n",
      "batch 46: loss 2.284237\n",
      "batch 47: loss 2.282652\n",
      "batch 48: loss 2.283037\n",
      "batch 49: loss 2.277883\n",
      "batch 50: loss 2.283005\n",
      "batch 51: loss 2.275639\n",
      "batch 52: loss 2.278942\n",
      "batch 53: loss 2.271163\n",
      "batch 54: loss 2.279461\n",
      "batch 55: loss 2.274109\n",
      "batch 56: loss 2.265883\n",
      "batch 57: loss 2.264432\n",
      "batch 58: loss 2.270503\n",
      "batch 59: loss 2.270309\n",
      "batch 60: loss 2.279461\n",
      "batch 61: loss 2.276463\n",
      "batch 62: loss 2.281311\n",
      "batch 63: loss 2.269753\n",
      "batch 64: loss 2.269519\n",
      "batch 65: loss 2.265872\n",
      "batch 66: loss 2.265586\n",
      "batch 67: loss 2.276283\n",
      "batch 68: loss 2.278709\n",
      "batch 69: loss 2.263303\n",
      "batch 70: loss 2.271766\n",
      "batch 71: loss 2.263992\n",
      "batch 72: loss 2.269934\n",
      "batch 73: loss 2.260977\n",
      "batch 74: loss 2.254533\n",
      "batch 75: loss 2.258013\n",
      "batch 76: loss 2.257001\n",
      "batch 77: loss 2.256603\n",
      "batch 78: loss 2.268128\n",
      "batch 79: loss 2.277409\n",
      "batch 80: loss 2.260509\n",
      "batch 81: loss 2.249227\n",
      "batch 82: loss 2.253140\n",
      "batch 83: loss 2.273930\n",
      "batch 84: loss 2.251284\n",
      "batch 85: loss 2.263623\n",
      "batch 86: loss 2.243248\n",
      "batch 87: loss 2.256529\n",
      "batch 88: loss 2.245637\n",
      "batch 89: loss 2.258521\n",
      "batch 90: loss 2.242714\n",
      "batch 91: loss 2.244355\n",
      "batch 92: loss 2.257372\n",
      "batch 93: loss 2.247303\n",
      "batch 94: loss 2.228437\n",
      "batch 95: loss 2.265163\n",
      "batch 96: loss 2.241579\n",
      "batch 97: loss 2.224319\n",
      "batch 98: loss 2.235646\n",
      "batch 99: loss 2.241774\n",
      "batch 100: loss 2.236431\n",
      "batch 101: loss 2.246852\n",
      "batch 102: loss 2.215469\n",
      "batch 103: loss 2.245149\n",
      "batch 104: loss 2.238922\n",
      "batch 105: loss 2.239837\n",
      "batch 106: loss 2.231184\n",
      "batch 107: loss 2.250622\n",
      "batch 108: loss 2.226485\n",
      "batch 109: loss 2.212404\n",
      "batch 110: loss 2.233885\n",
      "batch 111: loss 2.230566\n",
      "batch 112: loss 2.226228\n",
      "batch 113: loss 2.239946\n",
      "batch 114: loss 2.196831\n",
      "batch 115: loss 2.201507\n",
      "batch 116: loss 2.214926\n",
      "batch 117: loss 2.196708\n",
      "batch 118: loss 2.211552\n",
      "batch 119: loss 2.221610\n",
      "batch 120: loss 2.217142\n",
      "batch 121: loss 2.196269\n",
      "batch 122: loss 2.210342\n",
      "batch 123: loss 2.178955\n",
      "batch 124: loss 2.220696\n",
      "batch 125: loss 2.220165\n",
      "batch 126: loss 2.183078\n",
      "batch 127: loss 2.193554\n",
      "batch 128: loss 2.204238\n",
      "batch 129: loss 2.173121\n",
      "batch 130: loss 2.215568\n",
      "batch 131: loss 2.215983\n",
      "batch 132: loss 2.181240\n",
      "batch 133: loss 2.217530\n",
      "batch 134: loss 2.195987\n",
      "batch 135: loss 2.184166\n",
      "batch 136: loss 2.216616\n",
      "batch 137: loss 2.173480\n",
      "batch 138: loss 2.177847\n",
      "batch 139: loss 2.224677\n",
      "batch 140: loss 2.189452\n",
      "batch 141: loss 2.212643\n",
      "batch 142: loss 2.181995\n",
      "batch 143: loss 2.171243\n",
      "batch 144: loss 2.179856\n",
      "batch 145: loss 2.211121\n",
      "batch 146: loss 2.211359\n",
      "batch 147: loss 2.185725\n",
      "batch 148: loss 2.188208\n",
      "batch 149: loss 2.151523\n",
      "batch 150: loss 2.174091\n",
      "batch 151: loss 2.184956\n",
      "batch 152: loss 2.166051\n",
      "batch 153: loss 2.204332\n",
      "batch 154: loss 2.175953\n",
      "batch 155: loss 2.178462\n",
      "batch 156: loss 2.172673\n",
      "batch 157: loss 2.167011\n",
      "batch 158: loss 2.148238\n",
      "batch 159: loss 2.153288\n",
      "batch 160: loss 2.139783\n",
      "batch 161: loss 2.140208\n",
      "batch 162: loss 2.119918\n",
      "batch 163: loss 2.139398\n",
      "batch 164: loss 2.106750\n",
      "batch 165: loss 2.174122\n",
      "batch 166: loss 2.132306\n",
      "batch 167: loss 2.128613\n",
      "batch 168: loss 2.131717\n",
      "batch 169: loss 2.152785\n",
      "batch 170: loss 2.127766\n",
      "batch 171: loss 2.137058\n",
      "batch 172: loss 2.153980\n",
      "batch 173: loss 2.159516\n",
      "batch 174: loss 2.121560\n",
      "batch 175: loss 2.132840\n",
      "batch 176: loss 2.108883\n",
      "batch 177: loss 2.137624\n",
      "batch 178: loss 2.137194\n",
      "batch 179: loss 2.129136\n",
      "batch 180: loss 2.091496\n",
      "batch 181: loss 2.160378\n",
      "batch 182: loss 2.155445\n",
      "batch 183: loss 2.140507\n",
      "batch 184: loss 2.145474\n",
      "batch 185: loss 2.129223\n",
      "batch 186: loss 2.081531\n",
      "batch 187: loss 2.084313\n",
      "batch 188: loss 2.130092\n",
      "batch 189: loss 2.114420\n",
      "batch 190: loss 2.111251\n",
      "batch 191: loss 2.140023\n",
      "batch 192: loss 2.139146\n",
      "batch 193: loss 2.118332\n",
      "batch 194: loss 2.153535\n",
      "batch 195: loss 2.095563\n",
      "batch 196: loss 2.125132\n",
      "batch 197: loss 2.127501\n",
      "batch 198: loss 2.128494\n",
      "batch 199: loss 2.107877\n",
      "batch 200: loss 2.042678\n",
      "batch 201: loss 2.045154\n",
      "batch 202: loss 2.113821\n",
      "batch 203: loss 2.111265\n",
      "batch 204: loss 2.151622\n",
      "batch 205: loss 2.095506\n",
      "batch 206: loss 2.106156\n",
      "batch 207: loss 2.058019\n",
      "batch 208: loss 2.061820\n",
      "batch 209: loss 2.047709\n",
      "batch 210: loss 2.097426\n",
      "batch 211: loss 2.075249\n",
      "batch 212: loss 2.068168\n",
      "batch 213: loss 2.072362\n",
      "batch 214: loss 2.045561\n",
      "batch 215: loss 2.099705\n",
      "batch 216: loss 2.052634\n",
      "batch 217: loss 2.035570\n",
      "batch 218: loss 2.100495\n",
      "batch 219: loss 2.065081\n",
      "batch 220: loss 2.045920\n",
      "batch 221: loss 2.044690\n",
      "batch 222: loss 2.020890\n",
      "batch 223: loss 2.026752\n",
      "batch 224: loss 2.104738\n",
      "batch 225: loss 2.039982\n",
      "batch 226: loss 2.022416\n",
      "batch 227: loss 2.013467\n",
      "batch 228: loss 2.064509\n",
      "batch 229: loss 2.051112\n",
      "batch 230: loss 2.050328\n",
      "batch 231: loss 2.055877\n",
      "batch 232: loss 2.067744\n",
      "batch 233: loss 2.065069\n",
      "batch 234: loss 2.055607\n",
      "batch 235: loss 1.973967\n",
      "batch 236: loss 2.032748\n",
      "batch 237: loss 1.963299\n",
      "batch 238: loss 1.997737\n",
      "batch 239: loss 2.033063\n",
      "batch 240: loss 1.937670\n",
      "batch 241: loss 2.016246\n",
      "batch 242: loss 1.993075\n",
      "batch 243: loss 1.993827\n",
      "batch 244: loss 2.021057\n",
      "batch 245: loss 2.022964\n",
      "batch 246: loss 2.034125\n",
      "batch 247: loss 1.986034\n",
      "batch 248: loss 2.003427\n",
      "batch 249: loss 2.025358\n",
      "batch 250: loss 2.019322\n",
      "batch 251: loss 1.974168\n",
      "batch 252: loss 1.985863\n",
      "batch 253: loss 2.042705\n",
      "batch 254: loss 1.978682\n",
      "batch 255: loss 2.024628\n",
      "batch 256: loss 1.992238\n",
      "batch 257: loss 2.015933\n",
      "batch 258: loss 2.025175\n",
      "batch 259: loss 2.021307\n",
      "batch 260: loss 1.862113\n",
      "batch 261: loss 2.009288\n",
      "batch 262: loss 2.012286\n",
      "batch 263: loss 1.973677\n",
      "batch 264: loss 2.028983\n",
      "batch 265: loss 1.925674\n",
      "batch 266: loss 1.958593\n",
      "batch 267: loss 1.985678\n",
      "batch 268: loss 1.908860\n",
      "batch 269: loss 1.928792\n",
      "batch 270: loss 1.966136\n",
      "batch 271: loss 1.887162\n",
      "batch 272: loss 1.977146\n",
      "batch 273: loss 1.943297\n",
      "batch 274: loss 1.981455\n",
      "batch 275: loss 1.930323\n",
      "batch 276: loss 1.893775\n",
      "batch 277: loss 1.891570\n",
      "batch 278: loss 1.922965\n",
      "batch 279: loss 1.902304\n",
      "batch 280: loss 1.932958\n",
      "batch 281: loss 1.865784\n",
      "batch 282: loss 1.937055\n",
      "batch 283: loss 1.995283\n",
      "batch 284: loss 1.971190\n",
      "batch 285: loss 1.870562\n",
      "batch 286: loss 1.892289\n",
      "batch 287: loss 1.911394\n",
      "batch 288: loss 1.875448\n",
      "batch 289: loss 1.891919\n",
      "batch 290: loss 1.925658\n",
      "batch 291: loss 1.919151\n",
      "batch 292: loss 1.843263\n",
      "batch 293: loss 1.992989\n",
      "batch 294: loss 1.830317\n",
      "batch 295: loss 1.881986\n",
      "batch 296: loss 1.919572\n",
      "batch 297: loss 1.923836\n",
      "batch 298: loss 1.910855\n",
      "batch 299: loss 1.820619\n",
      "batch 300: loss 1.846724\n",
      "batch 301: loss 1.946553\n",
      "batch 302: loss 1.875015\n",
      "batch 303: loss 1.863272\n",
      "batch 304: loss 1.902347\n",
      "batch 305: loss 1.923683\n",
      "batch 306: loss 1.923672\n",
      "batch 307: loss 1.902613\n",
      "batch 308: loss 1.905516\n",
      "batch 309: loss 1.933427\n",
      "batch 310: loss 1.876201\n",
      "batch 311: loss 1.853496\n",
      "batch 312: loss 1.833001\n",
      "batch 313: loss 1.906076\n",
      "batch 314: loss 1.844108\n",
      "batch 315: loss 1.852865\n",
      "batch 316: loss 1.873665\n",
      "batch 317: loss 1.762352\n",
      "batch 318: loss 1.837362\n",
      "batch 319: loss 1.897323\n",
      "batch 320: loss 1.821616\n",
      "batch 321: loss 1.755577\n",
      "batch 322: loss 1.840748\n",
      "batch 323: loss 1.909350\n",
      "batch 324: loss 1.912472\n",
      "batch 325: loss 1.901796\n",
      "batch 326: loss 1.798287\n",
      "batch 327: loss 1.870835\n",
      "batch 328: loss 1.769265\n",
      "batch 329: loss 1.875643\n",
      "batch 330: loss 1.896133\n",
      "batch 331: loss 1.818853\n",
      "batch 332: loss 1.839877\n",
      "batch 333: loss 1.795825\n",
      "batch 334: loss 1.846313\n",
      "batch 335: loss 1.707407\n",
      "batch 336: loss 1.883523\n",
      "batch 337: loss 1.834392\n",
      "batch 338: loss 1.825046\n",
      "batch 339: loss 1.901254\n",
      "batch 340: loss 1.790807\n",
      "batch 341: loss 1.808569\n",
      "batch 342: loss 1.765885\n",
      "batch 343: loss 1.762757\n",
      "batch 344: loss 1.756225\n",
      "batch 345: loss 1.749993\n",
      "batch 346: loss 1.756149\n",
      "batch 347: loss 1.788384\n",
      "batch 348: loss 1.861886\n",
      "batch 349: loss 1.780848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 350: loss 1.774503\n",
      "batch 351: loss 1.809527\n",
      "batch 352: loss 1.666185\n",
      "batch 353: loss 1.753923\n",
      "batch 354: loss 1.845077\n",
      "batch 355: loss 1.774320\n",
      "batch 356: loss 1.739378\n",
      "batch 357: loss 1.764612\n",
      "batch 358: loss 1.706707\n",
      "batch 359: loss 1.783666\n",
      "batch 360: loss 1.684180\n",
      "batch 361: loss 1.809366\n",
      "batch 362: loss 1.680919\n",
      "batch 363: loss 1.746695\n",
      "batch 364: loss 1.789913\n",
      "batch 365: loss 1.734102\n",
      "batch 366: loss 1.733428\n",
      "batch 367: loss 1.848365\n",
      "batch 368: loss 1.744235\n",
      "batch 369: loss 1.811300\n",
      "batch 370: loss 1.822310\n",
      "batch 371: loss 1.777870\n",
      "batch 372: loss 1.739634\n",
      "batch 373: loss 1.604766\n",
      "batch 374: loss 1.677799\n",
      "batch 375: loss 1.759372\n",
      "batch 376: loss 1.687904\n",
      "batch 377: loss 1.708411\n",
      "batch 378: loss 1.763971\n",
      "batch 379: loss 1.731894\n",
      "batch 380: loss 1.678782\n",
      "batch 381: loss 1.753384\n",
      "batch 382: loss 1.724584\n",
      "batch 383: loss 1.708265\n",
      "batch 384: loss 1.686789\n",
      "batch 385: loss 1.769053\n",
      "batch 386: loss 1.608864\n",
      "batch 387: loss 1.670913\n",
      "batch 388: loss 1.714713\n",
      "batch 389: loss 1.734845\n",
      "batch 390: loss 1.604219\n",
      "batch 391: loss 1.659592\n",
      "batch 392: loss 1.611719\n",
      "batch 393: loss 1.660855\n",
      "batch 394: loss 1.682578\n",
      "batch 395: loss 1.753421\n",
      "batch 396: loss 1.633317\n",
      "batch 397: loss 1.670314\n",
      "batch 398: loss 1.611620\n",
      "batch 399: loss 1.745047\n",
      "batch 400: loss 1.680293\n",
      "batch 401: loss 1.695151\n",
      "batch 402: loss 1.647357\n",
      "batch 403: loss 1.654543\n",
      "batch 404: loss 1.595440\n",
      "batch 405: loss 1.713164\n",
      "batch 406: loss 1.698660\n",
      "batch 407: loss 1.665656\n",
      "batch 408: loss 1.694967\n",
      "batch 409: loss 1.663658\n",
      "batch 410: loss 1.613825\n",
      "batch 411: loss 1.564856\n",
      "batch 412: loss 1.687798\n",
      "batch 413: loss 1.629171\n",
      "batch 414: loss 1.686129\n",
      "batch 415: loss 1.666562\n",
      "batch 416: loss 1.612215\n",
      "batch 417: loss 1.669322\n",
      "batch 418: loss 1.663367\n",
      "batch 419: loss 1.593105\n",
      "batch 420: loss 1.538045\n",
      "batch 421: loss 1.730217\n",
      "batch 422: loss 1.547065\n",
      "batch 423: loss 1.589300\n",
      "batch 424: loss 1.648516\n",
      "batch 425: loss 1.585573\n",
      "batch 426: loss 1.613661\n",
      "batch 427: loss 1.619032\n",
      "batch 428: loss 1.622383\n",
      "batch 429: loss 1.608811\n",
      "batch 430: loss 1.606467\n",
      "batch 431: loss 1.673146\n",
      "batch 432: loss 1.684115\n",
      "batch 433: loss 1.687687\n",
      "batch 434: loss 1.542408\n",
      "batch 435: loss 1.609728\n",
      "batch 436: loss 1.638095\n",
      "batch 437: loss 1.498146\n",
      "batch 438: loss 1.537634\n",
      "batch 439: loss 1.535726\n",
      "batch 440: loss 1.540342\n",
      "batch 441: loss 1.548588\n",
      "batch 442: loss 1.586246\n",
      "batch 443: loss 1.606373\n",
      "batch 444: loss 1.695699\n",
      "batch 445: loss 1.489670\n",
      "batch 446: loss 1.717135\n",
      "batch 447: loss 1.572774\n",
      "batch 448: loss 1.638135\n",
      "batch 449: loss 1.703861\n",
      "batch 450: loss 1.597351\n",
      "batch 451: loss 1.572793\n",
      "batch 452: loss 1.586594\n",
      "batch 453: loss 1.476824\n",
      "batch 454: loss 1.447892\n",
      "batch 455: loss 1.534383\n",
      "batch 456: loss 1.628551\n",
      "batch 457: loss 1.549081\n",
      "batch 458: loss 1.553234\n",
      "batch 459: loss 1.620389\n",
      "batch 460: loss 1.495420\n",
      "batch 461: loss 1.531211\n",
      "batch 462: loss 1.614007\n",
      "batch 463: loss 1.666993\n",
      "batch 464: loss 1.635759\n",
      "batch 465: loss 1.560919\n",
      "batch 466: loss 1.603936\n",
      "batch 467: loss 1.491598\n",
      "batch 468: loss 1.536697\n",
      "batch 469: loss 1.648665\n",
      "batch 470: loss 1.491369\n",
      "batch 471: loss 1.496131\n",
      "batch 472: loss 1.513435\n",
      "batch 473: loss 1.492753\n",
      "batch 474: loss 1.610751\n",
      "batch 475: loss 1.483495\n",
      "batch 476: loss 1.537633\n",
      "batch 477: loss 1.601295\n",
      "batch 478: loss 1.455195\n",
      "batch 479: loss 1.652931\n",
      "batch 480: loss 1.464707\n",
      "batch 481: loss 1.488421\n",
      "batch 482: loss 1.337802\n",
      "batch 483: loss 1.553901\n",
      "batch 484: loss 1.569115\n",
      "batch 485: loss 1.391847\n",
      "batch 486: loss 1.567354\n",
      "batch 487: loss 1.565786\n",
      "batch 488: loss 1.493047\n",
      "batch 489: loss 1.364776\n",
      "batch 490: loss 1.359983\n",
      "batch 491: loss 1.512324\n",
      "batch 492: loss 1.359772\n",
      "batch 493: loss 1.587697\n",
      "batch 494: loss 1.346799\n",
      "batch 495: loss 1.607040\n",
      "batch 496: loss 1.525024\n",
      "batch 497: loss 1.555329\n",
      "batch 498: loss 1.360207\n",
      "batch 499: loss 1.456777\n",
      "batch 500: loss 1.539455\n",
      "batch 501: loss 1.570247\n",
      "batch 502: loss 1.385480\n",
      "batch 503: loss 1.471913\n",
      "batch 504: loss 1.482829\n",
      "batch 505: loss 1.591564\n",
      "batch 506: loss 1.326469\n",
      "batch 507: loss 1.462293\n",
      "batch 508: loss 1.489655\n",
      "batch 509: loss 1.333653\n",
      "batch 510: loss 1.400989\n",
      "batch 511: loss 1.396025\n",
      "batch 512: loss 1.554420\n",
      "batch 513: loss 1.421779\n",
      "batch 514: loss 1.466689\n",
      "batch 515: loss 1.419827\n",
      "batch 516: loss 1.419802\n",
      "batch 517: loss 1.422343\n",
      "batch 518: loss 1.502255\n",
      "batch 519: loss 1.470249\n",
      "batch 520: loss 1.486103\n",
      "batch 521: loss 1.450082\n",
      "batch 522: loss 1.367024\n",
      "batch 523: loss 1.381865\n",
      "batch 524: loss 1.408021\n",
      "batch 525: loss 1.420339\n",
      "batch 526: loss 1.475989\n",
      "batch 527: loss 1.426679\n",
      "batch 528: loss 1.459846\n",
      "batch 529: loss 1.479882\n",
      "batch 530: loss 1.430566\n",
      "batch 531: loss 1.427562\n",
      "batch 532: loss 1.338068\n",
      "batch 533: loss 1.499294\n",
      "batch 534: loss 1.398350\n",
      "batch 535: loss 1.365692\n",
      "batch 536: loss 1.349420\n",
      "batch 537: loss 1.304067\n",
      "batch 538: loss 1.370075\n",
      "batch 539: loss 1.398101\n",
      "batch 540: loss 1.439540\n",
      "batch 541: loss 1.362198\n",
      "batch 542: loss 1.493072\n",
      "batch 543: loss 1.478359\n",
      "batch 544: loss 1.484538\n",
      "batch 545: loss 1.380777\n",
      "batch 546: loss 1.300272\n",
      "batch 547: loss 1.391205\n",
      "batch 548: loss 1.492750\n",
      "batch 549: loss 1.422500\n",
      "batch 550: loss 1.305433\n",
      "batch 551: loss 1.363924\n",
      "batch 552: loss 1.340669\n",
      "batch 553: loss 1.470440\n",
      "batch 554: loss 1.245274\n",
      "batch 555: loss 1.420131\n",
      "batch 556: loss 1.275733\n",
      "batch 557: loss 1.510602\n",
      "batch 558: loss 1.380233\n",
      "batch 559: loss 1.294483\n",
      "batch 560: loss 1.502309\n",
      "batch 561: loss 1.323064\n",
      "batch 562: loss 1.456731\n",
      "batch 563: loss 1.326106\n",
      "batch 564: loss 1.334357\n",
      "batch 565: loss 1.448226\n",
      "batch 566: loss 1.327118\n",
      "batch 567: loss 1.286097\n",
      "batch 568: loss 1.284747\n",
      "batch 569: loss 1.287231\n",
      "batch 570: loss 1.379957\n",
      "batch 571: loss 1.418645\n",
      "batch 572: loss 1.378145\n",
      "batch 573: loss 1.422655\n",
      "batch 574: loss 1.372192\n",
      "batch 575: loss 1.463674\n",
      "batch 576: loss 1.248816\n",
      "batch 577: loss 1.325567\n",
      "batch 578: loss 1.221771\n",
      "batch 579: loss 1.464615\n",
      "batch 580: loss 1.340493\n",
      "batch 581: loss 1.320947\n",
      "batch 582: loss 1.287258\n",
      "batch 583: loss 1.444814\n",
      "batch 584: loss 1.406998\n",
      "batch 585: loss 1.262989\n",
      "batch 586: loss 1.349663\n",
      "batch 587: loss 1.473265\n",
      "batch 588: loss 1.389474\n",
      "batch 589: loss 1.426928\n",
      "batch 590: loss 1.249507\n",
      "batch 591: loss 1.293064\n",
      "batch 592: loss 1.300437\n",
      "batch 593: loss 1.328525\n",
      "batch 594: loss 1.295455\n",
      "batch 595: loss 1.217790\n",
      "batch 596: loss 1.346169\n",
      "batch 597: loss 1.370478\n",
      "batch 598: loss 1.220417\n",
      "batch 599: loss 1.325532\n",
      "batch 600: loss 1.270757\n",
      "batch 601: loss 1.364678\n",
      "batch 602: loss 1.304014\n",
      "batch 603: loss 1.375163\n",
      "batch 604: loss 1.324260\n",
      "batch 605: loss 1.230273\n",
      "batch 606: loss 1.319049\n",
      "batch 607: loss 1.254357\n",
      "batch 608: loss 1.295138\n",
      "batch 609: loss 1.290588\n",
      "batch 610: loss 1.217762\n",
      "batch 611: loss 1.263680\n",
      "batch 612: loss 1.335187\n",
      "batch 613: loss 1.357398\n",
      "batch 614: loss 1.364220\n",
      "batch 615: loss 1.358000\n",
      "batch 616: loss 1.294600\n",
      "batch 617: loss 1.449935\n",
      "batch 618: loss 1.247941\n",
      "batch 619: loss 1.386045\n",
      "batch 620: loss 1.209755\n",
      "batch 621: loss 1.246670\n",
      "batch 622: loss 1.356566\n",
      "batch 623: loss 1.251854\n",
      "batch 624: loss 1.383806\n",
      "batch 625: loss 1.229616\n",
      "batch 626: loss 1.317826\n",
      "batch 627: loss 1.281631\n",
      "batch 628: loss 1.337770\n",
      "batch 629: loss 1.329108\n",
      "batch 630: loss 1.236923\n",
      "batch 631: loss 1.295477\n",
      "batch 632: loss 1.219920\n",
      "batch 633: loss 1.200013\n",
      "batch 634: loss 1.391852\n",
      "batch 635: loss 1.210485\n",
      "batch 636: loss 1.260881\n",
      "batch 637: loss 1.253800\n",
      "batch 638: loss 1.222303\n",
      "batch 639: loss 1.210576\n",
      "batch 640: loss 1.228964\n",
      "batch 641: loss 1.306500\n",
      "batch 642: loss 1.265838\n",
      "batch 643: loss 1.294401\n",
      "batch 644: loss 1.140820\n",
      "batch 645: loss 1.263735\n",
      "batch 646: loss 1.409237\n",
      "batch 647: loss 1.227903\n",
      "batch 648: loss 1.222364\n",
      "batch 649: loss 1.228197\n",
      "batch 650: loss 1.381262\n",
      "batch 651: loss 1.189322\n",
      "batch 652: loss 1.155772\n",
      "batch 653: loss 1.321444\n",
      "batch 654: loss 1.121467\n",
      "batch 655: loss 1.393692\n",
      "batch 656: loss 1.286908\n",
      "batch 657: loss 1.271079\n",
      "batch 658: loss 1.286624\n",
      "batch 659: loss 1.182566\n",
      "batch 660: loss 1.262936\n",
      "batch 661: loss 1.210977\n",
      "batch 662: loss 1.229212\n",
      "batch 663: loss 1.322594\n",
      "batch 664: loss 1.315391\n",
      "batch 665: loss 1.247535\n",
      "batch 666: loss 1.303602\n",
      "batch 667: loss 1.216854\n",
      "batch 668: loss 1.121696\n",
      "batch 669: loss 1.290170\n",
      "batch 670: loss 1.176940\n",
      "batch 671: loss 1.282504\n",
      "batch 672: loss 1.029050\n",
      "batch 673: loss 1.152795\n",
      "batch 674: loss 1.219299\n",
      "batch 675: loss 1.132421\n",
      "batch 676: loss 1.145575\n",
      "batch 677: loss 1.178043\n",
      "batch 678: loss 1.135666\n",
      "batch 679: loss 1.418843\n",
      "batch 680: loss 1.050571\n",
      "batch 681: loss 1.205404\n",
      "batch 682: loss 1.042376\n",
      "batch 683: loss 1.140476\n",
      "batch 684: loss 1.220677\n",
      "batch 685: loss 1.210992\n",
      "batch 686: loss 1.059609\n",
      "batch 687: loss 1.118475\n",
      "batch 688: loss 1.241856\n",
      "batch 689: loss 1.048507\n",
      "batch 690: loss 1.051953\n",
      "batch 691: loss 1.163491\n",
      "batch 692: loss 1.100457\n",
      "batch 693: loss 1.178415\n",
      "batch 694: loss 1.300880\n",
      "batch 695: loss 0.993634\n",
      "batch 696: loss 1.191619\n",
      "batch 697: loss 1.215118\n",
      "batch 698: loss 1.163737\n",
      "batch 699: loss 1.147758\n",
      "batch 700: loss 1.330839\n",
      "batch 701: loss 1.038916\n",
      "batch 702: loss 1.216387\n",
      "batch 703: loss 1.155433\n",
      "batch 704: loss 1.222673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 705: loss 1.333263\n",
      "batch 706: loss 1.011966\n",
      "batch 707: loss 1.111473\n",
      "batch 708: loss 1.240898\n",
      "batch 709: loss 1.202002\n",
      "batch 710: loss 1.211281\n",
      "batch 711: loss 1.017386\n",
      "batch 712: loss 1.099118\n",
      "batch 713: loss 1.082567\n",
      "batch 714: loss 1.216051\n",
      "batch 715: loss 1.188115\n",
      "batch 716: loss 1.241982\n",
      "batch 717: loss 1.104452\n",
      "batch 718: loss 1.242048\n",
      "batch 719: loss 1.098869\n",
      "batch 720: loss 0.984577\n",
      "batch 721: loss 1.235808\n",
      "batch 722: loss 1.102329\n",
      "batch 723: loss 1.027271\n",
      "batch 724: loss 1.167986\n",
      "batch 725: loss 1.185712\n",
      "batch 726: loss 1.306799\n",
      "batch 727: loss 1.190672\n",
      "batch 728: loss 0.988073\n",
      "batch 729: loss 1.173586\n",
      "batch 730: loss 1.315361\n",
      "batch 731: loss 1.141990\n",
      "batch 732: loss 1.232649\n",
      "batch 733: loss 1.219970\n",
      "batch 734: loss 1.060838\n",
      "batch 735: loss 1.168921\n",
      "batch 736: loss 1.139076\n",
      "batch 737: loss 1.192413\n",
      "batch 738: loss 1.126483\n",
      "batch 739: loss 1.121278\n",
      "batch 740: loss 1.253220\n",
      "batch 741: loss 1.055990\n",
      "batch 742: loss 1.084806\n",
      "batch 743: loss 1.064524\n",
      "batch 744: loss 1.173006\n",
      "batch 745: loss 1.255105\n",
      "batch 746: loss 0.938788\n",
      "batch 747: loss 1.059872\n",
      "batch 748: loss 1.067990\n",
      "batch 749: loss 1.131143\n",
      "batch 750: loss 1.055703\n",
      "batch 751: loss 1.070066\n",
      "batch 752: loss 1.155079\n",
      "batch 753: loss 1.167375\n",
      "batch 754: loss 1.179931\n",
      "batch 755: loss 1.031636\n",
      "batch 756: loss 1.157348\n",
      "batch 757: loss 1.106809\n",
      "batch 758: loss 1.009238\n",
      "batch 759: loss 1.034582\n",
      "batch 760: loss 1.173329\n",
      "batch 761: loss 0.967551\n",
      "batch 762: loss 1.128438\n",
      "batch 763: loss 1.251789\n",
      "batch 764: loss 1.192741\n",
      "batch 765: loss 1.032622\n",
      "batch 766: loss 1.154055\n",
      "batch 767: loss 1.099908\n",
      "batch 768: loss 1.103292\n",
      "batch 769: loss 1.033710\n",
      "batch 770: loss 1.089397\n",
      "batch 771: loss 0.932939\n",
      "batch 772: loss 1.204309\n",
      "batch 773: loss 1.070695\n",
      "batch 774: loss 1.175826\n",
      "batch 775: loss 1.080096\n",
      "batch 776: loss 1.123170\n",
      "batch 777: loss 1.160505\n",
      "batch 778: loss 1.070434\n",
      "batch 779: loss 1.034486\n",
      "batch 780: loss 1.152254\n",
      "batch 781: loss 1.304729\n",
      "batch 782: loss 1.157891\n",
      "batch 783: loss 1.149496\n",
      "batch 784: loss 1.005693\n",
      "batch 785: loss 1.198586\n",
      "batch 786: loss 1.056000\n",
      "batch 787: loss 1.103813\n",
      "batch 788: loss 0.998730\n",
      "batch 789: loss 1.159879\n",
      "batch 790: loss 1.044050\n",
      "batch 791: loss 1.097968\n",
      "batch 792: loss 1.188713\n",
      "batch 793: loss 1.071765\n",
      "batch 794: loss 1.049261\n",
      "batch 795: loss 1.023428\n",
      "batch 796: loss 1.052488\n",
      "batch 797: loss 0.900397\n",
      "batch 798: loss 1.099589\n",
      "batch 799: loss 1.151710\n",
      "batch 800: loss 1.048903\n",
      "batch 801: loss 1.061856\n",
      "batch 802: loss 1.270488\n",
      "batch 803: loss 1.153919\n",
      "batch 804: loss 1.234602\n",
      "batch 805: loss 1.058509\n",
      "batch 806: loss 0.951527\n",
      "batch 807: loss 1.124088\n",
      "batch 808: loss 1.110724\n",
      "batch 809: loss 1.056221\n",
      "batch 810: loss 0.950154\n",
      "batch 811: loss 1.076002\n",
      "batch 812: loss 1.055454\n",
      "batch 813: loss 1.127750\n",
      "batch 814: loss 1.101526\n",
      "batch 815: loss 1.091223\n",
      "batch 816: loss 1.011716\n",
      "batch 817: loss 1.117773\n",
      "batch 818: loss 1.043074\n",
      "batch 819: loss 1.041218\n",
      "batch 820: loss 1.095518\n",
      "batch 821: loss 1.122877\n",
      "batch 822: loss 1.131686\n",
      "batch 823: loss 1.095626\n",
      "batch 824: loss 1.095200\n",
      "batch 825: loss 0.963422\n",
      "batch 826: loss 0.965864\n",
      "batch 827: loss 1.027575\n",
      "batch 828: loss 1.070574\n",
      "batch 829: loss 1.126298\n",
      "batch 830: loss 1.072088\n",
      "batch 831: loss 1.128950\n",
      "batch 832: loss 0.958354\n",
      "batch 833: loss 1.180103\n",
      "batch 834: loss 1.007743\n",
      "batch 835: loss 0.941165\n",
      "batch 836: loss 1.044451\n",
      "batch 837: loss 0.987678\n",
      "batch 838: loss 0.939491\n",
      "batch 839: loss 1.203047\n",
      "batch 840: loss 1.092342\n",
      "batch 841: loss 1.163583\n",
      "batch 842: loss 0.998264\n",
      "batch 843: loss 0.996116\n",
      "batch 844: loss 1.088629\n",
      "batch 845: loss 1.002480\n",
      "batch 846: loss 1.045117\n",
      "batch 847: loss 1.101288\n",
      "batch 848: loss 0.996909\n",
      "batch 849: loss 1.093500\n",
      "batch 850: loss 0.982113\n",
      "batch 851: loss 1.068653\n",
      "batch 852: loss 0.924191\n",
      "batch 853: loss 1.100595\n",
      "batch 854: loss 0.958846\n",
      "batch 855: loss 1.209790\n",
      "batch 856: loss 0.986223\n",
      "batch 857: loss 0.934916\n",
      "batch 858: loss 0.963366\n",
      "batch 859: loss 1.000335\n",
      "batch 860: loss 0.945054\n",
      "batch 861: loss 0.984515\n",
      "batch 862: loss 1.016665\n",
      "batch 863: loss 0.945905\n",
      "batch 864: loss 1.045305\n",
      "batch 865: loss 1.084919\n",
      "batch 866: loss 1.054767\n",
      "batch 867: loss 1.166673\n",
      "batch 868: loss 1.028033\n",
      "batch 869: loss 0.963994\n",
      "batch 870: loss 1.101023\n",
      "batch 871: loss 0.843343\n",
      "batch 872: loss 0.891673\n",
      "batch 873: loss 1.057842\n",
      "batch 874: loss 0.972772\n",
      "batch 875: loss 1.009962\n",
      "batch 876: loss 1.002385\n",
      "batch 877: loss 1.039313\n",
      "batch 878: loss 1.027124\n",
      "batch 879: loss 0.988447\n",
      "batch 880: loss 0.881152\n",
      "batch 881: loss 0.892399\n",
      "batch 882: loss 0.906588\n",
      "batch 883: loss 1.070179\n",
      "batch 884: loss 1.050056\n",
      "batch 885: loss 0.937952\n",
      "batch 886: loss 1.016741\n",
      "batch 887: loss 0.940331\n",
      "batch 888: loss 1.085461\n",
      "batch 889: loss 0.903305\n",
      "batch 890: loss 1.141193\n",
      "batch 891: loss 1.081134\n",
      "batch 892: loss 1.233665\n",
      "batch 893: loss 1.169018\n",
      "batch 894: loss 0.864590\n",
      "batch 895: loss 1.099681\n",
      "batch 896: loss 1.022065\n",
      "batch 897: loss 0.917709\n",
      "batch 898: loss 1.030257\n",
      "batch 899: loss 1.060898\n",
      "batch 900: loss 0.828493\n",
      "batch 901: loss 0.930977\n",
      "batch 902: loss 1.083999\n",
      "batch 903: loss 0.864034\n",
      "batch 904: loss 1.087378\n",
      "batch 905: loss 1.014561\n",
      "batch 906: loss 1.012399\n",
      "batch 907: loss 0.919102\n",
      "batch 908: loss 1.045235\n",
      "batch 909: loss 0.874102\n",
      "batch 910: loss 1.005029\n",
      "batch 911: loss 0.947627\n",
      "batch 912: loss 0.944022\n",
      "batch 913: loss 0.894303\n",
      "batch 914: loss 0.905759\n",
      "batch 915: loss 0.892581\n",
      "batch 916: loss 0.886743\n",
      "batch 917: loss 0.926854\n",
      "batch 918: loss 1.150727\n",
      "batch 919: loss 0.923424\n",
      "batch 920: loss 1.061254\n",
      "batch 921: loss 0.987280\n",
      "batch 922: loss 0.933441\n",
      "batch 923: loss 1.002677\n",
      "batch 924: loss 0.940688\n",
      "batch 925: loss 1.019179\n",
      "batch 926: loss 1.010832\n",
      "batch 927: loss 0.991300\n",
      "batch 928: loss 0.894785\n",
      "batch 929: loss 1.065358\n",
      "batch 930: loss 0.955145\n",
      "batch 931: loss 1.102668\n",
      "batch 932: loss 0.975031\n",
      "batch 933: loss 1.037655\n",
      "batch 934: loss 0.851937\n",
      "batch 935: loss 0.933311\n",
      "batch 936: loss 0.835414\n",
      "batch 937: loss 0.901702\n",
      "batch 938: loss 0.965971\n",
      "batch 939: loss 0.854569\n",
      "batch 940: loss 0.898245\n",
      "batch 941: loss 1.027803\n",
      "batch 942: loss 1.084354\n",
      "batch 943: loss 0.996419\n",
      "batch 944: loss 0.938364\n",
      "batch 945: loss 0.872654\n",
      "batch 946: loss 1.061875\n",
      "batch 947: loss 1.136147\n",
      "batch 948: loss 0.967620\n",
      "batch 949: loss 0.832698\n",
      "batch 950: loss 0.817500\n",
      "batch 951: loss 0.960274\n",
      "batch 952: loss 0.889685\n",
      "batch 953: loss 1.054119\n",
      "batch 954: loss 1.036537\n",
      "batch 955: loss 1.053132\n",
      "batch 956: loss 0.879880\n",
      "batch 957: loss 0.942194\n",
      "batch 958: loss 0.866932\n",
      "batch 959: loss 0.861354\n",
      "batch 960: loss 0.860384\n",
      "batch 961: loss 0.862209\n",
      "batch 962: loss 0.983099\n",
      "batch 963: loss 1.057406\n",
      "batch 964: loss 0.994023\n",
      "batch 965: loss 0.938107\n",
      "batch 966: loss 0.963322\n",
      "batch 967: loss 0.914766\n",
      "batch 968: loss 0.892189\n",
      "batch 969: loss 0.800192\n",
      "batch 970: loss 0.884978\n",
      "batch 971: loss 0.971871\n",
      "batch 972: loss 0.851119\n",
      "batch 973: loss 1.059087\n",
      "batch 974: loss 0.849932\n",
      "batch 975: loss 1.037105\n",
      "batch 976: loss 0.836891\n",
      "batch 977: loss 0.968790\n",
      "batch 978: loss 0.882212\n",
      "batch 979: loss 0.895050\n",
      "batch 980: loss 1.010273\n",
      "batch 981: loss 1.054073\n",
      "batch 982: loss 0.941429\n",
      "batch 983: loss 0.935096\n",
      "batch 984: loss 1.024065\n",
      "batch 985: loss 0.984428\n",
      "batch 986: loss 0.991325\n",
      "batch 987: loss 0.877486\n",
      "batch 988: loss 0.957686\n",
      "batch 989: loss 0.864953\n",
      "batch 990: loss 0.846414\n",
      "batch 991: loss 0.873169\n",
      "batch 992: loss 0.901182\n",
      "batch 993: loss 0.831365\n",
      "batch 994: loss 0.903918\n",
      "batch 995: loss 0.974481\n",
      "batch 996: loss 0.871217\n",
      "batch 997: loss 0.944435\n",
      "batch 998: loss 0.899929\n",
      "batch 999: loss 0.954480\n",
      "batch 1000: loss 0.931370\n",
      "batch 1001: loss 1.026599\n",
      "batch 1002: loss 0.843555\n",
      "batch 1003: loss 0.967624\n",
      "batch 1004: loss 1.000165\n",
      "batch 1005: loss 0.927822\n",
      "batch 1006: loss 0.914881\n",
      "batch 1007: loss 1.005169\n",
      "batch 1008: loss 0.940766\n",
      "batch 1009: loss 0.988752\n",
      "batch 1010: loss 1.058266\n",
      "batch 1011: loss 0.889344\n",
      "batch 1012: loss 0.856342\n",
      "batch 1013: loss 0.912113\n",
      "batch 1014: loss 0.887606\n",
      "batch 1015: loss 0.904618\n",
      "batch 1016: loss 0.935651\n",
      "batch 1017: loss 0.839005\n",
      "batch 1018: loss 0.779247\n",
      "batch 1019: loss 0.854819\n",
      "batch 1020: loss 0.817232\n",
      "batch 1021: loss 0.896521\n",
      "batch 1022: loss 0.727565\n",
      "batch 1023: loss 0.951091\n",
      "batch 1024: loss 0.934408\n",
      "batch 1025: loss 1.023020\n",
      "batch 1026: loss 0.923270\n",
      "batch 1027: loss 0.885406\n",
      "batch 1028: loss 0.711647\n",
      "batch 1029: loss 0.934384\n",
      "batch 1030: loss 0.919239\n",
      "batch 1031: loss 0.861711\n",
      "batch 1032: loss 0.990120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1033: loss 0.831840\n",
      "batch 1034: loss 0.767424\n",
      "batch 1035: loss 0.961367\n",
      "batch 1036: loss 0.948125\n",
      "batch 1037: loss 0.905473\n",
      "batch 1038: loss 0.971881\n",
      "batch 1039: loss 1.075371\n",
      "batch 1040: loss 0.913106\n",
      "batch 1041: loss 1.051556\n",
      "batch 1042: loss 0.714222\n",
      "batch 1043: loss 0.941194\n",
      "batch 1044: loss 0.868017\n",
      "batch 1045: loss 1.100184\n",
      "batch 1046: loss 0.821141\n",
      "batch 1047: loss 0.805836\n",
      "batch 1048: loss 0.933046\n",
      "batch 1049: loss 0.759255\n",
      "batch 1050: loss 0.881292\n",
      "batch 1051: loss 0.923828\n",
      "batch 1052: loss 0.917137\n",
      "batch 1053: loss 1.048269\n",
      "batch 1054: loss 0.947781\n",
      "batch 1055: loss 0.871568\n",
      "batch 1056: loss 0.932856\n",
      "batch 1057: loss 0.759362\n",
      "batch 1058: loss 0.807490\n",
      "batch 1059: loss 1.081104\n",
      "batch 1060: loss 0.953873\n",
      "batch 1061: loss 0.895893\n",
      "batch 1062: loss 0.913785\n",
      "batch 1063: loss 0.974323\n",
      "batch 1064: loss 0.849247\n",
      "batch 1065: loss 0.689231\n",
      "batch 1066: loss 0.840766\n",
      "batch 1067: loss 0.980692\n",
      "batch 1068: loss 0.762761\n",
      "batch 1069: loss 0.904833\n",
      "batch 1070: loss 0.868546\n",
      "batch 1071: loss 1.093278\n",
      "batch 1072: loss 0.921466\n",
      "batch 1073: loss 0.829725\n",
      "batch 1074: loss 0.730268\n",
      "batch 1075: loss 0.845345\n",
      "batch 1076: loss 0.964986\n",
      "batch 1077: loss 0.784783\n",
      "batch 1078: loss 0.775154\n",
      "batch 1079: loss 0.813443\n",
      "batch 1080: loss 0.832850\n",
      "batch 1081: loss 0.824455\n",
      "batch 1082: loss 0.892865\n",
      "batch 1083: loss 0.839316\n",
      "batch 1084: loss 0.932856\n",
      "batch 1085: loss 0.911451\n",
      "batch 1086: loss 0.807554\n",
      "batch 1087: loss 0.868244\n",
      "batch 1088: loss 0.800460\n",
      "batch 1089: loss 0.864080\n",
      "batch 1090: loss 0.787225\n",
      "batch 1091: loss 1.023411\n",
      "batch 1092: loss 1.023504\n",
      "batch 1093: loss 0.897523\n",
      "batch 1094: loss 0.768811\n",
      "batch 1095: loss 0.948969\n",
      "batch 1096: loss 0.734913\n",
      "batch 1097: loss 0.985100\n",
      "batch 1098: loss 0.870506\n",
      "batch 1099: loss 0.801249\n",
      "batch 1100: loss 0.677574\n",
      "batch 1101: loss 0.695581\n",
      "batch 1102: loss 0.804159\n",
      "batch 1103: loss 0.792318\n",
      "batch 1104: loss 0.928931\n",
      "batch 1105: loss 0.839155\n",
      "batch 1106: loss 0.774614\n",
      "batch 1107: loss 0.842474\n",
      "batch 1108: loss 0.927102\n",
      "batch 1109: loss 0.919533\n",
      "batch 1110: loss 0.971508\n",
      "batch 1111: loss 0.857047\n",
      "batch 1112: loss 0.715298\n",
      "batch 1113: loss 0.923569\n",
      "batch 1114: loss 0.860838\n",
      "batch 1115: loss 0.955013\n",
      "batch 1116: loss 0.776478\n",
      "batch 1117: loss 0.998156\n",
      "batch 1118: loss 0.954325\n",
      "batch 1119: loss 0.663173\n",
      "batch 1120: loss 0.756156\n",
      "batch 1121: loss 0.853678\n",
      "batch 1122: loss 1.108283\n",
      "batch 1123: loss 0.820051\n",
      "batch 1124: loss 0.938818\n",
      "batch 1125: loss 0.772651\n",
      "batch 1126: loss 0.906076\n",
      "batch 1127: loss 1.014603\n",
      "batch 1128: loss 0.838377\n",
      "batch 1129: loss 0.826121\n",
      "batch 1130: loss 0.834540\n",
      "batch 1131: loss 0.785086\n",
      "batch 1132: loss 0.955234\n",
      "batch 1133: loss 0.899646\n",
      "batch 1134: loss 0.846820\n",
      "batch 1135: loss 0.877841\n",
      "batch 1136: loss 0.633461\n",
      "batch 1137: loss 0.907889\n",
      "batch 1138: loss 0.831613\n",
      "batch 1139: loss 1.028021\n",
      "batch 1140: loss 0.790483\n",
      "batch 1141: loss 0.900968\n",
      "batch 1142: loss 0.929182\n",
      "batch 1143: loss 0.729637\n",
      "batch 1144: loss 0.752106\n",
      "batch 1145: loss 0.988206\n",
      "batch 1146: loss 0.825074\n",
      "batch 1147: loss 0.876074\n",
      "batch 1148: loss 0.944388\n",
      "batch 1149: loss 0.804237\n",
      "batch 1150: loss 0.684171\n",
      "batch 1151: loss 1.026286\n",
      "batch 1152: loss 0.928664\n",
      "batch 1153: loss 0.816931\n",
      "batch 1154: loss 0.702451\n",
      "batch 1155: loss 0.914692\n",
      "batch 1156: loss 0.991289\n",
      "batch 1157: loss 0.681914\n",
      "batch 1158: loss 0.769435\n",
      "batch 1159: loss 0.917714\n",
      "batch 1160: loss 0.708433\n",
      "batch 1161: loss 0.834107\n",
      "batch 1162: loss 0.807564\n",
      "batch 1163: loss 0.740392\n",
      "batch 1164: loss 0.916796\n",
      "batch 1165: loss 0.815181\n",
      "batch 1166: loss 0.856720\n",
      "batch 1167: loss 0.851952\n",
      "batch 1168: loss 0.934372\n",
      "batch 1169: loss 0.815307\n",
      "batch 1170: loss 0.687799\n",
      "batch 1171: loss 0.992290\n",
      "batch 1172: loss 0.739878\n",
      "batch 1173: loss 0.936445\n",
      "batch 1174: loss 0.899644\n",
      "batch 1175: loss 0.759476\n",
      "batch 1176: loss 0.671834\n",
      "batch 1177: loss 0.693940\n",
      "batch 1178: loss 0.687379\n",
      "batch 1179: loss 0.862410\n",
      "batch 1180: loss 0.901209\n",
      "batch 1181: loss 0.936212\n",
      "batch 1182: loss 0.702681\n",
      "batch 1183: loss 0.775944\n",
      "batch 1184: loss 0.873098\n",
      "batch 1185: loss 0.842898\n",
      "batch 1186: loss 0.893979\n",
      "batch 1187: loss 0.848128\n",
      "batch 1188: loss 0.875226\n",
      "batch 1189: loss 0.779267\n",
      "batch 1190: loss 0.850153\n",
      "batch 1191: loss 0.963171\n",
      "batch 1192: loss 0.769285\n",
      "batch 1193: loss 1.070745\n",
      "batch 1194: loss 0.879183\n",
      "batch 1195: loss 0.853615\n",
      "batch 1196: loss 0.864867\n",
      "batch 1197: loss 0.910488\n",
      "batch 1198: loss 0.682664\n",
      "batch 1199: loss 0.820415\n",
      "batch 1200: loss 0.901978\n",
      "batch 1201: loss 0.801300\n",
      "batch 1202: loss 0.766126\n",
      "batch 1203: loss 1.081723\n",
      "batch 1204: loss 0.773640\n",
      "batch 1205: loss 0.968216\n",
      "batch 1206: loss 0.779563\n",
      "batch 1207: loss 0.754347\n",
      "batch 1208: loss 0.944159\n",
      "batch 1209: loss 0.743490\n",
      "batch 1210: loss 0.840737\n",
      "batch 1211: loss 0.864794\n",
      "batch 1212: loss 0.892157\n",
      "batch 1213: loss 0.895470\n",
      "batch 1214: loss 0.603432\n",
      "batch 1215: loss 0.809470\n",
      "batch 1216: loss 0.724886\n",
      "batch 1217: loss 0.600321\n",
      "batch 1218: loss 0.599997\n",
      "batch 1219: loss 1.013405\n",
      "batch 1220: loss 0.829650\n",
      "batch 1221: loss 0.877114\n",
      "batch 1222: loss 0.971091\n",
      "batch 1223: loss 0.879706\n",
      "batch 1224: loss 0.797133\n",
      "batch 1225: loss 0.906461\n",
      "batch 1226: loss 0.778944\n",
      "batch 1227: loss 0.736022\n",
      "batch 1228: loss 0.940945\n",
      "batch 1229: loss 0.831214\n",
      "batch 1230: loss 0.786674\n",
      "batch 1231: loss 0.805612\n",
      "batch 1232: loss 0.656222\n",
      "batch 1233: loss 0.894483\n",
      "batch 1234: loss 0.815400\n",
      "batch 1235: loss 0.839061\n",
      "batch 1236: loss 0.870696\n",
      "batch 1237: loss 0.755954\n",
      "batch 1238: loss 0.864035\n",
      "batch 1239: loss 0.861158\n",
      "batch 1240: loss 0.742908\n",
      "batch 1241: loss 0.749729\n",
      "batch 1242: loss 1.030850\n",
      "batch 1243: loss 0.737161\n",
      "batch 1244: loss 0.719940\n",
      "batch 1245: loss 0.847032\n",
      "batch 1246: loss 0.662400\n",
      "batch 1247: loss 0.756822\n",
      "batch 1248: loss 0.696568\n",
      "batch 1249: loss 0.782670\n",
      "batch 1250: loss 0.805205\n",
      "batch 1251: loss 0.738606\n",
      "batch 1252: loss 0.778237\n",
      "batch 1253: loss 0.652450\n",
      "batch 1254: loss 0.746863\n",
      "batch 1255: loss 0.833072\n",
      "batch 1256: loss 0.657098\n",
      "batch 1257: loss 0.740703\n",
      "batch 1258: loss 0.819265\n",
      "batch 1259: loss 0.800876\n",
      "batch 1260: loss 0.656904\n",
      "batch 1261: loss 0.655820\n",
      "batch 1262: loss 0.870860\n",
      "batch 1263: loss 0.872721\n",
      "batch 1264: loss 0.766926\n",
      "batch 1265: loss 0.731370\n",
      "batch 1266: loss 0.848097\n",
      "batch 1267: loss 0.925348\n",
      "batch 1268: loss 0.780573\n",
      "batch 1269: loss 0.815920\n",
      "batch 1270: loss 0.761837\n",
      "batch 1271: loss 0.786233\n",
      "batch 1272: loss 0.764200\n",
      "batch 1273: loss 0.761213\n",
      "batch 1274: loss 0.680851\n",
      "batch 1275: loss 0.729485\n",
      "batch 1276: loss 0.891694\n",
      "batch 1277: loss 0.732988\n",
      "batch 1278: loss 0.815520\n",
      "batch 1279: loss 0.890793\n",
      "batch 1280: loss 0.765515\n",
      "batch 1281: loss 0.881021\n",
      "batch 1282: loss 0.716042\n",
      "batch 1283: loss 0.646717\n",
      "batch 1284: loss 0.912510\n",
      "batch 1285: loss 0.852937\n",
      "batch 1286: loss 0.819198\n",
      "batch 1287: loss 0.777287\n",
      "batch 1288: loss 0.798391\n",
      "batch 1289: loss 0.734753\n",
      "batch 1290: loss 0.829313\n",
      "batch 1291: loss 0.932441\n",
      "batch 1292: loss 0.794460\n",
      "batch 1293: loss 0.720135\n",
      "batch 1294: loss 0.784072\n",
      "batch 1295: loss 0.745106\n",
      "batch 1296: loss 0.744269\n",
      "batch 1297: loss 0.815736\n",
      "batch 1298: loss 0.782819\n",
      "batch 1299: loss 0.728798\n",
      "batch 1300: loss 0.805700\n",
      "batch 1301: loss 0.761347\n",
      "batch 1302: loss 0.956574\n",
      "batch 1303: loss 0.725022\n",
      "batch 1304: loss 0.786596\n",
      "batch 1305: loss 0.707161\n",
      "batch 1306: loss 0.785033\n",
      "batch 1307: loss 0.698955\n",
      "batch 1308: loss 0.818983\n",
      "batch 1309: loss 0.878811\n",
      "batch 1310: loss 0.692291\n",
      "batch 1311: loss 0.788717\n",
      "batch 1312: loss 0.717014\n",
      "batch 1313: loss 0.858313\n",
      "batch 1314: loss 0.667918\n",
      "batch 1315: loss 0.749662\n",
      "batch 1316: loss 0.563061\n",
      "batch 1317: loss 0.737283\n",
      "batch 1318: loss 0.803277\n",
      "batch 1319: loss 0.775589\n",
      "batch 1320: loss 0.818188\n",
      "batch 1321: loss 0.974721\n",
      "batch 1322: loss 0.622631\n",
      "batch 1323: loss 0.780906\n",
      "batch 1324: loss 0.867207\n",
      "batch 1325: loss 0.694001\n",
      "batch 1326: loss 0.773701\n",
      "batch 1327: loss 0.931851\n",
      "batch 1328: loss 0.692859\n",
      "batch 1329: loss 0.763308\n",
      "batch 1330: loss 0.839130\n",
      "batch 1331: loss 0.776293\n",
      "batch 1332: loss 0.869695\n",
      "batch 1333: loss 0.699263\n",
      "batch 1334: loss 0.733400\n",
      "batch 1335: loss 0.865866\n",
      "batch 1336: loss 0.668984\n",
      "batch 1337: loss 0.788816\n",
      "batch 1338: loss 0.754917\n",
      "batch 1339: loss 0.752458\n",
      "batch 1340: loss 0.625653\n",
      "batch 1341: loss 0.694643\n",
      "batch 1342: loss 0.974410\n",
      "batch 1343: loss 0.657285\n",
      "batch 1344: loss 0.667825\n",
      "batch 1345: loss 0.850007\n",
      "batch 1346: loss 0.632789\n",
      "batch 1347: loss 0.735165\n",
      "batch 1348: loss 0.673902\n",
      "batch 1349: loss 0.700382\n",
      "batch 1350: loss 0.571293\n",
      "batch 1351: loss 0.934753\n",
      "batch 1352: loss 0.587453\n",
      "batch 1353: loss 0.721278\n",
      "batch 1354: loss 0.673700\n",
      "batch 1355: loss 0.794338\n",
      "batch 1356: loss 0.870519\n",
      "batch 1357: loss 0.859286\n",
      "batch 1358: loss 0.749587\n",
      "batch 1359: loss 0.871259\n",
      "batch 1360: loss 0.718934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1361: loss 0.773775\n",
      "batch 1362: loss 0.795786\n",
      "batch 1363: loss 0.663745\n",
      "batch 1364: loss 0.720703\n",
      "batch 1365: loss 0.787121\n",
      "batch 1366: loss 0.588778\n",
      "batch 1367: loss 0.713757\n",
      "batch 1368: loss 0.872246\n",
      "batch 1369: loss 0.697384\n",
      "batch 1370: loss 0.673451\n",
      "batch 1371: loss 0.749426\n",
      "batch 1372: loss 0.670511\n",
      "batch 1373: loss 0.732898\n",
      "batch 1374: loss 0.828451\n",
      "batch 1375: loss 0.817398\n",
      "batch 1376: loss 0.659277\n",
      "batch 1377: loss 0.737702\n",
      "batch 1378: loss 0.756464\n",
      "batch 1379: loss 0.796043\n",
      "batch 1380: loss 0.684382\n",
      "batch 1381: loss 0.761843\n",
      "batch 1382: loss 0.584192\n",
      "batch 1383: loss 0.756992\n",
      "batch 1384: loss 0.699701\n",
      "batch 1385: loss 0.794403\n",
      "batch 1386: loss 0.771210\n",
      "batch 1387: loss 0.745555\n",
      "batch 1388: loss 0.708693\n",
      "batch 1389: loss 0.686615\n",
      "batch 1390: loss 0.687541\n",
      "batch 1391: loss 0.888250\n",
      "batch 1392: loss 0.627398\n",
      "batch 1393: loss 0.858360\n",
      "batch 1394: loss 0.610797\n",
      "batch 1395: loss 0.702154\n",
      "batch 1396: loss 0.702658\n",
      "batch 1397: loss 0.752253\n",
      "batch 1398: loss 0.804651\n",
      "batch 1399: loss 0.720205\n",
      "batch 1400: loss 0.780021\n",
      "batch 1401: loss 0.698085\n",
      "batch 1402: loss 0.859435\n",
      "batch 1403: loss 0.699053\n",
      "batch 1404: loss 0.719688\n",
      "batch 1405: loss 0.698469\n",
      "batch 1406: loss 0.845355\n",
      "batch 1407: loss 0.724046\n",
      "batch 1408: loss 0.715245\n",
      "batch 1409: loss 0.727967\n",
      "batch 1410: loss 0.671249\n",
      "batch 1411: loss 0.706301\n",
      "batch 1412: loss 0.799636\n",
      "batch 1413: loss 0.920540\n",
      "batch 1414: loss 0.747339\n",
      "batch 1415: loss 0.847222\n",
      "batch 1416: loss 0.602051\n",
      "batch 1417: loss 0.676906\n",
      "batch 1418: loss 0.679855\n",
      "batch 1419: loss 0.714155\n",
      "batch 1420: loss 0.738162\n",
      "batch 1421: loss 0.706178\n",
      "batch 1422: loss 0.736971\n",
      "batch 1423: loss 0.726755\n",
      "batch 1424: loss 0.704849\n",
      "batch 1425: loss 0.538835\n",
      "batch 1426: loss 0.580383\n",
      "batch 1427: loss 0.736129\n",
      "batch 1428: loss 0.853618\n",
      "batch 1429: loss 0.547477\n",
      "batch 1430: loss 0.849350\n",
      "batch 1431: loss 0.689723\n",
      "batch 1432: loss 0.586115\n",
      "batch 1433: loss 0.635308\n",
      "batch 1434: loss 0.766446\n",
      "batch 1435: loss 0.707535\n",
      "batch 1436: loss 0.678591\n",
      "batch 1437: loss 0.881337\n",
      "batch 1438: loss 0.671274\n",
      "batch 1439: loss 0.801056\n",
      "batch 1440: loss 0.536818\n",
      "batch 1441: loss 0.694759\n",
      "batch 1442: loss 0.721270\n",
      "batch 1443: loss 0.764012\n",
      "batch 1444: loss 0.701939\n",
      "batch 1445: loss 0.866194\n",
      "batch 1446: loss 0.690956\n",
      "batch 1447: loss 0.790595\n",
      "batch 1448: loss 0.589891\n",
      "batch 1449: loss 0.616117\n",
      "batch 1450: loss 0.725576\n",
      "batch 1451: loss 0.718102\n",
      "batch 1452: loss 0.692806\n",
      "batch 1453: loss 0.724899\n",
      "batch 1454: loss 0.617723\n",
      "batch 1455: loss 0.580280\n",
      "batch 1456: loss 0.763897\n",
      "batch 1457: loss 0.554526\n",
      "batch 1458: loss 0.936736\n",
      "batch 1459: loss 0.718362\n",
      "batch 1460: loss 0.564991\n",
      "batch 1461: loss 0.595874\n",
      "batch 1462: loss 0.538644\n",
      "batch 1463: loss 0.776373\n",
      "batch 1464: loss 0.700066\n",
      "batch 1465: loss 0.600841\n",
      "batch 1466: loss 0.645748\n",
      "batch 1467: loss 0.874437\n",
      "batch 1468: loss 0.577187\n",
      "batch 1469: loss 0.717574\n",
      "batch 1470: loss 0.639603\n",
      "batch 1471: loss 0.566026\n",
      "batch 1472: loss 0.628684\n",
      "batch 1473: loss 0.606610\n",
      "batch 1474: loss 0.701829\n",
      "batch 1475: loss 0.612369\n",
      "batch 1476: loss 0.620379\n",
      "batch 1477: loss 0.936604\n",
      "batch 1478: loss 0.873130\n",
      "batch 1479: loss 0.593579\n",
      "batch 1480: loss 0.631206\n",
      "batch 1481: loss 0.664272\n",
      "batch 1482: loss 0.730446\n",
      "batch 1483: loss 0.854810\n",
      "batch 1484: loss 0.780450\n",
      "batch 1485: loss 0.797748\n",
      "batch 1486: loss 0.651435\n",
      "batch 1487: loss 0.653957\n",
      "batch 1488: loss 0.630097\n",
      "batch 1489: loss 0.714681\n",
      "batch 1490: loss 0.689319\n",
      "batch 1491: loss 0.507694\n",
      "batch 1492: loss 0.876382\n",
      "batch 1493: loss 0.589606\n",
      "batch 1494: loss 0.798772\n",
      "batch 1495: loss 0.541193\n",
      "batch 1496: loss 0.808899\n",
      "batch 1497: loss 0.552189\n",
      "batch 1498: loss 0.717167\n",
      "batch 1499: loss 0.784638\n",
      "batch 1500: loss 0.833955\n",
      "batch 1501: loss 0.690379\n",
      "batch 1502: loss 0.628112\n",
      "batch 1503: loss 0.556541\n",
      "batch 1504: loss 0.664028\n",
      "batch 1505: loss 0.733640\n",
      "batch 1506: loss 0.627795\n",
      "batch 1507: loss 0.561012\n",
      "batch 1508: loss 0.662876\n",
      "batch 1509: loss 0.711570\n",
      "batch 1510: loss 0.654864\n",
      "batch 1511: loss 0.642474\n",
      "batch 1512: loss 0.960393\n",
      "batch 1513: loss 0.762647\n",
      "batch 1514: loss 0.617768\n",
      "batch 1515: loss 0.809355\n",
      "batch 1516: loss 0.610912\n",
      "batch 1517: loss 0.615412\n",
      "batch 1518: loss 0.659273\n",
      "batch 1519: loss 0.729503\n",
      "batch 1520: loss 0.670572\n",
      "batch 1521: loss 0.430270\n",
      "batch 1522: loss 0.684270\n",
      "batch 1523: loss 0.699518\n",
      "batch 1524: loss 0.696800\n",
      "batch 1525: loss 0.704843\n",
      "batch 1526: loss 0.646760\n",
      "batch 1527: loss 0.628526\n",
      "batch 1528: loss 0.577749\n",
      "batch 1529: loss 0.684552\n",
      "batch 1530: loss 0.480701\n",
      "batch 1531: loss 0.712939\n",
      "batch 1532: loss 0.747157\n",
      "batch 1533: loss 0.688984\n",
      "batch 1534: loss 0.827632\n",
      "batch 1535: loss 0.739895\n",
      "batch 1536: loss 0.833435\n",
      "batch 1537: loss 0.741910\n",
      "batch 1538: loss 0.885233\n",
      "batch 1539: loss 0.642802\n",
      "batch 1540: loss 0.808840\n",
      "batch 1541: loss 0.713222\n",
      "batch 1542: loss 0.716523\n",
      "batch 1543: loss 0.666866\n",
      "batch 1544: loss 0.571612\n",
      "batch 1545: loss 0.481420\n",
      "batch 1546: loss 0.791327\n",
      "batch 1547: loss 0.716046\n",
      "batch 1548: loss 0.676051\n",
      "batch 1549: loss 0.567685\n",
      "batch 1550: loss 0.673158\n",
      "batch 1551: loss 0.871961\n",
      "batch 1552: loss 0.589210\n",
      "batch 1553: loss 0.700402\n",
      "batch 1554: loss 0.782159\n",
      "batch 1555: loss 0.650530\n",
      "batch 1556: loss 0.757063\n",
      "batch 1557: loss 0.846770\n",
      "batch 1558: loss 0.725132\n",
      "batch 1559: loss 0.746197\n",
      "batch 1560: loss 0.703036\n",
      "batch 1561: loss 0.653623\n",
      "batch 1562: loss 0.612170\n",
      "batch 1563: loss 0.550974\n",
      "batch 1564: loss 0.544280\n",
      "batch 1565: loss 0.570486\n",
      "batch 1566: loss 0.770759\n",
      "batch 1567: loss 0.721133\n",
      "batch 1568: loss 0.616671\n",
      "batch 1569: loss 0.750985\n",
      "batch 1570: loss 0.556599\n",
      "batch 1571: loss 0.796702\n",
      "batch 1572: loss 0.684391\n",
      "batch 1573: loss 0.732165\n",
      "batch 1574: loss 0.670911\n",
      "batch 1575: loss 0.665647\n",
      "batch 1576: loss 0.671711\n",
      "batch 1577: loss 0.538302\n",
      "batch 1578: loss 0.625978\n",
      "batch 1579: loss 0.633962\n",
      "batch 1580: loss 0.704148\n",
      "batch 1581: loss 0.640540\n",
      "batch 1582: loss 0.565463\n",
      "batch 1583: loss 0.699757\n",
      "batch 1584: loss 0.543264\n",
      "batch 1585: loss 0.503273\n",
      "batch 1586: loss 0.605059\n",
      "batch 1587: loss 0.577612\n",
      "batch 1588: loss 0.608529\n",
      "batch 1589: loss 0.758791\n",
      "batch 1590: loss 0.612592\n",
      "batch 1591: loss 0.802017\n",
      "batch 1592: loss 0.962746\n",
      "batch 1593: loss 0.729266\n",
      "batch 1594: loss 0.723114\n",
      "batch 1595: loss 0.601196\n",
      "batch 1596: loss 0.516954\n",
      "batch 1597: loss 0.651367\n",
      "batch 1598: loss 0.552464\n",
      "batch 1599: loss 0.683748\n",
      "batch 1600: loss 0.842463\n",
      "batch 1601: loss 0.611452\n",
      "batch 1602: loss 0.737885\n",
      "batch 1603: loss 0.655316\n",
      "batch 1604: loss 0.624194\n",
      "batch 1605: loss 0.525525\n",
      "batch 1606: loss 0.631065\n",
      "batch 1607: loss 0.733024\n",
      "batch 1608: loss 0.722846\n",
      "batch 1609: loss 0.797445\n",
      "batch 1610: loss 0.624036\n",
      "batch 1611: loss 0.744517\n",
      "batch 1612: loss 0.656198\n",
      "batch 1613: loss 0.639187\n",
      "batch 1614: loss 0.526587\n",
      "batch 1615: loss 0.563082\n",
      "batch 1616: loss 0.665594\n",
      "batch 1617: loss 0.634503\n",
      "batch 1618: loss 0.714227\n",
      "batch 1619: loss 0.699006\n",
      "batch 1620: loss 0.598098\n",
      "batch 1621: loss 0.664929\n",
      "batch 1622: loss 0.807257\n",
      "batch 1623: loss 0.758557\n",
      "batch 1624: loss 0.731214\n",
      "batch 1625: loss 0.574846\n",
      "batch 1626: loss 0.605818\n",
      "batch 1627: loss 0.588562\n",
      "batch 1628: loss 0.624428\n",
      "batch 1629: loss 0.656741\n",
      "batch 1630: loss 0.555845\n",
      "batch 1631: loss 0.740797\n",
      "batch 1632: loss 0.704281\n",
      "batch 1633: loss 0.825557\n",
      "batch 1634: loss 0.503141\n",
      "batch 1635: loss 0.529652\n",
      "batch 1636: loss 0.825949\n",
      "batch 1637: loss 0.694706\n",
      "batch 1638: loss 0.648042\n",
      "batch 1639: loss 0.735728\n",
      "batch 1640: loss 0.698522\n",
      "batch 1641: loss 0.860338\n",
      "batch 1642: loss 0.617682\n",
      "batch 1643: loss 0.598976\n",
      "batch 1644: loss 0.575887\n",
      "batch 1645: loss 0.550216\n",
      "batch 1646: loss 0.757592\n",
      "batch 1647: loss 0.691899\n",
      "batch 1648: loss 0.432298\n",
      "batch 1649: loss 0.853351\n",
      "batch 1650: loss 0.642426\n",
      "batch 1651: loss 0.736836\n",
      "batch 1652: loss 0.638852\n",
      "batch 1653: loss 0.544708\n",
      "batch 1654: loss 0.565680\n",
      "batch 1655: loss 0.619198\n",
      "batch 1656: loss 0.637472\n",
      "batch 1657: loss 0.765414\n",
      "batch 1658: loss 0.650606\n",
      "batch 1659: loss 0.711283\n",
      "batch 1660: loss 0.566451\n",
      "batch 1661: loss 0.765917\n",
      "batch 1662: loss 0.614581\n",
      "batch 1663: loss 0.544763\n",
      "batch 1664: loss 0.671985\n",
      "batch 1665: loss 0.737000\n",
      "batch 1666: loss 0.571181\n",
      "batch 1667: loss 0.605159\n",
      "batch 1668: loss 0.542512\n",
      "batch 1669: loss 0.517010\n",
      "batch 1670: loss 0.591071\n",
      "batch 1671: loss 0.686955\n",
      "batch 1672: loss 0.789576\n",
      "batch 1673: loss 0.553161\n",
      "batch 1674: loss 0.512060\n",
      "batch 1675: loss 0.649169\n",
      "batch 1676: loss 0.434372\n",
      "batch 1677: loss 0.560966\n",
      "batch 1678: loss 0.640229\n",
      "batch 1679: loss 0.607708\n",
      "batch 1680: loss 0.720103\n",
      "batch 1681: loss 0.798139\n",
      "batch 1682: loss 0.732847\n",
      "batch 1683: loss 0.569942\n",
      "batch 1684: loss 0.779700\n",
      "batch 1685: loss 0.733501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1686: loss 0.673718\n",
      "batch 1687: loss 0.723272\n",
      "batch 1688: loss 0.596640\n",
      "batch 1689: loss 0.721145\n",
      "batch 1690: loss 0.693980\n",
      "batch 1691: loss 0.576328\n",
      "batch 1692: loss 0.635451\n",
      "batch 1693: loss 0.588928\n",
      "batch 1694: loss 0.512404\n",
      "batch 1695: loss 0.603119\n",
      "batch 1696: loss 0.659031\n",
      "batch 1697: loss 0.552516\n",
      "batch 1698: loss 0.661104\n",
      "batch 1699: loss 0.601540\n",
      "batch 1700: loss 0.634861\n",
      "batch 1701: loss 0.650063\n",
      "batch 1702: loss 0.611244\n",
      "batch 1703: loss 0.722503\n",
      "batch 1704: loss 0.611506\n",
      "batch 1705: loss 0.695285\n",
      "batch 1706: loss 0.629851\n",
      "batch 1707: loss 0.540928\n",
      "batch 1708: loss 0.582751\n",
      "batch 1709: loss 0.590519\n",
      "batch 1710: loss 0.579311\n",
      "batch 1711: loss 0.727693\n",
      "batch 1712: loss 0.391562\n",
      "batch 1713: loss 0.696238\n",
      "batch 1714: loss 0.703602\n",
      "batch 1715: loss 0.540105\n",
      "batch 1716: loss 0.679134\n",
      "batch 1717: loss 0.912626\n",
      "batch 1718: loss 0.541583\n",
      "batch 1719: loss 0.779008\n",
      "batch 1720: loss 0.613407\n",
      "batch 1721: loss 0.608746\n",
      "batch 1722: loss 0.607622\n",
      "batch 1723: loss 0.529223\n",
      "batch 1724: loss 0.491174\n",
      "batch 1725: loss 0.634747\n",
      "batch 1726: loss 0.623017\n",
      "batch 1727: loss 0.799510\n",
      "batch 1728: loss 0.701119\n",
      "batch 1729: loss 0.567228\n",
      "batch 1730: loss 0.498178\n",
      "batch 1731: loss 0.636754\n",
      "batch 1732: loss 0.760455\n",
      "batch 1733: loss 0.480219\n",
      "batch 1734: loss 0.509418\n",
      "batch 1735: loss 0.687598\n",
      "batch 1736: loss 0.510267\n",
      "batch 1737: loss 0.701802\n",
      "batch 1738: loss 0.557199\n",
      "batch 1739: loss 0.515595\n",
      "batch 1740: loss 0.707897\n",
      "batch 1741: loss 0.717145\n",
      "batch 1742: loss 0.552603\n",
      "batch 1743: loss 0.779845\n",
      "batch 1744: loss 0.503882\n",
      "batch 1745: loss 0.611920\n",
      "batch 1746: loss 0.604015\n",
      "batch 1747: loss 0.840836\n",
      "batch 1748: loss 0.706191\n",
      "batch 1749: loss 0.539428\n",
      "batch 1750: loss 0.426231\n",
      "batch 1751: loss 0.472600\n",
      "batch 1752: loss 0.689665\n",
      "batch 1753: loss 0.752052\n",
      "batch 1754: loss 0.523112\n",
      "batch 1755: loss 0.684740\n",
      "batch 1756: loss 0.551569\n",
      "batch 1757: loss 0.591026\n",
      "batch 1758: loss 0.567926\n",
      "batch 1759: loss 0.586949\n",
      "batch 1760: loss 0.649071\n",
      "batch 1761: loss 0.523897\n",
      "batch 1762: loss 0.530694\n",
      "batch 1763: loss 0.721637\n",
      "batch 1764: loss 0.519220\n",
      "batch 1765: loss 0.608661\n",
      "batch 1766: loss 0.734997\n",
      "batch 1767: loss 0.583202\n",
      "batch 1768: loss 0.506837\n",
      "batch 1769: loss 0.458463\n",
      "batch 1770: loss 0.487795\n",
      "batch 1771: loss 0.631606\n",
      "batch 1772: loss 0.744000\n",
      "batch 1773: loss 0.758763\n",
      "batch 1774: loss 0.520893\n",
      "batch 1775: loss 0.717298\n",
      "batch 1776: loss 0.583835\n",
      "batch 1777: loss 0.700965\n",
      "batch 1778: loss 0.745900\n",
      "batch 1779: loss 0.587031\n",
      "batch 1780: loss 0.575679\n",
      "batch 1781: loss 0.805262\n",
      "batch 1782: loss 0.623373\n",
      "batch 1783: loss 0.547817\n",
      "batch 1784: loss 0.527963\n",
      "batch 1785: loss 0.565581\n",
      "batch 1786: loss 0.564490\n",
      "batch 1787: loss 0.629254\n",
      "batch 1788: loss 0.512434\n",
      "batch 1789: loss 0.543588\n",
      "batch 1790: loss 0.691345\n",
      "batch 1791: loss 0.698145\n",
      "batch 1792: loss 0.617870\n",
      "batch 1793: loss 0.662769\n",
      "batch 1794: loss 0.666705\n",
      "batch 1795: loss 0.547094\n",
      "batch 1796: loss 0.690880\n",
      "batch 1797: loss 0.619635\n",
      "batch 1798: loss 0.552837\n",
      "batch 1799: loss 0.626522\n",
      "batch 1800: loss 0.594439\n",
      "batch 1801: loss 0.516866\n",
      "batch 1802: loss 0.482472\n",
      "batch 1803: loss 0.788866\n",
      "batch 1804: loss 0.491810\n",
      "batch 1805: loss 0.579931\n",
      "batch 1806: loss 0.863976\n",
      "batch 1807: loss 0.555243\n",
      "batch 1808: loss 0.598765\n",
      "batch 1809: loss 0.465244\n",
      "batch 1810: loss 0.560931\n",
      "batch 1811: loss 0.605934\n",
      "batch 1812: loss 0.680495\n",
      "batch 1813: loss 0.448087\n",
      "batch 1814: loss 0.518813\n",
      "batch 1815: loss 0.623793\n",
      "batch 1816: loss 0.730073\n",
      "batch 1817: loss 0.607630\n",
      "batch 1818: loss 0.541778\n",
      "batch 1819: loss 0.532885\n",
      "batch 1820: loss 0.604997\n",
      "batch 1821: loss 0.699316\n",
      "batch 1822: loss 0.741534\n",
      "batch 1823: loss 0.587884\n",
      "batch 1824: loss 0.738214\n",
      "batch 1825: loss 0.514678\n",
      "batch 1826: loss 0.538342\n",
      "batch 1827: loss 0.656469\n",
      "batch 1828: loss 0.696503\n",
      "batch 1829: loss 0.495820\n",
      "batch 1830: loss 0.656498\n",
      "batch 1831: loss 0.472873\n",
      "batch 1832: loss 0.529896\n",
      "batch 1833: loss 0.649391\n",
      "batch 1834: loss 0.553872\n",
      "batch 1835: loss 0.721433\n",
      "batch 1836: loss 0.716444\n",
      "batch 1837: loss 0.579182\n",
      "batch 1838: loss 0.583198\n",
      "batch 1839: loss 0.542179\n",
      "batch 1840: loss 0.870958\n",
      "batch 1841: loss 0.449568\n",
      "batch 1842: loss 0.634436\n",
      "batch 1843: loss 0.880059\n",
      "batch 1844: loss 0.451083\n",
      "batch 1845: loss 0.551371\n",
      "batch 1846: loss 0.730425\n",
      "batch 1847: loss 0.754431\n",
      "batch 1848: loss 0.657221\n",
      "batch 1849: loss 0.622647\n",
      "batch 1850: loss 0.487212\n",
      "batch 1851: loss 0.741730\n",
      "batch 1852: loss 0.670028\n",
      "batch 1853: loss 0.684132\n",
      "batch 1854: loss 0.560418\n",
      "batch 1855: loss 0.639497\n",
      "batch 1856: loss 0.584692\n",
      "batch 1857: loss 0.540570\n",
      "batch 1858: loss 0.715199\n",
      "batch 1859: loss 0.527448\n",
      "batch 1860: loss 0.673217\n",
      "batch 1861: loss 0.542257\n",
      "batch 1862: loss 0.614918\n",
      "batch 1863: loss 0.685662\n",
      "batch 1864: loss 0.520499\n",
      "batch 1865: loss 0.547901\n",
      "batch 1866: loss 0.720719\n",
      "batch 1867: loss 0.561402\n",
      "batch 1868: loss 0.558216\n",
      "batch 1869: loss 0.725115\n",
      "batch 1870: loss 0.706407\n",
      "batch 1871: loss 0.484199\n",
      "batch 1872: loss 0.475620\n",
      "batch 1873: loss 0.609805\n",
      "batch 1874: loss 0.581801\n",
      "batch 1875: loss 0.562060\n",
      "batch 1876: loss 1.057612\n",
      "batch 1877: loss 0.563743\n",
      "batch 1878: loss 0.555155\n",
      "batch 1879: loss 0.659467\n",
      "batch 1880: loss 0.734952\n",
      "batch 1881: loss 0.822565\n",
      "batch 1882: loss 0.612673\n",
      "batch 1883: loss 0.636183\n",
      "batch 1884: loss 0.569753\n",
      "batch 1885: loss 0.629156\n",
      "batch 1886: loss 0.594323\n",
      "batch 1887: loss 0.724727\n",
      "batch 1888: loss 0.394771\n",
      "batch 1889: loss 0.527046\n",
      "batch 1890: loss 0.666010\n",
      "batch 1891: loss 0.524292\n",
      "batch 1892: loss 0.521932\n",
      "batch 1893: loss 0.660794\n",
      "batch 1894: loss 0.520569\n",
      "batch 1895: loss 0.591317\n",
      "batch 1896: loss 0.635133\n",
      "batch 1897: loss 0.574140\n",
      "batch 1898: loss 0.588874\n",
      "batch 1899: loss 0.631032\n",
      "batch 1900: loss 0.676079\n",
      "batch 1901: loss 0.698815\n",
      "batch 1902: loss 0.581210\n",
      "batch 1903: loss 0.555386\n",
      "batch 1904: loss 0.715914\n",
      "batch 1905: loss 0.502587\n",
      "batch 1906: loss 0.696914\n",
      "batch 1907: loss 0.632451\n",
      "batch 1908: loss 0.581181\n",
      "batch 1909: loss 0.759869\n",
      "batch 1910: loss 0.759849\n",
      "batch 1911: loss 0.628164\n",
      "batch 1912: loss 0.727044\n",
      "batch 1913: loss 0.547679\n",
      "batch 1914: loss 0.460708\n",
      "batch 1915: loss 0.803799\n",
      "batch 1916: loss 0.587391\n",
      "batch 1917: loss 0.471955\n",
      "batch 1918: loss 0.565966\n",
      "batch 1919: loss 0.624646\n",
      "batch 1920: loss 0.460464\n",
      "batch 1921: loss 0.722118\n",
      "batch 1922: loss 0.883654\n",
      "batch 1923: loss 0.549383\n",
      "batch 1924: loss 0.565343\n",
      "batch 1925: loss 0.667539\n",
      "batch 1926: loss 0.711702\n",
      "batch 1927: loss 0.477702\n",
      "batch 1928: loss 0.717476\n",
      "batch 1929: loss 0.507222\n",
      "batch 1930: loss 0.523656\n",
      "batch 1931: loss 0.564446\n",
      "batch 1932: loss 0.561858\n",
      "batch 1933: loss 0.684793\n",
      "batch 1934: loss 0.638977\n",
      "batch 1935: loss 0.592538\n",
      "batch 1936: loss 0.385033\n",
      "batch 1937: loss 0.698490\n",
      "batch 1938: loss 0.534199\n",
      "batch 1939: loss 0.886720\n",
      "batch 1940: loss 0.630263\n",
      "batch 1941: loss 0.546373\n",
      "batch 1942: loss 0.483669\n",
      "batch 1943: loss 0.552925\n",
      "batch 1944: loss 0.561754\n",
      "batch 1945: loss 0.698533\n",
      "batch 1946: loss 0.622276\n",
      "batch 1947: loss 0.515267\n",
      "batch 1948: loss 0.536636\n",
      "batch 1949: loss 0.520984\n",
      "batch 1950: loss 0.647657\n",
      "batch 1951: loss 0.449549\n",
      "batch 1952: loss 0.526835\n",
      "batch 1953: loss 0.649065\n",
      "batch 1954: loss 0.543288\n",
      "batch 1955: loss 0.569690\n",
      "batch 1956: loss 0.739312\n",
      "batch 1957: loss 0.737896\n",
      "batch 1958: loss 0.658966\n",
      "batch 1959: loss 0.652165\n",
      "batch 1960: loss 0.497815\n",
      "batch 1961: loss 0.509757\n",
      "batch 1962: loss 0.598126\n",
      "batch 1963: loss 0.673876\n",
      "batch 1964: loss 0.651119\n",
      "batch 1965: loss 0.653619\n",
      "batch 1966: loss 0.332763\n",
      "batch 1967: loss 0.511123\n",
      "batch 1968: loss 0.605696\n",
      "batch 1969: loss 0.493346\n",
      "batch 1970: loss 0.567777\n",
      "batch 1971: loss 0.507053\n",
      "batch 1972: loss 0.548690\n",
      "batch 1973: loss 0.644269\n",
      "batch 1974: loss 0.671107\n",
      "batch 1975: loss 0.472355\n",
      "batch 1976: loss 0.586652\n",
      "batch 1977: loss 0.535810\n",
      "batch 1978: loss 0.558726\n",
      "batch 1979: loss 0.604167\n",
      "batch 1980: loss 0.526529\n",
      "batch 1981: loss 0.584930\n",
      "batch 1982: loss 0.663918\n",
      "batch 1983: loss 0.586342\n",
      "batch 1984: loss 0.546329\n",
      "batch 1985: loss 0.614785\n",
      "batch 1986: loss 0.576666\n",
      "batch 1987: loss 0.500155\n",
      "batch 1988: loss 0.528695\n",
      "batch 1989: loss 0.409082\n",
      "batch 1990: loss 0.498887\n",
      "batch 1991: loss 0.451917\n",
      "batch 1992: loss 0.834108\n",
      "batch 1993: loss 0.481101\n",
      "batch 1994: loss 0.633240\n",
      "batch 1995: loss 0.517220\n",
      "batch 1996: loss 0.713526\n",
      "batch 1997: loss 0.565631\n",
      "batch 1998: loss 0.778118\n",
      "batch 1999: loss 0.568202\n",
      "batch 2000: loss 0.626079\n",
      "batch 2001: loss 0.494537\n",
      "batch 2002: loss 0.494595\n",
      "batch 2003: loss 0.588165\n",
      "batch 2004: loss 0.557017\n",
      "batch 2005: loss 0.535266\n",
      "batch 2006: loss 0.409998\n",
      "batch 2007: loss 0.497510\n",
      "batch 2008: loss 0.412900\n",
      "batch 2009: loss 1.017079\n",
      "batch 2010: loss 0.799405\n",
      "batch 2011: loss 0.607465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2012: loss 0.685204\n",
      "batch 2013: loss 0.495669\n",
      "batch 2014: loss 0.577603\n",
      "batch 2015: loss 0.527786\n",
      "batch 2016: loss 0.619920\n",
      "batch 2017: loss 0.512271\n",
      "batch 2018: loss 0.750356\n",
      "batch 2019: loss 0.760569\n",
      "batch 2020: loss 0.549483\n",
      "batch 2021: loss 0.527262\n",
      "batch 2022: loss 0.615006\n",
      "batch 2023: loss 0.515591\n",
      "batch 2024: loss 0.530675\n",
      "batch 2025: loss 0.486276\n",
      "batch 2026: loss 0.601613\n",
      "batch 2027: loss 0.490514\n",
      "batch 2028: loss 0.441812\n",
      "batch 2029: loss 0.604909\n",
      "batch 2030: loss 0.506743\n",
      "batch 2031: loss 0.433905\n",
      "batch 2032: loss 0.560625\n",
      "batch 2033: loss 0.597027\n",
      "batch 2034: loss 0.566605\n",
      "batch 2035: loss 0.790710\n",
      "batch 2036: loss 0.798112\n",
      "batch 2037: loss 0.616366\n",
      "batch 2038: loss 0.576852\n",
      "batch 2039: loss 0.529920\n",
      "batch 2040: loss 0.599308\n",
      "batch 2041: loss 0.478179\n",
      "batch 2042: loss 0.871289\n",
      "batch 2043: loss 0.567733\n",
      "batch 2044: loss 0.628865\n",
      "batch 2045: loss 0.405573\n",
      "batch 2046: loss 0.450353\n",
      "batch 2047: loss 0.582707\n",
      "batch 2048: loss 0.533829\n",
      "batch 2049: loss 0.489167\n",
      "batch 2050: loss 0.460103\n",
      "batch 2051: loss 0.535812\n",
      "batch 2052: loss 0.574261\n",
      "batch 2053: loss 0.506941\n",
      "batch 2054: loss 0.397051\n",
      "batch 2055: loss 0.436514\n",
      "batch 2056: loss 0.584186\n",
      "batch 2057: loss 0.737416\n",
      "batch 2058: loss 0.533578\n",
      "batch 2059: loss 0.407235\n",
      "batch 2060: loss 0.611659\n",
      "batch 2061: loss 0.667205\n",
      "batch 2062: loss 0.548063\n",
      "batch 2063: loss 0.739704\n",
      "batch 2064: loss 0.711798\n",
      "batch 2065: loss 0.498005\n",
      "batch 2066: loss 0.634253\n",
      "batch 2067: loss 0.672872\n",
      "batch 2068: loss 0.492691\n",
      "batch 2069: loss 0.607781\n",
      "batch 2070: loss 0.501819\n",
      "batch 2071: loss 0.520628\n",
      "batch 2072: loss 0.823481\n",
      "batch 2073: loss 0.491069\n",
      "batch 2074: loss 0.639981\n",
      "batch 2075: loss 0.490068\n",
      "batch 2076: loss 0.672258\n",
      "batch 2077: loss 0.367013\n",
      "batch 2078: loss 0.455582\n",
      "batch 2079: loss 0.412122\n",
      "batch 2080: loss 0.506806\n",
      "batch 2081: loss 0.581968\n",
      "batch 2082: loss 0.536693\n",
      "batch 2083: loss 0.461591\n",
      "batch 2084: loss 0.403111\n",
      "batch 2085: loss 0.735381\n",
      "batch 2086: loss 0.674895\n",
      "batch 2087: loss 0.552917\n",
      "batch 2088: loss 0.472673\n",
      "batch 2089: loss 0.465501\n",
      "batch 2090: loss 0.707683\n",
      "batch 2091: loss 0.488105\n",
      "batch 2092: loss 0.646160\n",
      "batch 2093: loss 0.482410\n",
      "batch 2094: loss 0.389962\n",
      "batch 2095: loss 0.371103\n",
      "batch 2096: loss 0.579725\n",
      "batch 2097: loss 0.776457\n",
      "batch 2098: loss 0.851491\n",
      "batch 2099: loss 0.467016\n",
      "batch 2100: loss 0.605786\n",
      "batch 2101: loss 0.475655\n",
      "batch 2102: loss 0.677254\n",
      "batch 2103: loss 0.774170\n",
      "batch 2104: loss 0.529121\n",
      "batch 2105: loss 0.463613\n",
      "batch 2106: loss 0.506885\n",
      "batch 2107: loss 0.572083\n",
      "batch 2108: loss 0.566266\n",
      "batch 2109: loss 0.470823\n",
      "batch 2110: loss 0.649956\n",
      "batch 2111: loss 0.615180\n",
      "batch 2112: loss 0.545759\n",
      "batch 2113: loss 0.540516\n",
      "batch 2114: loss 0.658269\n",
      "batch 2115: loss 0.433835\n",
      "batch 2116: loss 0.734933\n",
      "batch 2117: loss 0.656842\n",
      "batch 2118: loss 0.657600\n",
      "batch 2119: loss 0.457515\n",
      "batch 2120: loss 0.481034\n",
      "batch 2121: loss 0.577044\n",
      "batch 2122: loss 0.705330\n",
      "batch 2123: loss 0.529753\n",
      "batch 2124: loss 0.486562\n",
      "batch 2125: loss 0.692247\n",
      "batch 2126: loss 0.533925\n",
      "batch 2127: loss 0.514303\n",
      "batch 2128: loss 0.507472\n",
      "batch 2129: loss 0.490640\n",
      "batch 2130: loss 0.487068\n",
      "batch 2131: loss 0.470277\n",
      "batch 2132: loss 0.554642\n",
      "batch 2133: loss 0.507031\n",
      "batch 2134: loss 0.597017\n",
      "batch 2135: loss 0.542830\n",
      "batch 2136: loss 0.379831\n",
      "batch 2137: loss 0.559403\n",
      "batch 2138: loss 0.577276\n",
      "batch 2139: loss 0.466721\n",
      "batch 2140: loss 0.540025\n",
      "batch 2141: loss 0.559246\n",
      "batch 2142: loss 0.571109\n",
      "batch 2143: loss 0.592249\n",
      "batch 2144: loss 0.486154\n",
      "batch 2145: loss 0.608951\n",
      "batch 2146: loss 0.604504\n",
      "batch 2147: loss 0.691283\n",
      "batch 2148: loss 0.496575\n",
      "batch 2149: loss 0.527378\n",
      "batch 2150: loss 0.573038\n",
      "batch 2151: loss 0.529215\n",
      "batch 2152: loss 0.659130\n",
      "batch 2153: loss 0.767958\n",
      "batch 2154: loss 0.717844\n",
      "batch 2155: loss 0.586347\n",
      "batch 2156: loss 0.564754\n",
      "batch 2157: loss 0.474245\n",
      "batch 2158: loss 0.604755\n",
      "batch 2159: loss 0.529799\n",
      "batch 2160: loss 0.327966\n",
      "batch 2161: loss 0.475644\n",
      "batch 2162: loss 0.442233\n",
      "batch 2163: loss 0.516944\n",
      "batch 2164: loss 0.544719\n",
      "batch 2165: loss 0.524181\n",
      "batch 2166: loss 0.488019\n",
      "batch 2167: loss 0.406544\n",
      "batch 2168: loss 0.584720\n",
      "batch 2169: loss 0.378201\n",
      "batch 2170: loss 0.558730\n",
      "batch 2171: loss 0.433386\n",
      "batch 2172: loss 0.595950\n",
      "batch 2173: loss 0.621120\n",
      "batch 2174: loss 0.527831\n",
      "batch 2175: loss 0.522949\n",
      "batch 2176: loss 0.688911\n",
      "batch 2177: loss 0.701977\n",
      "batch 2178: loss 0.702454\n",
      "batch 2179: loss 0.502501\n",
      "batch 2180: loss 0.514553\n",
      "batch 2181: loss 0.809971\n",
      "batch 2182: loss 0.509659\n",
      "batch 2183: loss 0.519041\n",
      "batch 2184: loss 0.574425\n",
      "batch 2185: loss 0.554546\n",
      "batch 2186: loss 0.613522\n",
      "batch 2187: loss 0.566097\n",
      "batch 2188: loss 0.464871\n",
      "batch 2189: loss 0.605297\n",
      "batch 2190: loss 0.722980\n",
      "batch 2191: loss 0.647360\n",
      "batch 2192: loss 0.568273\n",
      "batch 2193: loss 0.487888\n",
      "batch 2194: loss 0.639900\n",
      "batch 2195: loss 0.376192\n",
      "batch 2196: loss 0.474458\n",
      "batch 2197: loss 0.470059\n",
      "batch 2198: loss 0.678907\n",
      "batch 2199: loss 0.510021\n",
      "batch 2200: loss 0.589379\n",
      "batch 2201: loss 0.451762\n",
      "batch 2202: loss 0.536837\n",
      "batch 2203: loss 0.461605\n",
      "batch 2204: loss 0.476123\n",
      "batch 2205: loss 0.444552\n",
      "batch 2206: loss 0.486012\n",
      "batch 2207: loss 0.397886\n",
      "batch 2208: loss 0.432935\n",
      "batch 2209: loss 0.527542\n",
      "batch 2210: loss 0.641020\n",
      "batch 2211: loss 0.523339\n",
      "batch 2212: loss 0.396422\n",
      "batch 2213: loss 0.617157\n",
      "batch 2214: loss 0.444139\n",
      "batch 2215: loss 0.535173\n",
      "batch 2216: loss 0.509725\n",
      "batch 2217: loss 0.514618\n",
      "batch 2218: loss 0.505791\n",
      "batch 2219: loss 0.551819\n",
      "batch 2220: loss 0.586383\n",
      "batch 2221: loss 0.465087\n",
      "batch 2222: loss 0.614416\n",
      "batch 2223: loss 0.439860\n",
      "batch 2224: loss 0.586636\n",
      "batch 2225: loss 0.636790\n",
      "batch 2226: loss 0.541161\n",
      "batch 2227: loss 0.567220\n",
      "batch 2228: loss 0.481225\n",
      "batch 2229: loss 0.686912\n",
      "batch 2230: loss 0.470049\n",
      "batch 2231: loss 0.530456\n",
      "batch 2232: loss 0.552857\n",
      "batch 2233: loss 0.559395\n",
      "batch 2234: loss 0.702225\n",
      "batch 2235: loss 0.751251\n",
      "batch 2236: loss 0.468561\n",
      "batch 2237: loss 0.455427\n",
      "batch 2238: loss 0.508303\n",
      "batch 2239: loss 0.616913\n",
      "batch 2240: loss 0.480988\n",
      "batch 2241: loss 0.569593\n",
      "batch 2242: loss 0.473611\n",
      "batch 2243: loss 0.449778\n",
      "batch 2244: loss 0.449740\n",
      "batch 2245: loss 0.528238\n",
      "batch 2246: loss 0.673513\n",
      "batch 2247: loss 0.631717\n",
      "batch 2248: loss 0.623788\n",
      "batch 2249: loss 0.344923\n",
      "batch 2250: loss 0.642045\n",
      "batch 2251: loss 0.447619\n",
      "batch 2252: loss 0.389027\n",
      "batch 2253: loss 0.513442\n",
      "batch 2254: loss 0.521904\n",
      "batch 2255: loss 0.656715\n",
      "batch 2256: loss 0.511233\n",
      "batch 2257: loss 0.422280\n",
      "batch 2258: loss 0.483356\n",
      "batch 2259: loss 0.618479\n",
      "batch 2260: loss 0.682230\n",
      "batch 2261: loss 0.497118\n",
      "batch 2262: loss 0.580792\n",
      "batch 2263: loss 0.599251\n",
      "batch 2264: loss 0.605053\n",
      "batch 2265: loss 0.599033\n",
      "batch 2266: loss 0.542515\n",
      "batch 2267: loss 0.554783\n",
      "batch 2268: loss 0.633775\n",
      "batch 2269: loss 0.528980\n",
      "batch 2270: loss 0.467218\n",
      "batch 2271: loss 0.501232\n",
      "batch 2272: loss 0.512036\n",
      "batch 2273: loss 0.473104\n",
      "batch 2274: loss 0.443851\n",
      "batch 2275: loss 0.597038\n",
      "batch 2276: loss 0.494537\n",
      "batch 2277: loss 0.502164\n",
      "batch 2278: loss 0.486332\n",
      "batch 2279: loss 0.440379\n",
      "batch 2280: loss 0.565775\n",
      "batch 2281: loss 0.415044\n",
      "batch 2282: loss 0.504006\n",
      "batch 2283: loss 0.455821\n",
      "batch 2284: loss 0.425927\n",
      "batch 2285: loss 0.457836\n",
      "batch 2286: loss 0.529596\n",
      "batch 2287: loss 0.537221\n",
      "batch 2288: loss 0.595590\n",
      "batch 2289: loss 0.460194\n",
      "batch 2290: loss 0.500348\n",
      "batch 2291: loss 0.547303\n",
      "batch 2292: loss 0.487250\n",
      "batch 2293: loss 0.758601\n",
      "batch 2294: loss 0.744590\n",
      "batch 2295: loss 0.640078\n",
      "batch 2296: loss 0.455150\n",
      "batch 2297: loss 0.560868\n",
      "batch 2298: loss 0.718256\n",
      "batch 2299: loss 0.541434\n",
      "batch 2300: loss 0.570204\n",
      "batch 2301: loss 0.606454\n",
      "batch 2302: loss 0.557624\n",
      "batch 2303: loss 0.561644\n",
      "batch 2304: loss 0.638395\n",
      "batch 2305: loss 0.386218\n",
      "batch 2306: loss 0.591328\n",
      "batch 2307: loss 0.515655\n",
      "batch 2308: loss 0.430632\n",
      "batch 2309: loss 0.583915\n",
      "batch 2310: loss 0.477652\n",
      "batch 2311: loss 0.358011\n",
      "batch 2312: loss 0.646251\n",
      "batch 2313: loss 0.414119\n",
      "batch 2314: loss 0.696751\n",
      "batch 2315: loss 0.419146\n",
      "batch 2316: loss 0.600372\n",
      "batch 2317: loss 0.487652\n",
      "batch 2318: loss 0.575803\n",
      "batch 2319: loss 0.580630\n",
      "batch 2320: loss 0.431125\n",
      "batch 2321: loss 0.508133\n",
      "batch 2322: loss 0.550076\n",
      "batch 2323: loss 0.626362\n",
      "batch 2324: loss 0.470505\n",
      "batch 2325: loss 0.413932\n",
      "batch 2326: loss 0.552103\n",
      "batch 2327: loss 0.525908\n",
      "batch 2328: loss 0.477007\n",
      "batch 2329: loss 0.451506\n",
      "batch 2330: loss 0.386758\n",
      "batch 2331: loss 0.489217\n",
      "batch 2332: loss 0.463413\n",
      "batch 2333: loss 0.409572\n",
      "batch 2334: loss 0.741468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2335: loss 0.609598\n",
      "batch 2336: loss 0.661853\n",
      "batch 2337: loss 0.542693\n",
      "batch 2338: loss 0.314568\n",
      "batch 2339: loss 0.495342\n",
      "batch 2340: loss 0.452648\n",
      "batch 2341: loss 0.613725\n",
      "batch 2342: loss 0.779536\n",
      "batch 2343: loss 0.569938\n",
      "batch 2344: loss 0.610390\n",
      "batch 2345: loss 0.481263\n",
      "batch 2346: loss 0.581925\n",
      "batch 2347: loss 0.489189\n",
      "batch 2348: loss 0.583796\n",
      "batch 2349: loss 0.526369\n",
      "batch 2350: loss 0.458755\n",
      "batch 2351: loss 0.742949\n",
      "batch 2352: loss 0.515723\n",
      "batch 2353: loss 0.355325\n",
      "batch 2354: loss 0.446213\n",
      "batch 2355: loss 0.500247\n",
      "batch 2356: loss 0.324531\n",
      "batch 2357: loss 0.364579\n",
      "batch 2358: loss 0.562283\n",
      "batch 2359: loss 0.576799\n",
      "batch 2360: loss 0.636077\n",
      "batch 2361: loss 0.664900\n",
      "batch 2362: loss 0.491737\n",
      "batch 2363: loss 0.490703\n",
      "batch 2364: loss 0.371844\n",
      "batch 2365: loss 0.434745\n",
      "batch 2366: loss 0.627918\n",
      "batch 2367: loss 0.658969\n",
      "batch 2368: loss 0.506008\n",
      "batch 2369: loss 0.590982\n",
      "batch 2370: loss 0.428000\n",
      "batch 2371: loss 0.303992\n",
      "batch 2372: loss 0.480223\n",
      "batch 2373: loss 0.511252\n",
      "batch 2374: loss 0.394279\n",
      "batch 2375: loss 0.401805\n",
      "batch 2376: loss 0.438781\n",
      "batch 2377: loss 0.373562\n",
      "batch 2378: loss 0.481904\n",
      "batch 2379: loss 0.580767\n",
      "batch 2380: loss 0.355897\n",
      "batch 2381: loss 0.596687\n",
      "batch 2382: loss 0.414608\n",
      "batch 2383: loss 0.607491\n",
      "batch 2384: loss 0.472688\n",
      "batch 2385: loss 0.667123\n",
      "batch 2386: loss 0.431621\n",
      "batch 2387: loss 0.590160\n",
      "batch 2388: loss 0.798465\n",
      "batch 2389: loss 0.549534\n",
      "batch 2390: loss 0.520733\n",
      "batch 2391: loss 0.506153\n",
      "batch 2392: loss 0.658145\n",
      "batch 2393: loss 0.423021\n",
      "batch 2394: loss 0.464799\n",
      "batch 2395: loss 0.715112\n",
      "batch 2396: loss 0.512232\n",
      "batch 2397: loss 0.573211\n",
      "batch 2398: loss 0.507171\n",
      "batch 2399: loss 0.514157\n",
      "batch 2400: loss 0.645680\n",
      "batch 2401: loss 0.489940\n",
      "batch 2402: loss 0.632262\n",
      "batch 2403: loss 0.447298\n",
      "batch 2404: loss 0.446929\n",
      "batch 2405: loss 0.577957\n",
      "batch 2406: loss 0.478632\n",
      "batch 2407: loss 0.601298\n",
      "batch 2408: loss 0.517060\n",
      "batch 2409: loss 0.598189\n",
      "batch 2410: loss 0.412675\n",
      "batch 2411: loss 0.480713\n",
      "batch 2412: loss 0.615534\n",
      "batch 2413: loss 0.417238\n",
      "batch 2414: loss 0.530241\n",
      "batch 2415: loss 0.648792\n",
      "batch 2416: loss 0.414814\n",
      "batch 2417: loss 0.344190\n",
      "batch 2418: loss 0.608268\n",
      "batch 2419: loss 0.460844\n",
      "batch 2420: loss 0.512241\n",
      "batch 2421: loss 0.496715\n",
      "batch 2422: loss 0.513074\n",
      "batch 2423: loss 0.486523\n",
      "batch 2424: loss 0.428744\n",
      "batch 2425: loss 0.354014\n",
      "batch 2426: loss 0.460406\n",
      "batch 2427: loss 0.375768\n",
      "batch 2428: loss 0.407123\n",
      "batch 2429: loss 0.571675\n",
      "batch 2430: loss 0.480803\n",
      "batch 2431: loss 0.373874\n",
      "batch 2432: loss 0.449287\n",
      "batch 2433: loss 0.680184\n",
      "batch 2434: loss 0.389913\n",
      "batch 2435: loss 0.443012\n",
      "batch 2436: loss 0.529341\n",
      "batch 2437: loss 0.418922\n",
      "batch 2438: loss 0.408666\n",
      "batch 2439: loss 0.434594\n",
      "batch 2440: loss 0.396363\n",
      "batch 2441: loss 0.718186\n",
      "batch 2442: loss 0.450804\n",
      "batch 2443: loss 0.481575\n",
      "batch 2444: loss 0.538807\n",
      "batch 2445: loss 0.614786\n",
      "batch 2446: loss 0.462910\n",
      "batch 2447: loss 0.490338\n",
      "batch 2448: loss 0.487034\n",
      "batch 2449: loss 0.407731\n",
      "batch 2450: loss 0.435319\n",
      "batch 2451: loss 0.529828\n",
      "batch 2452: loss 0.412351\n",
      "batch 2453: loss 0.651692\n",
      "batch 2454: loss 0.607202\n",
      "batch 2455: loss 0.408666\n",
      "batch 2456: loss 0.378589\n",
      "batch 2457: loss 0.510608\n",
      "batch 2458: loss 0.382768\n",
      "batch 2459: loss 0.516103\n",
      "batch 2460: loss 0.497708\n",
      "batch 2461: loss 0.542467\n",
      "batch 2462: loss 0.464618\n",
      "batch 2463: loss 0.391717\n",
      "batch 2464: loss 0.566155\n",
      "batch 2465: loss 0.469626\n",
      "batch 2466: loss 0.648737\n",
      "batch 2467: loss 0.519951\n",
      "batch 2468: loss 0.394318\n",
      "batch 2469: loss 0.573566\n",
      "batch 2470: loss 0.526391\n",
      "batch 2471: loss 0.536976\n",
      "batch 2472: loss 0.527883\n",
      "batch 2473: loss 0.446153\n",
      "batch 2474: loss 0.331542\n",
      "batch 2475: loss 0.668658\n",
      "batch 2476: loss 0.720630\n",
      "batch 2477: loss 0.374203\n",
      "batch 2478: loss 0.502094\n",
      "batch 2479: loss 0.510746\n",
      "batch 2480: loss 0.460722\n",
      "batch 2481: loss 0.658405\n",
      "batch 2482: loss 0.535647\n",
      "batch 2483: loss 0.538376\n",
      "batch 2484: loss 0.565965\n",
      "batch 2485: loss 0.387507\n",
      "batch 2486: loss 0.566796\n",
      "batch 2487: loss 0.319098\n",
      "batch 2488: loss 0.519173\n",
      "batch 2489: loss 0.477915\n",
      "batch 2490: loss 0.644584\n",
      "batch 2491: loss 0.653083\n",
      "batch 2492: loss 0.579716\n",
      "batch 2493: loss 0.447711\n",
      "batch 2494: loss 0.554996\n",
      "batch 2495: loss 0.457955\n",
      "batch 2496: loss 0.631477\n",
      "batch 2497: loss 0.478439\n",
      "batch 2498: loss 0.489744\n",
      "batch 2499: loss 0.360063\n",
      "batch 2500: loss 0.453778\n",
      "batch 2501: loss 0.591469\n",
      "batch 2502: loss 0.627011\n",
      "batch 2503: loss 0.810504\n",
      "batch 2504: loss 0.296210\n",
      "batch 2505: loss 0.391106\n",
      "batch 2506: loss 0.430285\n",
      "batch 2507: loss 0.606000\n",
      "batch 2508: loss 0.409388\n",
      "batch 2509: loss 0.434322\n",
      "batch 2510: loss 0.638216\n",
      "batch 2511: loss 0.914528\n",
      "batch 2512: loss 0.429964\n",
      "batch 2513: loss 0.516479\n",
      "batch 2514: loss 0.529138\n",
      "batch 2515: loss 0.330750\n",
      "batch 2516: loss 0.416004\n",
      "batch 2517: loss 0.565670\n",
      "batch 2518: loss 0.492462\n",
      "batch 2519: loss 0.660444\n",
      "batch 2520: loss 0.677635\n",
      "batch 2521: loss 0.391331\n",
      "batch 2522: loss 0.501310\n",
      "batch 2523: loss 0.554556\n",
      "batch 2524: loss 0.556695\n",
      "batch 2525: loss 0.481917\n",
      "batch 2526: loss 0.446262\n",
      "batch 2527: loss 0.532071\n",
      "batch 2528: loss 0.748406\n",
      "batch 2529: loss 0.625330\n",
      "batch 2530: loss 0.624595\n",
      "batch 2531: loss 0.305368\n",
      "batch 2532: loss 0.561458\n",
      "batch 2533: loss 0.479242\n",
      "batch 2534: loss 0.538472\n",
      "batch 2535: loss 0.429376\n",
      "batch 2536: loss 0.424433\n",
      "batch 2537: loss 0.433002\n",
      "batch 2538: loss 0.561514\n",
      "batch 2539: loss 0.380542\n",
      "batch 2540: loss 0.505242\n",
      "batch 2541: loss 0.665367\n",
      "batch 2542: loss 0.340003\n",
      "batch 2543: loss 0.544115\n",
      "batch 2544: loss 0.577587\n",
      "batch 2545: loss 0.533520\n",
      "batch 2546: loss 0.602883\n",
      "batch 2547: loss 0.587101\n",
      "batch 2548: loss 0.625817\n",
      "batch 2549: loss 0.450594\n",
      "batch 2550: loss 0.530980\n",
      "batch 2551: loss 0.435345\n",
      "batch 2552: loss 0.472541\n",
      "batch 2553: loss 0.536635\n",
      "batch 2554: loss 0.556082\n",
      "batch 2555: loss 0.358425\n",
      "batch 2556: loss 0.536036\n",
      "batch 2557: loss 0.732390\n",
      "batch 2558: loss 0.445814\n",
      "batch 2559: loss 0.561279\n",
      "batch 2560: loss 0.490296\n",
      "batch 2561: loss 0.643762\n",
      "batch 2562: loss 0.456116\n",
      "batch 2563: loss 0.508205\n",
      "batch 2564: loss 0.724174\n",
      "batch 2565: loss 0.627635\n",
      "batch 2566: loss 0.459574\n",
      "batch 2567: loss 0.334246\n",
      "batch 2568: loss 0.379179\n",
      "batch 2569: loss 0.463135\n",
      "batch 2570: loss 0.431268\n",
      "batch 2571: loss 0.396583\n",
      "batch 2572: loss 0.398552\n",
      "batch 2573: loss 0.461213\n",
      "batch 2574: loss 0.517182\n",
      "batch 2575: loss 0.458451\n",
      "batch 2576: loss 0.583922\n",
      "batch 2577: loss 0.347663\n",
      "batch 2578: loss 0.364534\n",
      "batch 2579: loss 0.542337\n",
      "batch 2580: loss 0.683341\n",
      "batch 2581: loss 0.627754\n",
      "batch 2582: loss 0.385657\n",
      "batch 2583: loss 0.335163\n",
      "batch 2584: loss 0.400929\n",
      "batch 2585: loss 0.347161\n",
      "batch 2586: loss 0.546006\n",
      "batch 2587: loss 0.544815\n",
      "batch 2588: loss 0.458333\n",
      "batch 2589: loss 0.477598\n",
      "batch 2590: loss 0.489634\n",
      "batch 2591: loss 0.453000\n",
      "batch 2592: loss 0.831688\n",
      "batch 2593: loss 0.516441\n",
      "batch 2594: loss 0.406789\n",
      "batch 2595: loss 0.826790\n",
      "batch 2596: loss 0.536178\n",
      "batch 2597: loss 0.407902\n",
      "batch 2598: loss 0.522755\n",
      "batch 2599: loss 0.419422\n",
      "batch 2600: loss 0.707732\n",
      "batch 2601: loss 0.513937\n",
      "batch 2602: loss 0.963193\n",
      "batch 2603: loss 0.506543\n",
      "batch 2604: loss 0.407448\n",
      "batch 2605: loss 0.505432\n",
      "batch 2606: loss 0.517788\n",
      "batch 2607: loss 0.456172\n",
      "batch 2608: loss 0.442723\n",
      "batch 2609: loss 0.527416\n",
      "batch 2610: loss 0.654946\n",
      "batch 2611: loss 0.393659\n",
      "batch 2612: loss 0.506904\n",
      "batch 2613: loss 0.372177\n",
      "batch 2614: loss 0.634612\n",
      "batch 2615: loss 0.660905\n",
      "batch 2616: loss 0.663608\n",
      "batch 2617: loss 0.337056\n",
      "batch 2618: loss 0.596088\n",
      "batch 2619: loss 0.642209\n",
      "batch 2620: loss 0.602601\n",
      "batch 2621: loss 0.445601\n",
      "batch 2622: loss 0.438107\n",
      "batch 2623: loss 0.640494\n",
      "batch 2624: loss 0.429757\n",
      "batch 2625: loss 0.499682\n",
      "batch 2626: loss 0.496444\n",
      "batch 2627: loss 0.696110\n",
      "batch 2628: loss 0.447070\n",
      "batch 2629: loss 0.682116\n",
      "batch 2630: loss 0.569611\n",
      "batch 2631: loss 0.506663\n",
      "batch 2632: loss 0.464110\n",
      "batch 2633: loss 0.685722\n",
      "batch 2634: loss 0.414054\n",
      "batch 2635: loss 0.479295\n",
      "batch 2636: loss 0.424974\n",
      "batch 2637: loss 0.490531\n",
      "batch 2638: loss 0.402298\n",
      "batch 2639: loss 0.454716\n",
      "batch 2640: loss 0.403122\n",
      "batch 2641: loss 0.376665\n",
      "batch 2642: loss 0.614446\n",
      "batch 2643: loss 0.738582\n",
      "batch 2644: loss 0.548739\n",
      "batch 2645: loss 0.509845\n",
      "batch 2646: loss 0.555092\n",
      "batch 2647: loss 0.357773\n",
      "batch 2648: loss 0.522969\n",
      "batch 2649: loss 0.393767\n",
      "batch 2650: loss 0.517495\n",
      "batch 2651: loss 0.605816\n",
      "batch 2652: loss 0.333680\n",
      "batch 2653: loss 0.584418\n",
      "batch 2654: loss 0.596953\n",
      "batch 2655: loss 0.375124\n",
      "batch 2656: loss 0.509955\n",
      "batch 2657: loss 0.575359\n",
      "batch 2658: loss 0.439123\n",
      "batch 2659: loss 0.311128\n",
      "batch 2660: loss 0.345327\n",
      "batch 2661: loss 0.555723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2662: loss 0.483514\n",
      "batch 2663: loss 0.522322\n",
      "batch 2664: loss 0.307339\n",
      "batch 2665: loss 0.754772\n",
      "batch 2666: loss 0.445246\n",
      "batch 2667: loss 0.599424\n",
      "batch 2668: loss 0.416424\n",
      "batch 2669: loss 0.441128\n",
      "batch 2670: loss 0.757411\n",
      "batch 2671: loss 0.662647\n",
      "batch 2672: loss 0.484246\n",
      "batch 2673: loss 0.572686\n",
      "batch 2674: loss 0.723911\n",
      "batch 2675: loss 0.372324\n",
      "batch 2676: loss 0.369416\n",
      "batch 2677: loss 0.479370\n",
      "batch 2678: loss 0.614810\n",
      "batch 2679: loss 0.529749\n",
      "batch 2680: loss 0.439929\n",
      "batch 2681: loss 0.283482\n",
      "batch 2682: loss 0.401724\n",
      "batch 2683: loss 0.495782\n",
      "batch 2684: loss 0.514222\n",
      "batch 2685: loss 0.332961\n",
      "batch 2686: loss 0.367103\n",
      "batch 2687: loss 0.710241\n",
      "batch 2688: loss 0.414557\n",
      "batch 2689: loss 0.219758\n",
      "batch 2690: loss 0.321514\n",
      "batch 2691: loss 0.693225\n",
      "batch 2692: loss 0.536241\n",
      "batch 2693: loss 0.590470\n",
      "batch 2694: loss 0.403357\n",
      "batch 2695: loss 0.531590\n",
      "batch 2696: loss 0.576035\n",
      "batch 2697: loss 0.521278\n",
      "batch 2698: loss 0.474286\n",
      "batch 2699: loss 0.375983\n",
      "batch 2700: loss 0.470851\n",
      "batch 2701: loss 0.601893\n",
      "batch 2702: loss 0.564284\n",
      "batch 2703: loss 0.309229\n",
      "batch 2704: loss 0.462253\n",
      "batch 2705: loss 0.575501\n",
      "batch 2706: loss 0.475296\n",
      "batch 2707: loss 0.612180\n",
      "batch 2708: loss 0.429297\n",
      "batch 2709: loss 0.639912\n",
      "batch 2710: loss 0.423640\n",
      "batch 2711: loss 0.563173\n",
      "batch 2712: loss 0.721190\n",
      "batch 2713: loss 0.373087\n",
      "batch 2714: loss 0.638195\n",
      "batch 2715: loss 0.492618\n",
      "batch 2716: loss 0.579183\n",
      "batch 2717: loss 0.476604\n",
      "batch 2718: loss 0.489043\n",
      "batch 2719: loss 0.443497\n",
      "batch 2720: loss 0.530609\n",
      "batch 2721: loss 0.444991\n",
      "batch 2722: loss 0.289105\n",
      "batch 2723: loss 0.639799\n",
      "batch 2724: loss 0.455717\n",
      "batch 2725: loss 0.466449\n",
      "batch 2726: loss 0.395109\n",
      "batch 2727: loss 0.573430\n",
      "batch 2728: loss 0.489427\n",
      "batch 2729: loss 0.519238\n",
      "batch 2730: loss 0.562918\n",
      "batch 2731: loss 0.685458\n",
      "batch 2732: loss 0.570426\n",
      "batch 2733: loss 0.485952\n",
      "batch 2734: loss 0.568847\n",
      "batch 2735: loss 0.450987\n",
      "batch 2736: loss 0.614898\n",
      "batch 2737: loss 0.398923\n",
      "batch 2738: loss 0.339618\n",
      "batch 2739: loss 0.464876\n",
      "batch 2740: loss 0.565085\n",
      "batch 2741: loss 0.512157\n",
      "batch 2742: loss 0.345587\n",
      "batch 2743: loss 0.465271\n",
      "batch 2744: loss 0.645991\n",
      "batch 2745: loss 0.384107\n",
      "batch 2746: loss 0.520047\n",
      "batch 2747: loss 0.345507\n",
      "batch 2748: loss 0.410727\n",
      "batch 2749: loss 0.402481\n",
      "batch 2750: loss 0.386314\n",
      "batch 2751: loss 0.518205\n",
      "batch 2752: loss 0.477858\n",
      "batch 2753: loss 0.503114\n",
      "batch 2754: loss 0.320503\n",
      "batch 2755: loss 0.551013\n",
      "batch 2756: loss 0.611565\n",
      "batch 2757: loss 0.701257\n",
      "batch 2758: loss 0.409804\n",
      "batch 2759: loss 0.526575\n",
      "batch 2760: loss 0.321826\n",
      "batch 2761: loss 0.524999\n",
      "batch 2762: loss 0.413391\n",
      "batch 2763: loss 0.376587\n",
      "batch 2764: loss 0.385787\n",
      "batch 2765: loss 0.533687\n",
      "batch 2766: loss 0.545879\n",
      "batch 2767: loss 0.563116\n",
      "batch 2768: loss 0.393048\n",
      "batch 2769: loss 0.577228\n",
      "batch 2770: loss 0.496912\n",
      "batch 2771: loss 0.423858\n",
      "batch 2772: loss 0.489183\n",
      "batch 2773: loss 0.603208\n",
      "batch 2774: loss 0.589764\n",
      "batch 2775: loss 0.327673\n",
      "batch 2776: loss 0.375568\n",
      "batch 2777: loss 0.383094\n",
      "batch 2778: loss 0.386071\n",
      "batch 2779: loss 0.317987\n",
      "batch 2780: loss 0.691899\n",
      "batch 2781: loss 0.416689\n",
      "batch 2782: loss 0.517815\n",
      "batch 2783: loss 0.419319\n",
      "batch 2784: loss 0.358160\n",
      "batch 2785: loss 0.598237\n",
      "batch 2786: loss 0.488920\n",
      "batch 2787: loss 0.399325\n",
      "batch 2788: loss 0.399410\n",
      "batch 2789: loss 0.501935\n",
      "batch 2790: loss 0.501638\n",
      "batch 2791: loss 0.641777\n",
      "batch 2792: loss 0.543995\n",
      "batch 2793: loss 0.401419\n",
      "batch 2794: loss 0.560066\n",
      "batch 2795: loss 0.569195\n",
      "batch 2796: loss 0.396917\n",
      "batch 2797: loss 0.408994\n",
      "batch 2798: loss 0.383362\n",
      "batch 2799: loss 0.591823\n",
      "batch 2800: loss 0.371805\n",
      "batch 2801: loss 0.623097\n",
      "batch 2802: loss 0.467784\n",
      "batch 2803: loss 0.376021\n",
      "batch 2804: loss 0.493234\n",
      "batch 2805: loss 0.372796\n",
      "batch 2806: loss 0.377324\n",
      "batch 2807: loss 0.435711\n",
      "batch 2808: loss 0.536867\n",
      "batch 2809: loss 0.525592\n",
      "batch 2810: loss 0.475910\n",
      "batch 2811: loss 0.582677\n",
      "batch 2812: loss 0.513777\n",
      "batch 2813: loss 0.533347\n",
      "batch 2814: loss 0.554026\n",
      "batch 2815: loss 0.522483\n",
      "batch 2816: loss 0.397181\n",
      "batch 2817: loss 0.645680\n",
      "batch 2818: loss 0.546070\n",
      "batch 2819: loss 0.501339\n",
      "batch 2820: loss 0.598426\n",
      "batch 2821: loss 0.416858\n",
      "batch 2822: loss 0.359468\n",
      "batch 2823: loss 0.472254\n",
      "batch 2824: loss 0.288950\n",
      "batch 2825: loss 0.536717\n",
      "batch 2826: loss 0.477771\n",
      "batch 2827: loss 0.468120\n",
      "batch 2828: loss 0.420012\n",
      "batch 2829: loss 0.544232\n",
      "batch 2830: loss 0.394579\n",
      "batch 2831: loss 0.424647\n",
      "batch 2832: loss 0.407253\n",
      "batch 2833: loss 0.565785\n",
      "batch 2834: loss 0.493971\n",
      "batch 2835: loss 0.437920\n",
      "batch 2836: loss 0.529017\n",
      "batch 2837: loss 0.362388\n",
      "batch 2838: loss 0.417021\n",
      "batch 2839: loss 0.460578\n",
      "batch 2840: loss 0.468995\n",
      "batch 2841: loss 0.343724\n",
      "batch 2842: loss 0.506143\n",
      "batch 2843: loss 0.494449\n",
      "batch 2844: loss 0.340422\n",
      "batch 2845: loss 0.684265\n",
      "batch 2846: loss 0.630337\n",
      "batch 2847: loss 0.562293\n",
      "batch 2848: loss 0.412751\n",
      "batch 2849: loss 0.468437\n",
      "batch 2850: loss 0.572068\n",
      "batch 2851: loss 0.443707\n",
      "batch 2852: loss 0.372953\n",
      "batch 2853: loss 0.469409\n",
      "batch 2854: loss 0.657211\n",
      "batch 2855: loss 0.368763\n",
      "batch 2856: loss 0.423808\n",
      "batch 2857: loss 0.507595\n",
      "batch 2858: loss 0.567278\n",
      "batch 2859: loss 0.412408\n",
      "batch 2860: loss 0.629198\n",
      "batch 2861: loss 0.463405\n",
      "batch 2862: loss 0.444089\n",
      "batch 2863: loss 0.520658\n",
      "batch 2864: loss 0.520845\n",
      "batch 2865: loss 0.602663\n",
      "batch 2866: loss 0.390227\n",
      "batch 2867: loss 0.292978\n",
      "batch 2868: loss 0.444742\n",
      "batch 2869: loss 0.682115\n",
      "batch 2870: loss 0.539409\n",
      "batch 2871: loss 0.469071\n",
      "batch 2872: loss 0.498395\n",
      "batch 2873: loss 0.437304\n",
      "batch 2874: loss 0.508370\n",
      "batch 2875: loss 0.403637\n",
      "batch 2876: loss 0.598853\n",
      "batch 2877: loss 0.477788\n",
      "batch 2878: loss 0.327606\n",
      "batch 2879: loss 0.503531\n",
      "batch 2880: loss 0.424745\n",
      "batch 2881: loss 0.475792\n",
      "batch 2882: loss 0.473223\n",
      "batch 2883: loss 0.455755\n",
      "batch 2884: loss 0.461996\n",
      "batch 2885: loss 0.509853\n",
      "batch 2886: loss 0.459511\n",
      "batch 2887: loss 0.372439\n",
      "batch 2888: loss 0.391111\n",
      "batch 2889: loss 0.461274\n",
      "batch 2890: loss 0.578032\n",
      "batch 2891: loss 0.457896\n",
      "batch 2892: loss 0.284853\n",
      "batch 2893: loss 0.406202\n",
      "batch 2894: loss 0.554923\n",
      "batch 2895: loss 0.410487\n",
      "batch 2896: loss 0.533511\n",
      "batch 2897: loss 0.523736\n",
      "batch 2898: loss 0.374172\n",
      "batch 2899: loss 0.674969\n",
      "batch 2900: loss 0.409500\n",
      "batch 2901: loss 0.401973\n",
      "batch 2902: loss 0.369319\n",
      "batch 2903: loss 0.665042\n",
      "batch 2904: loss 0.567682\n",
      "batch 2905: loss 0.517285\n",
      "batch 2906: loss 0.379192\n",
      "batch 2907: loss 0.324165\n",
      "batch 2908: loss 0.368355\n",
      "batch 2909: loss 0.630598\n",
      "batch 2910: loss 0.343528\n",
      "batch 2911: loss 0.447283\n",
      "batch 2912: loss 0.398356\n",
      "batch 2913: loss 0.577872\n",
      "batch 2914: loss 0.618374\n",
      "batch 2915: loss 0.453099\n",
      "batch 2916: loss 0.566235\n",
      "batch 2917: loss 0.408133\n",
      "batch 2918: loss 0.474125\n",
      "batch 2919: loss 0.551749\n",
      "batch 2920: loss 0.420542\n",
      "batch 2921: loss 0.436608\n",
      "batch 2922: loss 0.304406\n",
      "batch 2923: loss 0.389653\n",
      "batch 2924: loss 0.346152\n",
      "batch 2925: loss 0.324447\n",
      "batch 2926: loss 0.503552\n",
      "batch 2927: loss 0.665801\n",
      "batch 2928: loss 0.728309\n",
      "batch 2929: loss 0.516057\n",
      "batch 2930: loss 0.269678\n",
      "batch 2931: loss 0.409586\n",
      "batch 2932: loss 0.366126\n",
      "batch 2933: loss 0.487613\n",
      "batch 2934: loss 0.576083\n",
      "batch 2935: loss 0.572326\n",
      "batch 2936: loss 0.457799\n",
      "batch 2937: loss 0.534190\n",
      "batch 2938: loss 0.774869\n",
      "batch 2939: loss 0.436844\n",
      "batch 2940: loss 0.571332\n",
      "batch 2941: loss 0.485593\n",
      "batch 2942: loss 0.373068\n",
      "batch 2943: loss 0.467972\n",
      "batch 2944: loss 0.493047\n",
      "batch 2945: loss 0.532958\n",
      "batch 2946: loss 0.397660\n",
      "batch 2947: loss 0.497519\n",
      "batch 2948: loss 0.589073\n",
      "batch 2949: loss 0.509526\n",
      "batch 2950: loss 0.575276\n",
      "batch 2951: loss 0.491005\n",
      "batch 2952: loss 0.480667\n",
      "batch 2953: loss 0.479724\n",
      "batch 2954: loss 0.497423\n",
      "batch 2955: loss 0.306623\n",
      "batch 2956: loss 0.666583\n",
      "batch 2957: loss 0.625560\n",
      "batch 2958: loss 0.439709\n",
      "batch 2959: loss 0.320721\n",
      "batch 2960: loss 0.634861\n",
      "batch 2961: loss 0.529068\n",
      "batch 2962: loss 0.511822\n",
      "batch 2963: loss 0.480240\n",
      "batch 2964: loss 0.236704\n",
      "batch 2965: loss 0.684776\n",
      "batch 2966: loss 0.590896\n",
      "batch 2967: loss 0.493013\n",
      "batch 2968: loss 0.378777\n",
      "batch 2969: loss 0.367994\n",
      "batch 2970: loss 0.608392\n",
      "batch 2971: loss 0.448108\n",
      "batch 2972: loss 0.429789\n",
      "batch 2973: loss 0.446387\n",
      "batch 2974: loss 0.387944\n",
      "batch 2975: loss 0.521705\n",
      "batch 2976: loss 0.413279\n",
      "batch 2977: loss 0.463259\n",
      "batch 2978: loss 0.378856\n",
      "batch 2979: loss 0.603836\n",
      "batch 2980: loss 0.652635\n",
      "batch 2981: loss 0.330361\n",
      "batch 2982: loss 0.529395\n",
      "batch 2983: loss 0.364470\n",
      "batch 2984: loss 0.379900\n",
      "batch 2985: loss 0.527606\n",
      "batch 2986: loss 0.316184\n",
      "batch 2987: loss 0.455708\n",
      "batch 2988: loss 0.319161\n",
      "batch 2989: loss 0.476610\n",
      "batch 2990: loss 0.543754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2991: loss 0.453584\n",
      "batch 2992: loss 0.410689\n",
      "batch 2993: loss 0.371262\n",
      "batch 2994: loss 0.590286\n",
      "batch 2995: loss 0.495078\n",
      "batch 2996: loss 0.315332\n",
      "batch 2997: loss 0.312400\n",
      "batch 2998: loss 0.289654\n",
      "batch 2999: loss 0.374356\n",
      "batch 3000: loss 0.421639\n",
      "batch 3001: loss 0.515121\n",
      "batch 3002: loss 0.513045\n",
      "batch 3003: loss 0.396185\n",
      "batch 3004: loss 0.456046\n",
      "batch 3005: loss 0.412581\n",
      "batch 3006: loss 0.433278\n",
      "batch 3007: loss 0.413425\n",
      "batch 3008: loss 0.302946\n",
      "batch 3009: loss 0.441344\n",
      "batch 3010: loss 0.624537\n",
      "batch 3011: loss 0.423811\n",
      "batch 3012: loss 0.409548\n",
      "batch 3013: loss 0.639892\n",
      "batch 3014: loss 0.434919\n",
      "batch 3015: loss 0.373403\n",
      "batch 3016: loss 0.395133\n",
      "batch 3017: loss 0.370810\n",
      "batch 3018: loss 0.649110\n",
      "batch 3019: loss 0.436566\n",
      "batch 3020: loss 0.576750\n",
      "batch 3021: loss 0.507780\n",
      "batch 3022: loss 0.449617\n",
      "batch 3023: loss 0.511369\n",
      "batch 3024: loss 0.555610\n",
      "batch 3025: loss 0.432724\n",
      "batch 3026: loss 0.438128\n",
      "batch 3027: loss 0.300019\n",
      "batch 3028: loss 0.609950\n",
      "batch 3029: loss 0.541658\n",
      "batch 3030: loss 0.273627\n",
      "batch 3031: loss 0.444905\n",
      "batch 3032: loss 0.355580\n",
      "batch 3033: loss 0.585268\n",
      "batch 3034: loss 0.493813\n",
      "batch 3035: loss 0.312247\n",
      "batch 3036: loss 0.363823\n",
      "batch 3037: loss 0.466132\n",
      "batch 3038: loss 0.546760\n",
      "batch 3039: loss 0.591679\n",
      "batch 3040: loss 0.494713\n",
      "batch 3041: loss 0.392684\n",
      "batch 3042: loss 0.233489\n",
      "batch 3043: loss 0.373324\n",
      "batch 3044: loss 0.483105\n",
      "batch 3045: loss 0.552592\n",
      "batch 3046: loss 0.489435\n",
      "batch 3047: loss 0.349923\n",
      "batch 3048: loss 0.411071\n",
      "batch 3049: loss 0.346441\n",
      "batch 3050: loss 0.501380\n",
      "batch 3051: loss 0.334593\n",
      "batch 3052: loss 0.326273\n",
      "batch 3053: loss 0.229416\n",
      "batch 3054: loss 0.517443\n",
      "batch 3055: loss 0.432654\n",
      "batch 3056: loss 0.479294\n",
      "batch 3057: loss 0.350523\n",
      "batch 3058: loss 0.464160\n",
      "batch 3059: loss 0.452887\n",
      "batch 3060: loss 0.503763\n",
      "batch 3061: loss 0.345994\n",
      "batch 3062: loss 0.420668\n",
      "batch 3063: loss 0.510152\n",
      "batch 3064: loss 0.555320\n",
      "batch 3065: loss 0.342480\n",
      "batch 3066: loss 0.523326\n",
      "batch 3067: loss 0.551075\n",
      "batch 3068: loss 0.326258\n",
      "batch 3069: loss 0.412527\n",
      "batch 3070: loss 0.394949\n",
      "batch 3071: loss 0.613489\n",
      "batch 3072: loss 0.614927\n",
      "batch 3073: loss 0.467576\n",
      "batch 3074: loss 0.396268\n",
      "batch 3075: loss 0.462919\n",
      "batch 3076: loss 0.367085\n",
      "batch 3077: loss 0.476187\n",
      "batch 3078: loss 0.449378\n",
      "batch 3079: loss 0.783044\n",
      "batch 3080: loss 0.362601\n",
      "batch 3081: loss 0.515251\n",
      "batch 3082: loss 0.244861\n",
      "batch 3083: loss 0.420615\n",
      "batch 3084: loss 0.432037\n",
      "batch 3085: loss 0.408202\n",
      "batch 3086: loss 0.360875\n",
      "batch 3087: loss 0.560732\n",
      "batch 3088: loss 0.508493\n",
      "batch 3089: loss 0.327649\n",
      "batch 3090: loss 0.438110\n",
      "batch 3091: loss 0.293373\n",
      "batch 3092: loss 0.521745\n",
      "batch 3093: loss 0.316511\n",
      "batch 3094: loss 0.243965\n",
      "batch 3095: loss 0.298877\n",
      "batch 3096: loss 0.412591\n",
      "batch 3097: loss 0.589152\n",
      "batch 3098: loss 0.313042\n",
      "batch 3099: loss 0.591881\n",
      "batch 3100: loss 0.403365\n",
      "batch 3101: loss 0.563331\n",
      "batch 3102: loss 0.510389\n",
      "batch 3103: loss 0.545448\n",
      "batch 3104: loss 0.420844\n",
      "batch 3105: loss 0.367020\n",
      "batch 3106: loss 0.375835\n",
      "batch 3107: loss 0.409959\n",
      "batch 3108: loss 0.402196\n",
      "batch 3109: loss 0.437113\n",
      "batch 3110: loss 0.417073\n",
      "batch 3111: loss 0.610281\n",
      "batch 3112: loss 0.467068\n",
      "batch 3113: loss 0.528898\n",
      "batch 3114: loss 0.437804\n",
      "batch 3115: loss 0.528940\n",
      "batch 3116: loss 0.239698\n",
      "batch 3117: loss 0.434242\n",
      "batch 3118: loss 0.331619\n",
      "batch 3119: loss 0.556447\n",
      "batch 3120: loss 0.354337\n",
      "batch 3121: loss 0.663758\n",
      "batch 3122: loss 0.596908\n",
      "batch 3123: loss 0.423954\n",
      "batch 3124: loss 0.333858\n",
      "batch 3125: loss 0.417009\n",
      "batch 3126: loss 0.426400\n",
      "batch 3127: loss 0.467042\n",
      "batch 3128: loss 0.457231\n",
      "batch 3129: loss 0.653017\n",
      "batch 3130: loss 0.309730\n",
      "batch 3131: loss 0.417267\n",
      "batch 3132: loss 0.501778\n",
      "batch 3133: loss 0.449850\n",
      "batch 3134: loss 0.452915\n",
      "batch 3135: loss 0.542605\n",
      "batch 3136: loss 0.386563\n",
      "batch 3137: loss 0.545339\n",
      "batch 3138: loss 0.494187\n",
      "batch 3139: loss 0.485516\n",
      "batch 3140: loss 0.366727\n",
      "batch 3141: loss 0.520846\n",
      "batch 3142: loss 0.603948\n",
      "batch 3143: loss 0.436170\n",
      "batch 3144: loss 0.437089\n",
      "batch 3145: loss 0.386842\n",
      "batch 3146: loss 0.464742\n",
      "batch 3147: loss 0.396270\n",
      "batch 3148: loss 0.338215\n",
      "batch 3149: loss 0.413764\n",
      "batch 3150: loss 0.331760\n",
      "batch 3151: loss 0.288024\n",
      "batch 3152: loss 0.421289\n",
      "batch 3153: loss 0.516843\n",
      "batch 3154: loss 0.403009\n",
      "batch 3155: loss 0.620465\n",
      "batch 3156: loss 0.344583\n",
      "batch 3157: loss 0.360973\n",
      "batch 3158: loss 0.344857\n",
      "batch 3159: loss 0.391135\n",
      "batch 3160: loss 0.593538\n",
      "batch 3161: loss 0.403592\n",
      "batch 3162: loss 0.362887\n",
      "batch 3163: loss 0.581577\n",
      "batch 3164: loss 0.674338\n",
      "batch 3165: loss 0.338273\n",
      "batch 3166: loss 0.591981\n",
      "batch 3167: loss 0.298693\n",
      "batch 3168: loss 0.461606\n",
      "batch 3169: loss 0.431076\n",
      "batch 3170: loss 0.357754\n",
      "batch 3171: loss 0.663436\n",
      "batch 3172: loss 0.402780\n",
      "batch 3173: loss 0.597660\n",
      "batch 3174: loss 0.353041\n",
      "batch 3175: loss 0.391822\n",
      "batch 3176: loss 0.368098\n",
      "batch 3177: loss 0.460144\n",
      "batch 3178: loss 0.506225\n",
      "batch 3179: loss 0.567765\n",
      "batch 3180: loss 0.405446\n",
      "batch 3181: loss 0.277881\n",
      "batch 3182: loss 0.328785\n",
      "batch 3183: loss 0.576612\n",
      "batch 3184: loss 0.526963\n",
      "batch 3185: loss 0.580380\n",
      "batch 3186: loss 0.439895\n",
      "batch 3187: loss 0.297493\n",
      "batch 3188: loss 0.478533\n",
      "batch 3189: loss 0.308090\n",
      "batch 3190: loss 0.677413\n",
      "batch 3191: loss 0.369404\n",
      "batch 3192: loss 0.677498\n",
      "batch 3193: loss 0.433535\n",
      "batch 3194: loss 0.375269\n",
      "batch 3195: loss 0.425626\n",
      "batch 3196: loss 0.275730\n",
      "batch 3197: loss 0.378635\n",
      "batch 3198: loss 0.567896\n",
      "batch 3199: loss 0.249593\n",
      "batch 3200: loss 0.302821\n",
      "batch 3201: loss 0.574902\n",
      "batch 3202: loss 0.321271\n",
      "batch 3203: loss 0.470436\n",
      "batch 3204: loss 0.403164\n",
      "batch 3205: loss 0.337167\n",
      "batch 3206: loss 0.441083\n",
      "batch 3207: loss 0.418084\n",
      "batch 3208: loss 0.444288\n",
      "batch 3209: loss 0.484899\n",
      "batch 3210: loss 0.382836\n",
      "batch 3211: loss 0.559251\n",
      "batch 3212: loss 0.298849\n",
      "batch 3213: loss 0.404197\n",
      "batch 3214: loss 0.429882\n",
      "batch 3215: loss 0.545336\n",
      "batch 3216: loss 0.486978\n",
      "batch 3217: loss 0.557921\n",
      "batch 3218: loss 0.447437\n",
      "batch 3219: loss 0.345289\n",
      "batch 3220: loss 0.408357\n",
      "batch 3221: loss 0.440499\n",
      "batch 3222: loss 0.451353\n",
      "batch 3223: loss 0.448744\n",
      "batch 3224: loss 0.476175\n",
      "batch 3225: loss 0.480649\n",
      "batch 3226: loss 0.398771\n",
      "batch 3227: loss 0.498371\n",
      "batch 3228: loss 0.332141\n",
      "batch 3229: loss 0.348389\n",
      "batch 3230: loss 0.488424\n",
      "batch 3231: loss 0.532238\n",
      "batch 3232: loss 0.508592\n",
      "batch 3233: loss 0.263854\n",
      "batch 3234: loss 0.402718\n",
      "batch 3235: loss 0.410091\n",
      "batch 3236: loss 0.395939\n",
      "batch 3237: loss 0.651709\n",
      "batch 3238: loss 0.275835\n",
      "batch 3239: loss 0.479699\n",
      "batch 3240: loss 0.499646\n",
      "batch 3241: loss 0.421703\n",
      "batch 3242: loss 0.347883\n",
      "batch 3243: loss 0.612495\n",
      "batch 3244: loss 0.460344\n",
      "batch 3245: loss 0.284745\n",
      "batch 3246: loss 0.367223\n",
      "batch 3247: loss 0.412214\n",
      "batch 3248: loss 0.331188\n",
      "batch 3249: loss 0.574574\n",
      "batch 3250: loss 0.478366\n",
      "batch 3251: loss 0.319537\n",
      "batch 3252: loss 0.477823\n",
      "batch 3253: loss 0.438029\n",
      "batch 3254: loss 0.392596\n",
      "batch 3255: loss 0.311935\n",
      "batch 3256: loss 0.522588\n",
      "batch 3257: loss 0.354251\n",
      "batch 3258: loss 0.306788\n",
      "batch 3259: loss 0.535752\n",
      "batch 3260: loss 0.427547\n",
      "batch 3261: loss 0.321402\n",
      "batch 3262: loss 0.553306\n",
      "batch 3263: loss 0.606285\n",
      "batch 3264: loss 0.306598\n",
      "batch 3265: loss 0.531668\n",
      "batch 3266: loss 0.446970\n",
      "batch 3267: loss 0.444643\n",
      "batch 3268: loss 0.392619\n",
      "batch 3269: loss 0.386906\n",
      "batch 3270: loss 0.367701\n",
      "batch 3271: loss 0.370738\n",
      "batch 3272: loss 0.425131\n",
      "batch 3273: loss 0.591585\n",
      "batch 3274: loss 0.405838\n",
      "batch 3275: loss 0.361122\n",
      "batch 3276: loss 0.656615\n",
      "batch 3277: loss 0.387793\n",
      "batch 3278: loss 0.777830\n",
      "batch 3279: loss 0.413147\n",
      "batch 3280: loss 0.417409\n",
      "batch 3281: loss 0.410891\n",
      "batch 3282: loss 0.401295\n",
      "batch 3283: loss 0.521295\n",
      "batch 3284: loss 0.579148\n",
      "batch 3285: loss 0.295503\n",
      "batch 3286: loss 0.446982\n",
      "batch 3287: loss 0.411089\n",
      "batch 3288: loss 0.298174\n",
      "batch 3289: loss 0.354315\n",
      "batch 3290: loss 0.372672\n",
      "batch 3291: loss 0.455286\n",
      "batch 3292: loss 0.401301\n",
      "batch 3293: loss 0.477095\n",
      "batch 3294: loss 0.426219\n",
      "batch 3295: loss 0.434639\n",
      "batch 3296: loss 0.424714\n",
      "batch 3297: loss 0.495450\n",
      "batch 3298: loss 0.444366\n",
      "batch 3299: loss 0.331525\n",
      "batch 3300: loss 0.573292\n",
      "batch 3301: loss 0.377565\n",
      "batch 3302: loss 0.350607\n",
      "batch 3303: loss 0.404266\n",
      "batch 3304: loss 0.433746\n",
      "batch 3305: loss 0.315005\n",
      "batch 3306: loss 0.341920\n",
      "batch 3307: loss 0.367325\n",
      "batch 3308: loss 0.459375\n",
      "batch 3309: loss 0.308688\n",
      "batch 3310: loss 0.341410\n",
      "batch 3311: loss 0.606685\n",
      "batch 3312: loss 0.587132\n",
      "batch 3313: loss 0.500837\n",
      "batch 3314: loss 0.513240\n",
      "batch 3315: loss 0.448468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3316: loss 0.490432\n",
      "batch 3317: loss 0.541608\n",
      "batch 3318: loss 0.406553\n",
      "batch 3319: loss 0.460917\n",
      "batch 3320: loss 0.388957\n",
      "batch 3321: loss 0.672935\n",
      "batch 3322: loss 0.619857\n",
      "batch 3323: loss 0.343706\n",
      "batch 3324: loss 0.229685\n",
      "batch 3325: loss 0.390471\n",
      "batch 3326: loss 0.281379\n",
      "batch 3327: loss 0.418001\n",
      "batch 3328: loss 0.257399\n",
      "batch 3329: loss 0.325930\n",
      "batch 3330: loss 0.476193\n",
      "batch 3331: loss 0.496427\n",
      "batch 3332: loss 0.389002\n",
      "batch 3333: loss 0.387352\n",
      "batch 3334: loss 0.528281\n",
      "batch 3335: loss 0.371272\n",
      "batch 3336: loss 0.405509\n",
      "batch 3337: loss 0.410445\n",
      "batch 3338: loss 0.240227\n",
      "batch 3339: loss 0.746333\n",
      "batch 3340: loss 0.348610\n",
      "batch 3341: loss 0.410526\n",
      "batch 3342: loss 0.501503\n",
      "batch 3343: loss 0.250917\n",
      "batch 3344: loss 0.245613\n",
      "batch 3345: loss 0.422779\n",
      "batch 3346: loss 0.440729\n",
      "batch 3347: loss 0.303724\n",
      "batch 3348: loss 0.466646\n",
      "batch 3349: loss 0.424858\n",
      "batch 3350: loss 0.424310\n",
      "batch 3351: loss 0.481873\n",
      "batch 3352: loss 0.353333\n",
      "batch 3353: loss 0.446008\n",
      "batch 3354: loss 0.428866\n",
      "batch 3355: loss 0.359517\n",
      "batch 3356: loss 0.394535\n",
      "batch 3357: loss 0.318767\n",
      "batch 3358: loss 0.408585\n",
      "batch 3359: loss 0.324296\n",
      "batch 3360: loss 0.504544\n",
      "batch 3361: loss 0.320925\n",
      "batch 3362: loss 0.428513\n",
      "batch 3363: loss 0.403146\n",
      "batch 3364: loss 0.488614\n",
      "batch 3365: loss 0.398517\n",
      "batch 3366: loss 0.254707\n",
      "batch 3367: loss 0.368858\n",
      "batch 3368: loss 0.306912\n",
      "batch 3369: loss 0.641242\n",
      "batch 3370: loss 0.550413\n",
      "batch 3371: loss 0.337978\n",
      "batch 3372: loss 0.429270\n",
      "batch 3373: loss 0.477545\n",
      "batch 3374: loss 0.409119\n",
      "batch 3375: loss 0.293455\n",
      "batch 3376: loss 0.236876\n",
      "batch 3377: loss 0.370749\n",
      "batch 3378: loss 0.509745\n",
      "batch 3379: loss 0.396897\n",
      "batch 3380: loss 0.349142\n",
      "batch 3381: loss 0.499572\n",
      "batch 3382: loss 0.362948\n",
      "batch 3383: loss 0.416217\n",
      "batch 3384: loss 0.474603\n",
      "batch 3385: loss 0.622210\n",
      "batch 3386: loss 0.481334\n",
      "batch 3387: loss 0.498276\n",
      "batch 3388: loss 0.409993\n",
      "batch 3389: loss 0.651772\n",
      "batch 3390: loss 0.211115\n",
      "batch 3391: loss 0.512621\n",
      "batch 3392: loss 0.422558\n",
      "batch 3393: loss 0.332052\n",
      "batch 3394: loss 0.549808\n",
      "batch 3395: loss 0.435545\n",
      "batch 3396: loss 0.415256\n",
      "batch 3397: loss 0.432643\n",
      "batch 3398: loss 0.482527\n",
      "batch 3399: loss 0.336225\n",
      "batch 3400: loss 0.398216\n",
      "batch 3401: loss 0.338102\n",
      "batch 3402: loss 0.457557\n",
      "batch 3403: loss 0.267348\n",
      "batch 3404: loss 0.251600\n",
      "batch 3405: loss 0.425340\n",
      "batch 3406: loss 0.379965\n",
      "batch 3407: loss 0.643789\n",
      "batch 3408: loss 0.288437\n",
      "batch 3409: loss 0.257720\n",
      "batch 3410: loss 0.370902\n",
      "batch 3411: loss 0.468295\n",
      "batch 3412: loss 0.346708\n",
      "batch 3413: loss 0.387647\n",
      "batch 3414: loss 0.631248\n",
      "batch 3415: loss 0.768741\n",
      "batch 3416: loss 0.381067\n",
      "batch 3417: loss 0.689055\n",
      "batch 3418: loss 0.499880\n",
      "batch 3419: loss 0.454048\n",
      "batch 3420: loss 0.316031\n",
      "batch 3421: loss 0.319526\n",
      "batch 3422: loss 0.395344\n",
      "batch 3423: loss 0.330207\n",
      "batch 3424: loss 0.390448\n",
      "batch 3425: loss 0.461104\n",
      "batch 3426: loss 0.348024\n",
      "batch 3427: loss 0.428175\n",
      "batch 3428: loss 0.515306\n",
      "batch 3429: loss 0.276671\n",
      "batch 3430: loss 0.570284\n",
      "batch 3431: loss 0.477978\n",
      "batch 3432: loss 0.276840\n",
      "batch 3433: loss 0.487060\n",
      "batch 3434: loss 0.383862\n",
      "batch 3435: loss 0.400463\n",
      "batch 3436: loss 0.402804\n",
      "batch 3437: loss 0.380890\n",
      "batch 3438: loss 0.470621\n",
      "batch 3439: loss 0.437265\n",
      "batch 3440: loss 0.651900\n",
      "batch 3441: loss 0.333054\n",
      "batch 3442: loss 0.277206\n",
      "batch 3443: loss 0.427276\n",
      "batch 3444: loss 0.300940\n",
      "batch 3445: loss 0.544930\n",
      "batch 3446: loss 0.460462\n",
      "batch 3447: loss 0.242839\n",
      "batch 3448: loss 0.362699\n",
      "batch 3449: loss 0.441425\n",
      "batch 3450: loss 0.597954\n",
      "batch 3451: loss 0.336066\n",
      "batch 3452: loss 0.436905\n",
      "batch 3453: loss 0.432052\n",
      "batch 3454: loss 0.316700\n",
      "batch 3455: loss 0.350307\n",
      "batch 3456: loss 0.367313\n",
      "batch 3457: loss 0.632854\n",
      "batch 3458: loss 0.550735\n",
      "batch 3459: loss 0.349594\n",
      "batch 3460: loss 0.416331\n",
      "batch 3461: loss 0.443220\n",
      "batch 3462: loss 0.492574\n",
      "batch 3463: loss 0.439740\n",
      "batch 3464: loss 0.535097\n",
      "batch 3465: loss 0.539595\n",
      "batch 3466: loss 0.606241\n",
      "batch 3467: loss 0.309832\n",
      "batch 3468: loss 0.356064\n",
      "batch 3469: loss 0.328242\n",
      "batch 3470: loss 0.399036\n",
      "batch 3471: loss 0.559148\n",
      "batch 3472: loss 0.405498\n",
      "batch 3473: loss 0.505590\n",
      "batch 3474: loss 0.459072\n",
      "batch 3475: loss 0.391699\n",
      "batch 3476: loss 0.391529\n",
      "batch 3477: loss 0.564594\n",
      "batch 3478: loss 0.361733\n",
      "batch 3479: loss 0.539087\n",
      "batch 3480: loss 0.465517\n",
      "batch 3481: loss 0.477746\n",
      "batch 3482: loss 0.284370\n",
      "batch 3483: loss 0.532618\n",
      "batch 3484: loss 0.404337\n",
      "batch 3485: loss 0.277523\n",
      "batch 3486: loss 0.443690\n",
      "batch 3487: loss 0.490525\n",
      "batch 3488: loss 0.347183\n",
      "batch 3489: loss 0.585114\n",
      "batch 3490: loss 0.642783\n",
      "batch 3491: loss 0.442459\n",
      "batch 3492: loss 0.461110\n",
      "batch 3493: loss 0.409083\n",
      "batch 3494: loss 0.571711\n",
      "batch 3495: loss 0.593552\n",
      "batch 3496: loss 0.285297\n",
      "batch 3497: loss 0.371803\n",
      "batch 3498: loss 0.446435\n",
      "batch 3499: loss 0.317564\n",
      "batch 3500: loss 0.332923\n",
      "batch 3501: loss 0.526471\n",
      "batch 3502: loss 0.432400\n",
      "batch 3503: loss 0.455845\n",
      "batch 3504: loss 0.264396\n",
      "batch 3505: loss 0.393408\n",
      "batch 3506: loss 0.470927\n",
      "batch 3507: loss 0.333259\n",
      "batch 3508: loss 0.405102\n",
      "batch 3509: loss 0.457461\n",
      "batch 3510: loss 0.351137\n",
      "batch 3511: loss 0.576387\n",
      "batch 3512: loss 0.338867\n",
      "batch 3513: loss 0.518287\n",
      "batch 3514: loss 0.435147\n",
      "batch 3515: loss 0.461510\n",
      "batch 3516: loss 0.288867\n",
      "batch 3517: loss 0.353253\n",
      "batch 3518: loss 0.384476\n",
      "batch 3519: loss 0.670704\n",
      "batch 3520: loss 0.377462\n",
      "batch 3521: loss 0.395318\n",
      "batch 3522: loss 0.428362\n",
      "batch 3523: loss 0.342702\n",
      "batch 3524: loss 0.294096\n",
      "batch 3525: loss 0.597037\n",
      "batch 3526: loss 0.376205\n",
      "batch 3527: loss 0.490009\n",
      "batch 3528: loss 0.336726\n",
      "batch 3529: loss 0.663086\n",
      "batch 3530: loss 0.600982\n",
      "batch 3531: loss 0.407542\n",
      "batch 3532: loss 0.470454\n",
      "batch 3533: loss 0.449856\n",
      "batch 3534: loss 0.388311\n",
      "batch 3535: loss 0.197783\n",
      "batch 3536: loss 0.428581\n",
      "batch 3537: loss 0.333201\n",
      "batch 3538: loss 0.346569\n",
      "batch 3539: loss 0.299102\n",
      "batch 3540: loss 0.232994\n",
      "batch 3541: loss 0.361070\n",
      "batch 3542: loss 0.408294\n",
      "batch 3543: loss 0.373336\n",
      "batch 3544: loss 0.435592\n",
      "batch 3545: loss 0.404071\n",
      "batch 3546: loss 0.544474\n",
      "batch 3547: loss 0.402918\n",
      "batch 3548: loss 0.540383\n",
      "batch 3549: loss 0.419297\n",
      "batch 3550: loss 0.360327\n",
      "batch 3551: loss 0.552994\n",
      "batch 3552: loss 0.503137\n",
      "batch 3553: loss 0.377710\n",
      "batch 3554: loss 0.328157\n",
      "batch 3555: loss 0.470409\n",
      "batch 3556: loss 0.317683\n",
      "batch 3557: loss 0.370213\n",
      "batch 3558: loss 0.334614\n",
      "batch 3559: loss 0.183887\n",
      "batch 3560: loss 0.436651\n",
      "batch 3561: loss 0.346447\n",
      "batch 3562: loss 0.555037\n",
      "batch 3563: loss 0.458189\n",
      "batch 3564: loss 0.468634\n",
      "batch 3565: loss 0.938066\n",
      "batch 3566: loss 0.734336\n",
      "batch 3567: loss 0.403816\n",
      "batch 3568: loss 0.443491\n",
      "batch 3569: loss 0.553469\n",
      "batch 3570: loss 0.320274\n",
      "batch 3571: loss 0.366549\n",
      "batch 3572: loss 0.425780\n",
      "batch 3573: loss 0.656253\n",
      "batch 3574: loss 0.374724\n",
      "batch 3575: loss 0.300798\n",
      "batch 3576: loss 0.396023\n",
      "batch 3577: loss 0.325117\n",
      "batch 3578: loss 0.274167\n",
      "batch 3579: loss 0.537752\n",
      "batch 3580: loss 0.524083\n",
      "batch 3581: loss 0.392399\n",
      "batch 3582: loss 0.416656\n",
      "batch 3583: loss 0.383197\n",
      "batch 3584: loss 0.308526\n",
      "batch 3585: loss 0.358796\n",
      "batch 3586: loss 0.458267\n",
      "batch 3587: loss 0.323951\n",
      "batch 3588: loss 0.274547\n",
      "batch 3589: loss 0.507316\n",
      "batch 3590: loss 0.407504\n",
      "batch 3591: loss 0.491748\n",
      "batch 3592: loss 0.511178\n",
      "batch 3593: loss 0.476204\n",
      "batch 3594: loss 0.437977\n",
      "batch 3595: loss 0.390117\n",
      "batch 3596: loss 0.381395\n",
      "batch 3597: loss 0.425874\n",
      "batch 3598: loss 0.343413\n",
      "batch 3599: loss 0.477218\n",
      "batch 3600: loss 0.370136\n",
      "batch 3601: loss 0.460428\n",
      "batch 3602: loss 0.519766\n",
      "batch 3603: loss 0.465040\n",
      "batch 3604: loss 0.461022\n",
      "batch 3605: loss 0.469595\n",
      "batch 3606: loss 0.599913\n",
      "batch 3607: loss 0.333891\n",
      "batch 3608: loss 0.324003\n",
      "batch 3609: loss 0.534345\n",
      "batch 3610: loss 0.455943\n",
      "batch 3611: loss 0.391345\n",
      "batch 3612: loss 0.224646\n",
      "batch 3613: loss 0.241388\n",
      "batch 3614: loss 0.309683\n",
      "batch 3615: loss 0.577983\n",
      "batch 3616: loss 0.450607\n",
      "batch 3617: loss 0.613467\n",
      "batch 3618: loss 0.351843\n",
      "batch 3619: loss 0.431169\n",
      "batch 3620: loss 0.294818\n",
      "batch 3621: loss 0.290687\n",
      "batch 3622: loss 0.394385\n",
      "batch 3623: loss 0.384298\n",
      "batch 3624: loss 0.621633\n",
      "batch 3625: loss 0.428788\n",
      "batch 3626: loss 0.440291\n",
      "batch 3627: loss 0.384532\n",
      "batch 3628: loss 0.807190\n",
      "batch 3629: loss 0.533154\n",
      "batch 3630: loss 0.334778\n",
      "batch 3631: loss 0.320734\n",
      "batch 3632: loss 0.278251\n",
      "batch 3633: loss 0.342739\n",
      "batch 3634: loss 0.342125\n",
      "batch 3635: loss 0.424096\n",
      "batch 3636: loss 0.347212\n",
      "batch 3637: loss 0.365488\n",
      "batch 3638: loss 0.416498\n",
      "batch 3639: loss 0.436088\n",
      "batch 3640: loss 0.298572\n",
      "batch 3641: loss 0.308079\n",
      "batch 3642: loss 0.341279\n",
      "batch 3643: loss 0.249037\n",
      "batch 3644: loss 0.310274\n",
      "batch 3645: loss 0.619870\n",
      "batch 3646: loss 0.392214\n",
      "batch 3647: loss 0.577487\n",
      "batch 3648: loss 0.286371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3649: loss 0.522164\n",
      "batch 3650: loss 0.595611\n",
      "batch 3651: loss 0.360061\n",
      "batch 3652: loss 0.209131\n",
      "batch 3653: loss 0.366732\n",
      "batch 3654: loss 0.444750\n",
      "batch 3655: loss 0.200708\n",
      "batch 3656: loss 0.324481\n",
      "batch 3657: loss 0.474035\n",
      "batch 3658: loss 0.238204\n",
      "batch 3659: loss 0.245587\n",
      "batch 3660: loss 0.478970\n",
      "batch 3661: loss 0.284604\n",
      "batch 3662: loss 0.480667\n",
      "batch 3663: loss 0.615447\n",
      "batch 3664: loss 0.692471\n",
      "batch 3665: loss 0.437034\n",
      "batch 3666: loss 0.357757\n",
      "batch 3667: loss 0.460996\n",
      "batch 3668: loss 0.561446\n",
      "batch 3669: loss 0.445456\n",
      "batch 3670: loss 0.291874\n",
      "batch 3671: loss 0.387967\n",
      "batch 3672: loss 0.252773\n",
      "batch 3673: loss 0.296958\n",
      "batch 3674: loss 0.502193\n",
      "batch 3675: loss 0.544676\n",
      "batch 3676: loss 0.425009\n",
      "batch 3677: loss 0.223255\n",
      "batch 3678: loss 0.344328\n",
      "batch 3679: loss 0.487788\n",
      "batch 3680: loss 0.397785\n",
      "batch 3681: loss 0.496277\n",
      "batch 3682: loss 0.514918\n",
      "batch 3683: loss 0.492898\n",
      "batch 3684: loss 0.337430\n",
      "batch 3685: loss 0.309859\n",
      "batch 3686: loss 0.496691\n",
      "batch 3687: loss 0.387924\n",
      "batch 3688: loss 0.399506\n",
      "batch 3689: loss 0.574231\n",
      "batch 3690: loss 0.364795\n",
      "batch 3691: loss 0.331630\n",
      "batch 3692: loss 0.337428\n",
      "batch 3693: loss 0.567928\n",
      "batch 3694: loss 0.296448\n",
      "batch 3695: loss 0.296977\n",
      "batch 3696: loss 0.401328\n",
      "batch 3697: loss 0.307099\n",
      "batch 3698: loss 0.424890\n",
      "batch 3699: loss 0.543496\n",
      "batch 3700: loss 0.535993\n",
      "batch 3701: loss 0.563158\n",
      "batch 3702: loss 0.434098\n",
      "batch 3703: loss 0.294427\n",
      "batch 3704: loss 0.377165\n",
      "batch 3705: loss 0.409237\n",
      "batch 3706: loss 0.336295\n",
      "batch 3707: loss 0.335792\n",
      "batch 3708: loss 0.433729\n",
      "batch 3709: loss 0.332973\n",
      "batch 3710: loss 0.473153\n",
      "batch 3711: loss 0.367173\n",
      "batch 3712: loss 0.318022\n",
      "batch 3713: loss 0.538600\n",
      "batch 3714: loss 0.505307\n",
      "batch 3715: loss 0.384619\n",
      "batch 3716: loss 0.454926\n",
      "batch 3717: loss 0.509953\n",
      "batch 3718: loss 0.782978\n",
      "batch 3719: loss 0.278777\n",
      "batch 3720: loss 0.380013\n",
      "batch 3721: loss 0.465252\n",
      "batch 3722: loss 0.274099\n",
      "batch 3723: loss 0.393370\n",
      "batch 3724: loss 0.383135\n",
      "batch 3725: loss 0.402170\n",
      "batch 3726: loss 0.518036\n",
      "batch 3727: loss 0.380168\n",
      "batch 3728: loss 0.437467\n",
      "batch 3729: loss 0.389803\n",
      "batch 3730: loss 0.338199\n",
      "batch 3731: loss 0.416110\n",
      "batch 3732: loss 0.403841\n",
      "batch 3733: loss 0.308211\n",
      "batch 3734: loss 0.343398\n",
      "batch 3735: loss 0.262620\n",
      "batch 3736: loss 0.286097\n",
      "batch 3737: loss 0.334021\n",
      "batch 3738: loss 0.602088\n",
      "batch 3739: loss 0.195527\n",
      "batch 3740: loss 0.491320\n",
      "batch 3741: loss 0.448886\n",
      "batch 3742: loss 0.323626\n",
      "batch 3743: loss 0.344455\n",
      "batch 3744: loss 0.584077\n",
      "batch 3745: loss 0.418227\n",
      "batch 3746: loss 0.536548\n",
      "batch 3747: loss 0.410413\n",
      "batch 3748: loss 0.490841\n",
      "batch 3749: loss 0.437944\n",
      "batch 3750: loss 0.433333\n",
      "batch 3751: loss 0.416381\n",
      "batch 3752: loss 0.324378\n",
      "batch 3753: loss 0.393160\n",
      "batch 3754: loss 0.368387\n",
      "batch 3755: loss 0.330415\n",
      "batch 3756: loss 0.325097\n",
      "batch 3757: loss 0.310565\n",
      "batch 3758: loss 0.339693\n",
      "batch 3759: loss 0.378719\n",
      "batch 3760: loss 0.456748\n",
      "batch 3761: loss 0.436916\n",
      "batch 3762: loss 0.491794\n",
      "batch 3763: loss 0.366432\n",
      "batch 3764: loss 0.306468\n",
      "batch 3765: loss 0.588946\n",
      "batch 3766: loss 0.452355\n",
      "batch 3767: loss 0.361040\n",
      "batch 3768: loss 0.452038\n",
      "batch 3769: loss 0.480315\n",
      "batch 3770: loss 0.385153\n",
      "batch 3771: loss 0.470379\n",
      "batch 3772: loss 0.352889\n",
      "batch 3773: loss 0.401906\n",
      "batch 3774: loss 0.480399\n",
      "batch 3775: loss 0.503967\n",
      "batch 3776: loss 0.390940\n",
      "batch 3777: loss 0.510361\n",
      "batch 3778: loss 0.334246\n",
      "batch 3779: loss 0.438530\n",
      "batch 3780: loss 0.406420\n",
      "batch 3781: loss 0.436889\n",
      "batch 3782: loss 0.302991\n",
      "batch 3783: loss 0.421069\n",
      "batch 3784: loss 0.383502\n",
      "batch 3785: loss 0.490902\n",
      "batch 3786: loss 0.407881\n",
      "batch 3787: loss 0.322697\n",
      "batch 3788: loss 0.451640\n",
      "batch 3789: loss 0.366024\n",
      "batch 3790: loss 0.345398\n",
      "batch 3791: loss 0.382472\n",
      "batch 3792: loss 0.357268\n",
      "batch 3793: loss 0.613401\n",
      "batch 3794: loss 0.502100\n",
      "batch 3795: loss 0.703342\n",
      "batch 3796: loss 0.377419\n",
      "batch 3797: loss 0.562777\n",
      "batch 3798: loss 0.329127\n",
      "batch 3799: loss 0.536679\n",
      "batch 3800: loss 0.542505\n",
      "batch 3801: loss 0.361988\n",
      "batch 3802: loss 0.488336\n",
      "batch 3803: loss 0.608157\n",
      "batch 3804: loss 0.337300\n",
      "batch 3805: loss 0.504171\n",
      "batch 3806: loss 0.585501\n",
      "batch 3807: loss 0.307553\n",
      "batch 3808: loss 0.356447\n",
      "batch 3809: loss 0.506751\n",
      "batch 3810: loss 0.397991\n",
      "batch 3811: loss 0.398342\n",
      "batch 3812: loss 0.444518\n",
      "batch 3813: loss 0.285387\n",
      "batch 3814: loss 0.415891\n",
      "batch 3815: loss 0.392651\n",
      "batch 3816: loss 0.344153\n",
      "batch 3817: loss 0.353840\n",
      "batch 3818: loss 0.321489\n",
      "batch 3819: loss 0.294300\n",
      "batch 3820: loss 0.564021\n",
      "batch 3821: loss 0.472164\n",
      "batch 3822: loss 0.434020\n",
      "batch 3823: loss 0.498211\n",
      "batch 3824: loss 0.265437\n",
      "batch 3825: loss 0.426809\n",
      "batch 3826: loss 0.651412\n",
      "batch 3827: loss 0.414156\n",
      "batch 3828: loss 0.397019\n",
      "batch 3829: loss 0.396958\n",
      "batch 3830: loss 0.519530\n",
      "batch 3831: loss 0.534591\n",
      "batch 3832: loss 0.380514\n",
      "batch 3833: loss 0.396315\n",
      "batch 3834: loss 0.303196\n",
      "batch 3835: loss 0.346691\n",
      "batch 3836: loss 0.387635\n",
      "batch 3837: loss 0.384354\n",
      "batch 3838: loss 0.308186\n",
      "batch 3839: loss 0.528885\n",
      "batch 3840: loss 0.420311\n",
      "batch 3841: loss 0.411097\n",
      "batch 3842: loss 0.399596\n",
      "batch 3843: loss 0.440795\n",
      "batch 3844: loss 0.342367\n",
      "batch 3845: loss 0.604609\n",
      "batch 3846: loss 0.504998\n",
      "batch 3847: loss 0.210461\n",
      "batch 3848: loss 0.361210\n",
      "batch 3849: loss 0.403517\n",
      "batch 3850: loss 0.424822\n",
      "batch 3851: loss 0.221088\n",
      "batch 3852: loss 0.311762\n",
      "batch 3853: loss 0.390139\n",
      "batch 3854: loss 0.376187\n",
      "batch 3855: loss 0.450650\n",
      "batch 3856: loss 0.344281\n",
      "batch 3857: loss 0.367363\n",
      "batch 3858: loss 0.533640\n",
      "batch 3859: loss 0.559034\n",
      "batch 3860: loss 0.500106\n",
      "batch 3861: loss 0.723816\n",
      "batch 3862: loss 0.400015\n",
      "batch 3863: loss 0.514557\n",
      "batch 3864: loss 0.302403\n",
      "batch 3865: loss 0.463468\n",
      "batch 3866: loss 0.381539\n",
      "batch 3867: loss 0.604128\n",
      "batch 3868: loss 0.372594\n",
      "batch 3869: loss 0.497480\n",
      "batch 3870: loss 0.497635\n",
      "batch 3871: loss 0.577936\n",
      "batch 3872: loss 0.229453\n",
      "batch 3873: loss 0.463479\n",
      "batch 3874: loss 0.286482\n",
      "batch 3875: loss 0.389081\n",
      "batch 3876: loss 0.537432\n",
      "batch 3877: loss 0.246344\n",
      "batch 3878: loss 0.389198\n",
      "batch 3879: loss 0.526187\n",
      "batch 3880: loss 0.321648\n",
      "batch 3881: loss 0.436973\n",
      "batch 3882: loss 0.514236\n",
      "batch 3883: loss 0.476595\n",
      "batch 3884: loss 0.422873\n",
      "batch 3885: loss 0.413344\n",
      "batch 3886: loss 0.476620\n",
      "batch 3887: loss 0.502313\n",
      "batch 3888: loss 0.309323\n",
      "batch 3889: loss 0.369396\n",
      "batch 3890: loss 0.435643\n",
      "batch 3891: loss 0.500651\n",
      "batch 3892: loss 0.271894\n",
      "batch 3893: loss 0.236597\n",
      "batch 3894: loss 0.421046\n",
      "batch 3895: loss 0.530222\n",
      "batch 3896: loss 0.421073\n",
      "batch 3897: loss 0.467746\n",
      "batch 3898: loss 0.347235\n",
      "batch 3899: loss 0.452241\n",
      "batch 3900: loss 0.288854\n",
      "batch 3901: loss 0.488689\n",
      "batch 3902: loss 0.529614\n",
      "batch 3903: loss 0.578970\n",
      "batch 3904: loss 0.313067\n",
      "batch 3905: loss 0.693696\n",
      "batch 3906: loss 0.385144\n",
      "batch 3907: loss 0.455661\n",
      "batch 3908: loss 0.437477\n",
      "batch 3909: loss 0.467571\n",
      "batch 3910: loss 0.396127\n",
      "batch 3911: loss 0.529652\n",
      "batch 3912: loss 0.567952\n",
      "batch 3913: loss 0.260738\n",
      "batch 3914: loss 0.366283\n",
      "batch 3915: loss 0.371818\n",
      "batch 3916: loss 0.240628\n",
      "batch 3917: loss 0.212829\n",
      "batch 3918: loss 0.301841\n",
      "batch 3919: loss 0.270565\n",
      "batch 3920: loss 0.258984\n",
      "batch 3921: loss 0.328152\n",
      "batch 3922: loss 0.543074\n",
      "batch 3923: loss 0.263538\n",
      "batch 3924: loss 0.493036\n",
      "batch 3925: loss 0.340430\n",
      "batch 3926: loss 0.389298\n",
      "batch 3927: loss 0.456725\n",
      "batch 3928: loss 0.301763\n",
      "batch 3929: loss 0.460540\n",
      "batch 3930: loss 0.470697\n",
      "batch 3931: loss 0.403091\n",
      "batch 3932: loss 0.282982\n",
      "batch 3933: loss 0.504406\n",
      "batch 3934: loss 0.364262\n",
      "batch 3935: loss 0.381403\n",
      "batch 3936: loss 0.417853\n",
      "batch 3937: loss 0.371175\n",
      "batch 3938: loss 0.394278\n",
      "batch 3939: loss 0.346799\n",
      "batch 3940: loss 0.275090\n",
      "batch 3941: loss 0.226788\n",
      "batch 3942: loss 0.354851\n",
      "batch 3943: loss 0.501391\n",
      "batch 3944: loss 0.275031\n",
      "batch 3945: loss 0.448250\n",
      "batch 3946: loss 0.410605\n",
      "batch 3947: loss 0.325264\n",
      "batch 3948: loss 0.404051\n",
      "batch 3949: loss 0.699718\n",
      "batch 3950: loss 0.301438\n",
      "batch 3951: loss 0.376029\n",
      "batch 3952: loss 0.341111\n",
      "batch 3953: loss 0.531531\n",
      "batch 3954: loss 0.309908\n",
      "batch 3955: loss 0.331151\n",
      "batch 3956: loss 0.392019\n",
      "batch 3957: loss 0.340968\n",
      "batch 3958: loss 0.537788\n",
      "batch 3959: loss 0.465798\n",
      "batch 3960: loss 0.365011\n",
      "batch 3961: loss 0.271124\n",
      "batch 3962: loss 0.363140\n",
      "batch 3963: loss 0.297654\n",
      "batch 3964: loss 0.209147\n",
      "batch 3965: loss 0.224939\n",
      "batch 3966: loss 0.394334\n",
      "batch 3967: loss 0.372109\n",
      "batch 3968: loss 0.475882\n",
      "batch 3969: loss 0.315696\n",
      "batch 3970: loss 0.197297\n",
      "batch 3971: loss 0.379700\n",
      "batch 3972: loss 0.303117\n",
      "batch 3973: loss 0.390924\n",
      "batch 3974: loss 0.393182\n",
      "batch 3975: loss 0.510592\n",
      "batch 3976: loss 0.418176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3977: loss 0.339728\n",
      "batch 3978: loss 0.303424\n",
      "batch 3979: loss 0.494425\n",
      "batch 3980: loss 0.269457\n",
      "batch 3981: loss 0.363186\n",
      "batch 3982: loss 0.233008\n",
      "batch 3983: loss 0.270126\n",
      "batch 3984: loss 0.354621\n",
      "batch 3985: loss 0.573781\n",
      "batch 3986: loss 0.410201\n",
      "batch 3987: loss 0.239675\n",
      "batch 3988: loss 0.383390\n",
      "batch 3989: loss 0.428591\n",
      "batch 3990: loss 0.425735\n",
      "batch 3991: loss 0.302080\n",
      "batch 3992: loss 0.321965\n",
      "batch 3993: loss 0.281339\n",
      "batch 3994: loss 0.212742\n",
      "batch 3995: loss 0.323592\n",
      "batch 3996: loss 0.431495\n",
      "batch 3997: loss 0.251212\n",
      "batch 3998: loss 0.438252\n",
      "batch 3999: loss 0.464646\n",
      "batch 4000: loss 0.318504\n",
      "batch 4001: loss 0.544564\n",
      "batch 4002: loss 0.374876\n",
      "batch 4003: loss 0.560401\n",
      "batch 4004: loss 0.370529\n",
      "batch 4005: loss 0.482095\n",
      "batch 4006: loss 0.592365\n",
      "batch 4007: loss 0.334088\n",
      "batch 4008: loss 0.306336\n",
      "batch 4009: loss 0.432720\n",
      "batch 4010: loss 0.551179\n",
      "batch 4011: loss 0.233611\n",
      "batch 4012: loss 0.343728\n",
      "batch 4013: loss 0.534131\n",
      "batch 4014: loss 0.250609\n",
      "batch 4015: loss 0.362414\n",
      "batch 4016: loss 0.306679\n",
      "batch 4017: loss 0.379044\n",
      "batch 4018: loss 0.442642\n",
      "batch 4019: loss 0.558954\n",
      "batch 4020: loss 0.586799\n",
      "batch 4021: loss 0.297296\n",
      "batch 4022: loss 0.324701\n",
      "batch 4023: loss 0.407331\n",
      "batch 4024: loss 0.322766\n",
      "batch 4025: loss 0.419518\n",
      "batch 4026: loss 0.453131\n",
      "batch 4027: loss 0.229972\n",
      "batch 4028: loss 0.241665\n",
      "batch 4029: loss 0.517921\n",
      "batch 4030: loss 0.447163\n",
      "batch 4031: loss 0.479762\n",
      "batch 4032: loss 0.338580\n",
      "batch 4033: loss 0.341884\n",
      "batch 4034: loss 0.502528\n",
      "batch 4035: loss 0.290592\n",
      "batch 4036: loss 0.423058\n",
      "batch 4037: loss 0.469691\n",
      "batch 4038: loss 0.411018\n",
      "batch 4039: loss 0.388506\n",
      "batch 4040: loss 0.278243\n",
      "batch 4041: loss 0.445902\n",
      "batch 4042: loss 0.271573\n",
      "batch 4043: loss 0.447645\n",
      "batch 4044: loss 0.323476\n",
      "batch 4045: loss 0.342309\n",
      "batch 4046: loss 0.401430\n",
      "batch 4047: loss 0.607957\n",
      "batch 4048: loss 0.476932\n",
      "batch 4049: loss 0.205976\n",
      "batch 4050: loss 0.329929\n",
      "batch 4051: loss 0.167405\n",
      "batch 4052: loss 0.390781\n",
      "batch 4053: loss 0.482222\n",
      "batch 4054: loss 0.541916\n",
      "batch 4055: loss 0.289608\n",
      "batch 4056: loss 0.620684\n",
      "batch 4057: loss 0.314113\n",
      "batch 4058: loss 0.355107\n",
      "batch 4059: loss 0.311996\n",
      "batch 4060: loss 0.539332\n",
      "batch 4061: loss 0.464950\n",
      "batch 4062: loss 0.328528\n",
      "batch 4063: loss 0.357032\n",
      "batch 4064: loss 0.439694\n",
      "batch 4065: loss 0.418785\n",
      "batch 4066: loss 0.359086\n",
      "batch 4067: loss 0.427428\n",
      "batch 4068: loss 0.442239\n",
      "batch 4069: loss 0.512610\n",
      "batch 4070: loss 0.454583\n",
      "batch 4071: loss 0.325539\n",
      "batch 4072: loss 0.460988\n",
      "batch 4073: loss 0.570747\n",
      "batch 4074: loss 0.412088\n",
      "batch 4075: loss 0.370671\n",
      "batch 4076: loss 0.305329\n",
      "batch 4077: loss 0.324443\n",
      "batch 4078: loss 0.481098\n",
      "batch 4079: loss 0.501123\n",
      "batch 4080: loss 0.361635\n",
      "batch 4081: loss 0.420482\n",
      "batch 4082: loss 0.378231\n",
      "batch 4083: loss 0.558628\n",
      "batch 4084: loss 0.349839\n",
      "batch 4085: loss 0.411232\n",
      "batch 4086: loss 0.609914\n",
      "batch 4087: loss 0.400866\n",
      "batch 4088: loss 0.416582\n",
      "batch 4089: loss 0.444154\n",
      "batch 4090: loss 0.278077\n",
      "batch 4091: loss 0.221921\n",
      "batch 4092: loss 0.321968\n",
      "batch 4093: loss 0.494461\n",
      "batch 4094: loss 0.449056\n",
      "batch 4095: loss 0.291433\n",
      "batch 4096: loss 0.441936\n",
      "batch 4097: loss 0.473340\n",
      "batch 4098: loss 0.534067\n",
      "batch 4099: loss 0.513084\n",
      "batch 4100: loss 0.622434\n",
      "batch 4101: loss 0.340275\n",
      "batch 4102: loss 0.277326\n",
      "batch 4103: loss 0.355006\n",
      "batch 4104: loss 0.474761\n",
      "batch 4105: loss 0.503067\n",
      "batch 4106: loss 0.274342\n",
      "batch 4107: loss 0.371415\n",
      "batch 4108: loss 0.491233\n",
      "batch 4109: loss 0.645150\n",
      "batch 4110: loss 0.394039\n",
      "batch 4111: loss 0.256196\n",
      "batch 4112: loss 0.596694\n",
      "batch 4113: loss 0.298948\n",
      "batch 4114: loss 0.383401\n",
      "batch 4115: loss 0.305918\n",
      "batch 4116: loss 0.301081\n",
      "batch 4117: loss 0.265265\n",
      "batch 4118: loss 0.508334\n",
      "batch 4119: loss 0.397038\n",
      "batch 4120: loss 0.430454\n",
      "batch 4121: loss 0.371857\n",
      "batch 4122: loss 0.245795\n",
      "batch 4123: loss 0.288572\n",
      "batch 4124: loss 0.417365\n",
      "batch 4125: loss 0.419727\n",
      "batch 4126: loss 0.518043\n",
      "batch 4127: loss 0.330392\n",
      "batch 4128: loss 0.463121\n",
      "batch 4129: loss 0.309380\n",
      "batch 4130: loss 0.494416\n",
      "batch 4131: loss 0.244864\n",
      "batch 4132: loss 0.569674\n",
      "batch 4133: loss 0.210746\n",
      "batch 4134: loss 0.331013\n",
      "batch 4135: loss 0.245647\n",
      "batch 4136: loss 0.378202\n",
      "batch 4137: loss 0.308223\n",
      "batch 4138: loss 0.275011\n",
      "batch 4139: loss 0.411855\n",
      "batch 4140: loss 0.345593\n",
      "batch 4141: loss 0.378278\n",
      "batch 4142: loss 0.311200\n",
      "batch 4143: loss 0.504184\n",
      "batch 4144: loss 0.613223\n",
      "batch 4145: loss 0.349081\n",
      "batch 4146: loss 0.342369\n",
      "batch 4147: loss 0.515826\n",
      "batch 4148: loss 0.360009\n",
      "batch 4149: loss 0.306511\n",
      "batch 4150: loss 0.481114\n",
      "batch 4151: loss 0.249700\n",
      "batch 4152: loss 0.405988\n",
      "batch 4153: loss 0.546783\n",
      "batch 4154: loss 0.464193\n",
      "batch 4155: loss 0.360593\n",
      "batch 4156: loss 0.268319\n",
      "batch 4157: loss 0.233020\n",
      "batch 4158: loss 0.305931\n",
      "batch 4159: loss 0.611192\n",
      "batch 4160: loss 0.450615\n",
      "batch 4161: loss 0.556153\n",
      "batch 4162: loss 0.640209\n",
      "batch 4163: loss 0.738465\n",
      "batch 4164: loss 0.433679\n",
      "batch 4165: loss 0.302584\n",
      "batch 4166: loss 0.354138\n",
      "batch 4167: loss 0.267474\n",
      "batch 4168: loss 0.359844\n",
      "batch 4169: loss 0.308101\n",
      "batch 4170: loss 0.471051\n",
      "batch 4171: loss 0.369726\n",
      "batch 4172: loss 0.642577\n",
      "batch 4173: loss 0.300807\n",
      "batch 4174: loss 0.407890\n",
      "batch 4175: loss 0.341014\n",
      "batch 4176: loss 0.495955\n",
      "batch 4177: loss 0.490465\n",
      "batch 4178: loss 0.514652\n",
      "batch 4179: loss 0.426500\n",
      "batch 4180: loss 0.439621\n",
      "batch 4181: loss 0.408453\n",
      "batch 4182: loss 0.477548\n",
      "batch 4183: loss 0.479439\n",
      "batch 4184: loss 0.317129\n",
      "batch 4185: loss 0.415284\n",
      "batch 4186: loss 0.466775\n",
      "batch 4187: loss 0.254717\n",
      "batch 4188: loss 0.369258\n",
      "batch 4189: loss 0.418875\n",
      "batch 4190: loss 0.481428\n",
      "batch 4191: loss 0.290324\n",
      "batch 4192: loss 0.427089\n",
      "batch 4193: loss 0.237359\n",
      "batch 4194: loss 0.477427\n",
      "batch 4195: loss 0.377664\n",
      "batch 4196: loss 0.444446\n",
      "batch 4197: loss 0.314629\n",
      "batch 4198: loss 0.553727\n",
      "batch 4199: loss 0.319384\n",
      "batch 4200: loss 0.351606\n",
      "batch 4201: loss 0.382898\n",
      "batch 4202: loss 0.404887\n",
      "batch 4203: loss 0.335946\n",
      "batch 4204: loss 0.367603\n",
      "batch 4205: loss 0.239699\n",
      "batch 4206: loss 0.356712\n",
      "batch 4207: loss 0.281486\n",
      "batch 4208: loss 0.229990\n",
      "batch 4209: loss 0.355187\n",
      "batch 4210: loss 0.573841\n",
      "batch 4211: loss 0.249678\n",
      "batch 4212: loss 0.344760\n",
      "batch 4213: loss 0.319509\n",
      "batch 4214: loss 0.377043\n",
      "batch 4215: loss 0.389479\n",
      "batch 4216: loss 0.469131\n",
      "batch 4217: loss 0.240030\n",
      "batch 4218: loss 0.479632\n",
      "batch 4219: loss 0.263516\n",
      "batch 4220: loss 0.454835\n",
      "batch 4221: loss 0.367579\n",
      "batch 4222: loss 0.433593\n",
      "batch 4223: loss 0.393026\n",
      "batch 4224: loss 0.369855\n",
      "batch 4225: loss 0.370955\n",
      "batch 4226: loss 0.342642\n",
      "batch 4227: loss 0.365676\n",
      "batch 4228: loss 0.538940\n",
      "batch 4229: loss 0.279029\n",
      "batch 4230: loss 0.346130\n",
      "batch 4231: loss 0.238527\n",
      "batch 4232: loss 0.416353\n",
      "batch 4233: loss 0.290628\n",
      "batch 4234: loss 0.343039\n",
      "batch 4235: loss 0.214210\n",
      "batch 4236: loss 0.640176\n",
      "batch 4237: loss 0.338574\n",
      "batch 4238: loss 0.265219\n",
      "batch 4239: loss 0.615795\n",
      "batch 4240: loss 0.285325\n",
      "batch 4241: loss 0.459620\n",
      "batch 4242: loss 0.349898\n",
      "batch 4243: loss 0.370274\n",
      "batch 4244: loss 0.225573\n",
      "batch 4245: loss 0.350474\n",
      "batch 4246: loss 0.476811\n",
      "batch 4247: loss 0.452783\n",
      "batch 4248: loss 0.342772\n",
      "batch 4249: loss 0.426118\n",
      "batch 4250: loss 0.360555\n",
      "batch 4251: loss 0.316857\n",
      "batch 4252: loss 0.440634\n",
      "batch 4253: loss 0.560600\n",
      "batch 4254: loss 0.546988\n",
      "batch 4255: loss 0.590450\n",
      "batch 4256: loss 0.256756\n",
      "batch 4257: loss 0.429559\n",
      "batch 4258: loss 0.303334\n",
      "batch 4259: loss 0.317485\n",
      "batch 4260: loss 0.333534\n",
      "batch 4261: loss 0.496671\n",
      "batch 4262: loss 0.414680\n",
      "batch 4263: loss 0.343926\n",
      "batch 4264: loss 0.412587\n",
      "batch 4265: loss 0.347763\n",
      "batch 4266: loss 0.260380\n",
      "batch 4267: loss 0.349412\n",
      "batch 4268: loss 0.331307\n",
      "batch 4269: loss 0.462036\n",
      "batch 4270: loss 0.513706\n",
      "batch 4271: loss 0.240766\n",
      "batch 4272: loss 0.614614\n",
      "batch 4273: loss 0.536001\n",
      "batch 4274: loss 0.338164\n",
      "batch 4275: loss 0.438326\n",
      "batch 4276: loss 0.209490\n",
      "batch 4277: loss 0.370864\n",
      "batch 4278: loss 0.438498\n",
      "batch 4279: loss 0.433529\n",
      "batch 4280: loss 0.517860\n",
      "batch 4281: loss 0.423885\n",
      "batch 4282: loss 0.466766\n",
      "batch 4283: loss 0.302561\n",
      "batch 4284: loss 0.350561\n",
      "batch 4285: loss 0.339697\n",
      "batch 4286: loss 0.467799\n",
      "batch 4287: loss 0.370360\n",
      "batch 4288: loss 0.317657\n",
      "batch 4289: loss 0.481677\n",
      "batch 4290: loss 0.517914\n",
      "batch 4291: loss 0.252139\n",
      "batch 4292: loss 0.504193\n",
      "batch 4293: loss 0.283067\n",
      "batch 4294: loss 0.346583\n",
      "batch 4295: loss 0.369904\n",
      "batch 4296: loss 0.432559\n",
      "batch 4297: loss 0.596790\n",
      "batch 4298: loss 0.647191\n",
      "batch 4299: loss 0.397945\n",
      "batch 4300: loss 0.551722\n",
      "batch 4301: loss 0.450294\n",
      "batch 4302: loss 0.353559\n",
      "batch 4303: loss 0.494480\n",
      "batch 4304: loss 0.280890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4305: loss 0.492349\n",
      "batch 4306: loss 0.341485\n",
      "batch 4307: loss 0.224654\n",
      "batch 4308: loss 0.572678\n",
      "batch 4309: loss 0.402187\n",
      "batch 4310: loss 0.454493\n",
      "batch 4311: loss 0.367574\n",
      "batch 4312: loss 0.321174\n",
      "batch 4313: loss 0.526058\n",
      "batch 4314: loss 0.564040\n",
      "batch 4315: loss 0.358831\n",
      "batch 4316: loss 0.266949\n",
      "batch 4317: loss 0.387256\n",
      "batch 4318: loss 0.394190\n",
      "batch 4319: loss 0.287064\n",
      "batch 4320: loss 0.493180\n",
      "batch 4321: loss 0.576545\n",
      "batch 4322: loss 0.460745\n",
      "batch 4323: loss 0.381647\n",
      "batch 4324: loss 0.450013\n",
      "batch 4325: loss 0.450888\n",
      "batch 4326: loss 0.240113\n",
      "batch 4327: loss 0.400488\n",
      "batch 4328: loss 0.364525\n",
      "batch 4329: loss 0.375633\n",
      "batch 4330: loss 0.230152\n",
      "batch 4331: loss 0.365357\n",
      "batch 4332: loss 0.286259\n",
      "batch 4333: loss 0.485070\n",
      "batch 4334: loss 0.513365\n",
      "batch 4335: loss 0.570176\n",
      "batch 4336: loss 0.273327\n",
      "batch 4337: loss 0.238769\n",
      "batch 4338: loss 0.383948\n",
      "batch 4339: loss 0.283496\n",
      "batch 4340: loss 0.300418\n",
      "batch 4341: loss 0.221843\n",
      "batch 4342: loss 0.614572\n",
      "batch 4343: loss 0.409035\n",
      "batch 4344: loss 0.450659\n",
      "batch 4345: loss 0.289091\n",
      "batch 4346: loss 0.435849\n",
      "batch 4347: loss 0.391750\n",
      "batch 4348: loss 0.596468\n",
      "batch 4349: loss 0.485140\n",
      "batch 4350: loss 0.340420\n",
      "batch 4351: loss 0.388100\n",
      "batch 4352: loss 0.324121\n",
      "batch 4353: loss 0.546461\n",
      "batch 4354: loss 0.557318\n",
      "batch 4355: loss 0.337402\n",
      "batch 4356: loss 0.321553\n",
      "batch 4357: loss 0.460551\n",
      "batch 4358: loss 0.511911\n",
      "batch 4359: loss 0.338467\n",
      "batch 4360: loss 0.257154\n",
      "batch 4361: loss 0.473857\n",
      "batch 4362: loss 0.267880\n",
      "batch 4363: loss 0.344278\n",
      "batch 4364: loss 0.252740\n",
      "batch 4365: loss 0.501025\n",
      "batch 4366: loss 0.259745\n",
      "batch 4367: loss 0.280865\n",
      "batch 4368: loss 0.344774\n",
      "batch 4369: loss 0.324196\n",
      "batch 4370: loss 0.697297\n",
      "batch 4371: loss 0.392918\n",
      "batch 4372: loss 0.242215\n",
      "batch 4373: loss 0.374544\n",
      "batch 4374: loss 0.339243\n",
      "batch 4375: loss 0.404765\n",
      "batch 4376: loss 0.395000\n",
      "batch 4377: loss 0.392988\n",
      "batch 4378: loss 0.740736\n",
      "batch 4379: loss 0.570115\n",
      "batch 4380: loss 0.586559\n",
      "batch 4381: loss 0.650028\n",
      "batch 4382: loss 0.296683\n",
      "batch 4383: loss 0.240157\n",
      "batch 4384: loss 0.397145\n",
      "batch 4385: loss 0.320128\n",
      "batch 4386: loss 0.345286\n",
      "batch 4387: loss 0.467902\n",
      "batch 4388: loss 0.328074\n",
      "batch 4389: loss 0.565005\n",
      "batch 4390: loss 0.306069\n",
      "batch 4391: loss 0.377875\n",
      "batch 4392: loss 0.248335\n",
      "batch 4393: loss 0.349510\n",
      "batch 4394: loss 0.529496\n",
      "batch 4395: loss 0.250502\n",
      "batch 4396: loss 0.285024\n",
      "batch 4397: loss 0.543517\n",
      "batch 4398: loss 0.480631\n",
      "batch 4399: loss 0.358828\n",
      "batch 4400: loss 0.332760\n",
      "batch 4401: loss 0.519659\n",
      "batch 4402: loss 0.327837\n",
      "batch 4403: loss 0.313989\n",
      "batch 4404: loss 0.530462\n",
      "batch 4405: loss 0.478552\n",
      "batch 4406: loss 0.546344\n",
      "batch 4407: loss 0.400310\n",
      "batch 4408: loss 0.346842\n",
      "batch 4409: loss 0.362198\n",
      "batch 4410: loss 0.329750\n",
      "batch 4411: loss 0.554468\n",
      "batch 4412: loss 0.353373\n",
      "batch 4413: loss 0.528072\n",
      "batch 4414: loss 0.347109\n",
      "batch 4415: loss 0.689683\n",
      "batch 4416: loss 0.394454\n",
      "batch 4417: loss 0.300924\n",
      "batch 4418: loss 0.307372\n",
      "batch 4419: loss 0.329419\n",
      "batch 4420: loss 0.358532\n",
      "batch 4421: loss 0.333072\n",
      "batch 4422: loss 0.229333\n",
      "batch 4423: loss 0.477407\n",
      "batch 4424: loss 0.416818\n",
      "batch 4425: loss 0.387256\n",
      "batch 4426: loss 0.293336\n",
      "batch 4427: loss 0.420630\n",
      "batch 4428: loss 0.320146\n",
      "batch 4429: loss 0.343105\n",
      "batch 4430: loss 0.349876\n",
      "batch 4431: loss 0.520446\n",
      "batch 4432: loss 0.445066\n",
      "batch 4433: loss 0.403893\n",
      "batch 4434: loss 0.578501\n",
      "batch 4435: loss 0.456820\n",
      "batch 4436: loss 0.473628\n",
      "batch 4437: loss 0.462354\n",
      "batch 4438: loss 0.594390\n",
      "batch 4439: loss 0.597542\n",
      "batch 4440: loss 0.308252\n",
      "batch 4441: loss 0.583985\n",
      "batch 4442: loss 0.403141\n",
      "batch 4443: loss 0.403686\n",
      "batch 4444: loss 0.333389\n",
      "batch 4445: loss 0.378027\n",
      "batch 4446: loss 0.229138\n",
      "batch 4447: loss 0.250100\n",
      "batch 4448: loss 0.330118\n",
      "batch 4449: loss 0.417029\n",
      "batch 4450: loss 0.249769\n",
      "batch 4451: loss 0.318101\n",
      "batch 4452: loss 0.285431\n",
      "batch 4453: loss 0.313857\n",
      "batch 4454: loss 0.231823\n",
      "batch 4455: loss 0.326298\n",
      "batch 4456: loss 0.389801\n",
      "batch 4457: loss 0.502575\n",
      "batch 4458: loss 0.282296\n",
      "batch 4459: loss 0.584053\n",
      "batch 4460: loss 0.417430\n",
      "batch 4461: loss 0.513463\n",
      "batch 4462: loss 0.274809\n",
      "batch 4463: loss 0.242018\n",
      "batch 4464: loss 0.365958\n",
      "batch 4465: loss 0.262577\n",
      "batch 4466: loss 0.238652\n",
      "batch 4467: loss 0.405346\n",
      "batch 4468: loss 0.343940\n",
      "batch 4469: loss 0.234871\n",
      "batch 4470: loss 0.303748\n",
      "batch 4471: loss 0.421510\n",
      "batch 4472: loss 0.482265\n",
      "batch 4473: loss 0.415002\n",
      "batch 4474: loss 0.349565\n",
      "batch 4475: loss 0.225320\n",
      "batch 4476: loss 0.352344\n",
      "batch 4477: loss 0.304941\n",
      "batch 4478: loss 0.499780\n",
      "batch 4479: loss 0.297992\n",
      "batch 4480: loss 0.342389\n",
      "batch 4481: loss 0.286135\n",
      "batch 4482: loss 0.641874\n",
      "batch 4483: loss 0.480356\n",
      "batch 4484: loss 0.307886\n",
      "batch 4485: loss 0.429829\n",
      "batch 4486: loss 0.241945\n",
      "batch 4487: loss 0.280098\n",
      "batch 4488: loss 0.366242\n",
      "batch 4489: loss 0.288890\n",
      "batch 4490: loss 0.609392\n",
      "batch 4491: loss 0.362197\n",
      "batch 4492: loss 0.582813\n",
      "batch 4493: loss 0.225774\n",
      "batch 4494: loss 0.443055\n",
      "batch 4495: loss 0.388055\n",
      "batch 4496: loss 0.187958\n",
      "batch 4497: loss 0.583485\n",
      "batch 4498: loss 0.231212\n",
      "batch 4499: loss 0.385312\n",
      "batch 4500: loss 0.418902\n",
      "batch 4501: loss 0.409887\n",
      "batch 4502: loss 0.463968\n",
      "batch 4503: loss 0.277094\n",
      "batch 4504: loss 0.433249\n",
      "batch 4505: loss 0.622147\n",
      "batch 4506: loss 0.323431\n",
      "batch 4507: loss 0.402822\n",
      "batch 4508: loss 0.263374\n",
      "batch 4509: loss 0.163765\n",
      "batch 4510: loss 0.379606\n",
      "batch 4511: loss 0.313218\n",
      "batch 4512: loss 0.264600\n",
      "batch 4513: loss 0.665760\n",
      "batch 4514: loss 0.255550\n",
      "batch 4515: loss 0.349726\n",
      "batch 4516: loss 0.336740\n",
      "batch 4517: loss 0.244686\n",
      "batch 4518: loss 0.352932\n",
      "batch 4519: loss 0.260470\n",
      "batch 4520: loss 0.286197\n",
      "batch 4521: loss 0.378847\n",
      "batch 4522: loss 0.438044\n",
      "batch 4523: loss 0.448854\n",
      "batch 4524: loss 0.451988\n",
      "batch 4525: loss 0.547259\n",
      "batch 4526: loss 0.476529\n",
      "batch 4527: loss 0.403094\n",
      "batch 4528: loss 0.546872\n",
      "batch 4529: loss 0.357742\n",
      "batch 4530: loss 0.264401\n",
      "batch 4531: loss 0.295889\n",
      "batch 4532: loss 0.500217\n",
      "batch 4533: loss 0.471145\n",
      "batch 4534: loss 0.364667\n",
      "batch 4535: loss 0.398427\n",
      "batch 4536: loss 0.524267\n",
      "batch 4537: loss 0.301852\n",
      "batch 4538: loss 0.221735\n",
      "batch 4539: loss 0.301362\n",
      "batch 4540: loss 0.334540\n",
      "batch 4541: loss 0.287833\n",
      "batch 4542: loss 0.289526\n",
      "batch 4543: loss 0.622441\n",
      "batch 4544: loss 0.448848\n",
      "batch 4545: loss 0.354435\n",
      "batch 4546: loss 0.260264\n",
      "batch 4547: loss 0.458108\n",
      "batch 4548: loss 0.366225\n",
      "batch 4549: loss 0.353676\n",
      "batch 4550: loss 0.197948\n",
      "batch 4551: loss 0.307094\n",
      "batch 4552: loss 0.371205\n",
      "batch 4553: loss 0.270651\n",
      "batch 4554: loss 0.366906\n",
      "batch 4555: loss 0.266646\n",
      "batch 4556: loss 0.370492\n",
      "batch 4557: loss 0.257280\n",
      "batch 4558: loss 0.301338\n",
      "batch 4559: loss 0.220586\n",
      "batch 4560: loss 0.535209\n",
      "batch 4561: loss 0.560431\n",
      "batch 4562: loss 0.347721\n",
      "batch 4563: loss 0.353949\n",
      "batch 4564: loss 0.449413\n",
      "batch 4565: loss 0.573129\n",
      "batch 4566: loss 0.368641\n",
      "batch 4567: loss 0.672880\n",
      "batch 4568: loss 0.342851\n",
      "batch 4569: loss 0.311068\n",
      "batch 4570: loss 0.405289\n",
      "batch 4571: loss 0.333103\n",
      "batch 4572: loss 0.285948\n",
      "batch 4573: loss 0.480824\n",
      "batch 4574: loss 0.227788\n",
      "batch 4575: loss 0.330206\n",
      "batch 4576: loss 0.550897\n",
      "batch 4577: loss 0.424937\n",
      "batch 4578: loss 0.574758\n",
      "batch 4579: loss 0.398886\n",
      "batch 4580: loss 0.383837\n",
      "batch 4581: loss 0.181980\n",
      "batch 4582: loss 0.462883\n",
      "batch 4583: loss 0.230517\n",
      "batch 4584: loss 0.364266\n",
      "batch 4585: loss 0.232569\n",
      "batch 4586: loss 0.643669\n",
      "batch 4587: loss 0.444390\n",
      "batch 4588: loss 0.360081\n",
      "batch 4589: loss 0.459392\n",
      "batch 4590: loss 0.465082\n",
      "batch 4591: loss 0.495089\n",
      "batch 4592: loss 0.345604\n",
      "batch 4593: loss 0.558861\n",
      "batch 4594: loss 0.323460\n",
      "batch 4595: loss 0.198493\n",
      "batch 4596: loss 0.491661\n",
      "batch 4597: loss 0.371224\n",
      "batch 4598: loss 0.562938\n",
      "batch 4599: loss 0.538239\n",
      "batch 4600: loss 0.358930\n",
      "batch 4601: loss 0.412503\n",
      "batch 4602: loss 0.271056\n",
      "batch 4603: loss 0.337465\n",
      "batch 4604: loss 0.365827\n",
      "batch 4605: loss 0.510280\n",
      "batch 4606: loss 0.478493\n",
      "batch 4607: loss 0.379584\n",
      "batch 4608: loss 0.227290\n",
      "batch 4609: loss 0.310875\n",
      "batch 4610: loss 0.260488\n",
      "batch 4611: loss 0.295030\n",
      "batch 4612: loss 0.373175\n",
      "batch 4613: loss 0.306278\n",
      "batch 4614: loss 0.447254\n",
      "batch 4615: loss 0.323134\n",
      "batch 4616: loss 0.321359\n",
      "batch 4617: loss 0.615603\n",
      "batch 4618: loss 0.318943\n",
      "batch 4619: loss 0.218884\n",
      "batch 4620: loss 0.418239\n",
      "batch 4621: loss 0.241086\n",
      "batch 4622: loss 0.294373\n",
      "batch 4623: loss 0.348459\n",
      "batch 4624: loss 0.376936\n",
      "batch 4625: loss 0.272684\n",
      "batch 4626: loss 0.533107\n",
      "batch 4627: loss 0.477372\n",
      "batch 4628: loss 0.338101\n",
      "batch 4629: loss 0.220893\n",
      "batch 4630: loss 0.346886\n",
      "batch 4631: loss 0.150915\n",
      "batch 4632: loss 0.259558\n",
      "batch 4633: loss 0.412416\n",
      "batch 4634: loss 0.592786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4635: loss 0.375206\n",
      "batch 4636: loss 0.588501\n",
      "batch 4637: loss 0.432065\n",
      "batch 4638: loss 0.321087\n",
      "batch 4639: loss 0.338004\n",
      "batch 4640: loss 0.288607\n",
      "batch 4641: loss 0.208908\n",
      "batch 4642: loss 0.162260\n",
      "batch 4643: loss 0.478978\n",
      "batch 4644: loss 0.434874\n",
      "batch 4645: loss 0.254572\n",
      "batch 4646: loss 0.324136\n",
      "batch 4647: loss 0.392964\n",
      "batch 4648: loss 0.577620\n",
      "batch 4649: loss 0.379867\n",
      "batch 4650: loss 0.344705\n",
      "batch 4651: loss 0.385163\n",
      "batch 4652: loss 0.278307\n",
      "batch 4653: loss 0.174207\n",
      "batch 4654: loss 0.334014\n",
      "batch 4655: loss 0.290537\n",
      "batch 4656: loss 0.239412\n",
      "batch 4657: loss 0.310337\n",
      "batch 4658: loss 0.475814\n",
      "batch 4659: loss 0.265721\n",
      "batch 4660: loss 0.329293\n",
      "batch 4661: loss 0.545681\n",
      "batch 4662: loss 0.245342\n",
      "batch 4663: loss 0.331637\n",
      "batch 4664: loss 0.324455\n",
      "batch 4665: loss 0.553482\n",
      "batch 4666: loss 0.674934\n",
      "batch 4667: loss 0.444207\n",
      "batch 4668: loss 0.296244\n",
      "batch 4669: loss 0.378837\n",
      "batch 4670: loss 0.271951\n",
      "batch 4671: loss 0.469290\n",
      "batch 4672: loss 0.519028\n",
      "batch 4673: loss 0.293120\n",
      "batch 4674: loss 0.420896\n",
      "batch 4675: loss 0.286507\n",
      "batch 4676: loss 0.407402\n",
      "batch 4677: loss 0.261476\n",
      "batch 4678: loss 0.309233\n",
      "batch 4679: loss 0.504974\n",
      "batch 4680: loss 0.399124\n",
      "batch 4681: loss 0.353903\n",
      "batch 4682: loss 0.330325\n",
      "batch 4683: loss 0.358547\n",
      "batch 4684: loss 0.238731\n",
      "batch 4685: loss 0.536953\n",
      "batch 4686: loss 0.297695\n",
      "batch 4687: loss 0.486628\n",
      "batch 4688: loss 0.321419\n",
      "batch 4689: loss 0.320910\n",
      "batch 4690: loss 0.245064\n",
      "batch 4691: loss 0.374487\n",
      "batch 4692: loss 0.474934\n",
      "batch 4693: loss 0.142552\n",
      "batch 4694: loss 0.216594\n",
      "batch 4695: loss 0.423452\n",
      "batch 4696: loss 0.474310\n",
      "batch 4697: loss 0.508148\n",
      "batch 4698: loss 0.390160\n",
      "batch 4699: loss 0.308024\n",
      "batch 4700: loss 0.315534\n",
      "batch 4701: loss 0.459292\n",
      "batch 4702: loss 0.274168\n",
      "batch 4703: loss 0.285255\n",
      "batch 4704: loss 0.454921\n",
      "batch 4705: loss 0.194938\n",
      "batch 4706: loss 0.431126\n",
      "batch 4707: loss 0.491690\n",
      "batch 4708: loss 0.282435\n",
      "batch 4709: loss 0.458861\n",
      "batch 4710: loss 0.303139\n",
      "batch 4711: loss 0.335639\n",
      "batch 4712: loss 0.285327\n",
      "batch 4713: loss 0.522325\n",
      "batch 4714: loss 0.466826\n",
      "batch 4715: loss 0.495068\n",
      "batch 4716: loss 0.401222\n",
      "batch 4717: loss 0.224179\n",
      "batch 4718: loss 0.361018\n",
      "batch 4719: loss 0.524205\n",
      "batch 4720: loss 0.419906\n",
      "batch 4721: loss 0.417984\n",
      "batch 4722: loss 0.312191\n",
      "batch 4723: loss 0.474767\n",
      "batch 4724: loss 0.463776\n",
      "batch 4725: loss 0.266874\n",
      "batch 4726: loss 0.339711\n",
      "batch 4727: loss 0.329881\n",
      "batch 4728: loss 0.343050\n",
      "batch 4729: loss 0.526391\n",
      "batch 4730: loss 0.307162\n",
      "batch 4731: loss 0.615508\n",
      "batch 4732: loss 0.430017\n",
      "batch 4733: loss 0.541096\n",
      "batch 4734: loss 0.472287\n",
      "batch 4735: loss 0.418079\n",
      "batch 4736: loss 0.325241\n",
      "batch 4737: loss 0.492699\n",
      "batch 4738: loss 0.516129\n",
      "batch 4739: loss 0.381840\n",
      "batch 4740: loss 0.421439\n",
      "batch 4741: loss 0.446136\n",
      "batch 4742: loss 0.440855\n",
      "batch 4743: loss 0.374726\n",
      "batch 4744: loss 0.648900\n",
      "batch 4745: loss 0.356134\n",
      "batch 4746: loss 0.403205\n",
      "batch 4747: loss 0.382625\n",
      "batch 4748: loss 0.327273\n",
      "batch 4749: loss 0.210039\n",
      "batch 4750: loss 0.397886\n",
      "batch 4751: loss 0.413634\n",
      "batch 4752: loss 0.301698\n",
      "batch 4753: loss 0.250126\n",
      "batch 4754: loss 0.277130\n",
      "batch 4755: loss 0.417918\n",
      "batch 4756: loss 0.287172\n",
      "batch 4757: loss 0.307913\n",
      "batch 4758: loss 0.471966\n",
      "batch 4759: loss 0.181999\n",
      "batch 4760: loss 0.433120\n",
      "batch 4761: loss 0.417052\n",
      "batch 4762: loss 0.586441\n",
      "batch 4763: loss 0.389517\n",
      "batch 4764: loss 0.215168\n",
      "batch 4765: loss 0.255785\n",
      "batch 4766: loss 0.334981\n",
      "batch 4767: loss 0.686621\n",
      "batch 4768: loss 0.493473\n",
      "batch 4769: loss 0.429769\n",
      "batch 4770: loss 0.466755\n",
      "batch 4771: loss 0.357187\n",
      "batch 4772: loss 0.561911\n",
      "batch 4773: loss 0.328148\n",
      "batch 4774: loss 0.505420\n",
      "batch 4775: loss 0.436346\n",
      "batch 4776: loss 0.538534\n",
      "batch 4777: loss 0.511600\n",
      "batch 4778: loss 0.199813\n",
      "batch 4779: loss 0.425741\n",
      "batch 4780: loss 0.462468\n",
      "batch 4781: loss 0.330455\n",
      "batch 4782: loss 0.272967\n",
      "batch 4783: loss 0.208272\n",
      "batch 4784: loss 0.571528\n",
      "batch 4785: loss 0.446306\n",
      "batch 4786: loss 0.287070\n",
      "batch 4787: loss 0.322515\n",
      "batch 4788: loss 0.164863\n",
      "batch 4789: loss 0.335417\n",
      "batch 4790: loss 0.228096\n",
      "batch 4791: loss 0.408416\n",
      "batch 4792: loss 0.455644\n",
      "batch 4793: loss 0.337324\n",
      "batch 4794: loss 0.178339\n",
      "batch 4795: loss 0.430114\n",
      "batch 4796: loss 0.313108\n",
      "batch 4797: loss 0.241822\n",
      "batch 4798: loss 0.333696\n",
      "batch 4799: loss 0.307395\n",
      "batch 4800: loss 0.376363\n",
      "batch 4801: loss 0.488034\n",
      "batch 4802: loss 0.332774\n",
      "batch 4803: loss 0.223364\n",
      "batch 4804: loss 0.304602\n",
      "batch 4805: loss 0.137447\n",
      "batch 4806: loss 0.541711\n",
      "batch 4807: loss 0.256289\n",
      "batch 4808: loss 0.342213\n",
      "batch 4809: loss 0.310924\n",
      "batch 4810: loss 0.373042\n",
      "batch 4811: loss 0.507169\n",
      "batch 4812: loss 0.495660\n",
      "batch 4813: loss 0.446798\n",
      "batch 4814: loss 0.267562\n",
      "batch 4815: loss 0.396349\n",
      "batch 4816: loss 0.499502\n",
      "batch 4817: loss 0.333079\n",
      "batch 4818: loss 0.230741\n",
      "batch 4819: loss 0.320186\n",
      "batch 4820: loss 0.552427\n",
      "batch 4821: loss 0.212174\n",
      "batch 4822: loss 0.371277\n",
      "batch 4823: loss 0.431477\n",
      "batch 4824: loss 0.415029\n",
      "batch 4825: loss 0.276738\n",
      "batch 4826: loss 0.377615\n",
      "batch 4827: loss 0.302097\n",
      "batch 4828: loss 0.306512\n",
      "batch 4829: loss 0.403644\n",
      "batch 4830: loss 0.303601\n",
      "batch 4831: loss 0.354421\n",
      "batch 4832: loss 0.213872\n",
      "batch 4833: loss 0.244690\n",
      "batch 4834: loss 0.340073\n",
      "batch 4835: loss 0.406335\n",
      "batch 4836: loss 0.305801\n",
      "batch 4837: loss 0.599057\n",
      "batch 4838: loss 0.342658\n",
      "batch 4839: loss 0.454753\n",
      "batch 4840: loss 0.332142\n",
      "batch 4841: loss 0.295707\n",
      "batch 4842: loss 0.437605\n",
      "batch 4843: loss 0.543379\n",
      "batch 4844: loss 0.592564\n",
      "batch 4845: loss 0.219286\n",
      "batch 4846: loss 0.222398\n",
      "batch 4847: loss 0.502785\n",
      "batch 4848: loss 0.386613\n",
      "batch 4849: loss 0.368485\n",
      "batch 4850: loss 0.649464\n",
      "batch 4851: loss 0.415957\n",
      "batch 4852: loss 0.368619\n",
      "batch 4853: loss 0.354838\n",
      "batch 4854: loss 0.532754\n",
      "batch 4855: loss 0.403802\n",
      "batch 4856: loss 0.289878\n",
      "batch 4857: loss 0.332900\n",
      "batch 4858: loss 0.374166\n",
      "batch 4859: loss 0.207765\n",
      "batch 4860: loss 0.297519\n",
      "batch 4861: loss 0.330122\n",
      "batch 4862: loss 0.295617\n",
      "batch 4863: loss 0.425540\n",
      "batch 4864: loss 0.193205\n",
      "batch 4865: loss 0.454701\n",
      "batch 4866: loss 0.351377\n",
      "batch 4867: loss 0.412740\n",
      "batch 4868: loss 0.340692\n",
      "batch 4869: loss 0.373049\n",
      "batch 4870: loss 0.479610\n",
      "batch 4871: loss 0.296062\n",
      "batch 4872: loss 0.272658\n",
      "batch 4873: loss 0.355125\n",
      "batch 4874: loss 0.467804\n",
      "batch 4875: loss 0.307934\n",
      "batch 4876: loss 0.346145\n",
      "batch 4877: loss 0.458254\n",
      "batch 4878: loss 0.176428\n",
      "batch 4879: loss 0.471096\n",
      "batch 4880: loss 0.344450\n",
      "batch 4881: loss 0.361081\n",
      "batch 4882: loss 0.346211\n",
      "batch 4883: loss 0.261146\n",
      "batch 4884: loss 0.237280\n",
      "batch 4885: loss 0.323338\n",
      "batch 4886: loss 0.281152\n",
      "batch 4887: loss 0.293471\n",
      "batch 4888: loss 0.352408\n",
      "batch 4889: loss 0.351259\n",
      "batch 4890: loss 0.510954\n",
      "batch 4891: loss 0.400881\n",
      "batch 4892: loss 0.427433\n",
      "batch 4893: loss 0.361525\n",
      "batch 4894: loss 0.457987\n",
      "batch 4895: loss 0.273877\n",
      "batch 4896: loss 0.499408\n",
      "batch 4897: loss 0.290505\n",
      "batch 4898: loss 0.391720\n",
      "batch 4899: loss 0.304985\n",
      "batch 4900: loss 0.376273\n",
      "batch 4901: loss 0.250777\n",
      "batch 4902: loss 0.457677\n",
      "batch 4903: loss 0.322367\n",
      "batch 4904: loss 0.352554\n",
      "batch 4905: loss 0.376163\n",
      "batch 4906: loss 0.494939\n",
      "batch 4907: loss 0.308356\n",
      "batch 4908: loss 0.263740\n",
      "batch 4909: loss 0.233930\n",
      "batch 4910: loss 0.253379\n",
      "batch 4911: loss 0.323754\n",
      "batch 4912: loss 0.236585\n",
      "batch 4913: loss 0.433192\n",
      "batch 4914: loss 0.422114\n",
      "batch 4915: loss 0.359192\n",
      "batch 4916: loss 0.340812\n",
      "batch 4917: loss 0.287963\n",
      "batch 4918: loss 0.487433\n",
      "batch 4919: loss 0.381011\n",
      "batch 4920: loss 0.503881\n",
      "batch 4921: loss 0.338035\n",
      "batch 4922: loss 0.227898\n",
      "batch 4923: loss 0.260982\n",
      "batch 4924: loss 0.463442\n",
      "batch 4925: loss 0.258047\n",
      "batch 4926: loss 0.441158\n",
      "batch 4927: loss 0.289148\n",
      "batch 4928: loss 0.403061\n",
      "batch 4929: loss 0.397253\n",
      "batch 4930: loss 0.362265\n",
      "batch 4931: loss 0.310516\n",
      "batch 4932: loss 0.429040\n",
      "batch 4933: loss 0.366939\n",
      "batch 4934: loss 0.348366\n",
      "batch 4935: loss 0.324050\n",
      "batch 4936: loss 0.204909\n",
      "batch 4937: loss 0.418145\n",
      "batch 4938: loss 0.370705\n",
      "batch 4939: loss 0.287011\n",
      "batch 4940: loss 0.330176\n",
      "batch 4941: loss 0.377841\n",
      "batch 4942: loss 0.275073\n",
      "batch 4943: loss 0.306529\n",
      "batch 4944: loss 0.428653\n",
      "batch 4945: loss 0.361833\n",
      "batch 4946: loss 0.322269\n",
      "batch 4947: loss 0.508908\n",
      "batch 4948: loss 0.425425\n",
      "batch 4949: loss 0.440668\n",
      "batch 4950: loss 0.449479\n",
      "batch 4951: loss 0.404862\n",
      "batch 4952: loss 0.234642\n",
      "batch 4953: loss 0.277965\n",
      "batch 4954: loss 0.389988\n",
      "batch 4955: loss 0.679725\n",
      "batch 4956: loss 0.328289\n",
      "batch 4957: loss 0.225993\n",
      "batch 4958: loss 0.387230\n",
      "batch 4959: loss 0.447909\n",
      "batch 4960: loss 0.259045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4961: loss 0.232262\n",
      "batch 4962: loss 0.400667\n",
      "batch 4963: loss 0.274248\n",
      "batch 4964: loss 0.309046\n",
      "batch 4965: loss 0.200455\n",
      "batch 4966: loss 0.352738\n",
      "batch 4967: loss 0.310184\n",
      "batch 4968: loss 0.267645\n",
      "batch 4969: loss 0.280052\n",
      "batch 4970: loss 0.345052\n",
      "batch 4971: loss 0.206470\n",
      "batch 4972: loss 0.439096\n",
      "batch 4973: loss 0.195030\n",
      "batch 4974: loss 0.614498\n",
      "batch 4975: loss 0.263709\n",
      "batch 4976: loss 0.342925\n",
      "batch 4977: loss 0.369374\n",
      "batch 4978: loss 0.768360\n",
      "batch 4979: loss 0.407379\n",
      "batch 4980: loss 0.314284\n",
      "batch 4981: loss 0.245948\n",
      "batch 4982: loss 0.388315\n",
      "batch 4983: loss 0.263710\n",
      "batch 4984: loss 0.592436\n",
      "batch 4985: loss 0.221680\n",
      "batch 4986: loss 0.259901\n",
      "batch 4987: loss 0.419136\n",
      "batch 4988: loss 0.257102\n",
      "batch 4989: loss 0.464214\n",
      "batch 4990: loss 0.548073\n",
      "batch 4991: loss 0.467024\n",
      "batch 4992: loss 0.224153\n",
      "batch 4993: loss 0.441127\n",
      "batch 4994: loss 0.328882\n",
      "batch 4995: loss 0.544309\n",
      "batch 4996: loss 0.293592\n",
      "batch 4997: loss 0.502163\n",
      "batch 4998: loss 0.371613\n",
      "batch 4999: loss 0.152663\n",
      "batch 5000: loss 0.390927\n",
      "batch 5001: loss 0.347322\n",
      "batch 5002: loss 0.233543\n",
      "batch 5003: loss 0.400708\n",
      "batch 5004: loss 0.239105\n",
      "batch 5005: loss 0.267270\n",
      "batch 5006: loss 0.346448\n",
      "batch 5007: loss 0.278333\n",
      "batch 5008: loss 0.368579\n",
      "batch 5009: loss 0.222530\n",
      "batch 5010: loss 0.364376\n",
      "batch 5011: loss 0.422137\n",
      "batch 5012: loss 0.341704\n",
      "batch 5013: loss 0.330279\n",
      "batch 5014: loss 0.213555\n",
      "batch 5015: loss 0.323667\n",
      "batch 5016: loss 0.434709\n",
      "batch 5017: loss 0.260613\n",
      "batch 5018: loss 0.337088\n",
      "batch 5019: loss 0.283773\n",
      "batch 5020: loss 0.326453\n",
      "batch 5021: loss 0.346717\n",
      "batch 5022: loss 0.327509\n",
      "batch 5023: loss 0.359056\n",
      "batch 5024: loss 0.309317\n",
      "batch 5025: loss 0.355822\n",
      "batch 5026: loss 0.262540\n",
      "batch 5027: loss 0.366262\n",
      "batch 5028: loss 0.260443\n",
      "batch 5029: loss 0.541359\n",
      "batch 5030: loss 0.501139\n",
      "batch 5031: loss 0.211667\n",
      "batch 5032: loss 0.259235\n",
      "batch 5033: loss 0.419345\n",
      "batch 5034: loss 0.239190\n",
      "batch 5035: loss 0.216911\n",
      "batch 5036: loss 0.274321\n",
      "batch 5037: loss 0.311164\n",
      "batch 5038: loss 0.309896\n",
      "batch 5039: loss 0.411657\n",
      "batch 5040: loss 0.442686\n",
      "batch 5041: loss 0.298157\n",
      "batch 5042: loss 0.309792\n",
      "batch 5043: loss 0.587288\n",
      "batch 5044: loss 0.322084\n",
      "batch 5045: loss 0.358135\n",
      "batch 5046: loss 0.392606\n",
      "batch 5047: loss 0.289232\n",
      "batch 5048: loss 0.388478\n",
      "batch 5049: loss 0.454848\n",
      "batch 5050: loss 0.417176\n",
      "batch 5051: loss 0.248331\n",
      "batch 5052: loss 0.285526\n",
      "batch 5053: loss 0.219760\n",
      "batch 5054: loss 0.259014\n",
      "batch 5055: loss 0.407733\n",
      "batch 5056: loss 0.412784\n",
      "batch 5057: loss 0.216103\n",
      "batch 5058: loss 0.268650\n",
      "batch 5059: loss 0.298655\n",
      "batch 5060: loss 0.270059\n",
      "batch 5061: loss 0.403621\n",
      "batch 5062: loss 0.302450\n",
      "batch 5063: loss 0.412627\n",
      "batch 5064: loss 0.393815\n",
      "batch 5065: loss 0.253459\n",
      "batch 5066: loss 0.339544\n",
      "batch 5067: loss 0.515114\n",
      "batch 5068: loss 0.406077\n",
      "batch 5069: loss 0.301927\n",
      "batch 5070: loss 0.323300\n",
      "batch 5071: loss 0.351804\n",
      "batch 5072: loss 0.325728\n",
      "batch 5073: loss 0.231756\n",
      "batch 5074: loss 0.193044\n",
      "batch 5075: loss 0.428884\n",
      "batch 5076: loss 0.472589\n",
      "batch 5077: loss 0.459607\n",
      "batch 5078: loss 0.366258\n",
      "batch 5079: loss 0.264014\n",
      "batch 5080: loss 0.264599\n",
      "batch 5081: loss 0.398118\n",
      "batch 5082: loss 0.597907\n",
      "batch 5083: loss 0.295954\n",
      "batch 5084: loss 0.444068\n",
      "batch 5085: loss 0.282605\n",
      "batch 5086: loss 0.511709\n",
      "batch 5087: loss 0.234763\n",
      "batch 5088: loss 0.357876\n",
      "batch 5089: loss 0.330456\n",
      "batch 5090: loss 0.210865\n",
      "batch 5091: loss 0.417496\n",
      "batch 5092: loss 0.417849\n",
      "batch 5093: loss 0.475606\n",
      "batch 5094: loss 0.403480\n",
      "batch 5095: loss 0.188269\n",
      "batch 5096: loss 0.253159\n",
      "batch 5097: loss 0.304347\n",
      "batch 5098: loss 0.301594\n",
      "batch 5099: loss 0.396107\n",
      "batch 5100: loss 0.613307\n",
      "batch 5101: loss 0.610824\n",
      "batch 5102: loss 0.382884\n",
      "batch 5103: loss 0.344623\n",
      "batch 5104: loss 0.191173\n",
      "batch 5105: loss 0.522882\n",
      "batch 5106: loss 0.337544\n",
      "batch 5107: loss 0.459710\n",
      "batch 5108: loss 0.296131\n",
      "batch 5109: loss 0.508317\n",
      "batch 5110: loss 0.316733\n",
      "batch 5111: loss 0.439319\n",
      "batch 5112: loss 0.333841\n",
      "batch 5113: loss 0.367714\n",
      "batch 5114: loss 0.288355\n",
      "batch 5115: loss 0.236405\n",
      "batch 5116: loss 0.345431\n",
      "batch 5117: loss 0.588211\n",
      "batch 5118: loss 0.231152\n",
      "batch 5119: loss 0.347720\n",
      "batch 5120: loss 0.304548\n",
      "batch 5121: loss 0.125827\n",
      "batch 5122: loss 0.299897\n",
      "batch 5123: loss 0.469788\n",
      "batch 5124: loss 0.448800\n",
      "batch 5125: loss 0.299700\n",
      "batch 5126: loss 0.239660\n",
      "batch 5127: loss 0.335021\n",
      "batch 5128: loss 0.232918\n",
      "batch 5129: loss 0.577697\n",
      "batch 5130: loss 0.350477\n",
      "batch 5131: loss 0.225130\n",
      "batch 5132: loss 0.359868\n",
      "batch 5133: loss 0.294739\n",
      "batch 5134: loss 0.149010\n",
      "batch 5135: loss 0.548852\n",
      "batch 5136: loss 0.213688\n",
      "batch 5137: loss 0.212425\n",
      "batch 5138: loss 0.392989\n",
      "batch 5139: loss 0.338104\n",
      "batch 5140: loss 0.468957\n",
      "batch 5141: loss 0.381379\n",
      "batch 5142: loss 0.357560\n",
      "batch 5143: loss 0.238504\n",
      "batch 5144: loss 0.193990\n",
      "batch 5145: loss 0.344919\n",
      "batch 5146: loss 0.353785\n",
      "batch 5147: loss 0.321091\n",
      "batch 5148: loss 0.469695\n",
      "batch 5149: loss 0.426239\n",
      "batch 5150: loss 0.511913\n",
      "batch 5151: loss 0.324971\n",
      "batch 5152: loss 0.366728\n",
      "batch 5153: loss 0.493249\n",
      "batch 5154: loss 0.397388\n",
      "batch 5155: loss 0.421279\n",
      "batch 5156: loss 0.294514\n",
      "batch 5157: loss 0.392769\n",
      "batch 5158: loss 0.486284\n",
      "batch 5159: loss 0.373220\n",
      "batch 5160: loss 0.273238\n",
      "batch 5161: loss 0.372227\n",
      "batch 5162: loss 0.413580\n",
      "batch 5163: loss 0.414799\n",
      "batch 5164: loss 0.229444\n",
      "batch 5165: loss 0.517207\n",
      "batch 5166: loss 0.367049\n",
      "batch 5167: loss 0.445912\n",
      "batch 5168: loss 0.501182\n",
      "batch 5169: loss 0.571992\n",
      "batch 5170: loss 0.264841\n",
      "batch 5171: loss 0.330089\n",
      "batch 5172: loss 0.254651\n",
      "batch 5173: loss 0.405679\n",
      "batch 5174: loss 0.225025\n",
      "batch 5175: loss 0.325708\n",
      "batch 5176: loss 0.453902\n",
      "batch 5177: loss 0.231535\n",
      "batch 5178: loss 0.528049\n",
      "batch 5179: loss 0.307862\n",
      "batch 5180: loss 0.331361\n",
      "batch 5181: loss 0.547689\n",
      "batch 5182: loss 0.434635\n",
      "batch 5183: loss 0.239818\n",
      "batch 5184: loss 0.304343\n",
      "batch 5185: loss 0.232011\n",
      "batch 5186: loss 0.351273\n",
      "batch 5187: loss 0.274979\n",
      "batch 5188: loss 0.311544\n",
      "batch 5189: loss 0.323470\n",
      "batch 5190: loss 0.348203\n",
      "batch 5191: loss 0.297482\n",
      "batch 5192: loss 0.451696\n",
      "batch 5193: loss 0.359291\n",
      "batch 5194: loss 0.331208\n",
      "batch 5195: loss 0.284312\n",
      "batch 5196: loss 0.266297\n",
      "batch 5197: loss 0.243849\n",
      "batch 5198: loss 0.265060\n",
      "batch 5199: loss 0.307545\n",
      "batch 5200: loss 0.294362\n",
      "batch 5201: loss 0.364529\n",
      "batch 5202: loss 0.282299\n",
      "batch 5203: loss 0.282159\n",
      "batch 5204: loss 0.190458\n",
      "batch 5205: loss 0.249203\n",
      "batch 5206: loss 0.249959\n",
      "batch 5207: loss 0.335075\n",
      "batch 5208: loss 0.254378\n",
      "batch 5209: loss 0.306134\n",
      "batch 5210: loss 0.319381\n",
      "batch 5211: loss 0.281665\n",
      "batch 5212: loss 0.522254\n",
      "batch 5213: loss 0.417697\n",
      "batch 5214: loss 0.448411\n",
      "batch 5215: loss 0.306142\n",
      "batch 5216: loss 0.457195\n",
      "batch 5217: loss 0.303616\n",
      "batch 5218: loss 0.330258\n",
      "batch 5219: loss 0.437447\n",
      "batch 5220: loss 0.374496\n",
      "batch 5221: loss 0.344606\n",
      "batch 5222: loss 0.285197\n",
      "batch 5223: loss 0.388566\n",
      "batch 5224: loss 0.167973\n",
      "batch 5225: loss 0.373191\n",
      "batch 5226: loss 0.336581\n",
      "batch 5227: loss 0.225394\n",
      "batch 5228: loss 0.240850\n",
      "batch 5229: loss 0.222552\n",
      "batch 5230: loss 0.182716\n",
      "batch 5231: loss 0.397531\n",
      "batch 5232: loss 0.414217\n",
      "batch 5233: loss 0.209317\n",
      "batch 5234: loss 0.351596\n",
      "batch 5235: loss 0.292034\n",
      "batch 5236: loss 0.556984\n",
      "batch 5237: loss 0.255436\n",
      "batch 5238: loss 0.363142\n",
      "batch 5239: loss 0.399602\n",
      "batch 5240: loss 0.249108\n",
      "batch 5241: loss 0.254655\n",
      "batch 5242: loss 0.240273\n",
      "batch 5243: loss 0.277087\n",
      "batch 5244: loss 0.457338\n",
      "batch 5245: loss 0.416858\n",
      "batch 5246: loss 0.437926\n",
      "batch 5247: loss 0.359211\n",
      "batch 5248: loss 0.498394\n",
      "batch 5249: loss 0.263680\n",
      "batch 5250: loss 0.287524\n",
      "batch 5251: loss 0.475120\n",
      "batch 5252: loss 0.202346\n",
      "batch 5253: loss 0.214452\n",
      "batch 5254: loss 0.377835\n",
      "batch 5255: loss 0.256793\n",
      "batch 5256: loss 0.250736\n",
      "batch 5257: loss 0.290993\n",
      "batch 5258: loss 0.353267\n",
      "batch 5259: loss 0.208168\n",
      "batch 5260: loss 0.536629\n",
      "batch 5261: loss 0.271105\n",
      "batch 5262: loss 0.359031\n",
      "batch 5263: loss 0.273031\n",
      "batch 5264: loss 0.450991\n",
      "batch 5265: loss 0.446303\n",
      "batch 5266: loss 0.339496\n",
      "batch 5267: loss 0.411612\n",
      "batch 5268: loss 0.320234\n",
      "batch 5269: loss 0.266580\n",
      "batch 5270: loss 0.299078\n",
      "batch 5271: loss 0.357281\n",
      "batch 5272: loss 0.215959\n",
      "batch 5273: loss 0.460323\n",
      "batch 5274: loss 0.327213\n",
      "batch 5275: loss 0.366268\n",
      "batch 5276: loss 0.204245\n",
      "batch 5277: loss 0.416702\n",
      "batch 5278: loss 0.463146\n",
      "batch 5279: loss 0.259814\n",
      "batch 5280: loss 0.369833\n",
      "batch 5281: loss 0.471219\n",
      "batch 5282: loss 0.407577\n",
      "batch 5283: loss 0.302287\n",
      "batch 5284: loss 0.257009\n",
      "batch 5285: loss 0.515449\n",
      "batch 5286: loss 0.223848\n",
      "batch 5287: loss 0.300990\n",
      "batch 5288: loss 0.219680\n",
      "batch 5289: loss 0.278523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5290: loss 0.293274\n",
      "batch 5291: loss 0.229051\n",
      "batch 5292: loss 0.382054\n",
      "batch 5293: loss 0.521158\n",
      "batch 5294: loss 0.539311\n",
      "batch 5295: loss 0.457191\n",
      "batch 5296: loss 0.240623\n",
      "batch 5297: loss 0.340440\n",
      "batch 5298: loss 0.412481\n",
      "batch 5299: loss 0.398810\n",
      "batch 5300: loss 0.257309\n",
      "batch 5301: loss 0.371697\n",
      "batch 5302: loss 0.330001\n",
      "batch 5303: loss 0.380280\n",
      "batch 5304: loss 0.310776\n",
      "batch 5305: loss 0.365516\n",
      "batch 5306: loss 0.510881\n",
      "batch 5307: loss 0.378243\n",
      "batch 5308: loss 0.302615\n",
      "batch 5309: loss 0.147866\n",
      "batch 5310: loss 0.285852\n",
      "batch 5311: loss 0.485785\n",
      "batch 5312: loss 0.292692\n",
      "batch 5313: loss 0.493444\n",
      "batch 5314: loss 0.332411\n",
      "batch 5315: loss 0.444494\n",
      "batch 5316: loss 0.333315\n",
      "batch 5317: loss 0.365181\n",
      "batch 5318: loss 0.439655\n",
      "batch 5319: loss 0.389291\n",
      "batch 5320: loss 0.425077\n",
      "batch 5321: loss 0.423146\n",
      "batch 5322: loss 0.375635\n",
      "batch 5323: loss 0.300534\n",
      "batch 5324: loss 0.290688\n",
      "batch 5325: loss 0.299351\n",
      "batch 5326: loss 0.188709\n",
      "batch 5327: loss 0.434423\n",
      "batch 5328: loss 0.268771\n",
      "batch 5329: loss 0.350164\n",
      "batch 5330: loss 0.253681\n",
      "batch 5331: loss 0.522818\n",
      "batch 5332: loss 0.166506\n",
      "batch 5333: loss 0.328239\n",
      "batch 5334: loss 0.319088\n",
      "batch 5335: loss 0.138757\n",
      "batch 5336: loss 0.397209\n",
      "batch 5337: loss 0.332728\n",
      "batch 5338: loss 0.348043\n",
      "batch 5339: loss 0.417060\n",
      "batch 5340: loss 0.356076\n",
      "batch 5341: loss 0.691607\n",
      "batch 5342: loss 0.527277\n",
      "batch 5343: loss 0.749903\n",
      "batch 5344: loss 0.425299\n",
      "batch 5345: loss 0.314621\n",
      "batch 5346: loss 0.324299\n",
      "batch 5347: loss 0.331526\n",
      "batch 5348: loss 0.452377\n",
      "batch 5349: loss 0.253429\n",
      "batch 5350: loss 0.409751\n",
      "batch 5351: loss 0.261124\n",
      "batch 5352: loss 0.219473\n",
      "batch 5353: loss 0.344398\n",
      "batch 5354: loss 0.218984\n",
      "batch 5355: loss 0.338337\n",
      "batch 5356: loss 0.426756\n",
      "batch 5357: loss 0.475034\n",
      "batch 5358: loss 0.334336\n",
      "batch 5359: loss 0.158790\n",
      "batch 5360: loss 0.469498\n",
      "batch 5361: loss 0.363482\n",
      "batch 5362: loss 0.232942\n",
      "batch 5363: loss 0.336287\n",
      "batch 5364: loss 0.544987\n",
      "batch 5365: loss 0.344804\n",
      "batch 5366: loss 0.182628\n",
      "batch 5367: loss 0.593433\n",
      "batch 5368: loss 0.336412\n",
      "batch 5369: loss 0.227237\n",
      "batch 5370: loss 0.294651\n",
      "batch 5371: loss 0.225661\n",
      "batch 5372: loss 0.237945\n",
      "batch 5373: loss 0.625865\n",
      "batch 5374: loss 0.277327\n",
      "batch 5375: loss 0.440719\n",
      "batch 5376: loss 0.397386\n",
      "batch 5377: loss 0.369691\n",
      "batch 5378: loss 0.274005\n",
      "batch 5379: loss 0.325591\n",
      "batch 5380: loss 0.434478\n",
      "batch 5381: loss 0.361699\n",
      "batch 5382: loss 0.489588\n",
      "batch 5383: loss 0.303192\n",
      "batch 5384: loss 0.379289\n",
      "batch 5385: loss 0.427054\n",
      "batch 5386: loss 0.426252\n",
      "batch 5387: loss 0.260719\n",
      "batch 5388: loss 0.253228\n",
      "batch 5389: loss 0.296976\n",
      "batch 5390: loss 0.358193\n",
      "batch 5391: loss 0.373616\n",
      "batch 5392: loss 0.376330\n",
      "batch 5393: loss 0.352234\n",
      "batch 5394: loss 0.346802\n",
      "batch 5395: loss 0.327491\n",
      "batch 5396: loss 0.308317\n",
      "batch 5397: loss 0.225735\n",
      "batch 5398: loss 0.344328\n",
      "batch 5399: loss 0.411583\n",
      "batch 5400: loss 0.384726\n",
      "batch 5401: loss 0.306083\n",
      "batch 5402: loss 0.693415\n",
      "batch 5403: loss 0.213871\n",
      "batch 5404: loss 0.298733\n",
      "batch 5405: loss 0.434165\n",
      "batch 5406: loss 0.301672\n",
      "batch 5407: loss 0.274099\n",
      "batch 5408: loss 0.421895\n",
      "batch 5409: loss 0.257786\n",
      "batch 5410: loss 0.436221\n",
      "batch 5411: loss 0.515603\n",
      "batch 5412: loss 0.409467\n",
      "batch 5413: loss 0.540719\n",
      "batch 5414: loss 0.367675\n",
      "batch 5415: loss 0.375391\n",
      "batch 5416: loss 0.285293\n",
      "batch 5417: loss 0.390860\n",
      "batch 5418: loss 0.337516\n",
      "batch 5419: loss 0.307360\n",
      "batch 5420: loss 0.430567\n",
      "batch 5421: loss 0.357098\n",
      "batch 5422: loss 0.313878\n",
      "batch 5423: loss 0.317384\n",
      "batch 5424: loss 0.462617\n",
      "batch 5425: loss 0.381102\n",
      "batch 5426: loss 0.336244\n",
      "batch 5427: loss 0.503436\n",
      "batch 5428: loss 0.398309\n",
      "batch 5429: loss 0.334729\n",
      "batch 5430: loss 0.550440\n",
      "batch 5431: loss 0.202021\n",
      "batch 5432: loss 0.211754\n",
      "batch 5433: loss 0.399543\n",
      "batch 5434: loss 0.166184\n",
      "batch 5435: loss 0.436928\n",
      "batch 5436: loss 0.226677\n",
      "batch 5437: loss 0.285405\n",
      "batch 5438: loss 0.269552\n",
      "batch 5439: loss 0.316128\n",
      "batch 5440: loss 0.261029\n",
      "batch 5441: loss 0.489760\n",
      "batch 5442: loss 0.341890\n",
      "batch 5443: loss 0.195733\n",
      "batch 5444: loss 0.408738\n",
      "batch 5445: loss 0.383704\n",
      "batch 5446: loss 0.534210\n",
      "batch 5447: loss 0.292727\n",
      "batch 5448: loss 0.291318\n",
      "batch 5449: loss 0.237681\n",
      "batch 5450: loss 0.381224\n",
      "batch 5451: loss 0.179346\n",
      "batch 5452: loss 0.308747\n",
      "batch 5453: loss 0.306249\n",
      "batch 5454: loss 0.200305\n",
      "batch 5455: loss 0.247193\n",
      "batch 5456: loss 0.332156\n",
      "batch 5457: loss 0.289647\n",
      "batch 5458: loss 0.490492\n",
      "batch 5459: loss 0.646387\n",
      "batch 5460: loss 0.350666\n",
      "batch 5461: loss 0.501786\n",
      "batch 5462: loss 0.519022\n",
      "batch 5463: loss 0.441691\n",
      "batch 5464: loss 0.309359\n",
      "batch 5465: loss 0.466743\n",
      "batch 5466: loss 0.498195\n",
      "batch 5467: loss 0.388731\n",
      "batch 5468: loss 0.319901\n",
      "batch 5469: loss 0.455276\n",
      "batch 5470: loss 0.458990\n",
      "batch 5471: loss 0.411155\n",
      "batch 5472: loss 0.409385\n",
      "batch 5473: loss 0.185153\n",
      "batch 5474: loss 0.259934\n",
      "batch 5475: loss 0.271443\n",
      "batch 5476: loss 0.475740\n",
      "batch 5477: loss 0.409683\n",
      "batch 5478: loss 0.535426\n",
      "batch 5479: loss 0.224904\n",
      "batch 5480: loss 0.305891\n",
      "batch 5481: loss 0.396706\n",
      "batch 5482: loss 0.499385\n",
      "batch 5483: loss 0.549646\n",
      "batch 5484: loss 0.304567\n",
      "batch 5485: loss 0.386070\n",
      "batch 5486: loss 0.272708\n",
      "batch 5487: loss 0.233748\n",
      "batch 5488: loss 0.633973\n",
      "batch 5489: loss 0.233638\n",
      "batch 5490: loss 0.198560\n",
      "batch 5491: loss 0.345517\n",
      "batch 5492: loss 0.242694\n",
      "batch 5493: loss 0.397233\n",
      "batch 5494: loss 0.376148\n",
      "batch 5495: loss 0.433092\n",
      "batch 5496: loss 0.330096\n",
      "batch 5497: loss 0.520568\n",
      "batch 5498: loss 0.388194\n",
      "batch 5499: loss 0.360005\n"
     ]
    }
   ],
   "source": [
    "# 定义一些模型超参数：\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型和数据读取类，并实例化一个 tf.keras.optimizer 的优化器（这里使用常用的 Adam 优化器）：\n",
    "model = MLP()\n",
    "# data_loader = MNISTLoader() # 导入数据 \n",
    "data_loader = MNISTLoader_my_download()  # 导入数据\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # 更新梯度\n",
    "\n",
    "# num_batches = int(mnist.train.num_examples // batch_size * num_epochs)\n",
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras model <__main__.MLP object at 0x0000016D1FDA8390>, because its inputs are not defined.\n",
      "INFO:tensorflow:Assets written to: saved\\1\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"saved\\\\1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.905000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "model = tf.saved_model.load(\"saved/1\")\n",
    "sparse_categorical_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model(data_loader.test_data[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
