{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 第四部分：TensorFlow 模型导出  <br/>\n",
    "   &emsp; 4.1 使用 SavedModel 完整导出模型 <br/>\n",
    "   &emsp; 4.2 Keras 自有的模型导出格式（Jinpeng） <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_core.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "class MNISTLoader_my_download():\n",
    "    def __init__(self):\n",
    "        # 读取数据，预先已经下载了相应的数据直\n",
    "        mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "        self.train_data = mnist.train.images\n",
    "        self.train_label = mnist.train.labels\n",
    "        self.test_data = mnist.test.images\n",
    "        self.test_label = mnist.test.labels\n",
    "        \n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 784, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 784, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "        \n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)  # 第一层神经元的个数为100\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)   # 第二层神经元的个数为10,输出一个样本的维度为10\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "batch 0: loss 2.302643\n",
      "batch 1: loss 2.301799\n",
      "batch 2: loss 2.302603\n",
      "batch 3: loss 2.302225\n",
      "batch 4: loss 2.301180\n",
      "batch 5: loss 2.301542\n",
      "batch 6: loss 2.300638\n",
      "batch 7: loss 2.299495\n",
      "batch 8: loss 2.299714\n",
      "batch 9: loss 2.298243\n",
      "batch 10: loss 2.301099\n",
      "batch 11: loss 2.300594\n",
      "batch 12: loss 2.299020\n",
      "batch 13: loss 2.299688\n",
      "batch 14: loss 2.297707\n",
      "batch 15: loss 2.296647\n",
      "batch 16: loss 2.299434\n",
      "batch 17: loss 2.297530\n",
      "batch 18: loss 2.297919\n",
      "batch 19: loss 2.299123\n",
      "batch 20: loss 2.297805\n",
      "batch 21: loss 2.296417\n",
      "batch 22: loss 2.293397\n",
      "batch 23: loss 2.296087\n",
      "batch 24: loss 2.296263\n",
      "batch 25: loss 2.290941\n",
      "batch 26: loss 2.294185\n",
      "batch 27: loss 2.292846\n",
      "batch 28: loss 2.290687\n",
      "batch 29: loss 2.293303\n",
      "batch 30: loss 2.291676\n",
      "batch 31: loss 2.293294\n",
      "batch 32: loss 2.291065\n",
      "batch 33: loss 2.290572\n",
      "batch 34: loss 2.288302\n",
      "batch 35: loss 2.285501\n",
      "batch 36: loss 2.287742\n",
      "batch 37: loss 2.289291\n",
      "batch 38: loss 2.286239\n",
      "batch 39: loss 2.281149\n",
      "batch 40: loss 2.284968\n",
      "batch 41: loss 2.291321\n",
      "batch 42: loss 2.290110\n",
      "batch 43: loss 2.286807\n",
      "batch 44: loss 2.286734\n",
      "batch 45: loss 2.284071\n",
      "batch 46: loss 2.278720\n",
      "batch 47: loss 2.284084\n",
      "batch 48: loss 2.279172\n",
      "batch 49: loss 2.279064\n",
      "batch 50: loss 2.276029\n",
      "batch 51: loss 2.276493\n",
      "batch 52: loss 2.282337\n",
      "batch 53: loss 2.280138\n",
      "batch 54: loss 2.280362\n",
      "batch 55: loss 2.286000\n",
      "batch 56: loss 2.277120\n",
      "batch 57: loss 2.279039\n",
      "batch 58: loss 2.273811\n",
      "batch 59: loss 2.273489\n",
      "batch 60: loss 2.278243\n",
      "batch 61: loss 2.279027\n",
      "batch 62: loss 2.272583\n",
      "batch 63: loss 2.273837\n",
      "batch 64: loss 2.276708\n",
      "batch 65: loss 2.279974\n",
      "batch 66: loss 2.263616\n",
      "batch 67: loss 2.267452\n",
      "batch 68: loss 2.271542\n",
      "batch 69: loss 2.260942\n",
      "batch 70: loss 2.268420\n",
      "batch 71: loss 2.272988\n",
      "batch 72: loss 2.264001\n",
      "batch 73: loss 2.265233\n",
      "batch 74: loss 2.266170\n",
      "batch 75: loss 2.268448\n",
      "batch 76: loss 2.255739\n",
      "batch 77: loss 2.269970\n",
      "batch 78: loss 2.255912\n",
      "batch 79: loss 2.256932\n",
      "batch 80: loss 2.261255\n",
      "batch 81: loss 2.257519\n",
      "batch 82: loss 2.266212\n",
      "batch 83: loss 2.258532\n",
      "batch 84: loss 2.249887\n",
      "batch 85: loss 2.259211\n",
      "batch 86: loss 2.257365\n",
      "batch 87: loss 2.251017\n",
      "batch 88: loss 2.270398\n",
      "batch 89: loss 2.239635\n",
      "batch 90: loss 2.259538\n",
      "batch 91: loss 2.255648\n",
      "batch 92: loss 2.240078\n",
      "batch 93: loss 2.254405\n",
      "batch 94: loss 2.252297\n",
      "batch 95: loss 2.245247\n",
      "batch 96: loss 2.238189\n",
      "batch 97: loss 2.253911\n",
      "batch 98: loss 2.242363\n",
      "batch 99: loss 2.250200\n",
      "batch 100: loss 2.236486\n",
      "batch 101: loss 2.239851\n",
      "batch 102: loss 2.229655\n",
      "batch 103: loss 2.245300\n",
      "batch 104: loss 2.218812\n",
      "batch 105: loss 2.241395\n",
      "batch 106: loss 2.253218\n",
      "batch 107: loss 2.227711\n",
      "batch 108: loss 2.237893\n",
      "batch 109: loss 2.231937\n",
      "batch 110: loss 2.239335\n",
      "batch 111: loss 2.231304\n",
      "batch 112: loss 2.226930\n",
      "batch 113: loss 2.225946\n",
      "batch 114: loss 2.234329\n",
      "batch 115: loss 2.219867\n",
      "batch 116: loss 2.229782\n",
      "batch 117: loss 2.243141\n",
      "batch 118: loss 2.214018\n",
      "batch 119: loss 2.223014\n",
      "batch 120: loss 2.209475\n",
      "batch 121: loss 2.224337\n",
      "batch 122: loss 2.214298\n",
      "batch 123: loss 2.214930\n",
      "batch 124: loss 2.232088\n",
      "batch 125: loss 2.206597\n",
      "batch 126: loss 2.227511\n",
      "batch 127: loss 2.209988\n",
      "batch 128: loss 2.184999\n",
      "batch 129: loss 2.220857\n",
      "batch 130: loss 2.203346\n",
      "batch 131: loss 2.231972\n",
      "batch 132: loss 2.215661\n",
      "batch 133: loss 2.220163\n",
      "batch 134: loss 2.203110\n",
      "batch 135: loss 2.223209\n",
      "batch 136: loss 2.193253\n",
      "batch 137: loss 2.191335\n",
      "batch 138: loss 2.166112\n",
      "batch 139: loss 2.194146\n",
      "batch 140: loss 2.193512\n",
      "batch 141: loss 2.205703\n",
      "batch 142: loss 2.178127\n",
      "batch 143: loss 2.210998\n",
      "batch 144: loss 2.173896\n",
      "batch 145: loss 2.175144\n",
      "batch 146: loss 2.157299\n",
      "batch 147: loss 2.191593\n",
      "batch 148: loss 2.204578\n",
      "batch 149: loss 2.171641\n",
      "batch 150: loss 2.182839\n",
      "batch 151: loss 2.186186\n",
      "batch 152: loss 2.183632\n",
      "batch 153: loss 2.213874\n",
      "batch 154: loss 2.186143\n",
      "batch 155: loss 2.167386\n",
      "batch 156: loss 2.177713\n",
      "batch 157: loss 2.178624\n",
      "batch 158: loss 2.192807\n",
      "batch 159: loss 2.188453\n",
      "batch 160: loss 2.194609\n",
      "batch 161: loss 2.162429\n",
      "batch 162: loss 2.191766\n",
      "batch 163: loss 2.181181\n",
      "batch 164: loss 2.121463\n",
      "batch 165: loss 2.178283\n",
      "batch 166: loss 2.136084\n",
      "batch 167: loss 2.147281\n",
      "batch 168: loss 2.146638\n",
      "batch 169: loss 2.134052\n",
      "batch 170: loss 2.171548\n",
      "batch 171: loss 2.150402\n",
      "batch 172: loss 2.137607\n",
      "batch 173: loss 2.110857\n",
      "batch 174: loss 2.163779\n",
      "batch 175: loss 2.149293\n",
      "batch 176: loss 2.131659\n",
      "batch 177: loss 2.119210\n",
      "batch 178: loss 2.152647\n",
      "batch 179: loss 2.135139\n",
      "batch 180: loss 2.124255\n",
      "batch 181: loss 2.123074\n",
      "batch 182: loss 2.099810\n",
      "batch 183: loss 2.113633\n",
      "batch 184: loss 2.160818\n",
      "batch 185: loss 2.155978\n",
      "batch 186: loss 2.127557\n",
      "batch 187: loss 2.109555\n",
      "batch 188: loss 2.118681\n",
      "batch 189: loss 2.120913\n",
      "batch 190: loss 2.129785\n",
      "batch 191: loss 2.083323\n",
      "batch 192: loss 2.102777\n",
      "batch 193: loss 2.109142\n",
      "batch 194: loss 2.125632\n",
      "batch 195: loss 2.097281\n",
      "batch 196: loss 2.149237\n",
      "batch 197: loss 2.129259\n",
      "batch 198: loss 2.096687\n",
      "batch 199: loss 2.074916\n",
      "batch 200: loss 2.078460\n",
      "batch 201: loss 2.112446\n",
      "batch 202: loss 2.095734\n",
      "batch 203: loss 2.084210\n",
      "batch 204: loss 2.108010\n",
      "batch 205: loss 2.087483\n",
      "batch 206: loss 2.091959\n",
      "batch 207: loss 2.037954\n",
      "batch 208: loss 2.104320\n",
      "batch 209: loss 2.080355\n",
      "batch 210: loss 2.040247\n",
      "batch 211: loss 2.042368\n",
      "batch 212: loss 2.065955\n",
      "batch 213: loss 2.093975\n",
      "batch 214: loss 2.089173\n",
      "batch 215: loss 1.992555\n",
      "batch 216: loss 2.104972\n",
      "batch 217: loss 2.076083\n",
      "batch 218: loss 1.997426\n",
      "batch 219: loss 1.999312\n",
      "batch 220: loss 2.040153\n",
      "batch 221: loss 2.080471\n",
      "batch 222: loss 2.068044\n",
      "batch 223: loss 2.035750\n",
      "batch 224: loss 2.009137\n",
      "batch 225: loss 2.071764\n",
      "batch 226: loss 2.086605\n",
      "batch 227: loss 2.049450\n",
      "batch 228: loss 2.099711\n",
      "batch 229: loss 2.033329\n",
      "batch 230: loss 2.063113\n",
      "batch 231: loss 2.063685\n",
      "batch 232: loss 2.063554\n",
      "batch 233: loss 2.030469\n",
      "batch 234: loss 2.006897\n",
      "batch 235: loss 2.003785\n",
      "batch 236: loss 2.010606\n",
      "batch 237: loss 2.021124\n",
      "batch 238: loss 2.028184\n",
      "batch 239: loss 1.987844\n",
      "batch 240: loss 1.961332\n",
      "batch 241: loss 2.032634\n",
      "batch 242: loss 2.000580\n",
      "batch 243: loss 2.007195\n",
      "batch 244: loss 2.011957\n",
      "batch 245: loss 2.052258\n",
      "batch 246: loss 1.982339\n",
      "batch 247: loss 1.981201\n",
      "batch 248: loss 1.960597\n",
      "batch 249: loss 1.995869\n",
      "batch 250: loss 1.973609\n",
      "batch 251: loss 1.995537\n",
      "batch 252: loss 1.957474\n",
      "batch 253: loss 2.055668\n",
      "batch 254: loss 1.989989\n",
      "batch 255: loss 1.966092\n",
      "batch 256: loss 2.011214\n",
      "batch 257: loss 2.042727\n",
      "batch 258: loss 1.966422\n",
      "batch 259: loss 1.953369\n",
      "batch 260: loss 1.991912\n",
      "batch 261: loss 2.050817\n",
      "batch 262: loss 1.992561\n",
      "batch 263: loss 1.997694\n",
      "batch 264: loss 1.919680\n",
      "batch 265: loss 1.985161\n",
      "batch 266: loss 1.922759\n",
      "batch 267: loss 1.964793\n",
      "batch 268: loss 1.925632\n",
      "batch 269: loss 1.881698\n",
      "batch 270: loss 1.931128\n",
      "batch 271: loss 2.006664\n",
      "batch 272: loss 1.959438\n",
      "batch 273: loss 1.909913\n",
      "batch 274: loss 1.922565\n",
      "batch 275: loss 1.967995\n",
      "batch 276: loss 1.917675\n",
      "batch 277: loss 1.913680\n",
      "batch 278: loss 1.923440\n",
      "batch 279: loss 1.954431\n",
      "batch 280: loss 1.880786\n",
      "batch 281: loss 1.927890\n",
      "batch 282: loss 1.905917\n",
      "batch 283: loss 1.859206\n",
      "batch 284: loss 1.935831\n",
      "batch 285: loss 1.898472\n",
      "batch 286: loss 1.882058\n",
      "batch 287: loss 1.900985\n",
      "batch 288: loss 1.868408\n",
      "batch 289: loss 1.853848\n",
      "batch 290: loss 1.910326\n",
      "batch 291: loss 1.899994\n",
      "batch 292: loss 1.943530\n",
      "batch 293: loss 1.884692\n",
      "batch 294: loss 1.932004\n",
      "batch 295: loss 1.938619\n",
      "batch 296: loss 1.872578\n",
      "batch 297: loss 1.816527\n",
      "batch 298: loss 1.796091\n",
      "batch 299: loss 1.877132\n",
      "batch 300: loss 1.882421\n",
      "batch 301: loss 1.900750\n",
      "batch 302: loss 1.840177\n",
      "batch 303: loss 1.900770\n",
      "batch 304: loss 1.902069\n",
      "batch 305: loss 1.816798\n",
      "batch 306: loss 1.888164\n",
      "batch 307: loss 1.771302\n",
      "batch 308: loss 1.920556\n",
      "batch 309: loss 1.796934\n",
      "batch 310: loss 1.832397\n",
      "batch 311: loss 1.942946\n",
      "batch 312: loss 1.836057\n",
      "batch 313: loss 1.813563\n",
      "batch 314: loss 1.880769\n",
      "batch 315: loss 1.809825\n",
      "batch 316: loss 1.796332\n",
      "batch 317: loss 1.840277\n",
      "batch 318: loss 1.810201\n",
      "batch 319: loss 1.868320\n",
      "batch 320: loss 1.870305\n",
      "batch 321: loss 1.773013\n",
      "batch 322: loss 1.855916\n",
      "batch 323: loss 1.850867\n",
      "batch 324: loss 1.764621\n",
      "batch 325: loss 1.877888\n",
      "batch 326: loss 1.842369\n",
      "batch 327: loss 1.736538\n",
      "batch 328: loss 1.929631\n",
      "batch 329: loss 1.840914\n",
      "batch 330: loss 1.794106\n",
      "batch 331: loss 1.851019\n",
      "batch 332: loss 1.785620\n",
      "batch 333: loss 1.799533\n",
      "batch 334: loss 1.778919\n",
      "batch 335: loss 1.760834\n",
      "batch 336: loss 1.780619\n",
      "batch 337: loss 1.727147\n",
      "batch 338: loss 1.744158\n",
      "batch 339: loss 1.859125\n",
      "batch 340: loss 1.759001\n",
      "batch 341: loss 1.733430\n",
      "batch 342: loss 1.792598\n",
      "batch 343: loss 1.813589\n",
      "batch 344: loss 1.668619\n",
      "batch 345: loss 1.808155\n",
      "batch 346: loss 1.731393\n",
      "batch 347: loss 1.766914\n",
      "batch 348: loss 1.783312\n",
      "batch 349: loss 1.710577\n",
      "batch 350: loss 1.796013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 351: loss 1.734943\n",
      "batch 352: loss 1.717589\n",
      "batch 353: loss 1.746754\n",
      "batch 354: loss 1.817168\n",
      "batch 355: loss 1.747950\n",
      "batch 356: loss 1.735922\n",
      "batch 357: loss 1.736252\n",
      "batch 358: loss 1.773902\n",
      "batch 359: loss 1.662208\n",
      "batch 360: loss 1.742712\n",
      "batch 361: loss 1.639705\n",
      "batch 362: loss 1.681749\n",
      "batch 363: loss 1.602814\n",
      "batch 364: loss 1.688803\n",
      "batch 365: loss 1.750672\n",
      "batch 366: loss 1.747290\n",
      "batch 367: loss 1.714188\n",
      "batch 368: loss 1.724599\n",
      "batch 369: loss 1.717234\n",
      "batch 370: loss 1.673671\n",
      "batch 371: loss 1.728030\n",
      "batch 372: loss 1.749232\n",
      "batch 373: loss 1.645709\n",
      "batch 374: loss 1.740792\n",
      "batch 375: loss 1.592468\n",
      "batch 376: loss 1.730510\n",
      "batch 377: loss 1.787460\n",
      "batch 378: loss 1.676455\n",
      "batch 379: loss 1.675340\n",
      "batch 380: loss 1.606389\n",
      "batch 381: loss 1.692972\n",
      "batch 382: loss 1.683313\n",
      "batch 383: loss 1.647904\n",
      "batch 384: loss 1.715754\n",
      "batch 385: loss 1.656535\n",
      "batch 386: loss 1.679291\n",
      "batch 387: loss 1.630689\n",
      "batch 388: loss 1.787637\n",
      "batch 389: loss 1.683315\n",
      "batch 390: loss 1.655793\n",
      "batch 391: loss 1.659953\n",
      "batch 392: loss 1.643708\n",
      "batch 393: loss 1.726464\n",
      "batch 394: loss 1.648358\n",
      "batch 395: loss 1.641844\n",
      "batch 396: loss 1.698448\n",
      "batch 397: loss 1.637306\n",
      "batch 398: loss 1.643246\n",
      "batch 399: loss 1.599392\n",
      "batch 400: loss 1.644998\n",
      "batch 401: loss 1.646003\n",
      "batch 402: loss 1.617258\n",
      "batch 403: loss 1.725788\n",
      "batch 404: loss 1.653592\n",
      "batch 405: loss 1.561960\n",
      "batch 406: loss 1.516060\n",
      "batch 407: loss 1.671476\n",
      "batch 408: loss 1.650592\n",
      "batch 409: loss 1.640785\n",
      "batch 410: loss 1.664377\n",
      "batch 411: loss 1.573917\n",
      "batch 412: loss 1.656200\n",
      "batch 413: loss 1.666474\n",
      "batch 414: loss 1.604532\n",
      "batch 415: loss 1.669715\n",
      "batch 416: loss 1.625515\n",
      "batch 417: loss 1.590082\n",
      "batch 418: loss 1.644526\n",
      "batch 419: loss 1.566320\n",
      "batch 420: loss 1.629810\n",
      "batch 421: loss 1.648692\n",
      "batch 422: loss 1.693828\n",
      "batch 423: loss 1.622360\n",
      "batch 424: loss 1.521589\n",
      "batch 425: loss 1.605115\n",
      "batch 426: loss 1.611930\n",
      "batch 427: loss 1.733363\n",
      "batch 428: loss 1.585662\n",
      "batch 429: loss 1.489125\n",
      "batch 430: loss 1.487052\n",
      "batch 431: loss 1.618952\n",
      "batch 432: loss 1.576426\n",
      "batch 433: loss 1.678088\n",
      "batch 434: loss 1.675650\n",
      "batch 435: loss 1.565123\n",
      "batch 436: loss 1.470391\n",
      "batch 437: loss 1.574663\n",
      "batch 438: loss 1.562697\n",
      "batch 439: loss 1.443523\n",
      "batch 440: loss 1.552506\n",
      "batch 441: loss 1.587044\n",
      "batch 442: loss 1.581050\n",
      "batch 443: loss 1.512107\n",
      "batch 444: loss 1.481415\n",
      "batch 445: loss 1.483448\n",
      "batch 446: loss 1.610987\n",
      "batch 447: loss 1.623028\n",
      "batch 448: loss 1.559891\n",
      "batch 449: loss 1.615966\n",
      "batch 450: loss 1.648531\n",
      "batch 451: loss 1.547541\n",
      "batch 452: loss 1.547395\n",
      "batch 453: loss 1.548947\n",
      "batch 454: loss 1.502205\n",
      "batch 455: loss 1.548726\n",
      "batch 456: loss 1.534575\n",
      "batch 457: loss 1.568152\n",
      "batch 458: loss 1.485453\n",
      "batch 459: loss 1.527459\n",
      "batch 460: loss 1.428644\n",
      "batch 461: loss 1.550370\n",
      "batch 462: loss 1.575236\n",
      "batch 463: loss 1.550674\n",
      "batch 464: loss 1.452518\n",
      "batch 465: loss 1.582366\n",
      "batch 466: loss 1.549334\n",
      "batch 467: loss 1.456146\n",
      "batch 468: loss 1.367439\n",
      "batch 469: loss 1.566859\n",
      "batch 470: loss 1.440328\n",
      "batch 471: loss 1.457366\n",
      "batch 472: loss 1.433721\n",
      "batch 473: loss 1.582655\n",
      "batch 474: loss 1.593968\n",
      "batch 475: loss 1.416338\n",
      "batch 476: loss 1.558341\n",
      "batch 477: loss 1.456802\n",
      "batch 478: loss 1.454331\n",
      "batch 479: loss 1.485266\n",
      "batch 480: loss 1.470844\n",
      "batch 481: loss 1.323652\n",
      "batch 482: loss 1.434992\n",
      "batch 483: loss 1.392452\n",
      "batch 484: loss 1.388669\n",
      "batch 485: loss 1.434484\n",
      "batch 486: loss 1.481125\n",
      "batch 487: loss 1.489336\n",
      "batch 488: loss 1.441663\n",
      "batch 489: loss 1.465514\n",
      "batch 490: loss 1.371405\n",
      "batch 491: loss 1.392616\n",
      "batch 492: loss 1.444987\n",
      "batch 493: loss 1.503531\n",
      "batch 494: loss 1.381692\n",
      "batch 495: loss 1.466372\n",
      "batch 496: loss 1.360317\n",
      "batch 497: loss 1.483268\n",
      "batch 498: loss 1.517214\n",
      "batch 499: loss 1.473693\n",
      "batch 500: loss 1.486058\n",
      "batch 501: loss 1.435766\n",
      "batch 502: loss 1.386267\n",
      "batch 503: loss 1.435911\n",
      "batch 504: loss 1.486078\n",
      "batch 505: loss 1.501339\n",
      "batch 506: loss 1.376925\n",
      "batch 507: loss 1.484983\n",
      "batch 508: loss 1.234070\n",
      "batch 509: loss 1.343026\n",
      "batch 510: loss 1.306402\n",
      "batch 511: loss 1.527091\n",
      "batch 512: loss 1.420437\n",
      "batch 513: loss 1.409736\n",
      "batch 514: loss 1.497319\n",
      "batch 515: loss 1.310054\n",
      "batch 516: loss 1.402541\n",
      "batch 517: loss 1.527546\n",
      "batch 518: loss 1.447621\n",
      "batch 519: loss 1.410968\n",
      "batch 520: loss 1.285949\n",
      "batch 521: loss 1.584037\n",
      "batch 522: loss 1.371634\n",
      "batch 523: loss 1.386256\n",
      "batch 524: loss 1.403674\n",
      "batch 525: loss 1.328158\n",
      "batch 526: loss 1.367122\n",
      "batch 527: loss 1.340730\n",
      "batch 528: loss 1.327273\n",
      "batch 529: loss 1.355286\n",
      "batch 530: loss 1.380516\n",
      "batch 531: loss 1.392560\n",
      "batch 532: loss 1.273260\n",
      "batch 533: loss 1.330149\n",
      "batch 534: loss 1.431656\n",
      "batch 535: loss 1.429926\n",
      "batch 536: loss 1.308513\n",
      "batch 537: loss 1.535803\n",
      "batch 538: loss 1.295455\n",
      "batch 539: loss 1.482952\n",
      "batch 540: loss 1.531413\n",
      "batch 541: loss 1.322108\n",
      "batch 542: loss 1.426846\n",
      "batch 543: loss 1.481793\n",
      "batch 544: loss 1.359836\n",
      "batch 545: loss 1.302510\n",
      "batch 546: loss 1.438984\n",
      "batch 547: loss 1.346038\n",
      "batch 548: loss 1.345043\n",
      "batch 549: loss 1.341536\n",
      "batch 550: loss 1.346805\n",
      "batch 551: loss 1.342448\n",
      "batch 552: loss 1.410984\n",
      "batch 553: loss 1.369320\n",
      "batch 554: loss 1.266909\n",
      "batch 555: loss 1.335109\n",
      "batch 556: loss 1.470186\n",
      "batch 557: loss 1.269236\n",
      "batch 558: loss 1.316652\n",
      "batch 559: loss 1.276212\n",
      "batch 560: loss 1.313119\n",
      "batch 561: loss 1.258777\n",
      "batch 562: loss 1.364281\n",
      "batch 563: loss 1.414139\n",
      "batch 564: loss 1.266938\n",
      "batch 565: loss 1.380349\n",
      "batch 566: loss 1.326535\n",
      "batch 567: loss 1.412536\n",
      "batch 568: loss 1.341795\n",
      "batch 569: loss 1.283498\n",
      "batch 570: loss 1.223270\n",
      "batch 571: loss 1.414149\n",
      "batch 572: loss 1.395842\n",
      "batch 573: loss 1.253848\n",
      "batch 574: loss 1.246146\n",
      "batch 575: loss 1.390797\n",
      "batch 576: loss 1.340361\n",
      "batch 577: loss 1.388037\n",
      "batch 578: loss 1.340369\n",
      "batch 579: loss 1.314895\n",
      "batch 580: loss 1.333636\n",
      "batch 581: loss 1.296891\n",
      "batch 582: loss 1.362022\n",
      "batch 583: loss 1.356583\n",
      "batch 584: loss 1.260790\n",
      "batch 585: loss 1.204996\n",
      "batch 586: loss 1.295106\n",
      "batch 587: loss 1.234027\n",
      "batch 588: loss 1.256762\n",
      "batch 589: loss 1.503131\n",
      "batch 590: loss 1.381896\n",
      "batch 591: loss 1.269634\n",
      "batch 592: loss 1.241965\n",
      "batch 593: loss 1.269630\n",
      "batch 594: loss 1.284443\n",
      "batch 595: loss 1.288488\n",
      "batch 596: loss 1.261149\n",
      "batch 597: loss 1.190374\n",
      "batch 598: loss 1.124503\n",
      "batch 599: loss 1.188482\n",
      "batch 600: loss 1.238475\n",
      "batch 601: loss 1.260073\n",
      "batch 602: loss 1.273777\n",
      "batch 603: loss 1.293531\n",
      "batch 604: loss 1.231335\n",
      "batch 605: loss 1.237109\n",
      "batch 606: loss 1.256801\n",
      "batch 607: loss 1.157621\n",
      "batch 608: loss 1.157871\n",
      "batch 609: loss 1.362015\n",
      "batch 610: loss 1.300021\n",
      "batch 611: loss 1.291339\n",
      "batch 612: loss 1.209484\n",
      "batch 613: loss 1.081840\n",
      "batch 614: loss 1.289174\n",
      "batch 615: loss 1.295256\n",
      "batch 616: loss 1.229337\n",
      "batch 617: loss 1.128047\n",
      "batch 618: loss 1.293594\n",
      "batch 619: loss 1.234579\n",
      "batch 620: loss 1.321637\n",
      "batch 621: loss 1.227361\n",
      "batch 622: loss 1.145602\n",
      "batch 623: loss 1.297316\n",
      "batch 624: loss 1.209080\n",
      "batch 625: loss 1.179885\n",
      "batch 626: loss 1.174753\n",
      "batch 627: loss 1.202298\n",
      "batch 628: loss 1.246755\n",
      "batch 629: loss 1.241557\n",
      "batch 630: loss 1.339168\n",
      "batch 631: loss 1.370572\n",
      "batch 632: loss 1.162679\n",
      "batch 633: loss 1.236989\n",
      "batch 634: loss 1.209095\n",
      "batch 635: loss 1.268147\n",
      "batch 636: loss 1.348936\n",
      "batch 637: loss 1.295828\n",
      "batch 638: loss 1.232207\n",
      "batch 639: loss 1.188709\n",
      "batch 640: loss 1.299811\n",
      "batch 641: loss 1.102047\n",
      "batch 642: loss 1.207766\n",
      "batch 643: loss 1.266747\n",
      "batch 644: loss 1.305361\n",
      "batch 645: loss 1.251707\n",
      "batch 646: loss 1.346828\n",
      "batch 647: loss 1.220977\n",
      "batch 648: loss 1.131043\n",
      "batch 649: loss 1.166838\n",
      "batch 650: loss 1.334028\n",
      "batch 651: loss 1.360821\n",
      "batch 652: loss 1.206551\n",
      "batch 653: loss 1.333993\n",
      "batch 654: loss 1.315390\n",
      "batch 655: loss 1.205942\n",
      "batch 656: loss 1.215419\n",
      "batch 657: loss 1.089391\n",
      "batch 658: loss 1.238935\n",
      "batch 659: loss 1.216430\n",
      "batch 660: loss 1.246643\n",
      "batch 661: loss 1.338233\n",
      "batch 662: loss 1.039311\n",
      "batch 663: loss 1.375949\n",
      "batch 664: loss 1.220054\n",
      "batch 665: loss 1.220210\n",
      "batch 666: loss 1.164392\n",
      "batch 667: loss 1.298365\n",
      "batch 668: loss 1.215229\n",
      "batch 669: loss 1.108101\n",
      "batch 670: loss 1.161933\n",
      "batch 671: loss 1.162535\n",
      "batch 672: loss 1.246840\n",
      "batch 673: loss 1.112564\n",
      "batch 674: loss 1.183415\n",
      "batch 675: loss 1.158970\n",
      "batch 676: loss 1.245278\n",
      "batch 677: loss 1.120599\n",
      "batch 678: loss 1.305721\n",
      "batch 679: loss 1.039686\n",
      "batch 680: loss 0.991034\n",
      "batch 681: loss 1.226779\n",
      "batch 682: loss 1.232882\n",
      "batch 683: loss 1.071215\n",
      "batch 684: loss 1.134306\n",
      "batch 685: loss 1.150920\n",
      "batch 686: loss 1.154006\n",
      "batch 687: loss 1.241512\n",
      "batch 688: loss 1.072676\n",
      "batch 689: loss 1.141744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 690: loss 1.266107\n",
      "batch 691: loss 1.210415\n",
      "batch 692: loss 1.088680\n",
      "batch 693: loss 1.138302\n",
      "batch 694: loss 1.195412\n",
      "batch 695: loss 1.119628\n",
      "batch 696: loss 1.118680\n",
      "batch 697: loss 1.020716\n",
      "batch 698: loss 1.160108\n",
      "batch 699: loss 1.108284\n",
      "batch 700: loss 1.083138\n",
      "batch 701: loss 1.135447\n",
      "batch 702: loss 1.051618\n",
      "batch 703: loss 1.057718\n",
      "batch 704: loss 1.091801\n",
      "batch 705: loss 1.152697\n",
      "batch 706: loss 1.246926\n",
      "batch 707: loss 1.114609\n",
      "batch 708: loss 1.164019\n",
      "batch 709: loss 1.260595\n",
      "batch 710: loss 1.030509\n",
      "batch 711: loss 0.989021\n",
      "batch 712: loss 0.983583\n",
      "batch 713: loss 1.108461\n",
      "batch 714: loss 1.115162\n",
      "batch 715: loss 1.181884\n",
      "batch 716: loss 1.038350\n",
      "batch 717: loss 1.034064\n",
      "batch 718: loss 1.134526\n",
      "batch 719: loss 1.259911\n",
      "batch 720: loss 1.068229\n",
      "batch 721: loss 1.036055\n",
      "batch 722: loss 1.078259\n",
      "batch 723: loss 1.103709\n",
      "batch 724: loss 1.129956\n",
      "batch 725: loss 1.096777\n",
      "batch 726: loss 1.066424\n",
      "batch 727: loss 1.131852\n",
      "batch 728: loss 1.077152\n",
      "batch 729: loss 1.117536\n",
      "batch 730: loss 1.050172\n",
      "batch 731: loss 1.013124\n",
      "batch 732: loss 1.267970\n",
      "batch 733: loss 1.082369\n",
      "batch 734: loss 0.989493\n",
      "batch 735: loss 1.098049\n",
      "batch 736: loss 1.082266\n",
      "batch 737: loss 0.986935\n",
      "batch 738: loss 1.043315\n",
      "batch 739: loss 1.141805\n",
      "batch 740: loss 1.169207\n",
      "batch 741: loss 1.016590\n",
      "batch 742: loss 1.102872\n",
      "batch 743: loss 1.098809\n",
      "batch 744: loss 1.021610\n",
      "batch 745: loss 1.099429\n",
      "batch 746: loss 1.136447\n",
      "batch 747: loss 1.134421\n",
      "batch 748: loss 0.932894\n",
      "batch 749: loss 0.923075\n",
      "batch 750: loss 1.062815\n",
      "batch 751: loss 1.137503\n",
      "batch 752: loss 1.131346\n",
      "batch 753: loss 1.022842\n",
      "batch 754: loss 1.149801\n",
      "batch 755: loss 0.954198\n",
      "batch 756: loss 1.120285\n",
      "batch 757: loss 1.046894\n",
      "batch 758: loss 1.021333\n",
      "batch 759: loss 1.114355\n",
      "batch 760: loss 0.999802\n",
      "batch 761: loss 1.022283\n",
      "batch 762: loss 1.098942\n",
      "batch 763: loss 1.103051\n",
      "batch 764: loss 0.963917\n",
      "batch 765: loss 1.290250\n",
      "batch 766: loss 1.168732\n",
      "batch 767: loss 1.060830\n",
      "batch 768: loss 1.110210\n",
      "batch 769: loss 1.082181\n",
      "batch 770: loss 1.140664\n",
      "batch 771: loss 1.097295\n",
      "batch 772: loss 1.081331\n",
      "batch 773: loss 0.988922\n",
      "batch 774: loss 1.136240\n",
      "batch 775: loss 1.114488\n",
      "batch 776: loss 1.055083\n",
      "batch 777: loss 1.028943\n",
      "batch 778: loss 0.985540\n",
      "batch 779: loss 1.098423\n",
      "batch 780: loss 0.893998\n",
      "batch 781: loss 0.962028\n",
      "batch 782: loss 1.101226\n",
      "batch 783: loss 1.128717\n",
      "batch 784: loss 1.071965\n",
      "batch 785: loss 0.933111\n",
      "batch 786: loss 0.982571\n",
      "batch 787: loss 1.011040\n",
      "batch 788: loss 1.160976\n",
      "batch 789: loss 0.967894\n",
      "batch 790: loss 1.056806\n",
      "batch 791: loss 0.907916\n",
      "batch 792: loss 1.014177\n",
      "batch 793: loss 1.051080\n",
      "batch 794: loss 0.944108\n",
      "batch 795: loss 1.090568\n",
      "batch 796: loss 1.105119\n",
      "batch 797: loss 1.023615\n",
      "batch 798: loss 1.101717\n",
      "batch 799: loss 0.892616\n",
      "batch 800: loss 0.913029\n",
      "batch 801: loss 1.028896\n",
      "batch 802: loss 0.850472\n",
      "batch 803: loss 0.926465\n",
      "batch 804: loss 0.983590\n",
      "batch 805: loss 0.913178\n",
      "batch 806: loss 1.039331\n",
      "batch 807: loss 1.101341\n",
      "batch 808: loss 1.082534\n",
      "batch 809: loss 0.897336\n",
      "batch 810: loss 1.055950\n",
      "batch 811: loss 0.914272\n",
      "batch 812: loss 0.858206\n",
      "batch 813: loss 1.006390\n",
      "batch 814: loss 1.059777\n",
      "batch 815: loss 1.044947\n",
      "batch 816: loss 0.994460\n",
      "batch 817: loss 1.066647\n",
      "batch 818: loss 0.974766\n",
      "batch 819: loss 1.041170\n",
      "batch 820: loss 1.029031\n",
      "batch 821: loss 0.864065\n",
      "batch 822: loss 0.917353\n",
      "batch 823: loss 0.973784\n",
      "batch 824: loss 1.054361\n",
      "batch 825: loss 1.052090\n",
      "batch 826: loss 0.933812\n",
      "batch 827: loss 1.034270\n",
      "batch 828: loss 0.919991\n",
      "batch 829: loss 0.907933\n",
      "batch 830: loss 0.852992\n",
      "batch 831: loss 1.039702\n",
      "batch 832: loss 0.840826\n",
      "batch 833: loss 1.035745\n",
      "batch 834: loss 0.947269\n",
      "batch 835: loss 1.012111\n",
      "batch 836: loss 0.764750\n",
      "batch 837: loss 0.984950\n",
      "batch 838: loss 1.063438\n",
      "batch 839: loss 0.961068\n",
      "batch 840: loss 1.034223\n",
      "batch 841: loss 0.924666\n",
      "batch 842: loss 1.163209\n",
      "batch 843: loss 0.799690\n",
      "batch 844: loss 0.911178\n",
      "batch 845: loss 1.026193\n",
      "batch 846: loss 0.956405\n",
      "batch 847: loss 0.897016\n",
      "batch 848: loss 0.893878\n",
      "batch 849: loss 1.103041\n",
      "batch 850: loss 0.966535\n",
      "batch 851: loss 0.902667\n",
      "batch 852: loss 1.014286\n",
      "batch 853: loss 0.962939\n",
      "batch 854: loss 0.899056\n",
      "batch 855: loss 1.084832\n",
      "batch 856: loss 0.804504\n",
      "batch 857: loss 0.912390\n",
      "batch 858: loss 0.986625\n",
      "batch 859: loss 1.265747\n",
      "batch 860: loss 0.971325\n",
      "batch 861: loss 0.965668\n",
      "batch 862: loss 0.924980\n",
      "batch 863: loss 1.048835\n",
      "batch 864: loss 1.128458\n",
      "batch 865: loss 1.058385\n",
      "batch 866: loss 0.950378\n",
      "batch 867: loss 0.919918\n",
      "batch 868: loss 1.067244\n",
      "batch 869: loss 0.966996\n",
      "batch 870: loss 0.896630\n",
      "batch 871: loss 0.986281\n",
      "batch 872: loss 1.086301\n",
      "batch 873: loss 0.803328\n",
      "batch 874: loss 0.965478\n",
      "batch 875: loss 1.001338\n",
      "batch 876: loss 0.871740\n",
      "batch 877: loss 1.029757\n",
      "batch 878: loss 1.014425\n",
      "batch 879: loss 0.842233\n",
      "batch 880: loss 0.858762\n",
      "batch 881: loss 1.120642\n",
      "batch 882: loss 0.972832\n",
      "batch 883: loss 1.080691\n",
      "batch 884: loss 0.986005\n",
      "batch 885: loss 0.792168\n",
      "batch 886: loss 0.947653\n",
      "batch 887: loss 1.006919\n",
      "batch 888: loss 0.861391\n",
      "batch 889: loss 0.812531\n",
      "batch 890: loss 1.049289\n",
      "batch 891: loss 0.981881\n",
      "batch 892: loss 0.820360\n",
      "batch 893: loss 0.890837\n",
      "batch 894: loss 1.030918\n",
      "batch 895: loss 0.833433\n",
      "batch 896: loss 0.854762\n",
      "batch 897: loss 0.860277\n",
      "batch 898: loss 0.738266\n",
      "batch 899: loss 0.865376\n",
      "batch 900: loss 0.989043\n",
      "batch 901: loss 0.960360\n",
      "batch 902: loss 0.955451\n",
      "batch 903: loss 0.796734\n",
      "batch 904: loss 0.893317\n",
      "batch 905: loss 1.075338\n",
      "batch 906: loss 0.758181\n",
      "batch 907: loss 0.929520\n",
      "batch 908: loss 0.904827\n",
      "batch 909: loss 0.898129\n",
      "batch 910: loss 0.965371\n",
      "batch 911: loss 0.914050\n",
      "batch 912: loss 0.926754\n",
      "batch 913: loss 1.032432\n",
      "batch 914: loss 0.937460\n",
      "batch 915: loss 0.919382\n",
      "batch 916: loss 1.047392\n",
      "batch 917: loss 0.941218\n",
      "batch 918: loss 0.976615\n",
      "batch 919: loss 0.925281\n",
      "batch 920: loss 0.969428\n",
      "batch 921: loss 0.939286\n",
      "batch 922: loss 0.907405\n",
      "batch 923: loss 0.871485\n",
      "batch 924: loss 0.983143\n",
      "batch 925: loss 0.768100\n",
      "batch 926: loss 0.931251\n",
      "batch 927: loss 0.955550\n",
      "batch 928: loss 0.868469\n",
      "batch 929: loss 0.934690\n",
      "batch 930: loss 0.922701\n",
      "batch 931: loss 0.947778\n",
      "batch 932: loss 0.904445\n",
      "batch 933: loss 0.972802\n",
      "batch 934: loss 1.004130\n",
      "batch 935: loss 0.932044\n",
      "batch 936: loss 0.843244\n",
      "batch 937: loss 0.855218\n",
      "batch 938: loss 0.992665\n",
      "batch 939: loss 0.954033\n",
      "batch 940: loss 0.984593\n",
      "batch 941: loss 0.825096\n",
      "batch 942: loss 0.913246\n",
      "batch 943: loss 0.853063\n",
      "batch 944: loss 0.924159\n",
      "batch 945: loss 0.996143\n",
      "batch 946: loss 1.100505\n",
      "batch 947: loss 0.843384\n",
      "batch 948: loss 0.940626\n",
      "batch 949: loss 0.872239\n",
      "batch 950: loss 0.839884\n",
      "batch 951: loss 1.033452\n",
      "batch 952: loss 0.935315\n",
      "batch 953: loss 0.812241\n",
      "batch 954: loss 0.830977\n",
      "batch 955: loss 0.900547\n",
      "batch 956: loss 0.871159\n",
      "batch 957: loss 0.966185\n",
      "batch 958: loss 0.925576\n",
      "batch 959: loss 0.920032\n",
      "batch 960: loss 0.909389\n",
      "batch 961: loss 1.011555\n",
      "batch 962: loss 0.880662\n",
      "batch 963: loss 0.953423\n",
      "batch 964: loss 0.894116\n",
      "batch 965: loss 0.894944\n",
      "batch 966: loss 1.039478\n",
      "batch 967: loss 0.951997\n",
      "batch 968: loss 0.944001\n",
      "batch 969: loss 0.772061\n",
      "batch 970: loss 0.875413\n",
      "batch 971: loss 0.806133\n",
      "batch 972: loss 0.893569\n",
      "batch 973: loss 0.711371\n",
      "batch 974: loss 0.881411\n",
      "batch 975: loss 1.122175\n",
      "batch 976: loss 0.851336\n",
      "batch 977: loss 0.965348\n",
      "batch 978: loss 0.863861\n",
      "batch 979: loss 0.994907\n",
      "batch 980: loss 0.852739\n",
      "batch 981: loss 0.865013\n",
      "batch 982: loss 0.943913\n",
      "batch 983: loss 0.914601\n",
      "batch 984: loss 0.937585\n",
      "batch 985: loss 0.917180\n",
      "batch 986: loss 0.955505\n",
      "batch 987: loss 0.676750\n",
      "batch 988: loss 1.033804\n",
      "batch 989: loss 0.929068\n",
      "batch 990: loss 0.996206\n",
      "batch 991: loss 0.819936\n",
      "batch 992: loss 0.871066\n",
      "batch 993: loss 0.766192\n",
      "batch 994: loss 0.858769\n",
      "batch 995: loss 0.916815\n",
      "batch 996: loss 0.868119\n",
      "batch 997: loss 0.765196\n",
      "batch 998: loss 0.939593\n",
      "batch 999: loss 0.717077\n",
      "batch 1000: loss 0.720759\n",
      "batch 1001: loss 0.861848\n",
      "batch 1002: loss 0.843835\n",
      "batch 1003: loss 0.860829\n",
      "batch 1004: loss 0.775519\n",
      "batch 1005: loss 0.806945\n",
      "batch 1006: loss 0.831167\n",
      "batch 1007: loss 0.783363\n",
      "batch 1008: loss 0.938010\n",
      "batch 1009: loss 0.758671\n",
      "batch 1010: loss 0.874564\n",
      "batch 1011: loss 0.855322\n",
      "batch 1012: loss 0.893807\n",
      "batch 1013: loss 0.827111\n",
      "batch 1014: loss 0.875558\n",
      "batch 1015: loss 0.885521\n",
      "batch 1016: loss 1.080096\n",
      "batch 1017: loss 0.839373\n",
      "batch 1018: loss 0.835034\n",
      "batch 1019: loss 0.951682\n",
      "batch 1020: loss 0.831295\n",
      "batch 1021: loss 0.995140\n",
      "batch 1022: loss 0.914632\n",
      "batch 1023: loss 0.904104\n",
      "batch 1024: loss 0.932496\n",
      "batch 1025: loss 1.059297\n",
      "batch 1026: loss 0.977326\n",
      "batch 1027: loss 0.891117\n",
      "batch 1028: loss 0.915123\n",
      "batch 1029: loss 0.880711\n",
      "batch 1030: loss 0.613969\n",
      "batch 1031: loss 0.726335\n",
      "batch 1032: loss 0.890991\n",
      "batch 1033: loss 0.743279\n",
      "batch 1034: loss 0.763786\n",
      "batch 1035: loss 0.814931\n",
      "batch 1036: loss 0.773350\n",
      "batch 1037: loss 1.015041\n",
      "batch 1038: loss 0.748564\n",
      "batch 1039: loss 0.903125\n",
      "batch 1040: loss 0.939399\n",
      "batch 1041: loss 0.859610\n",
      "batch 1042: loss 0.790427\n",
      "batch 1043: loss 0.845758\n",
      "batch 1044: loss 0.813780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1045: loss 0.734064\n",
      "batch 1046: loss 0.897324\n",
      "batch 1047: loss 0.813515\n",
      "batch 1048: loss 1.018422\n",
      "batch 1049: loss 0.777984\n",
      "batch 1050: loss 0.857251\n",
      "batch 1051: loss 0.931520\n",
      "batch 1052: loss 0.946347\n",
      "batch 1053: loss 0.892197\n",
      "batch 1054: loss 0.809341\n",
      "batch 1055: loss 0.723361\n",
      "batch 1056: loss 0.817453\n",
      "batch 1057: loss 0.782016\n",
      "batch 1058: loss 0.831183\n",
      "batch 1059: loss 0.949572\n",
      "batch 1060: loss 0.842253\n",
      "batch 1061: loss 0.873905\n",
      "batch 1062: loss 0.817738\n",
      "batch 1063: loss 0.835279\n",
      "batch 1064: loss 0.809385\n",
      "batch 1065: loss 0.795710\n",
      "batch 1066: loss 0.877624\n",
      "batch 1067: loss 0.843203\n",
      "batch 1068: loss 0.930756\n",
      "batch 1069: loss 0.852211\n",
      "batch 1070: loss 0.881119\n",
      "batch 1071: loss 0.906188\n",
      "batch 1072: loss 0.707146\n",
      "batch 1073: loss 0.815194\n",
      "batch 1074: loss 0.954605\n",
      "batch 1075: loss 0.990198\n",
      "batch 1076: loss 0.833570\n",
      "batch 1077: loss 0.868966\n",
      "batch 1078: loss 0.732350\n",
      "batch 1079: loss 0.783846\n",
      "batch 1080: loss 0.881832\n",
      "batch 1081: loss 0.884563\n",
      "batch 1082: loss 0.714804\n",
      "batch 1083: loss 0.785508\n",
      "batch 1084: loss 1.039431\n",
      "batch 1085: loss 0.940916\n",
      "batch 1086: loss 0.839198\n",
      "batch 1087: loss 0.811863\n",
      "batch 1088: loss 0.961162\n",
      "batch 1089: loss 0.857970\n",
      "batch 1090: loss 0.624470\n",
      "batch 1091: loss 0.859719\n",
      "batch 1092: loss 0.798181\n",
      "batch 1093: loss 0.759475\n",
      "batch 1094: loss 0.780566\n",
      "batch 1095: loss 0.894529\n",
      "batch 1096: loss 0.821292\n",
      "batch 1097: loss 0.813252\n",
      "batch 1098: loss 0.754797\n",
      "batch 1099: loss 0.923431\n",
      "batch 1100: loss 0.808613\n",
      "batch 1101: loss 0.915402\n",
      "batch 1102: loss 0.821290\n",
      "batch 1103: loss 0.855492\n",
      "batch 1104: loss 0.736809\n",
      "batch 1105: loss 0.872056\n",
      "batch 1106: loss 0.792382\n",
      "batch 1107: loss 0.928075\n",
      "batch 1108: loss 0.806542\n",
      "batch 1109: loss 0.842240\n",
      "batch 1110: loss 0.812953\n",
      "batch 1111: loss 0.689317\n",
      "batch 1112: loss 0.885670\n",
      "batch 1113: loss 1.090981\n",
      "batch 1114: loss 0.788660\n",
      "batch 1115: loss 0.694637\n",
      "batch 1116: loss 0.774340\n",
      "batch 1117: loss 0.922277\n",
      "batch 1118: loss 0.903904\n",
      "batch 1119: loss 0.951458\n",
      "batch 1120: loss 0.724779\n",
      "batch 1121: loss 0.671613\n",
      "batch 1122: loss 0.693820\n",
      "batch 1123: loss 0.851017\n",
      "batch 1124: loss 0.699891\n",
      "batch 1125: loss 0.870569\n",
      "batch 1126: loss 0.716406\n",
      "batch 1127: loss 0.746677\n",
      "batch 1128: loss 0.934328\n",
      "batch 1129: loss 0.797148\n",
      "batch 1130: loss 0.757644\n",
      "batch 1131: loss 0.673223\n",
      "batch 1132: loss 0.820664\n",
      "batch 1133: loss 0.970756\n",
      "batch 1134: loss 0.756099\n",
      "batch 1135: loss 0.731602\n",
      "batch 1136: loss 0.996952\n",
      "batch 1137: loss 0.812787\n",
      "batch 1138: loss 0.853051\n",
      "batch 1139: loss 0.743333\n",
      "batch 1140: loss 0.922064\n",
      "batch 1141: loss 0.918058\n",
      "batch 1142: loss 0.872169\n",
      "batch 1143: loss 0.786472\n",
      "batch 1144: loss 0.838759\n",
      "batch 1145: loss 0.721502\n",
      "batch 1146: loss 0.601370\n",
      "batch 1147: loss 0.822539\n",
      "batch 1148: loss 0.825832\n",
      "batch 1149: loss 0.782255\n",
      "batch 1150: loss 0.799407\n",
      "batch 1151: loss 0.870704\n",
      "batch 1152: loss 0.819066\n",
      "batch 1153: loss 0.902426\n",
      "batch 1154: loss 0.983115\n",
      "batch 1155: loss 0.849407\n",
      "batch 1156: loss 0.714126\n",
      "batch 1157: loss 0.832521\n",
      "batch 1158: loss 0.664459\n",
      "batch 1159: loss 0.703310\n",
      "batch 1160: loss 0.894666\n",
      "batch 1161: loss 0.628794\n",
      "batch 1162: loss 0.860656\n",
      "batch 1163: loss 0.792459\n",
      "batch 1164: loss 0.737249\n",
      "batch 1165: loss 0.862792\n",
      "batch 1166: loss 0.716023\n",
      "batch 1167: loss 0.783620\n",
      "batch 1168: loss 0.871761\n",
      "batch 1169: loss 0.808117\n",
      "batch 1170: loss 0.654367\n",
      "batch 1171: loss 0.764353\n",
      "batch 1172: loss 0.772256\n",
      "batch 1173: loss 0.699968\n",
      "batch 1174: loss 0.633041\n",
      "batch 1175: loss 0.846616\n",
      "batch 1176: loss 0.654634\n",
      "batch 1177: loss 0.727185\n",
      "batch 1178: loss 0.731234\n",
      "batch 1179: loss 0.774630\n",
      "batch 1180: loss 0.657703\n",
      "batch 1181: loss 0.783556\n",
      "batch 1182: loss 0.735816\n",
      "batch 1183: loss 0.829555\n",
      "batch 1184: loss 0.891957\n",
      "batch 1185: loss 0.826453\n",
      "batch 1186: loss 0.807979\n",
      "batch 1187: loss 0.791410\n",
      "batch 1188: loss 0.714682\n",
      "batch 1189: loss 0.823094\n",
      "batch 1190: loss 0.674465\n",
      "batch 1191: loss 0.812617\n",
      "batch 1192: loss 0.986393\n",
      "batch 1193: loss 0.652533\n",
      "batch 1194: loss 0.742378\n",
      "batch 1195: loss 0.759016\n",
      "batch 1196: loss 0.660928\n",
      "batch 1197: loss 0.812028\n",
      "batch 1198: loss 0.783788\n",
      "batch 1199: loss 0.715520\n",
      "batch 1200: loss 0.767439\n",
      "batch 1201: loss 0.756352\n",
      "batch 1202: loss 0.830456\n",
      "batch 1203: loss 0.645161\n",
      "batch 1204: loss 0.796443\n",
      "batch 1205: loss 0.651594\n",
      "batch 1206: loss 0.667595\n",
      "batch 1207: loss 0.666976\n",
      "batch 1208: loss 0.822888\n",
      "batch 1209: loss 0.746676\n",
      "batch 1210: loss 0.623307\n",
      "batch 1211: loss 0.771034\n",
      "batch 1212: loss 0.731685\n",
      "batch 1213: loss 0.858795\n",
      "batch 1214: loss 0.690565\n",
      "batch 1215: loss 0.797337\n",
      "batch 1216: loss 0.674862\n",
      "batch 1217: loss 0.718398\n",
      "batch 1218: loss 0.830104\n",
      "batch 1219: loss 0.627403\n",
      "batch 1220: loss 0.807705\n",
      "batch 1221: loss 0.611987\n",
      "batch 1222: loss 0.781375\n",
      "batch 1223: loss 0.728340\n",
      "batch 1224: loss 0.881973\n",
      "batch 1225: loss 0.645195\n",
      "batch 1226: loss 0.669777\n",
      "batch 1227: loss 0.727152\n",
      "batch 1228: loss 0.772641\n",
      "batch 1229: loss 0.735189\n",
      "batch 1230: loss 0.846977\n",
      "batch 1231: loss 0.716473\n",
      "batch 1232: loss 0.712054\n",
      "batch 1233: loss 0.808313\n",
      "batch 1234: loss 0.729695\n",
      "batch 1235: loss 0.771987\n",
      "batch 1236: loss 0.762492\n",
      "batch 1237: loss 0.835397\n",
      "batch 1238: loss 0.906528\n",
      "batch 1239: loss 0.926178\n",
      "batch 1240: loss 0.774501\n",
      "batch 1241: loss 0.764449\n",
      "batch 1242: loss 0.757934\n",
      "batch 1243: loss 0.913291\n",
      "batch 1244: loss 0.741391\n",
      "batch 1245: loss 0.762953\n",
      "batch 1246: loss 0.651185\n",
      "batch 1247: loss 0.799257\n",
      "batch 1248: loss 0.695226\n",
      "batch 1249: loss 0.631228\n",
      "batch 1250: loss 0.745178\n",
      "batch 1251: loss 0.794740\n",
      "batch 1252: loss 0.857689\n",
      "batch 1253: loss 0.895011\n",
      "batch 1254: loss 0.710535\n",
      "batch 1255: loss 0.767444\n",
      "batch 1256: loss 0.674654\n",
      "batch 1257: loss 0.836667\n",
      "batch 1258: loss 0.784364\n",
      "batch 1259: loss 0.752901\n",
      "batch 1260: loss 0.684093\n",
      "batch 1261: loss 0.830721\n",
      "batch 1262: loss 0.764408\n",
      "batch 1263: loss 0.795723\n",
      "batch 1264: loss 0.879661\n",
      "batch 1265: loss 0.768640\n",
      "batch 1266: loss 0.667108\n",
      "batch 1267: loss 0.818039\n",
      "batch 1268: loss 0.673576\n",
      "batch 1269: loss 0.813998\n",
      "batch 1270: loss 0.748837\n",
      "batch 1271: loss 0.752204\n",
      "batch 1272: loss 0.654101\n",
      "batch 1273: loss 0.740863\n",
      "batch 1274: loss 0.660821\n",
      "batch 1275: loss 0.600412\n",
      "batch 1276: loss 0.841620\n",
      "batch 1277: loss 0.656139\n",
      "batch 1278: loss 0.691438\n",
      "batch 1279: loss 0.917454\n",
      "batch 1280: loss 0.670873\n",
      "batch 1281: loss 0.801644\n",
      "batch 1282: loss 0.797330\n",
      "batch 1283: loss 0.731690\n",
      "batch 1284: loss 0.694573\n",
      "batch 1285: loss 0.792379\n",
      "batch 1286: loss 0.691501\n",
      "batch 1287: loss 0.734652\n",
      "batch 1288: loss 0.768879\n",
      "batch 1289: loss 0.863730\n",
      "batch 1290: loss 0.839578\n",
      "batch 1291: loss 0.819817\n",
      "batch 1292: loss 0.612749\n",
      "batch 1293: loss 0.579416\n",
      "batch 1294: loss 0.712912\n",
      "batch 1295: loss 0.564071\n",
      "batch 1296: loss 0.860201\n",
      "batch 1297: loss 0.574780\n",
      "batch 1298: loss 0.771112\n",
      "batch 1299: loss 0.773781\n",
      "batch 1300: loss 0.815463\n",
      "batch 1301: loss 0.773868\n",
      "batch 1302: loss 0.736314\n",
      "batch 1303: loss 0.757923\n",
      "batch 1304: loss 0.712025\n",
      "batch 1305: loss 0.731625\n",
      "batch 1306: loss 0.905937\n",
      "batch 1307: loss 0.731553\n",
      "batch 1308: loss 0.729630\n",
      "batch 1309: loss 0.732257\n",
      "batch 1310: loss 0.679714\n",
      "batch 1311: loss 0.643467\n",
      "batch 1312: loss 0.805283\n",
      "batch 1313: loss 0.800955\n",
      "batch 1314: loss 0.713162\n",
      "batch 1315: loss 0.722995\n",
      "batch 1316: loss 0.773988\n",
      "batch 1317: loss 0.857384\n",
      "batch 1318: loss 0.742910\n",
      "batch 1319: loss 0.587297\n",
      "batch 1320: loss 0.698132\n",
      "batch 1321: loss 0.881906\n",
      "batch 1322: loss 0.710752\n",
      "batch 1323: loss 0.764830\n",
      "batch 1324: loss 0.801628\n",
      "batch 1325: loss 0.722733\n",
      "batch 1326: loss 0.672706\n",
      "batch 1327: loss 0.780624\n",
      "batch 1328: loss 0.714240\n",
      "batch 1329: loss 0.678860\n",
      "batch 1330: loss 0.874093\n",
      "batch 1331: loss 0.757153\n",
      "batch 1332: loss 0.622020\n",
      "batch 1333: loss 0.584537\n",
      "batch 1334: loss 0.684180\n",
      "batch 1335: loss 0.651996\n",
      "batch 1336: loss 0.726302\n",
      "batch 1337: loss 0.741547\n",
      "batch 1338: loss 0.885449\n",
      "batch 1339: loss 0.548242\n",
      "batch 1340: loss 0.652662\n",
      "batch 1341: loss 0.622611\n",
      "batch 1342: loss 0.630108\n",
      "batch 1343: loss 0.804819\n",
      "batch 1344: loss 0.680105\n",
      "batch 1345: loss 0.871197\n",
      "batch 1346: loss 0.627230\n",
      "batch 1347: loss 0.665921\n",
      "batch 1348: loss 0.807998\n",
      "batch 1349: loss 0.689730\n",
      "batch 1350: loss 0.793720\n",
      "batch 1351: loss 0.710479\n",
      "batch 1352: loss 0.633108\n",
      "batch 1353: loss 0.692590\n",
      "batch 1354: loss 0.579233\n",
      "batch 1355: loss 0.653587\n",
      "batch 1356: loss 0.763696\n",
      "batch 1357: loss 0.820790\n",
      "batch 1358: loss 0.719708\n",
      "batch 1359: loss 0.592598\n",
      "batch 1360: loss 0.949849\n",
      "batch 1361: loss 0.586422\n",
      "batch 1362: loss 0.717217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1363: loss 0.696965\n",
      "batch 1364: loss 0.732575\n",
      "batch 1365: loss 0.668751\n",
      "batch 1366: loss 0.669507\n",
      "batch 1367: loss 0.590747\n",
      "batch 1368: loss 0.621324\n",
      "batch 1369: loss 0.618797\n",
      "batch 1370: loss 0.773376\n",
      "batch 1371: loss 0.568595\n",
      "batch 1372: loss 0.590521\n",
      "batch 1373: loss 0.636020\n",
      "batch 1374: loss 0.768477\n",
      "batch 1375: loss 0.810796\n",
      "batch 1376: loss 0.916021\n",
      "batch 1377: loss 0.719857\n",
      "batch 1378: loss 0.614954\n",
      "batch 1379: loss 0.757353\n",
      "batch 1380: loss 0.685695\n",
      "batch 1381: loss 0.685879\n",
      "batch 1382: loss 0.644755\n",
      "batch 1383: loss 0.821842\n",
      "batch 1384: loss 0.685386\n",
      "batch 1385: loss 0.792516\n",
      "batch 1386: loss 0.697359\n",
      "batch 1387: loss 0.669218\n",
      "batch 1388: loss 0.747285\n",
      "batch 1389: loss 0.683494\n",
      "batch 1390: loss 0.642349\n",
      "batch 1391: loss 0.671826\n",
      "batch 1392: loss 0.730739\n",
      "batch 1393: loss 0.634707\n",
      "batch 1394: loss 0.567053\n",
      "batch 1395: loss 0.839080\n",
      "batch 1396: loss 0.729280\n",
      "batch 1397: loss 0.839153\n",
      "batch 1398: loss 0.554817\n",
      "batch 1399: loss 0.895457\n",
      "batch 1400: loss 0.738119\n",
      "batch 1401: loss 0.638996\n",
      "batch 1402: loss 0.658957\n",
      "batch 1403: loss 0.657489\n",
      "batch 1404: loss 0.692822\n",
      "batch 1405: loss 0.820288\n",
      "batch 1406: loss 1.037609\n",
      "batch 1407: loss 0.654781\n",
      "batch 1408: loss 0.814110\n",
      "batch 1409: loss 0.763752\n",
      "batch 1410: loss 0.506092\n",
      "batch 1411: loss 0.705360\n",
      "batch 1412: loss 0.736610\n",
      "batch 1413: loss 0.555093\n",
      "batch 1414: loss 0.679827\n",
      "batch 1415: loss 0.525392\n",
      "batch 1416: loss 0.680692\n",
      "batch 1417: loss 0.673399\n",
      "batch 1418: loss 0.624757\n",
      "batch 1419: loss 0.642169\n",
      "batch 1420: loss 0.558642\n",
      "batch 1421: loss 0.593680\n",
      "batch 1422: loss 0.543284\n",
      "batch 1423: loss 0.798476\n",
      "batch 1424: loss 0.648273\n",
      "batch 1425: loss 0.780532\n",
      "batch 1426: loss 0.748817\n",
      "batch 1427: loss 0.695139\n",
      "batch 1428: loss 0.679309\n",
      "batch 1429: loss 0.487750\n",
      "batch 1430: loss 0.602385\n",
      "batch 1431: loss 0.742452\n",
      "batch 1432: loss 0.961225\n",
      "batch 1433: loss 0.484842\n",
      "batch 1434: loss 0.625510\n",
      "batch 1435: loss 0.732814\n",
      "batch 1436: loss 0.626011\n",
      "batch 1437: loss 0.747795\n",
      "batch 1438: loss 0.787719\n",
      "batch 1439: loss 0.566580\n",
      "batch 1440: loss 0.732816\n",
      "batch 1441: loss 0.621326\n",
      "batch 1442: loss 0.677111\n",
      "batch 1443: loss 0.633893\n",
      "batch 1444: loss 0.807416\n",
      "batch 1445: loss 0.631696\n",
      "batch 1446: loss 0.723490\n",
      "batch 1447: loss 0.474134\n",
      "batch 1448: loss 0.581403\n",
      "batch 1449: loss 0.641941\n",
      "batch 1450: loss 0.677194\n",
      "batch 1451: loss 0.759081\n",
      "batch 1452: loss 0.549700\n",
      "batch 1453: loss 0.632464\n",
      "batch 1454: loss 0.573584\n",
      "batch 1455: loss 0.746894\n",
      "batch 1456: loss 0.649949\n",
      "batch 1457: loss 0.656505\n",
      "batch 1458: loss 0.944643\n",
      "batch 1459: loss 0.815690\n",
      "batch 1460: loss 0.753311\n",
      "batch 1461: loss 0.644644\n",
      "batch 1462: loss 0.860663\n",
      "batch 1463: loss 0.690788\n",
      "batch 1464: loss 0.518545\n",
      "batch 1465: loss 0.716009\n",
      "batch 1466: loss 0.646897\n",
      "batch 1467: loss 0.692492\n",
      "batch 1468: loss 0.692952\n",
      "batch 1469: loss 0.532485\n",
      "batch 1470: loss 0.710952\n",
      "batch 1471: loss 0.721831\n",
      "batch 1472: loss 0.601092\n",
      "batch 1473: loss 0.737301\n",
      "batch 1474: loss 0.536115\n",
      "batch 1475: loss 0.678090\n",
      "batch 1476: loss 0.710274\n",
      "batch 1477: loss 0.565269\n",
      "batch 1478: loss 0.581779\n",
      "batch 1479: loss 0.638523\n",
      "batch 1480: loss 0.708707\n",
      "batch 1481: loss 0.669272\n",
      "batch 1482: loss 0.603848\n",
      "batch 1483: loss 0.628391\n",
      "batch 1484: loss 0.655985\n",
      "batch 1485: loss 0.485235\n",
      "batch 1486: loss 0.433087\n",
      "batch 1487: loss 0.634880\n",
      "batch 1488: loss 0.563494\n",
      "batch 1489: loss 0.683626\n",
      "batch 1490: loss 0.662462\n",
      "batch 1491: loss 0.740309\n",
      "batch 1492: loss 0.769453\n",
      "batch 1493: loss 0.792155\n",
      "batch 1494: loss 0.642159\n",
      "batch 1495: loss 0.585467\n",
      "batch 1496: loss 0.718172\n",
      "batch 1497: loss 0.688710\n",
      "batch 1498: loss 0.601577\n",
      "batch 1499: loss 0.731283\n",
      "batch 1500: loss 0.628769\n",
      "batch 1501: loss 0.766819\n",
      "batch 1502: loss 0.731373\n",
      "batch 1503: loss 0.728446\n",
      "batch 1504: loss 0.652548\n",
      "batch 1505: loss 0.656420\n",
      "batch 1506: loss 0.681685\n",
      "batch 1507: loss 0.734159\n",
      "batch 1508: loss 0.614778\n",
      "batch 1509: loss 0.619388\n",
      "batch 1510: loss 0.551437\n",
      "batch 1511: loss 0.578524\n",
      "batch 1512: loss 0.572446\n",
      "batch 1513: loss 0.572607\n",
      "batch 1514: loss 0.552080\n",
      "batch 1515: loss 0.859659\n",
      "batch 1516: loss 0.535661\n",
      "batch 1517: loss 0.585446\n",
      "batch 1518: loss 0.665448\n",
      "batch 1519: loss 0.520310\n",
      "batch 1520: loss 0.514674\n",
      "batch 1521: loss 0.411343\n",
      "batch 1522: loss 0.510700\n",
      "batch 1523: loss 0.516036\n",
      "batch 1524: loss 0.818974\n",
      "batch 1525: loss 0.656367\n",
      "batch 1526: loss 0.652126\n",
      "batch 1527: loss 0.610287\n",
      "batch 1528: loss 0.875008\n",
      "batch 1529: loss 0.832609\n",
      "batch 1530: loss 0.969210\n",
      "batch 1531: loss 0.697568\n",
      "batch 1532: loss 0.634739\n",
      "batch 1533: loss 0.594331\n",
      "batch 1534: loss 0.825104\n",
      "batch 1535: loss 0.765003\n",
      "batch 1536: loss 0.537924\n",
      "batch 1537: loss 0.917241\n",
      "batch 1538: loss 0.502308\n",
      "batch 1539: loss 0.619981\n",
      "batch 1540: loss 0.561247\n",
      "batch 1541: loss 0.652453\n",
      "batch 1542: loss 0.632524\n",
      "batch 1543: loss 0.695354\n",
      "batch 1544: loss 0.488742\n",
      "batch 1545: loss 0.537786\n",
      "batch 1546: loss 0.571487\n",
      "batch 1547: loss 0.563127\n",
      "batch 1548: loss 0.612380\n",
      "batch 1549: loss 0.560390\n",
      "batch 1550: loss 0.662663\n",
      "batch 1551: loss 0.766263\n",
      "batch 1552: loss 0.533675\n",
      "batch 1553: loss 0.738273\n",
      "batch 1554: loss 0.922847\n",
      "batch 1555: loss 0.604487\n",
      "batch 1556: loss 0.707002\n",
      "batch 1557: loss 0.459641\n",
      "batch 1558: loss 0.640178\n",
      "batch 1559: loss 0.625496\n",
      "batch 1560: loss 0.722954\n",
      "batch 1561: loss 0.675262\n",
      "batch 1562: loss 0.681181\n",
      "batch 1563: loss 0.558320\n",
      "batch 1564: loss 0.536709\n",
      "batch 1565: loss 0.470181\n",
      "batch 1566: loss 0.544033\n",
      "batch 1567: loss 0.609838\n",
      "batch 1568: loss 0.661456\n",
      "batch 1569: loss 0.571313\n",
      "batch 1570: loss 0.583251\n",
      "batch 1571: loss 0.750939\n",
      "batch 1572: loss 0.446986\n",
      "batch 1573: loss 0.663476\n",
      "batch 1574: loss 0.740290\n",
      "batch 1575: loss 0.812073\n",
      "batch 1576: loss 0.758286\n",
      "batch 1577: loss 0.623579\n",
      "batch 1578: loss 0.557260\n",
      "batch 1579: loss 0.565178\n",
      "batch 1580: loss 0.569504\n",
      "batch 1581: loss 0.499702\n",
      "batch 1582: loss 0.761530\n",
      "batch 1583: loss 0.573126\n",
      "batch 1584: loss 0.790645\n",
      "batch 1585: loss 0.714715\n",
      "batch 1586: loss 0.782031\n",
      "batch 1587: loss 0.887111\n",
      "batch 1588: loss 0.583731\n",
      "batch 1589: loss 0.524405\n",
      "batch 1590: loss 0.775784\n",
      "batch 1591: loss 0.741684\n",
      "batch 1592: loss 0.654315\n",
      "batch 1593: loss 0.755126\n",
      "batch 1594: loss 0.593831\n",
      "batch 1595: loss 0.562875\n",
      "batch 1596: loss 0.617482\n",
      "batch 1597: loss 0.568947\n",
      "batch 1598: loss 0.474606\n",
      "batch 1599: loss 0.578099\n",
      "batch 1600: loss 0.723933\n",
      "batch 1601: loss 0.682036\n",
      "batch 1602: loss 0.739616\n",
      "batch 1603: loss 0.632027\n",
      "batch 1604: loss 0.868544\n",
      "batch 1605: loss 0.540909\n",
      "batch 1606: loss 0.692205\n",
      "batch 1607: loss 0.725759\n",
      "batch 1608: loss 0.620484\n",
      "batch 1609: loss 0.670016\n",
      "batch 1610: loss 0.691770\n",
      "batch 1611: loss 0.544671\n",
      "batch 1612: loss 0.570984\n",
      "batch 1613: loss 0.685581\n",
      "batch 1614: loss 0.550227\n",
      "batch 1615: loss 0.597932\n",
      "batch 1616: loss 0.602567\n",
      "batch 1617: loss 0.601859\n",
      "batch 1618: loss 0.688124\n",
      "batch 1619: loss 0.676213\n",
      "batch 1620: loss 0.577166\n",
      "batch 1621: loss 0.478186\n",
      "batch 1622: loss 0.589153\n",
      "batch 1623: loss 0.699900\n",
      "batch 1624: loss 0.456881\n",
      "batch 1625: loss 0.672789\n",
      "batch 1626: loss 0.687133\n",
      "batch 1627: loss 0.786111\n",
      "batch 1628: loss 0.529749\n",
      "batch 1629: loss 0.579647\n",
      "batch 1630: loss 0.681101\n",
      "batch 1631: loss 0.598549\n",
      "batch 1632: loss 0.588370\n",
      "batch 1633: loss 0.595687\n",
      "batch 1634: loss 0.664825\n",
      "batch 1635: loss 0.581571\n",
      "batch 1636: loss 0.663296\n",
      "batch 1637: loss 0.679043\n",
      "batch 1638: loss 0.687745\n",
      "batch 1639: loss 0.503348\n",
      "batch 1640: loss 0.571871\n",
      "batch 1641: loss 0.717737\n",
      "batch 1642: loss 0.704197\n",
      "batch 1643: loss 0.729560\n",
      "batch 1644: loss 0.687149\n",
      "batch 1645: loss 0.700438\n",
      "batch 1646: loss 0.678004\n",
      "batch 1647: loss 0.709074\n",
      "batch 1648: loss 0.598800\n",
      "batch 1649: loss 0.692449\n",
      "batch 1650: loss 0.735337\n",
      "batch 1651: loss 0.674149\n",
      "batch 1652: loss 0.450272\n",
      "batch 1653: loss 0.565219\n",
      "batch 1654: loss 0.844642\n",
      "batch 1655: loss 0.440257\n",
      "batch 1656: loss 0.415674\n",
      "batch 1657: loss 0.485439\n",
      "batch 1658: loss 0.651303\n",
      "batch 1659: loss 0.574988\n",
      "batch 1660: loss 0.685263\n",
      "batch 1661: loss 0.767155\n",
      "batch 1662: loss 0.510141\n",
      "batch 1663: loss 0.436061\n",
      "batch 1664: loss 0.714742\n",
      "batch 1665: loss 0.513677\n",
      "batch 1666: loss 0.532528\n",
      "batch 1667: loss 0.458942\n",
      "batch 1668: loss 0.613990\n",
      "batch 1669: loss 0.615388\n",
      "batch 1670: loss 0.698337\n",
      "batch 1671: loss 0.754548\n",
      "batch 1672: loss 0.711585\n",
      "batch 1673: loss 0.485695\n",
      "batch 1674: loss 0.548017\n",
      "batch 1675: loss 0.632633\n",
      "batch 1676: loss 0.549418\n",
      "batch 1677: loss 0.653114\n",
      "batch 1678: loss 0.608654\n",
      "batch 1679: loss 0.462771\n",
      "batch 1680: loss 0.809725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1681: loss 0.584044\n",
      "batch 1682: loss 0.700174\n",
      "batch 1683: loss 0.534506\n",
      "batch 1684: loss 0.592797\n",
      "batch 1685: loss 0.570278\n",
      "batch 1686: loss 0.608199\n",
      "batch 1687: loss 0.548660\n",
      "batch 1688: loss 0.570942\n",
      "batch 1689: loss 0.739286\n",
      "batch 1690: loss 0.535929\n",
      "batch 1691: loss 0.725040\n",
      "batch 1692: loss 0.457220\n",
      "batch 1693: loss 0.571232\n",
      "batch 1694: loss 0.866453\n",
      "batch 1695: loss 0.566969\n",
      "batch 1696: loss 0.557931\n",
      "batch 1697: loss 0.919621\n",
      "batch 1698: loss 0.647946\n",
      "batch 1699: loss 0.582708\n",
      "batch 1700: loss 0.565306\n",
      "batch 1701: loss 0.459521\n",
      "batch 1702: loss 0.753393\n",
      "batch 1703: loss 0.516679\n",
      "batch 1704: loss 0.629870\n",
      "batch 1705: loss 0.493295\n",
      "batch 1706: loss 0.587411\n",
      "batch 1707: loss 0.648457\n",
      "batch 1708: loss 0.604518\n",
      "batch 1709: loss 0.622656\n",
      "batch 1710: loss 0.565197\n",
      "batch 1711: loss 0.535519\n",
      "batch 1712: loss 0.683226\n",
      "batch 1713: loss 0.488991\n",
      "batch 1714: loss 0.620640\n",
      "batch 1715: loss 0.528106\n",
      "batch 1716: loss 0.594271\n",
      "batch 1717: loss 0.793343\n",
      "batch 1718: loss 0.621974\n",
      "batch 1719: loss 0.537114\n",
      "batch 1720: loss 0.721602\n",
      "batch 1721: loss 0.465058\n",
      "batch 1722: loss 0.770468\n",
      "batch 1723: loss 0.580419\n",
      "batch 1724: loss 0.931302\n",
      "batch 1725: loss 0.701580\n",
      "batch 1726: loss 0.682197\n",
      "batch 1727: loss 0.598055\n",
      "batch 1728: loss 0.503230\n",
      "batch 1729: loss 0.588388\n",
      "batch 1730: loss 0.631148\n",
      "batch 1731: loss 0.711560\n",
      "batch 1732: loss 0.607933\n",
      "batch 1733: loss 0.700441\n",
      "batch 1734: loss 0.620848\n",
      "batch 1735: loss 0.766248\n",
      "batch 1736: loss 0.456087\n",
      "batch 1737: loss 0.655203\n",
      "batch 1738: loss 0.536400\n",
      "batch 1739: loss 0.623564\n",
      "batch 1740: loss 0.727547\n",
      "batch 1741: loss 0.645094\n",
      "batch 1742: loss 0.699759\n",
      "batch 1743: loss 0.658485\n",
      "batch 1744: loss 0.507166\n",
      "batch 1745: loss 0.629668\n",
      "batch 1746: loss 0.375383\n",
      "batch 1747: loss 0.481728\n",
      "batch 1748: loss 0.615735\n",
      "batch 1749: loss 0.717059\n",
      "batch 1750: loss 0.523845\n",
      "batch 1751: loss 0.645919\n",
      "batch 1752: loss 0.597973\n",
      "batch 1753: loss 0.622561\n",
      "batch 1754: loss 0.568522\n",
      "batch 1755: loss 0.620071\n",
      "batch 1756: loss 0.528926\n",
      "batch 1757: loss 0.581217\n",
      "batch 1758: loss 0.575530\n",
      "batch 1759: loss 0.419732\n",
      "batch 1760: loss 0.515512\n",
      "batch 1761: loss 0.836252\n",
      "batch 1762: loss 0.512362\n",
      "batch 1763: loss 0.664704\n",
      "batch 1764: loss 0.684163\n",
      "batch 1765: loss 0.601357\n",
      "batch 1766: loss 0.473944\n",
      "batch 1767: loss 0.385137\n",
      "batch 1768: loss 0.471783\n",
      "batch 1769: loss 0.810302\n",
      "batch 1770: loss 0.571423\n",
      "batch 1771: loss 0.597497\n",
      "batch 1772: loss 0.607634\n",
      "batch 1773: loss 0.615757\n",
      "batch 1774: loss 0.614979\n",
      "batch 1775: loss 0.517831\n",
      "batch 1776: loss 0.606415\n",
      "batch 1777: loss 0.590005\n",
      "batch 1778: loss 0.472937\n",
      "batch 1779: loss 0.454028\n",
      "batch 1780: loss 0.644760\n",
      "batch 1781: loss 0.690929\n",
      "batch 1782: loss 0.636366\n",
      "batch 1783: loss 0.540734\n",
      "batch 1784: loss 0.675040\n",
      "batch 1785: loss 0.659023\n",
      "batch 1786: loss 0.442782\n",
      "batch 1787: loss 0.667495\n",
      "batch 1788: loss 0.584727\n",
      "batch 1789: loss 0.511081\n",
      "batch 1790: loss 0.691160\n",
      "batch 1791: loss 0.593059\n",
      "batch 1792: loss 0.593439\n",
      "batch 1793: loss 0.591661\n",
      "batch 1794: loss 0.507890\n",
      "batch 1795: loss 0.433633\n",
      "batch 1796: loss 0.721573\n",
      "batch 1797: loss 0.692098\n",
      "batch 1798: loss 0.608181\n",
      "batch 1799: loss 0.496413\n",
      "batch 1800: loss 0.586715\n",
      "batch 1801: loss 0.553862\n",
      "batch 1802: loss 0.546128\n",
      "batch 1803: loss 0.832428\n",
      "batch 1804: loss 0.541938\n",
      "batch 1805: loss 0.533393\n",
      "batch 1806: loss 0.461609\n",
      "batch 1807: loss 0.560394\n",
      "batch 1808: loss 0.534059\n",
      "batch 1809: loss 0.483685\n",
      "batch 1810: loss 0.549870\n",
      "batch 1811: loss 0.456856\n",
      "batch 1812: loss 0.562437\n",
      "batch 1813: loss 0.590639\n",
      "batch 1814: loss 0.537390\n",
      "batch 1815: loss 0.867964\n",
      "batch 1816: loss 0.578410\n",
      "batch 1817: loss 0.619864\n",
      "batch 1818: loss 0.483255\n",
      "batch 1819: loss 0.579767\n",
      "batch 1820: loss 0.629715\n",
      "batch 1821: loss 0.709860\n",
      "batch 1822: loss 0.438622\n",
      "batch 1823: loss 0.585628\n",
      "batch 1824: loss 0.501854\n",
      "batch 1825: loss 0.667892\n",
      "batch 1826: loss 0.591413\n",
      "batch 1827: loss 0.536515\n",
      "batch 1828: loss 0.648848\n",
      "batch 1829: loss 0.790333\n",
      "batch 1830: loss 0.531883\n",
      "batch 1831: loss 0.715420\n",
      "batch 1832: loss 0.449470\n",
      "batch 1833: loss 0.515448\n",
      "batch 1834: loss 0.562009\n",
      "batch 1835: loss 0.729098\n",
      "batch 1836: loss 0.639224\n",
      "batch 1837: loss 0.623109\n",
      "batch 1838: loss 0.601366\n",
      "batch 1839: loss 0.623368\n",
      "batch 1840: loss 0.504676\n",
      "batch 1841: loss 0.641595\n",
      "batch 1842: loss 0.511285\n",
      "batch 1843: loss 0.558008\n",
      "batch 1844: loss 0.654461\n",
      "batch 1845: loss 0.572017\n",
      "batch 1846: loss 0.572190\n",
      "batch 1847: loss 0.745201\n",
      "batch 1848: loss 0.627419\n",
      "batch 1849: loss 0.719299\n",
      "batch 1850: loss 0.478996\n",
      "batch 1851: loss 0.812700\n",
      "batch 1852: loss 0.532035\n",
      "batch 1853: loss 0.892329\n",
      "batch 1854: loss 0.791813\n",
      "batch 1855: loss 0.644132\n",
      "batch 1856: loss 0.454566\n",
      "batch 1857: loss 0.503469\n",
      "batch 1858: loss 0.616829\n",
      "batch 1859: loss 0.593528\n",
      "batch 1860: loss 0.507091\n",
      "batch 1861: loss 0.447773\n",
      "batch 1862: loss 0.674307\n",
      "batch 1863: loss 0.403800\n",
      "batch 1864: loss 0.517505\n",
      "batch 1865: loss 0.678000\n",
      "batch 1866: loss 0.496585\n",
      "batch 1867: loss 0.545883\n",
      "batch 1868: loss 0.763184\n",
      "batch 1869: loss 0.472606\n",
      "batch 1870: loss 0.534390\n",
      "batch 1871: loss 0.551174\n",
      "batch 1872: loss 0.500435\n",
      "batch 1873: loss 0.575976\n",
      "batch 1874: loss 0.659061\n",
      "batch 1875: loss 0.451678\n",
      "batch 1876: loss 0.461918\n",
      "batch 1877: loss 0.698390\n",
      "batch 1878: loss 0.643341\n",
      "batch 1879: loss 0.410680\n",
      "batch 1880: loss 0.667881\n",
      "batch 1881: loss 0.530799\n",
      "batch 1882: loss 0.688342\n",
      "batch 1883: loss 0.757945\n",
      "batch 1884: loss 0.645488\n",
      "batch 1885: loss 0.713165\n",
      "batch 1886: loss 0.500326\n",
      "batch 1887: loss 0.643071\n",
      "batch 1888: loss 0.474013\n",
      "batch 1889: loss 0.532403\n",
      "batch 1890: loss 0.520849\n",
      "batch 1891: loss 0.724069\n",
      "batch 1892: loss 0.581633\n",
      "batch 1893: loss 0.605202\n",
      "batch 1894: loss 0.728212\n",
      "batch 1895: loss 0.446680\n",
      "batch 1896: loss 0.517118\n",
      "batch 1897: loss 0.727075\n",
      "batch 1898: loss 0.521507\n",
      "batch 1899: loss 0.585312\n",
      "batch 1900: loss 0.615835\n",
      "batch 1901: loss 0.651347\n",
      "batch 1902: loss 0.646472\n",
      "batch 1903: loss 0.403601\n",
      "batch 1904: loss 0.535528\n",
      "batch 1905: loss 0.623248\n",
      "batch 1906: loss 0.595061\n",
      "batch 1907: loss 0.572250\n",
      "batch 1908: loss 0.721402\n",
      "batch 1909: loss 0.626519\n",
      "batch 1910: loss 0.304018\n",
      "batch 1911: loss 0.508367\n",
      "batch 1912: loss 0.808507\n",
      "batch 1913: loss 0.608697\n",
      "batch 1914: loss 0.573099\n",
      "batch 1915: loss 0.766404\n",
      "batch 1916: loss 0.300793\n",
      "batch 1917: loss 0.562695\n",
      "batch 1918: loss 0.505029\n",
      "batch 1919: loss 0.677674\n",
      "batch 1920: loss 0.626557\n",
      "batch 1921: loss 0.441245\n",
      "batch 1922: loss 0.566170\n",
      "batch 1923: loss 0.464680\n",
      "batch 1924: loss 0.425114\n",
      "batch 1925: loss 0.467943\n",
      "batch 1926: loss 0.494998\n",
      "batch 1927: loss 0.650519\n",
      "batch 1928: loss 0.800916\n",
      "batch 1929: loss 0.698137\n",
      "batch 1930: loss 0.619050\n",
      "batch 1931: loss 0.552814\n",
      "batch 1932: loss 0.632867\n",
      "batch 1933: loss 0.572459\n",
      "batch 1934: loss 0.492652\n",
      "batch 1935: loss 0.464990\n",
      "batch 1936: loss 0.642201\n",
      "batch 1937: loss 0.609884\n",
      "batch 1938: loss 0.434290\n",
      "batch 1939: loss 0.493536\n",
      "batch 1940: loss 0.450382\n",
      "batch 1941: loss 0.635974\n",
      "batch 1942: loss 0.698438\n",
      "batch 1943: loss 0.403354\n",
      "batch 1944: loss 0.474361\n",
      "batch 1945: loss 0.512065\n",
      "batch 1946: loss 0.506168\n",
      "batch 1947: loss 0.579966\n",
      "batch 1948: loss 0.486687\n",
      "batch 1949: loss 0.486209\n",
      "batch 1950: loss 0.400643\n",
      "batch 1951: loss 0.531759\n",
      "batch 1952: loss 0.653001\n",
      "batch 1953: loss 0.599052\n",
      "batch 1954: loss 0.574415\n",
      "batch 1955: loss 0.596844\n",
      "batch 1956: loss 0.554527\n",
      "batch 1957: loss 0.565888\n",
      "batch 1958: loss 0.771787\n",
      "batch 1959: loss 0.336098\n",
      "batch 1960: loss 0.574791\n",
      "batch 1961: loss 0.497204\n",
      "batch 1962: loss 0.529205\n",
      "batch 1963: loss 0.564200\n",
      "batch 1964: loss 0.513019\n",
      "batch 1965: loss 0.533109\n",
      "batch 1966: loss 0.497996\n",
      "batch 1967: loss 0.524064\n",
      "batch 1968: loss 0.702552\n",
      "batch 1969: loss 0.460065\n",
      "batch 1970: loss 0.535545\n",
      "batch 1971: loss 0.631445\n",
      "batch 1972: loss 0.605756\n",
      "batch 1973: loss 0.622358\n",
      "batch 1974: loss 0.698899\n",
      "batch 1975: loss 0.471085\n",
      "batch 1976: loss 0.543523\n",
      "batch 1977: loss 0.481180\n",
      "batch 1978: loss 0.505727\n",
      "batch 1979: loss 0.517554\n",
      "batch 1980: loss 0.511194\n",
      "batch 1981: loss 0.500149\n",
      "batch 1982: loss 0.457740\n",
      "batch 1983: loss 0.486458\n",
      "batch 1984: loss 0.349595\n",
      "batch 1985: loss 0.487237\n",
      "batch 1986: loss 0.540824\n",
      "batch 1987: loss 0.683384\n",
      "batch 1988: loss 0.548144\n",
      "batch 1989: loss 0.468598\n",
      "batch 1990: loss 0.364816\n",
      "batch 1991: loss 0.492023\n",
      "batch 1992: loss 0.685081\n",
      "batch 1993: loss 0.557418\n",
      "batch 1994: loss 0.566844\n",
      "batch 1995: loss 0.769666\n",
      "batch 1996: loss 0.495745\n",
      "batch 1997: loss 0.535318\n",
      "batch 1998: loss 0.527347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1999: loss 0.501760\n",
      "batch 2000: loss 0.644602\n",
      "batch 2001: loss 0.583661\n",
      "batch 2002: loss 0.790734\n",
      "batch 2003: loss 0.699461\n",
      "batch 2004: loss 0.754037\n",
      "batch 2005: loss 0.509695\n",
      "batch 2006: loss 0.541466\n",
      "batch 2007: loss 0.494433\n",
      "batch 2008: loss 0.504857\n",
      "batch 2009: loss 0.485256\n",
      "batch 2010: loss 0.776694\n",
      "batch 2011: loss 0.500636\n",
      "batch 2012: loss 0.419993\n",
      "batch 2013: loss 0.450271\n",
      "batch 2014: loss 0.592319\n",
      "batch 2015: loss 0.539655\n",
      "batch 2016: loss 0.386913\n",
      "batch 2017: loss 0.437810\n",
      "batch 2018: loss 0.515108\n",
      "batch 2019: loss 0.445173\n",
      "batch 2020: loss 0.443164\n",
      "batch 2021: loss 0.560904\n",
      "batch 2022: loss 0.564469\n",
      "batch 2023: loss 0.588494\n",
      "batch 2024: loss 0.477994\n",
      "batch 2025: loss 0.551815\n",
      "batch 2026: loss 0.541233\n",
      "batch 2027: loss 0.486216\n",
      "batch 2028: loss 0.432467\n",
      "batch 2029: loss 0.533035\n",
      "batch 2030: loss 0.561796\n",
      "batch 2031: loss 0.537077\n",
      "batch 2032: loss 0.486556\n",
      "batch 2033: loss 0.534445\n",
      "batch 2034: loss 0.484275\n",
      "batch 2035: loss 0.306522\n",
      "batch 2036: loss 0.580106\n",
      "batch 2037: loss 0.604279\n",
      "batch 2038: loss 0.642011\n",
      "batch 2039: loss 0.516901\n",
      "batch 2040: loss 0.729715\n",
      "batch 2041: loss 0.571551\n",
      "batch 2042: loss 0.719687\n",
      "batch 2043: loss 0.362370\n",
      "batch 2044: loss 0.465216\n",
      "batch 2045: loss 0.544542\n",
      "batch 2046: loss 0.533459\n",
      "batch 2047: loss 0.501262\n",
      "batch 2048: loss 0.422721\n",
      "batch 2049: loss 0.442392\n",
      "batch 2050: loss 0.508478\n",
      "batch 2051: loss 0.607044\n",
      "batch 2052: loss 0.450742\n",
      "batch 2053: loss 0.377953\n",
      "batch 2054: loss 0.729718\n",
      "batch 2055: loss 0.563696\n",
      "batch 2056: loss 0.731908\n",
      "batch 2057: loss 0.469087\n",
      "batch 2058: loss 0.591852\n",
      "batch 2059: loss 0.484077\n",
      "batch 2060: loss 0.668774\n",
      "batch 2061: loss 0.671998\n",
      "batch 2062: loss 0.493620\n",
      "batch 2063: loss 0.512633\n",
      "batch 2064: loss 0.656079\n",
      "batch 2065: loss 0.611739\n",
      "batch 2066: loss 0.504708\n",
      "batch 2067: loss 0.464934\n",
      "batch 2068: loss 0.559536\n",
      "batch 2069: loss 0.476157\n",
      "batch 2070: loss 0.478969\n",
      "batch 2071: loss 0.599431\n",
      "batch 2072: loss 0.521180\n",
      "batch 2073: loss 0.454850\n",
      "batch 2074: loss 0.368244\n",
      "batch 2075: loss 0.554766\n",
      "batch 2076: loss 0.585090\n",
      "batch 2077: loss 0.570348\n",
      "batch 2078: loss 0.553755\n",
      "batch 2079: loss 0.534396\n",
      "batch 2080: loss 0.519755\n",
      "batch 2081: loss 0.398606\n",
      "batch 2082: loss 0.536497\n",
      "batch 2083: loss 0.809736\n",
      "batch 2084: loss 0.527876\n",
      "batch 2085: loss 0.456129\n",
      "batch 2086: loss 0.313251\n",
      "batch 2087: loss 0.456213\n",
      "batch 2088: loss 0.566832\n",
      "batch 2089: loss 0.498698\n",
      "batch 2090: loss 0.443159\n",
      "batch 2091: loss 0.483521\n",
      "batch 2092: loss 0.415148\n",
      "batch 2093: loss 0.496672\n",
      "batch 2094: loss 0.424268\n",
      "batch 2095: loss 0.766418\n",
      "batch 2096: loss 0.501704\n",
      "batch 2097: loss 0.509727\n",
      "batch 2098: loss 0.412830\n",
      "batch 2099: loss 0.589471\n",
      "batch 2100: loss 0.488553\n",
      "batch 2101: loss 0.475210\n",
      "batch 2102: loss 0.523044\n",
      "batch 2103: loss 0.608293\n",
      "batch 2104: loss 0.546209\n",
      "batch 2105: loss 0.516305\n",
      "batch 2106: loss 0.578933\n",
      "batch 2107: loss 0.373096\n",
      "batch 2108: loss 0.488792\n",
      "batch 2109: loss 0.510384\n",
      "batch 2110: loss 0.416299\n",
      "batch 2111: loss 0.683100\n",
      "batch 2112: loss 0.529800\n",
      "batch 2113: loss 0.378094\n",
      "batch 2114: loss 0.524018\n",
      "batch 2115: loss 0.489312\n",
      "batch 2116: loss 0.491083\n",
      "batch 2117: loss 0.475439\n",
      "batch 2118: loss 0.483253\n",
      "batch 2119: loss 0.594991\n",
      "batch 2120: loss 0.417618\n",
      "batch 2121: loss 0.473674\n",
      "batch 2122: loss 0.439304\n",
      "batch 2123: loss 0.381734\n",
      "batch 2124: loss 0.507650\n",
      "batch 2125: loss 0.448368\n",
      "batch 2126: loss 0.358292\n",
      "batch 2127: loss 0.577191\n",
      "batch 2128: loss 0.452511\n",
      "batch 2129: loss 0.680949\n",
      "batch 2130: loss 0.503652\n",
      "batch 2131: loss 0.498823\n",
      "batch 2132: loss 0.464794\n",
      "batch 2133: loss 0.428886\n",
      "batch 2134: loss 0.611558\n",
      "batch 2135: loss 0.553808\n",
      "batch 2136: loss 0.569157\n",
      "batch 2137: loss 0.536437\n",
      "batch 2138: loss 0.504667\n",
      "batch 2139: loss 0.425630\n",
      "batch 2140: loss 0.622575\n",
      "batch 2141: loss 0.473364\n",
      "batch 2142: loss 0.606085\n",
      "batch 2143: loss 0.679907\n",
      "batch 2144: loss 0.488995\n",
      "batch 2145: loss 0.393396\n",
      "batch 2146: loss 0.519786\n",
      "batch 2147: loss 0.472810\n",
      "batch 2148: loss 0.494854\n",
      "batch 2149: loss 0.409065\n",
      "batch 2150: loss 0.527379\n",
      "batch 2151: loss 0.438659\n",
      "batch 2152: loss 0.613918\n",
      "batch 2153: loss 0.569230\n",
      "batch 2154: loss 0.533332\n",
      "batch 2155: loss 0.528050\n",
      "batch 2156: loss 0.458284\n",
      "batch 2157: loss 0.560326\n",
      "batch 2158: loss 0.445080\n",
      "batch 2159: loss 0.574738\n",
      "batch 2160: loss 0.554135\n",
      "batch 2161: loss 0.677338\n",
      "batch 2162: loss 0.639946\n",
      "batch 2163: loss 0.531771\n",
      "batch 2164: loss 0.485114\n",
      "batch 2165: loss 0.651930\n",
      "batch 2166: loss 0.478927\n",
      "batch 2167: loss 0.643017\n",
      "batch 2168: loss 0.475841\n",
      "batch 2169: loss 0.522601\n",
      "batch 2170: loss 0.555134\n",
      "batch 2171: loss 0.526996\n",
      "batch 2172: loss 0.495843\n",
      "batch 2173: loss 0.646182\n",
      "batch 2174: loss 0.491714\n",
      "batch 2175: loss 0.720355\n",
      "batch 2176: loss 0.576747\n",
      "batch 2177: loss 0.447046\n",
      "batch 2178: loss 0.614572\n",
      "batch 2179: loss 0.517620\n",
      "batch 2180: loss 0.543736\n",
      "batch 2181: loss 0.482715\n",
      "batch 2182: loss 0.564842\n",
      "batch 2183: loss 0.473771\n",
      "batch 2184: loss 0.500574\n",
      "batch 2185: loss 0.550954\n",
      "batch 2186: loss 0.505770\n",
      "batch 2187: loss 0.592424\n",
      "batch 2188: loss 0.428865\n",
      "batch 2189: loss 0.550099\n",
      "batch 2190: loss 0.464549\n",
      "batch 2191: loss 0.499099\n",
      "batch 2192: loss 0.559729\n",
      "batch 2193: loss 0.596121\n",
      "batch 2194: loss 0.464406\n",
      "batch 2195: loss 0.520576\n",
      "batch 2196: loss 0.477942\n",
      "batch 2197: loss 0.629695\n",
      "batch 2198: loss 0.462112\n",
      "batch 2199: loss 0.415969\n",
      "batch 2200: loss 0.497033\n",
      "batch 2201: loss 0.501478\n",
      "batch 2202: loss 0.465847\n",
      "batch 2203: loss 0.425703\n",
      "batch 2204: loss 0.561874\n",
      "batch 2205: loss 0.513241\n",
      "batch 2206: loss 0.478690\n",
      "batch 2207: loss 0.670887\n",
      "batch 2208: loss 0.616345\n",
      "batch 2209: loss 0.570432\n",
      "batch 2210: loss 0.451184\n",
      "batch 2211: loss 0.699383\n",
      "batch 2212: loss 0.404198\n",
      "batch 2213: loss 0.410413\n",
      "batch 2214: loss 0.544955\n",
      "batch 2215: loss 0.593444\n",
      "batch 2216: loss 0.487093\n",
      "batch 2217: loss 0.586125\n",
      "batch 2218: loss 0.582728\n",
      "batch 2219: loss 0.397793\n",
      "batch 2220: loss 0.467805\n",
      "batch 2221: loss 0.614125\n",
      "batch 2222: loss 0.507079\n",
      "batch 2223: loss 0.717571\n",
      "batch 2224: loss 0.590243\n",
      "batch 2225: loss 0.416395\n",
      "batch 2226: loss 0.435148\n",
      "batch 2227: loss 0.294035\n",
      "batch 2228: loss 0.489807\n",
      "batch 2229: loss 0.450104\n",
      "batch 2230: loss 0.453836\n",
      "batch 2231: loss 0.511459\n",
      "batch 2232: loss 0.624648\n",
      "batch 2233: loss 0.423310\n",
      "batch 2234: loss 0.506183\n",
      "batch 2235: loss 0.518356\n",
      "batch 2236: loss 0.456623\n",
      "batch 2237: loss 0.662691\n",
      "batch 2238: loss 0.523710\n",
      "batch 2239: loss 0.492790\n",
      "batch 2240: loss 0.417554\n",
      "batch 2241: loss 0.408347\n",
      "batch 2242: loss 0.737847\n",
      "batch 2243: loss 0.545029\n",
      "batch 2244: loss 0.672320\n",
      "batch 2245: loss 0.572918\n",
      "batch 2246: loss 0.659633\n",
      "batch 2247: loss 0.574669\n",
      "batch 2248: loss 0.595317\n",
      "batch 2249: loss 0.658442\n",
      "batch 2250: loss 0.477744\n",
      "batch 2251: loss 0.565552\n",
      "batch 2252: loss 0.440508\n",
      "batch 2253: loss 0.535946\n",
      "batch 2254: loss 0.420242\n",
      "batch 2255: loss 0.653611\n",
      "batch 2256: loss 0.525546\n",
      "batch 2257: loss 0.767946\n",
      "batch 2258: loss 0.662567\n",
      "batch 2259: loss 0.572347\n",
      "batch 2260: loss 0.601133\n",
      "batch 2261: loss 0.710941\n",
      "batch 2262: loss 0.518839\n",
      "batch 2263: loss 0.471659\n",
      "batch 2264: loss 0.473890\n",
      "batch 2265: loss 0.490566\n",
      "batch 2266: loss 0.677305\n",
      "batch 2267: loss 0.662374\n",
      "batch 2268: loss 0.426973\n",
      "batch 2269: loss 0.521716\n",
      "batch 2270: loss 0.562605\n",
      "batch 2271: loss 0.564073\n",
      "batch 2272: loss 0.474535\n",
      "batch 2273: loss 0.387381\n",
      "batch 2274: loss 0.319936\n",
      "batch 2275: loss 0.453077\n",
      "batch 2276: loss 0.617178\n",
      "batch 2277: loss 0.650860\n",
      "batch 2278: loss 0.384362\n",
      "batch 2279: loss 0.477668\n",
      "batch 2280: loss 0.555755\n",
      "batch 2281: loss 0.515460\n",
      "batch 2282: loss 0.446174\n",
      "batch 2283: loss 0.571363\n",
      "batch 2284: loss 0.460765\n",
      "batch 2285: loss 0.617967\n",
      "batch 2286: loss 0.333331\n",
      "batch 2287: loss 0.658529\n",
      "batch 2288: loss 0.465931\n",
      "batch 2289: loss 0.614697\n",
      "batch 2290: loss 0.470857\n",
      "batch 2291: loss 0.473442\n",
      "batch 2292: loss 0.593533\n",
      "batch 2293: loss 0.744755\n",
      "batch 2294: loss 0.728936\n",
      "batch 2295: loss 0.547763\n",
      "batch 2296: loss 0.476453\n",
      "batch 2297: loss 0.463200\n",
      "batch 2298: loss 0.495597\n",
      "batch 2299: loss 0.546179\n",
      "batch 2300: loss 0.441456\n",
      "batch 2301: loss 0.577345\n",
      "batch 2302: loss 0.413686\n",
      "batch 2303: loss 0.455434\n",
      "batch 2304: loss 0.387611\n",
      "batch 2305: loss 0.493540\n",
      "batch 2306: loss 0.396777\n",
      "batch 2307: loss 0.376106\n",
      "batch 2308: loss 0.345033\n",
      "batch 2309: loss 0.617396\n",
      "batch 2310: loss 0.583870\n",
      "batch 2311: loss 0.407209\n",
      "batch 2312: loss 0.354093\n",
      "batch 2313: loss 0.403005\n",
      "batch 2314: loss 0.353209\n",
      "batch 2315: loss 0.386426\n",
      "batch 2316: loss 0.655990\n",
      "batch 2317: loss 0.594735\n",
      "batch 2318: loss 0.632388\n",
      "batch 2319: loss 0.412436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2320: loss 0.494214\n",
      "batch 2321: loss 0.555278\n",
      "batch 2322: loss 0.495976\n",
      "batch 2323: loss 0.636027\n",
      "batch 2324: loss 0.520669\n",
      "batch 2325: loss 0.688249\n",
      "batch 2326: loss 0.545825\n",
      "batch 2327: loss 0.515970\n",
      "batch 2328: loss 0.526150\n",
      "batch 2329: loss 0.485323\n",
      "batch 2330: loss 0.558980\n",
      "batch 2331: loss 0.464775\n",
      "batch 2332: loss 0.392984\n",
      "batch 2333: loss 0.395785\n",
      "batch 2334: loss 0.356502\n",
      "batch 2335: loss 0.445724\n",
      "batch 2336: loss 0.447695\n",
      "batch 2337: loss 0.524284\n",
      "batch 2338: loss 0.629966\n",
      "batch 2339: loss 0.519895\n",
      "batch 2340: loss 0.457353\n",
      "batch 2341: loss 0.400087\n",
      "batch 2342: loss 0.549884\n",
      "batch 2343: loss 0.395522\n",
      "batch 2344: loss 0.455526\n",
      "batch 2345: loss 0.437846\n",
      "batch 2346: loss 0.509832\n",
      "batch 2347: loss 0.420450\n",
      "batch 2348: loss 0.326481\n",
      "batch 2349: loss 0.519418\n",
      "batch 2350: loss 0.599756\n",
      "batch 2351: loss 0.322655\n",
      "batch 2352: loss 0.341230\n",
      "batch 2353: loss 0.675549\n",
      "batch 2354: loss 0.457271\n",
      "batch 2355: loss 0.430579\n",
      "batch 2356: loss 0.332539\n",
      "batch 2357: loss 0.363586\n",
      "batch 2358: loss 0.520481\n",
      "batch 2359: loss 0.683880\n",
      "batch 2360: loss 0.468158\n",
      "batch 2361: loss 0.563847\n",
      "batch 2362: loss 0.418801\n",
      "batch 2363: loss 0.450009\n",
      "batch 2364: loss 0.532568\n",
      "batch 2365: loss 0.394339\n",
      "batch 2366: loss 0.472193\n",
      "batch 2367: loss 0.395075\n",
      "batch 2368: loss 0.359891\n",
      "batch 2369: loss 0.661342\n",
      "batch 2370: loss 0.438101\n",
      "batch 2371: loss 0.485410\n",
      "batch 2372: loss 0.496608\n",
      "batch 2373: loss 0.484495\n",
      "batch 2374: loss 0.591157\n",
      "batch 2375: loss 0.444174\n",
      "batch 2376: loss 0.390680\n",
      "batch 2377: loss 0.374972\n",
      "batch 2378: loss 0.533719\n",
      "batch 2379: loss 0.349333\n",
      "batch 2380: loss 0.358313\n",
      "batch 2381: loss 0.604735\n",
      "batch 2382: loss 0.359108\n",
      "batch 2383: loss 0.675648\n",
      "batch 2384: loss 0.399568\n",
      "batch 2385: loss 0.556146\n",
      "batch 2386: loss 0.332547\n",
      "batch 2387: loss 0.433555\n",
      "batch 2388: loss 0.665446\n",
      "batch 2389: loss 0.466969\n",
      "batch 2390: loss 0.396705\n",
      "batch 2391: loss 0.260717\n",
      "batch 2392: loss 0.501588\n",
      "batch 2393: loss 0.319787\n",
      "batch 2394: loss 0.502414\n",
      "batch 2395: loss 0.458866\n",
      "batch 2396: loss 0.347994\n",
      "batch 2397: loss 0.610017\n",
      "batch 2398: loss 0.507765\n",
      "batch 2399: loss 0.503984\n",
      "batch 2400: loss 0.585030\n",
      "batch 2401: loss 0.747974\n",
      "batch 2402: loss 0.539613\n",
      "batch 2403: loss 0.615790\n",
      "batch 2404: loss 0.492971\n",
      "batch 2405: loss 0.406571\n",
      "batch 2406: loss 0.447368\n",
      "batch 2407: loss 0.397586\n",
      "batch 2408: loss 0.465352\n",
      "batch 2409: loss 0.501854\n",
      "batch 2410: loss 0.351163\n",
      "batch 2411: loss 0.642750\n",
      "batch 2412: loss 0.437778\n",
      "batch 2413: loss 0.295540\n",
      "batch 2414: loss 0.589639\n",
      "batch 2415: loss 0.379425\n",
      "batch 2416: loss 0.424313\n",
      "batch 2417: loss 0.557613\n",
      "batch 2418: loss 0.714797\n",
      "batch 2419: loss 0.457479\n",
      "batch 2420: loss 0.397031\n",
      "batch 2421: loss 0.394008\n",
      "batch 2422: loss 0.535637\n",
      "batch 2423: loss 0.509347\n",
      "batch 2424: loss 0.384521\n",
      "batch 2425: loss 0.407283\n",
      "batch 2426: loss 0.267238\n",
      "batch 2427: loss 0.391751\n",
      "batch 2428: loss 0.381718\n",
      "batch 2429: loss 0.518125\n",
      "batch 2430: loss 0.431655\n",
      "batch 2431: loss 0.589480\n",
      "batch 2432: loss 0.639458\n",
      "batch 2433: loss 0.384031\n",
      "batch 2434: loss 0.492307\n",
      "batch 2435: loss 0.413167\n",
      "batch 2436: loss 0.452303\n",
      "batch 2437: loss 0.673568\n",
      "batch 2438: loss 0.611178\n",
      "batch 2439: loss 0.690478\n",
      "batch 2440: loss 0.421756\n",
      "batch 2441: loss 0.425179\n",
      "batch 2442: loss 0.420297\n",
      "batch 2443: loss 0.339002\n",
      "batch 2444: loss 0.429499\n",
      "batch 2445: loss 0.675754\n",
      "batch 2446: loss 0.409753\n",
      "batch 2447: loss 0.473877\n",
      "batch 2448: loss 0.427579\n",
      "batch 2449: loss 0.496320\n",
      "batch 2450: loss 0.523066\n",
      "batch 2451: loss 0.454608\n",
      "batch 2452: loss 0.335302\n",
      "batch 2453: loss 0.444807\n",
      "batch 2454: loss 0.373839\n",
      "batch 2455: loss 0.520371\n",
      "batch 2456: loss 0.361338\n",
      "batch 2457: loss 0.475259\n",
      "batch 2458: loss 0.399722\n",
      "batch 2459: loss 0.524175\n",
      "batch 2460: loss 0.450779\n",
      "batch 2461: loss 0.507006\n",
      "batch 2462: loss 0.414579\n",
      "batch 2463: loss 0.404748\n",
      "batch 2464: loss 0.441235\n",
      "batch 2465: loss 0.304476\n",
      "batch 2466: loss 0.521437\n",
      "batch 2467: loss 0.441554\n",
      "batch 2468: loss 0.465463\n",
      "batch 2469: loss 0.569815\n",
      "batch 2470: loss 0.433501\n",
      "batch 2471: loss 0.735498\n",
      "batch 2472: loss 0.424297\n",
      "batch 2473: loss 0.462812\n",
      "batch 2474: loss 0.476362\n",
      "batch 2475: loss 0.585435\n",
      "batch 2476: loss 0.559249\n",
      "batch 2477: loss 0.422923\n",
      "batch 2478: loss 0.463935\n",
      "batch 2479: loss 0.568703\n",
      "batch 2480: loss 0.489856\n",
      "batch 2481: loss 0.614082\n",
      "batch 2482: loss 0.437558\n",
      "batch 2483: loss 0.628762\n",
      "batch 2484: loss 0.416097\n",
      "batch 2485: loss 0.423257\n",
      "batch 2486: loss 0.434255\n",
      "batch 2487: loss 0.639144\n",
      "batch 2488: loss 0.565962\n",
      "batch 2489: loss 0.511550\n",
      "batch 2490: loss 0.445208\n",
      "batch 2491: loss 0.506547\n",
      "batch 2492: loss 0.521933\n",
      "batch 2493: loss 0.367643\n",
      "batch 2494: loss 0.382153\n",
      "batch 2495: loss 0.450247\n",
      "batch 2496: loss 0.579997\n",
      "batch 2497: loss 0.360588\n",
      "batch 2498: loss 0.587698\n",
      "batch 2499: loss 0.452180\n",
      "batch 2500: loss 0.562154\n",
      "batch 2501: loss 0.309864\n",
      "batch 2502: loss 0.414708\n",
      "batch 2503: loss 0.342538\n",
      "batch 2504: loss 0.398936\n",
      "batch 2505: loss 0.504729\n",
      "batch 2506: loss 0.449749\n",
      "batch 2507: loss 0.592521\n",
      "batch 2508: loss 0.437247\n",
      "batch 2509: loss 0.392496\n",
      "batch 2510: loss 0.670989\n",
      "batch 2511: loss 0.587251\n",
      "batch 2512: loss 0.390114\n",
      "batch 2513: loss 0.371282\n",
      "batch 2514: loss 0.473627\n",
      "batch 2515: loss 0.644062\n",
      "batch 2516: loss 0.594240\n",
      "batch 2517: loss 0.460214\n",
      "batch 2518: loss 0.318958\n",
      "batch 2519: loss 0.703879\n",
      "batch 2520: loss 0.443217\n",
      "batch 2521: loss 0.607516\n",
      "batch 2522: loss 0.814815\n",
      "batch 2523: loss 0.597569\n",
      "batch 2524: loss 0.341738\n",
      "batch 2525: loss 0.375739\n",
      "batch 2526: loss 0.419887\n",
      "batch 2527: loss 0.549466\n",
      "batch 2528: loss 0.600550\n",
      "batch 2529: loss 0.358087\n",
      "batch 2530: loss 0.705400\n",
      "batch 2531: loss 0.499312\n",
      "batch 2532: loss 0.406681\n",
      "batch 2533: loss 0.278025\n",
      "batch 2534: loss 0.525368\n",
      "batch 2535: loss 0.320431\n",
      "batch 2536: loss 0.435459\n",
      "batch 2537: loss 0.463351\n",
      "batch 2538: loss 0.407055\n",
      "batch 2539: loss 0.604822\n",
      "batch 2540: loss 0.355610\n",
      "batch 2541: loss 0.652845\n",
      "batch 2542: loss 0.532627\n",
      "batch 2543: loss 0.418926\n",
      "batch 2544: loss 0.316144\n",
      "batch 2545: loss 0.413214\n",
      "batch 2546: loss 0.380294\n",
      "batch 2547: loss 0.361443\n",
      "batch 2548: loss 0.480612\n",
      "batch 2549: loss 0.373281\n",
      "batch 2550: loss 0.414772\n",
      "batch 2551: loss 0.696388\n",
      "batch 2552: loss 0.685134\n",
      "batch 2553: loss 0.457079\n",
      "batch 2554: loss 0.553390\n",
      "batch 2555: loss 0.481638\n",
      "batch 2556: loss 0.551396\n",
      "batch 2557: loss 0.587525\n",
      "batch 2558: loss 0.599843\n",
      "batch 2559: loss 0.331458\n",
      "batch 2560: loss 0.256524\n",
      "batch 2561: loss 0.430486\n",
      "batch 2562: loss 0.439011\n",
      "batch 2563: loss 0.468297\n",
      "batch 2564: loss 0.845083\n",
      "batch 2565: loss 0.370549\n",
      "batch 2566: loss 0.495342\n",
      "batch 2567: loss 0.498530\n",
      "batch 2568: loss 0.394249\n",
      "batch 2569: loss 0.396518\n",
      "batch 2570: loss 0.446524\n",
      "batch 2571: loss 0.697107\n",
      "batch 2572: loss 0.379500\n",
      "batch 2573: loss 0.418630\n",
      "batch 2574: loss 0.367276\n",
      "batch 2575: loss 0.357146\n",
      "batch 2576: loss 0.656278\n",
      "batch 2577: loss 0.442785\n",
      "batch 2578: loss 0.344550\n",
      "batch 2579: loss 0.539499\n",
      "batch 2580: loss 0.400542\n",
      "batch 2581: loss 0.285676\n",
      "batch 2582: loss 0.385218\n",
      "batch 2583: loss 0.414183\n",
      "batch 2584: loss 0.450768\n",
      "batch 2585: loss 0.686041\n",
      "batch 2586: loss 0.281354\n",
      "batch 2587: loss 0.477585\n",
      "batch 2588: loss 0.494721\n",
      "batch 2589: loss 0.596985\n",
      "batch 2590: loss 0.438154\n",
      "batch 2591: loss 0.648755\n",
      "batch 2592: loss 0.360476\n",
      "batch 2593: loss 0.507440\n",
      "batch 2594: loss 0.364944\n",
      "batch 2595: loss 0.385278\n",
      "batch 2596: loss 0.447153\n",
      "batch 2597: loss 0.530502\n",
      "batch 2598: loss 0.477259\n",
      "batch 2599: loss 0.495453\n",
      "batch 2600: loss 0.454019\n",
      "batch 2601: loss 0.501077\n",
      "batch 2602: loss 0.545669\n",
      "batch 2603: loss 0.325996\n",
      "batch 2604: loss 0.277232\n",
      "batch 2605: loss 0.422084\n",
      "batch 2606: loss 0.562336\n",
      "batch 2607: loss 0.444280\n",
      "batch 2608: loss 0.330571\n",
      "batch 2609: loss 0.380678\n",
      "batch 2610: loss 0.479448\n",
      "batch 2611: loss 0.567091\n",
      "batch 2612: loss 0.470610\n",
      "batch 2613: loss 0.492819\n",
      "batch 2614: loss 0.440557\n",
      "batch 2615: loss 0.445597\n",
      "batch 2616: loss 0.328917\n",
      "batch 2617: loss 0.481908\n",
      "batch 2618: loss 0.341532\n",
      "batch 2619: loss 0.309403\n",
      "batch 2620: loss 0.555898\n",
      "batch 2621: loss 0.648761\n",
      "batch 2622: loss 0.528496\n",
      "batch 2623: loss 0.354775\n",
      "batch 2624: loss 0.436081\n",
      "batch 2625: loss 0.644266\n",
      "batch 2626: loss 0.532522\n",
      "batch 2627: loss 0.336656\n",
      "batch 2628: loss 0.391968\n",
      "batch 2629: loss 0.371029\n",
      "batch 2630: loss 0.607176\n",
      "batch 2631: loss 0.510267\n",
      "batch 2632: loss 0.427936\n",
      "batch 2633: loss 0.303349\n",
      "batch 2634: loss 0.713414\n",
      "batch 2635: loss 0.633187\n",
      "batch 2636: loss 0.374905\n",
      "batch 2637: loss 0.496831\n",
      "batch 2638: loss 0.646177\n",
      "batch 2639: loss 0.385599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2640: loss 0.357841\n",
      "batch 2641: loss 0.523095\n",
      "batch 2642: loss 0.497477\n",
      "batch 2643: loss 0.518398\n",
      "batch 2644: loss 0.476729\n",
      "batch 2645: loss 0.377781\n",
      "batch 2646: loss 0.435324\n",
      "batch 2647: loss 0.675416\n",
      "batch 2648: loss 0.460483\n",
      "batch 2649: loss 0.499916\n",
      "batch 2650: loss 0.406676\n",
      "batch 2651: loss 0.438209\n",
      "batch 2652: loss 0.619704\n",
      "batch 2653: loss 0.542728\n",
      "batch 2654: loss 0.471273\n",
      "batch 2655: loss 0.433272\n",
      "batch 2656: loss 0.497681\n",
      "batch 2657: loss 0.538825\n",
      "batch 2658: loss 0.580715\n",
      "batch 2659: loss 0.548582\n",
      "batch 2660: loss 0.662133\n",
      "batch 2661: loss 0.651784\n",
      "batch 2662: loss 0.457204\n",
      "batch 2663: loss 0.398793\n",
      "batch 2664: loss 0.357466\n",
      "batch 2665: loss 0.447105\n",
      "batch 2666: loss 0.643446\n",
      "batch 2667: loss 0.352193\n",
      "batch 2668: loss 0.536817\n",
      "batch 2669: loss 0.354826\n",
      "batch 2670: loss 0.417431\n",
      "batch 2671: loss 0.449607\n",
      "batch 2672: loss 0.467688\n",
      "batch 2673: loss 0.462228\n",
      "batch 2674: loss 0.398938\n",
      "batch 2675: loss 0.501339\n",
      "batch 2676: loss 0.437134\n",
      "batch 2677: loss 0.414675\n",
      "batch 2678: loss 0.491289\n",
      "batch 2679: loss 0.757507\n",
      "batch 2680: loss 0.668103\n",
      "batch 2681: loss 0.413530\n",
      "batch 2682: loss 0.422004\n",
      "batch 2683: loss 0.436588\n",
      "batch 2684: loss 0.602586\n",
      "batch 2685: loss 0.523183\n",
      "batch 2686: loss 0.593114\n",
      "batch 2687: loss 0.528098\n",
      "batch 2688: loss 0.428128\n",
      "batch 2689: loss 0.409005\n",
      "batch 2690: loss 0.487962\n",
      "batch 2691: loss 0.392426\n",
      "batch 2692: loss 0.557595\n",
      "batch 2693: loss 0.265505\n",
      "batch 2694: loss 0.417034\n",
      "batch 2695: loss 0.437597\n",
      "batch 2696: loss 0.568167\n",
      "batch 2697: loss 0.487717\n",
      "batch 2698: loss 0.231495\n",
      "batch 2699: loss 0.385215\n",
      "batch 2700: loss 0.565805\n",
      "batch 2701: loss 0.465732\n",
      "batch 2702: loss 0.474672\n",
      "batch 2703: loss 0.382402\n",
      "batch 2704: loss 0.399222\n",
      "batch 2705: loss 0.255709\n",
      "batch 2706: loss 0.471659\n",
      "batch 2707: loss 0.323930\n",
      "batch 2708: loss 0.348314\n",
      "batch 2709: loss 0.464536\n",
      "batch 2710: loss 0.681302\n",
      "batch 2711: loss 0.518537\n",
      "batch 2712: loss 0.471584\n",
      "batch 2713: loss 0.360591\n",
      "batch 2714: loss 0.379303\n",
      "batch 2715: loss 0.519414\n",
      "batch 2716: loss 0.405031\n",
      "batch 2717: loss 0.447322\n",
      "batch 2718: loss 0.571877\n",
      "batch 2719: loss 0.590751\n",
      "batch 2720: loss 0.639628\n",
      "batch 2721: loss 0.516673\n",
      "batch 2722: loss 0.572898\n",
      "batch 2723: loss 0.363769\n",
      "batch 2724: loss 0.387061\n",
      "batch 2725: loss 0.606550\n",
      "batch 2726: loss 0.603315\n",
      "batch 2727: loss 0.471740\n",
      "batch 2728: loss 0.428553\n",
      "batch 2729: loss 0.510188\n",
      "batch 2730: loss 0.516235\n",
      "batch 2731: loss 0.560269\n",
      "batch 2732: loss 0.602698\n",
      "batch 2733: loss 0.331065\n",
      "batch 2734: loss 0.462038\n",
      "batch 2735: loss 0.320164\n",
      "batch 2736: loss 0.536340\n",
      "batch 2737: loss 0.427863\n",
      "batch 2738: loss 0.356110\n",
      "batch 2739: loss 0.420249\n",
      "batch 2740: loss 0.403344\n",
      "batch 2741: loss 0.274189\n",
      "batch 2742: loss 0.622342\n",
      "batch 2743: loss 0.493053\n",
      "batch 2744: loss 0.429818\n",
      "batch 2745: loss 0.358476\n",
      "batch 2746: loss 0.526678\n",
      "batch 2747: loss 0.738768\n",
      "batch 2748: loss 0.384832\n",
      "batch 2749: loss 0.537492\n",
      "batch 2750: loss 0.319853\n",
      "batch 2751: loss 0.571084\n",
      "batch 2752: loss 0.447590\n",
      "batch 2753: loss 0.352954\n",
      "batch 2754: loss 0.450463\n",
      "batch 2755: loss 0.491843\n",
      "batch 2756: loss 0.512973\n",
      "batch 2757: loss 0.521811\n",
      "batch 2758: loss 0.541231\n",
      "batch 2759: loss 0.427302\n",
      "batch 2760: loss 0.465126\n",
      "batch 2761: loss 0.477216\n",
      "batch 2762: loss 0.578942\n",
      "batch 2763: loss 0.448499\n",
      "batch 2764: loss 0.417234\n",
      "batch 2765: loss 0.391864\n",
      "batch 2766: loss 0.418088\n",
      "batch 2767: loss 0.508936\n",
      "batch 2768: loss 0.497512\n",
      "batch 2769: loss 0.819617\n",
      "batch 2770: loss 0.544388\n",
      "batch 2771: loss 0.413762\n",
      "batch 2772: loss 0.316059\n",
      "batch 2773: loss 0.630512\n",
      "batch 2774: loss 0.552993\n",
      "batch 2775: loss 0.504820\n",
      "batch 2776: loss 0.426750\n",
      "batch 2777: loss 0.550679\n",
      "batch 2778: loss 0.550730\n",
      "batch 2779: loss 0.457377\n",
      "batch 2780: loss 0.520432\n",
      "batch 2781: loss 0.431988\n",
      "batch 2782: loss 0.504507\n",
      "batch 2783: loss 0.323508\n",
      "batch 2784: loss 0.600875\n",
      "batch 2785: loss 0.470517\n",
      "batch 2786: loss 0.530585\n",
      "batch 2787: loss 0.501648\n",
      "batch 2788: loss 0.369266\n",
      "batch 2789: loss 0.342629\n",
      "batch 2790: loss 0.557961\n",
      "batch 2791: loss 0.436058\n",
      "batch 2792: loss 0.571234\n",
      "batch 2793: loss 0.386540\n",
      "batch 2794: loss 0.499499\n",
      "batch 2795: loss 0.519734\n",
      "batch 2796: loss 0.399203\n",
      "batch 2797: loss 0.360944\n",
      "batch 2798: loss 0.729387\n",
      "batch 2799: loss 0.415734\n",
      "batch 2800: loss 0.527580\n",
      "batch 2801: loss 0.428593\n",
      "batch 2802: loss 0.337184\n",
      "batch 2803: loss 0.394359\n",
      "batch 2804: loss 0.423106\n",
      "batch 2805: loss 0.501814\n",
      "batch 2806: loss 0.465987\n",
      "batch 2807: loss 0.582572\n",
      "batch 2808: loss 0.474452\n",
      "batch 2809: loss 0.492733\n",
      "batch 2810: loss 0.344920\n",
      "batch 2811: loss 0.558154\n",
      "batch 2812: loss 0.415400\n",
      "batch 2813: loss 0.282977\n",
      "batch 2814: loss 0.385022\n",
      "batch 2815: loss 0.482316\n",
      "batch 2816: loss 0.490814\n",
      "batch 2817: loss 0.448857\n",
      "batch 2818: loss 0.556783\n",
      "batch 2819: loss 0.545069\n",
      "batch 2820: loss 0.309469\n",
      "batch 2821: loss 0.488270\n",
      "batch 2822: loss 0.498948\n",
      "batch 2823: loss 0.357594\n",
      "batch 2824: loss 0.611742\n",
      "batch 2825: loss 0.518873\n",
      "batch 2826: loss 0.485655\n",
      "batch 2827: loss 0.400982\n",
      "batch 2828: loss 0.260153\n",
      "batch 2829: loss 0.393819\n",
      "batch 2830: loss 0.264177\n",
      "batch 2831: loss 0.552357\n",
      "batch 2832: loss 0.523124\n",
      "batch 2833: loss 0.388471\n",
      "batch 2834: loss 0.554822\n",
      "batch 2835: loss 0.310294\n",
      "batch 2836: loss 0.452258\n",
      "batch 2837: loss 0.567174\n",
      "batch 2838: loss 0.480143\n",
      "batch 2839: loss 0.496452\n",
      "batch 2840: loss 0.325299\n",
      "batch 2841: loss 0.460058\n",
      "batch 2842: loss 0.653659\n",
      "batch 2843: loss 0.535373\n",
      "batch 2844: loss 0.295839\n",
      "batch 2845: loss 0.495484\n",
      "batch 2846: loss 0.443509\n",
      "batch 2847: loss 0.494275\n",
      "batch 2848: loss 0.461538\n",
      "batch 2849: loss 0.383443\n",
      "batch 2850: loss 0.703301\n",
      "batch 2851: loss 0.363310\n",
      "batch 2852: loss 0.404933\n",
      "batch 2853: loss 0.476123\n",
      "batch 2854: loss 0.323364\n",
      "batch 2855: loss 0.434431\n",
      "batch 2856: loss 0.312548\n",
      "batch 2857: loss 0.437072\n",
      "batch 2858: loss 0.568781\n",
      "batch 2859: loss 0.288570\n",
      "batch 2860: loss 0.508404\n",
      "batch 2861: loss 0.291087\n",
      "batch 2862: loss 0.484802\n",
      "batch 2863: loss 0.380882\n",
      "batch 2864: loss 0.471948\n",
      "batch 2865: loss 0.588205\n",
      "batch 2866: loss 0.454609\n",
      "batch 2867: loss 0.351772\n",
      "batch 2868: loss 0.524128\n",
      "batch 2869: loss 0.632872\n",
      "batch 2870: loss 0.482569\n",
      "batch 2871: loss 0.522663\n",
      "batch 2872: loss 0.360954\n",
      "batch 2873: loss 0.660123\n",
      "batch 2874: loss 0.478292\n",
      "batch 2875: loss 0.398329\n",
      "batch 2876: loss 0.520705\n",
      "batch 2877: loss 0.417034\n",
      "batch 2878: loss 0.422930\n",
      "batch 2879: loss 0.548696\n",
      "batch 2880: loss 0.337881\n",
      "batch 2881: loss 0.348046\n",
      "batch 2882: loss 0.258816\n",
      "batch 2883: loss 0.538094\n",
      "batch 2884: loss 0.525133\n",
      "batch 2885: loss 0.619839\n",
      "batch 2886: loss 0.419916\n",
      "batch 2887: loss 0.416811\n",
      "batch 2888: loss 0.430151\n",
      "batch 2889: loss 0.435870\n",
      "batch 2890: loss 0.442473\n",
      "batch 2891: loss 0.700801\n",
      "batch 2892: loss 0.367402\n",
      "batch 2893: loss 0.508043\n",
      "batch 2894: loss 0.563110\n",
      "batch 2895: loss 0.423419\n",
      "batch 2896: loss 0.290468\n",
      "batch 2897: loss 0.724080\n",
      "batch 2898: loss 0.551855\n",
      "batch 2899: loss 0.337765\n",
      "batch 2900: loss 0.535871\n",
      "batch 2901: loss 0.469437\n",
      "batch 2902: loss 0.442743\n",
      "batch 2903: loss 0.503219\n",
      "batch 2904: loss 0.500094\n",
      "batch 2905: loss 0.372965\n",
      "batch 2906: loss 0.421125\n",
      "batch 2907: loss 0.454069\n",
      "batch 2908: loss 0.577986\n",
      "batch 2909: loss 0.737422\n",
      "batch 2910: loss 0.440262\n",
      "batch 2911: loss 0.440549\n",
      "batch 2912: loss 0.419352\n",
      "batch 2913: loss 0.482728\n",
      "batch 2914: loss 0.472574\n",
      "batch 2915: loss 0.450746\n",
      "batch 2916: loss 0.386236\n",
      "batch 2917: loss 0.361725\n",
      "batch 2918: loss 0.451021\n",
      "batch 2919: loss 0.357172\n",
      "batch 2920: loss 0.400274\n",
      "batch 2921: loss 0.635778\n",
      "batch 2922: loss 0.437259\n",
      "batch 2923: loss 0.494604\n",
      "batch 2924: loss 0.510887\n",
      "batch 2925: loss 0.335017\n",
      "batch 2926: loss 0.483883\n",
      "batch 2927: loss 0.457759\n",
      "batch 2928: loss 0.496556\n",
      "batch 2929: loss 0.353805\n",
      "batch 2930: loss 0.482609\n",
      "batch 2931: loss 0.485929\n",
      "batch 2932: loss 0.324594\n",
      "batch 2933: loss 0.415376\n",
      "batch 2934: loss 0.352106\n",
      "batch 2935: loss 0.615772\n",
      "batch 2936: loss 0.388370\n",
      "batch 2937: loss 0.589253\n",
      "batch 2938: loss 0.486485\n",
      "batch 2939: loss 0.471995\n",
      "batch 2940: loss 0.521362\n",
      "batch 2941: loss 0.633749\n",
      "batch 2942: loss 0.361454\n",
      "batch 2943: loss 0.624044\n",
      "batch 2944: loss 0.369379\n",
      "batch 2945: loss 0.404258\n",
      "batch 2946: loss 0.256065\n",
      "batch 2947: loss 0.309745\n",
      "batch 2948: loss 0.626589\n",
      "batch 2949: loss 0.450458\n",
      "batch 2950: loss 0.551215\n",
      "batch 2951: loss 0.302627\n",
      "batch 2952: loss 0.451459\n",
      "batch 2953: loss 0.328011\n",
      "batch 2954: loss 0.588154\n",
      "batch 2955: loss 0.371770\n",
      "batch 2956: loss 0.311463\n",
      "batch 2957: loss 0.395886\n",
      "batch 2958: loss 0.427505\n",
      "batch 2959: loss 0.419641\n",
      "batch 2960: loss 0.415479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2961: loss 0.482057\n",
      "batch 2962: loss 0.335571\n",
      "batch 2963: loss 0.514552\n",
      "batch 2964: loss 0.409671\n",
      "batch 2965: loss 0.293593\n",
      "batch 2966: loss 0.765377\n",
      "batch 2967: loss 0.361714\n",
      "batch 2968: loss 0.493688\n",
      "batch 2969: loss 0.594464\n",
      "batch 2970: loss 0.474760\n",
      "batch 2971: loss 0.401781\n",
      "batch 2972: loss 0.359249\n",
      "batch 2973: loss 0.459904\n",
      "batch 2974: loss 0.450497\n",
      "batch 2975: loss 0.506579\n",
      "batch 2976: loss 0.513576\n",
      "batch 2977: loss 0.447995\n",
      "batch 2978: loss 0.320899\n",
      "batch 2979: loss 0.585995\n",
      "batch 2980: loss 0.429440\n",
      "batch 2981: loss 0.333486\n",
      "batch 2982: loss 0.412884\n",
      "batch 2983: loss 0.358251\n",
      "batch 2984: loss 0.409083\n",
      "batch 2985: loss 0.432564\n",
      "batch 2986: loss 0.332291\n",
      "batch 2987: loss 0.533169\n",
      "batch 2988: loss 0.468520\n",
      "batch 2989: loss 0.533809\n",
      "batch 2990: loss 0.459113\n",
      "batch 2991: loss 0.273401\n",
      "batch 2992: loss 0.417302\n",
      "batch 2993: loss 0.343597\n",
      "batch 2994: loss 0.413612\n",
      "batch 2995: loss 0.443484\n",
      "batch 2996: loss 0.393501\n",
      "batch 2997: loss 0.356458\n",
      "batch 2998: loss 0.456663\n",
      "batch 2999: loss 0.489015\n",
      "batch 3000: loss 0.459860\n",
      "batch 3001: loss 0.446252\n",
      "batch 3002: loss 0.297759\n",
      "batch 3003: loss 0.432267\n",
      "batch 3004: loss 0.518039\n",
      "batch 3005: loss 0.364708\n",
      "batch 3006: loss 0.250918\n",
      "batch 3007: loss 0.476617\n",
      "batch 3008: loss 0.683427\n",
      "batch 3009: loss 0.457340\n",
      "batch 3010: loss 0.469328\n",
      "batch 3011: loss 0.339582\n",
      "batch 3012: loss 0.452839\n",
      "batch 3013: loss 0.717643\n",
      "batch 3014: loss 0.419605\n",
      "batch 3015: loss 0.411348\n",
      "batch 3016: loss 0.341340\n",
      "batch 3017: loss 0.434788\n",
      "batch 3018: loss 0.413993\n",
      "batch 3019: loss 0.644055\n",
      "batch 3020: loss 0.510601\n",
      "batch 3021: loss 0.589136\n",
      "batch 3022: loss 0.419232\n",
      "batch 3023: loss 0.383490\n",
      "batch 3024: loss 0.344554\n",
      "batch 3025: loss 0.441948\n",
      "batch 3026: loss 0.373456\n",
      "batch 3027: loss 0.411134\n",
      "batch 3028: loss 0.312190\n",
      "batch 3029: loss 0.262048\n",
      "batch 3030: loss 0.416112\n",
      "batch 3031: loss 0.446275\n",
      "batch 3032: loss 0.511088\n",
      "batch 3033: loss 0.400766\n",
      "batch 3034: loss 0.402414\n",
      "batch 3035: loss 0.448670\n",
      "batch 3036: loss 0.620405\n",
      "batch 3037: loss 0.362256\n",
      "batch 3038: loss 0.407317\n",
      "batch 3039: loss 0.493655\n",
      "batch 3040: loss 0.557904\n",
      "batch 3041: loss 0.331918\n",
      "batch 3042: loss 0.598312\n",
      "batch 3043: loss 0.448119\n",
      "batch 3044: loss 0.362916\n",
      "batch 3045: loss 0.298574\n",
      "batch 3046: loss 0.622123\n",
      "batch 3047: loss 0.476126\n",
      "batch 3048: loss 0.467852\n",
      "batch 3049: loss 0.431136\n",
      "batch 3050: loss 0.406747\n",
      "batch 3051: loss 0.466911\n",
      "batch 3052: loss 0.543595\n",
      "batch 3053: loss 0.571362\n",
      "batch 3054: loss 0.564656\n",
      "batch 3055: loss 0.605124\n",
      "batch 3056: loss 0.576844\n",
      "batch 3057: loss 0.417187\n",
      "batch 3058: loss 0.469219\n",
      "batch 3059: loss 0.298381\n",
      "batch 3060: loss 0.396950\n",
      "batch 3061: loss 0.351513\n",
      "batch 3062: loss 0.609399\n",
      "batch 3063: loss 0.464771\n",
      "batch 3064: loss 0.297520\n",
      "batch 3065: loss 0.549243\n",
      "batch 3066: loss 0.477906\n",
      "batch 3067: loss 0.618491\n",
      "batch 3068: loss 0.619477\n",
      "batch 3069: loss 0.718372\n",
      "batch 3070: loss 0.352266\n",
      "batch 3071: loss 0.459318\n",
      "batch 3072: loss 0.326139\n",
      "batch 3073: loss 0.252821\n",
      "batch 3074: loss 0.622891\n",
      "batch 3075: loss 0.414566\n",
      "batch 3076: loss 0.331057\n",
      "batch 3077: loss 0.363690\n",
      "batch 3078: loss 0.407314\n",
      "batch 3079: loss 0.405842\n",
      "batch 3080: loss 0.485113\n",
      "batch 3081: loss 0.599854\n",
      "batch 3082: loss 0.606910\n",
      "batch 3083: loss 0.529909\n",
      "batch 3084: loss 0.405010\n",
      "batch 3085: loss 0.452503\n",
      "batch 3086: loss 0.314270\n",
      "batch 3087: loss 0.520899\n",
      "batch 3088: loss 0.484303\n",
      "batch 3089: loss 0.362656\n",
      "batch 3090: loss 0.466033\n",
      "batch 3091: loss 0.265472\n",
      "batch 3092: loss 0.470576\n",
      "batch 3093: loss 0.494826\n",
      "batch 3094: loss 0.511781\n",
      "batch 3095: loss 0.526230\n",
      "batch 3096: loss 0.461358\n",
      "batch 3097: loss 0.279971\n",
      "batch 3098: loss 0.440936\n",
      "batch 3099: loss 0.355740\n",
      "batch 3100: loss 0.537030\n",
      "batch 3101: loss 0.254181\n",
      "batch 3102: loss 0.501179\n",
      "batch 3103: loss 0.466187\n",
      "batch 3104: loss 0.302937\n",
      "batch 3105: loss 0.279877\n",
      "batch 3106: loss 0.465113\n",
      "batch 3107: loss 0.284637\n",
      "batch 3108: loss 0.593924\n",
      "batch 3109: loss 0.583511\n",
      "batch 3110: loss 0.550152\n",
      "batch 3111: loss 0.398326\n",
      "batch 3112: loss 0.389020\n",
      "batch 3113: loss 0.461250\n",
      "batch 3114: loss 0.399965\n",
      "batch 3115: loss 0.368848\n",
      "batch 3116: loss 0.627129\n",
      "batch 3117: loss 0.517593\n",
      "batch 3118: loss 0.620127\n",
      "batch 3119: loss 0.414510\n",
      "batch 3120: loss 0.411217\n",
      "batch 3121: loss 0.490641\n",
      "batch 3122: loss 0.503049\n",
      "batch 3123: loss 0.479119\n",
      "batch 3124: loss 0.368462\n",
      "batch 3125: loss 0.366575\n",
      "batch 3126: loss 0.360829\n",
      "batch 3127: loss 0.537952\n",
      "batch 3128: loss 0.591469\n",
      "batch 3129: loss 0.603485\n",
      "batch 3130: loss 0.334069\n",
      "batch 3131: loss 0.491791\n",
      "batch 3132: loss 0.213570\n",
      "batch 3133: loss 0.364312\n",
      "batch 3134: loss 0.557455\n",
      "batch 3135: loss 0.463991\n",
      "batch 3136: loss 0.265127\n",
      "batch 3137: loss 0.316767\n",
      "batch 3138: loss 0.469633\n",
      "batch 3139: loss 0.290370\n",
      "batch 3140: loss 0.222038\n",
      "batch 3141: loss 0.227196\n",
      "batch 3142: loss 0.412448\n",
      "batch 3143: loss 0.583497\n",
      "batch 3144: loss 0.506444\n",
      "batch 3145: loss 0.328812\n",
      "batch 3146: loss 0.477254\n",
      "batch 3147: loss 0.443752\n",
      "batch 3148: loss 0.551031\n",
      "batch 3149: loss 0.317587\n",
      "batch 3150: loss 0.515737\n",
      "batch 3151: loss 0.547041\n",
      "batch 3152: loss 0.694161\n",
      "batch 3153: loss 0.400503\n",
      "batch 3154: loss 0.297804\n",
      "batch 3155: loss 0.375490\n",
      "batch 3156: loss 0.328504\n",
      "batch 3157: loss 0.650480\n",
      "batch 3158: loss 0.631346\n",
      "batch 3159: loss 0.316037\n",
      "batch 3160: loss 0.344226\n",
      "batch 3161: loss 0.403765\n",
      "batch 3162: loss 0.320132\n",
      "batch 3163: loss 0.349760\n",
      "batch 3164: loss 0.598424\n",
      "batch 3165: loss 0.960495\n",
      "batch 3166: loss 0.394593\n",
      "batch 3167: loss 0.679938\n",
      "batch 3168: loss 0.374486\n",
      "batch 3169: loss 0.471774\n",
      "batch 3170: loss 0.342171\n",
      "batch 3171: loss 0.633706\n",
      "batch 3172: loss 0.513913\n",
      "batch 3173: loss 0.400139\n",
      "batch 3174: loss 0.538872\n",
      "batch 3175: loss 0.453278\n",
      "batch 3176: loss 0.207408\n",
      "batch 3177: loss 0.212704\n",
      "batch 3178: loss 0.262892\n",
      "batch 3179: loss 0.521881\n",
      "batch 3180: loss 0.527213\n",
      "batch 3181: loss 0.559838\n",
      "batch 3182: loss 0.662195\n",
      "batch 3183: loss 0.441396\n",
      "batch 3184: loss 0.465418\n",
      "batch 3185: loss 0.253167\n",
      "batch 3186: loss 0.382396\n",
      "batch 3187: loss 0.455676\n",
      "batch 3188: loss 0.289733\n",
      "batch 3189: loss 0.543558\n",
      "batch 3190: loss 0.260886\n",
      "batch 3191: loss 0.576503\n",
      "batch 3192: loss 0.529054\n",
      "batch 3193: loss 0.550893\n",
      "batch 3194: loss 0.407620\n",
      "batch 3195: loss 0.416849\n",
      "batch 3196: loss 0.491087\n",
      "batch 3197: loss 0.466333\n",
      "batch 3198: loss 0.444719\n",
      "batch 3199: loss 0.339889\n",
      "batch 3200: loss 0.445217\n",
      "batch 3201: loss 0.623291\n",
      "batch 3202: loss 0.437959\n",
      "batch 3203: loss 0.377164\n",
      "batch 3204: loss 0.810076\n",
      "batch 3205: loss 0.640569\n",
      "batch 3206: loss 0.321640\n",
      "batch 3207: loss 0.285993\n",
      "batch 3208: loss 0.361391\n",
      "batch 3209: loss 0.502138\n",
      "batch 3210: loss 0.358592\n",
      "batch 3211: loss 0.420284\n",
      "batch 3212: loss 0.330105\n",
      "batch 3213: loss 0.574878\n",
      "batch 3214: loss 0.444550\n",
      "batch 3215: loss 0.478030\n",
      "batch 3216: loss 0.614421\n",
      "batch 3217: loss 0.373642\n",
      "batch 3218: loss 0.449664\n",
      "batch 3219: loss 0.418798\n",
      "batch 3220: loss 0.495755\n",
      "batch 3221: loss 0.329505\n",
      "batch 3222: loss 0.352556\n",
      "batch 3223: loss 0.444062\n",
      "batch 3224: loss 0.587095\n",
      "batch 3225: loss 0.297035\n",
      "batch 3226: loss 0.399777\n",
      "batch 3227: loss 0.356995\n",
      "batch 3228: loss 0.417892\n",
      "batch 3229: loss 0.383800\n",
      "batch 3230: loss 0.460462\n",
      "batch 3231: loss 0.407989\n",
      "batch 3232: loss 0.319957\n",
      "batch 3233: loss 0.479946\n",
      "batch 3234: loss 0.313381\n",
      "batch 3235: loss 0.360607\n",
      "batch 3236: loss 0.495354\n",
      "batch 3237: loss 0.401212\n",
      "batch 3238: loss 0.354967\n",
      "batch 3239: loss 0.342296\n",
      "batch 3240: loss 0.288810\n",
      "batch 3241: loss 0.378662\n",
      "batch 3242: loss 0.272845\n",
      "batch 3243: loss 0.637733\n",
      "batch 3244: loss 0.292280\n",
      "batch 3245: loss 0.593882\n",
      "batch 3246: loss 0.402022\n",
      "batch 3247: loss 0.691278\n",
      "batch 3248: loss 0.238175\n",
      "batch 3249: loss 0.504953\n",
      "batch 3250: loss 0.309344\n",
      "batch 3251: loss 0.267822\n",
      "batch 3252: loss 0.580055\n",
      "batch 3253: loss 0.273297\n",
      "batch 3254: loss 0.381488\n",
      "batch 3255: loss 0.435256\n",
      "batch 3256: loss 0.626542\n",
      "batch 3257: loss 0.309013\n",
      "batch 3258: loss 0.486849\n",
      "batch 3259: loss 0.547003\n",
      "batch 3260: loss 0.255971\n",
      "batch 3261: loss 0.541292\n",
      "batch 3262: loss 0.412557\n",
      "batch 3263: loss 0.840230\n",
      "batch 3264: loss 0.527816\n",
      "batch 3265: loss 0.431531\n",
      "batch 3266: loss 0.555692\n",
      "batch 3267: loss 0.241864\n",
      "batch 3268: loss 0.425188\n",
      "batch 3269: loss 0.410901\n",
      "batch 3270: loss 0.362794\n",
      "batch 3271: loss 0.405048\n",
      "batch 3272: loss 0.365449\n",
      "batch 3273: loss 0.401010\n",
      "batch 3274: loss 0.532454\n",
      "batch 3275: loss 0.470284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3276: loss 0.501864\n",
      "batch 3277: loss 0.466814\n",
      "batch 3278: loss 0.360294\n",
      "batch 3279: loss 0.441201\n",
      "batch 3280: loss 0.474159\n",
      "batch 3281: loss 0.353918\n",
      "batch 3282: loss 0.490730\n",
      "batch 3283: loss 0.438539\n",
      "batch 3284: loss 0.461514\n",
      "batch 3285: loss 0.416050\n",
      "batch 3286: loss 0.382789\n",
      "batch 3287: loss 0.430820\n",
      "batch 3288: loss 0.396773\n",
      "batch 3289: loss 0.429514\n",
      "batch 3290: loss 0.495535\n",
      "batch 3291: loss 0.691059\n",
      "batch 3292: loss 0.393250\n",
      "batch 3293: loss 0.435851\n",
      "batch 3294: loss 0.453488\n",
      "batch 3295: loss 0.397140\n",
      "batch 3296: loss 0.308324\n",
      "batch 3297: loss 0.335772\n",
      "batch 3298: loss 0.554656\n",
      "batch 3299: loss 0.382662\n",
      "batch 3300: loss 0.478515\n",
      "batch 3301: loss 0.257461\n",
      "batch 3302: loss 0.411508\n",
      "batch 3303: loss 0.498710\n",
      "batch 3304: loss 0.473942\n",
      "batch 3305: loss 0.491247\n",
      "batch 3306: loss 0.410318\n",
      "batch 3307: loss 0.517592\n",
      "batch 3308: loss 0.193912\n",
      "batch 3309: loss 0.549533\n",
      "batch 3310: loss 0.451662\n",
      "batch 3311: loss 0.523555\n",
      "batch 3312: loss 0.298593\n",
      "batch 3313: loss 0.399091\n",
      "batch 3314: loss 0.366302\n",
      "batch 3315: loss 0.246013\n",
      "batch 3316: loss 0.337864\n",
      "batch 3317: loss 0.560216\n",
      "batch 3318: loss 0.735015\n",
      "batch 3319: loss 0.348018\n",
      "batch 3320: loss 0.325502\n",
      "batch 3321: loss 0.275473\n",
      "batch 3322: loss 0.711430\n",
      "batch 3323: loss 0.466814\n",
      "batch 3324: loss 0.391088\n",
      "batch 3325: loss 0.246468\n",
      "batch 3326: loss 0.508582\n",
      "batch 3327: loss 0.651450\n",
      "batch 3328: loss 0.402281\n",
      "batch 3329: loss 0.491503\n",
      "batch 3330: loss 0.488805\n",
      "batch 3331: loss 0.344067\n",
      "batch 3332: loss 0.309364\n",
      "batch 3333: loss 0.306944\n",
      "batch 3334: loss 0.397953\n",
      "batch 3335: loss 0.474435\n",
      "batch 3336: loss 0.374625\n",
      "batch 3337: loss 0.480110\n",
      "batch 3338: loss 0.240638\n",
      "batch 3339: loss 0.342419\n",
      "batch 3340: loss 0.623679\n",
      "batch 3341: loss 0.550428\n",
      "batch 3342: loss 0.525898\n",
      "batch 3343: loss 0.479717\n",
      "batch 3344: loss 0.422382\n",
      "batch 3345: loss 0.433101\n",
      "batch 3346: loss 0.397082\n",
      "batch 3347: loss 0.470292\n",
      "batch 3348: loss 0.379789\n",
      "batch 3349: loss 0.355237\n",
      "batch 3350: loss 0.474321\n",
      "batch 3351: loss 0.495197\n",
      "batch 3352: loss 0.356097\n",
      "batch 3353: loss 0.519102\n",
      "batch 3354: loss 0.553674\n",
      "batch 3355: loss 0.303746\n",
      "batch 3356: loss 0.389799\n",
      "batch 3357: loss 0.407086\n",
      "batch 3358: loss 0.268571\n",
      "batch 3359: loss 0.494146\n",
      "batch 3360: loss 0.332907\n",
      "batch 3361: loss 0.408620\n",
      "batch 3362: loss 0.420932\n",
      "batch 3363: loss 0.325979\n",
      "batch 3364: loss 0.389916\n",
      "batch 3365: loss 0.460866\n",
      "batch 3366: loss 0.323665\n",
      "batch 3367: loss 0.329760\n",
      "batch 3368: loss 0.512818\n",
      "batch 3369: loss 0.392768\n",
      "batch 3370: loss 0.486011\n",
      "batch 3371: loss 0.545355\n",
      "batch 3372: loss 0.455972\n",
      "batch 3373: loss 0.419814\n",
      "batch 3374: loss 0.680219\n",
      "batch 3375: loss 0.398920\n",
      "batch 3376: loss 0.557496\n",
      "batch 3377: loss 0.367551\n",
      "batch 3378: loss 0.523283\n",
      "batch 3379: loss 0.418643\n",
      "batch 3380: loss 0.327334\n",
      "batch 3381: loss 0.396527\n",
      "batch 3382: loss 0.323300\n",
      "batch 3383: loss 0.488513\n",
      "batch 3384: loss 0.383737\n",
      "batch 3385: loss 0.394668\n",
      "batch 3386: loss 0.408535\n",
      "batch 3387: loss 0.403002\n",
      "batch 3388: loss 0.379136\n",
      "batch 3389: loss 0.493371\n",
      "batch 3390: loss 0.527391\n",
      "batch 3391: loss 0.433285\n",
      "batch 3392: loss 0.483379\n",
      "batch 3393: loss 0.388571\n",
      "batch 3394: loss 0.401774\n",
      "batch 3395: loss 0.230381\n",
      "batch 3396: loss 0.441582\n",
      "batch 3397: loss 0.337599\n",
      "batch 3398: loss 0.296225\n",
      "batch 3399: loss 0.323405\n",
      "batch 3400: loss 0.500950\n",
      "batch 3401: loss 0.425913\n",
      "batch 3402: loss 0.340339\n",
      "batch 3403: loss 0.415586\n",
      "batch 3404: loss 0.414721\n",
      "batch 3405: loss 0.478630\n",
      "batch 3406: loss 0.463084\n",
      "batch 3407: loss 0.414023\n",
      "batch 3408: loss 0.631331\n",
      "batch 3409: loss 0.345977\n",
      "batch 3410: loss 0.519122\n",
      "batch 3411: loss 0.442342\n",
      "batch 3412: loss 0.377129\n",
      "batch 3413: loss 0.376389\n",
      "batch 3414: loss 0.617512\n",
      "batch 3415: loss 0.247922\n",
      "batch 3416: loss 0.431625\n",
      "batch 3417: loss 0.518967\n",
      "batch 3418: loss 0.317955\n",
      "batch 3419: loss 0.516291\n",
      "batch 3420: loss 0.512758\n",
      "batch 3421: loss 0.432197\n",
      "batch 3422: loss 0.306776\n",
      "batch 3423: loss 0.501855\n",
      "batch 3424: loss 0.481824\n",
      "batch 3425: loss 0.623478\n",
      "batch 3426: loss 0.418631\n",
      "batch 3427: loss 0.443682\n",
      "batch 3428: loss 0.505027\n",
      "batch 3429: loss 0.324785\n",
      "batch 3430: loss 0.490322\n",
      "batch 3431: loss 0.307332\n",
      "batch 3432: loss 0.364122\n",
      "batch 3433: loss 0.345920\n",
      "batch 3434: loss 0.414549\n",
      "batch 3435: loss 0.458629\n",
      "batch 3436: loss 0.605106\n",
      "batch 3437: loss 0.360958\n",
      "batch 3438: loss 0.394933\n",
      "batch 3439: loss 0.326940\n",
      "batch 3440: loss 0.518634\n",
      "batch 3441: loss 0.367327\n",
      "batch 3442: loss 0.516495\n",
      "batch 3443: loss 0.530549\n",
      "batch 3444: loss 0.359362\n",
      "batch 3445: loss 0.319192\n",
      "batch 3446: loss 0.263527\n",
      "batch 3447: loss 0.389515\n",
      "batch 3448: loss 0.367039\n",
      "batch 3449: loss 0.367188\n",
      "batch 3450: loss 0.402776\n",
      "batch 3451: loss 0.470704\n",
      "batch 3452: loss 0.354766\n",
      "batch 3453: loss 0.256657\n",
      "batch 3454: loss 0.388095\n",
      "batch 3455: loss 0.495591\n",
      "batch 3456: loss 0.341987\n",
      "batch 3457: loss 0.247149\n",
      "batch 3458: loss 0.758223\n",
      "batch 3459: loss 0.336782\n",
      "batch 3460: loss 0.501517\n",
      "batch 3461: loss 0.325765\n",
      "batch 3462: loss 0.493862\n",
      "batch 3463: loss 0.436872\n",
      "batch 3464: loss 0.284796\n",
      "batch 3465: loss 0.511684\n",
      "batch 3466: loss 0.601527\n",
      "batch 3467: loss 0.430326\n",
      "batch 3468: loss 0.445193\n",
      "batch 3469: loss 0.504992\n",
      "batch 3470: loss 0.396392\n",
      "batch 3471: loss 0.569165\n",
      "batch 3472: loss 0.521045\n",
      "batch 3473: loss 0.454296\n",
      "batch 3474: loss 0.178061\n",
      "batch 3475: loss 0.467568\n",
      "batch 3476: loss 0.523728\n",
      "batch 3477: loss 0.522687\n",
      "batch 3478: loss 0.404135\n",
      "batch 3479: loss 0.461303\n",
      "batch 3480: loss 0.483764\n",
      "batch 3481: loss 0.523365\n",
      "batch 3482: loss 0.541284\n",
      "batch 3483: loss 0.351169\n",
      "batch 3484: loss 0.447074\n",
      "batch 3485: loss 0.486932\n",
      "batch 3486: loss 0.381894\n",
      "batch 3487: loss 0.321506\n",
      "batch 3488: loss 0.426908\n",
      "batch 3489: loss 0.443555\n",
      "batch 3490: loss 0.387719\n",
      "batch 3491: loss 0.360982\n",
      "batch 3492: loss 0.651979\n",
      "batch 3493: loss 0.355022\n",
      "batch 3494: loss 0.389546\n",
      "batch 3495: loss 0.392266\n",
      "batch 3496: loss 0.277111\n",
      "batch 3497: loss 0.274031\n",
      "batch 3498: loss 0.336858\n",
      "batch 3499: loss 0.443999\n",
      "batch 3500: loss 0.345740\n",
      "batch 3501: loss 0.578660\n",
      "batch 3502: loss 0.403487\n",
      "batch 3503: loss 0.352974\n",
      "batch 3504: loss 0.379731\n",
      "batch 3505: loss 0.452152\n",
      "batch 3506: loss 0.472875\n",
      "batch 3507: loss 0.404295\n",
      "batch 3508: loss 0.387009\n",
      "batch 3509: loss 0.471930\n",
      "batch 3510: loss 0.352583\n",
      "batch 3511: loss 0.498767\n",
      "batch 3512: loss 0.500435\n",
      "batch 3513: loss 0.541414\n",
      "batch 3514: loss 0.382529\n",
      "batch 3515: loss 0.357644\n",
      "batch 3516: loss 0.236942\n",
      "batch 3517: loss 0.360907\n",
      "batch 3518: loss 0.433302\n",
      "batch 3519: loss 0.240224\n",
      "batch 3520: loss 0.379936\n",
      "batch 3521: loss 0.438205\n",
      "batch 3522: loss 0.241887\n",
      "batch 3523: loss 0.512652\n",
      "batch 3524: loss 0.310546\n",
      "batch 3525: loss 0.343523\n",
      "batch 3526: loss 0.423611\n",
      "batch 3527: loss 0.297966\n",
      "batch 3528: loss 0.305614\n",
      "batch 3529: loss 0.280864\n",
      "batch 3530: loss 0.393628\n",
      "batch 3531: loss 0.485441\n",
      "batch 3532: loss 0.474952\n",
      "batch 3533: loss 0.235717\n",
      "batch 3534: loss 0.258526\n",
      "batch 3535: loss 0.265329\n",
      "batch 3536: loss 0.306705\n",
      "batch 3537: loss 0.328507\n",
      "batch 3538: loss 0.395814\n",
      "batch 3539: loss 0.334733\n",
      "batch 3540: loss 0.480396\n",
      "batch 3541: loss 0.529312\n",
      "batch 3542: loss 0.360309\n",
      "batch 3543: loss 0.371646\n",
      "batch 3544: loss 0.440677\n",
      "batch 3545: loss 0.656492\n",
      "batch 3546: loss 0.313080\n",
      "batch 3547: loss 0.406148\n",
      "batch 3548: loss 0.324751\n",
      "batch 3549: loss 0.292189\n",
      "batch 3550: loss 0.358258\n",
      "batch 3551: loss 0.429689\n",
      "batch 3552: loss 0.285269\n",
      "batch 3553: loss 0.519533\n",
      "batch 3554: loss 0.205768\n",
      "batch 3555: loss 0.334767\n",
      "batch 3556: loss 0.581593\n",
      "batch 3557: loss 0.560721\n",
      "batch 3558: loss 0.371705\n",
      "batch 3559: loss 0.470059\n",
      "batch 3560: loss 0.472278\n",
      "batch 3561: loss 0.464287\n",
      "batch 3562: loss 0.520901\n",
      "batch 3563: loss 0.233334\n",
      "batch 3564: loss 0.351330\n",
      "batch 3565: loss 0.385843\n",
      "batch 3566: loss 0.297945\n",
      "batch 3567: loss 0.249886\n",
      "batch 3568: loss 0.388874\n",
      "batch 3569: loss 0.493780\n",
      "batch 3570: loss 0.459190\n",
      "batch 3571: loss 0.529127\n",
      "batch 3572: loss 0.242976\n",
      "batch 3573: loss 0.459990\n",
      "batch 3574: loss 0.368456\n",
      "batch 3575: loss 0.474935\n",
      "batch 3576: loss 0.272218\n",
      "batch 3577: loss 0.379231\n",
      "batch 3578: loss 0.331146\n",
      "batch 3579: loss 0.574053\n",
      "batch 3580: loss 0.542822\n",
      "batch 3581: loss 0.324060\n",
      "batch 3582: loss 0.475664\n",
      "batch 3583: loss 0.555552\n",
      "batch 3584: loss 0.609640\n",
      "batch 3585: loss 0.325866\n",
      "batch 3586: loss 0.348628\n",
      "batch 3587: loss 0.287140\n",
      "batch 3588: loss 0.362475\n",
      "batch 3589: loss 0.320830\n",
      "batch 3590: loss 0.322317\n",
      "batch 3591: loss 0.671069\n",
      "batch 3592: loss 0.331123\n",
      "batch 3593: loss 0.371594\n",
      "batch 3594: loss 0.693734\n",
      "batch 3595: loss 0.366250\n",
      "batch 3596: loss 0.374075\n",
      "batch 3597: loss 0.524320\n",
      "batch 3598: loss 0.417091\n",
      "batch 3599: loss 0.431539\n",
      "batch 3600: loss 0.337937\n",
      "batch 3601: loss 0.435018\n",
      "batch 3602: loss 0.278805\n",
      "batch 3603: loss 0.383916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3604: loss 0.522563\n",
      "batch 3605: loss 0.603710\n",
      "batch 3606: loss 0.188935\n",
      "batch 3607: loss 0.347606\n",
      "batch 3608: loss 0.332667\n",
      "batch 3609: loss 0.420320\n",
      "batch 3610: loss 0.663146\n",
      "batch 3611: loss 0.340771\n",
      "batch 3612: loss 0.351061\n",
      "batch 3613: loss 0.388101\n",
      "batch 3614: loss 0.396273\n",
      "batch 3615: loss 0.380957\n",
      "batch 3616: loss 0.640495\n",
      "batch 3617: loss 0.336759\n",
      "batch 3618: loss 0.589681\n",
      "batch 3619: loss 0.442527\n",
      "batch 3620: loss 0.446417\n",
      "batch 3621: loss 0.266150\n",
      "batch 3622: loss 0.385277\n",
      "batch 3623: loss 0.507279\n",
      "batch 3624: loss 0.377241\n",
      "batch 3625: loss 0.261653\n",
      "batch 3626: loss 0.451519\n",
      "batch 3627: loss 0.514267\n",
      "batch 3628: loss 0.261054\n",
      "batch 3629: loss 0.293596\n",
      "batch 3630: loss 0.350646\n",
      "batch 3631: loss 0.418672\n",
      "batch 3632: loss 0.518761\n",
      "batch 3633: loss 0.371823\n",
      "batch 3634: loss 0.395133\n",
      "batch 3635: loss 0.298260\n",
      "batch 3636: loss 0.272693\n",
      "batch 3637: loss 0.293052\n",
      "batch 3638: loss 0.680142\n",
      "batch 3639: loss 0.470072\n",
      "batch 3640: loss 0.448679\n",
      "batch 3641: loss 0.279041\n",
      "batch 3642: loss 0.367878\n",
      "batch 3643: loss 0.355745\n",
      "batch 3644: loss 0.393503\n",
      "batch 3645: loss 0.367380\n",
      "batch 3646: loss 0.348077\n",
      "batch 3647: loss 0.340514\n",
      "batch 3648: loss 0.275162\n",
      "batch 3649: loss 0.300193\n",
      "batch 3650: loss 0.316980\n",
      "batch 3651: loss 0.486934\n",
      "batch 3652: loss 0.293386\n",
      "batch 3653: loss 0.456380\n",
      "batch 3654: loss 0.462543\n",
      "batch 3655: loss 0.290286\n",
      "batch 3656: loss 0.396292\n",
      "batch 3657: loss 0.246539\n",
      "batch 3658: loss 0.391760\n",
      "batch 3659: loss 0.403267\n",
      "batch 3660: loss 0.315455\n",
      "batch 3661: loss 0.472288\n",
      "batch 3662: loss 0.450804\n",
      "batch 3663: loss 0.422532\n",
      "batch 3664: loss 0.374912\n",
      "batch 3665: loss 0.299086\n",
      "batch 3666: loss 0.440428\n",
      "batch 3667: loss 0.410966\n",
      "batch 3668: loss 0.608497\n",
      "batch 3669: loss 0.314017\n",
      "batch 3670: loss 0.366614\n",
      "batch 3671: loss 0.506909\n",
      "batch 3672: loss 0.298153\n",
      "batch 3673: loss 0.159598\n",
      "batch 3674: loss 0.526169\n",
      "batch 3675: loss 0.312620\n",
      "batch 3676: loss 0.300890\n",
      "batch 3677: loss 0.442905\n",
      "batch 3678: loss 0.352353\n",
      "batch 3679: loss 0.635051\n",
      "batch 3680: loss 0.488519\n",
      "batch 3681: loss 0.365824\n",
      "batch 3682: loss 0.386334\n",
      "batch 3683: loss 0.480071\n",
      "batch 3684: loss 0.588021\n",
      "batch 3685: loss 0.458930\n",
      "batch 3686: loss 0.677585\n",
      "batch 3687: loss 0.314060\n",
      "batch 3688: loss 0.551899\n",
      "batch 3689: loss 0.420521\n",
      "batch 3690: loss 0.410576\n",
      "batch 3691: loss 0.535775\n",
      "batch 3692: loss 0.339944\n",
      "batch 3693: loss 0.486961\n",
      "batch 3694: loss 0.635854\n",
      "batch 3695: loss 0.507946\n",
      "batch 3696: loss 0.521039\n",
      "batch 3697: loss 0.258447\n",
      "batch 3698: loss 0.330746\n",
      "batch 3699: loss 0.360006\n",
      "batch 3700: loss 0.362063\n",
      "batch 3701: loss 0.366588\n",
      "batch 3702: loss 0.496632\n",
      "batch 3703: loss 0.373383\n",
      "batch 3704: loss 0.456285\n",
      "batch 3705: loss 0.362772\n",
      "batch 3706: loss 0.276338\n",
      "batch 3707: loss 0.430718\n",
      "batch 3708: loss 0.286756\n",
      "batch 3709: loss 0.305822\n",
      "batch 3710: loss 0.414824\n",
      "batch 3711: loss 0.436611\n",
      "batch 3712: loss 0.408356\n",
      "batch 3713: loss 0.304436\n",
      "batch 3714: loss 0.289711\n",
      "batch 3715: loss 0.528624\n",
      "batch 3716: loss 0.363214\n",
      "batch 3717: loss 0.431550\n",
      "batch 3718: loss 0.263948\n",
      "batch 3719: loss 0.372315\n",
      "batch 3720: loss 0.642064\n",
      "batch 3721: loss 0.571415\n",
      "batch 3722: loss 0.269339\n",
      "batch 3723: loss 0.383556\n",
      "batch 3724: loss 0.491925\n",
      "batch 3725: loss 0.494605\n",
      "batch 3726: loss 0.524380\n",
      "batch 3727: loss 0.455203\n",
      "batch 3728: loss 0.260982\n",
      "batch 3729: loss 0.253608\n",
      "batch 3730: loss 0.203839\n",
      "batch 3731: loss 0.484822\n",
      "batch 3732: loss 0.375090\n",
      "batch 3733: loss 0.531044\n",
      "batch 3734: loss 0.484644\n",
      "batch 3735: loss 0.469092\n",
      "batch 3736: loss 0.431008\n",
      "batch 3737: loss 0.654555\n",
      "batch 3738: loss 0.516202\n",
      "batch 3739: loss 0.351550\n",
      "batch 3740: loss 0.405279\n",
      "batch 3741: loss 0.500768\n",
      "batch 3742: loss 0.410183\n",
      "batch 3743: loss 0.472381\n",
      "batch 3744: loss 0.753418\n",
      "batch 3745: loss 0.580235\n",
      "batch 3746: loss 0.328503\n",
      "batch 3747: loss 0.578851\n",
      "batch 3748: loss 0.526877\n",
      "batch 3749: loss 0.338883\n",
      "batch 3750: loss 0.293424\n",
      "batch 3751: loss 0.329141\n",
      "batch 3752: loss 0.304567\n",
      "batch 3753: loss 0.334893\n",
      "batch 3754: loss 0.410761\n",
      "batch 3755: loss 0.477114\n",
      "batch 3756: loss 0.530375\n",
      "batch 3757: loss 0.285208\n",
      "batch 3758: loss 0.331447\n",
      "batch 3759: loss 0.460870\n",
      "batch 3760: loss 0.333563\n",
      "batch 3761: loss 0.464954\n",
      "batch 3762: loss 0.604410\n",
      "batch 3763: loss 0.320564\n",
      "batch 3764: loss 0.530114\n",
      "batch 3765: loss 0.392526\n",
      "batch 3766: loss 0.674121\n",
      "batch 3767: loss 0.312911\n",
      "batch 3768: loss 0.633582\n",
      "batch 3769: loss 0.383686\n",
      "batch 3770: loss 0.411411\n",
      "batch 3771: loss 0.595248\n",
      "batch 3772: loss 0.517819\n",
      "batch 3773: loss 0.429824\n",
      "batch 3774: loss 0.511832\n",
      "batch 3775: loss 0.521417\n",
      "batch 3776: loss 0.571014\n",
      "batch 3777: loss 0.369816\n",
      "batch 3778: loss 0.567313\n",
      "batch 3779: loss 0.414785\n",
      "batch 3780: loss 0.240037\n",
      "batch 3781: loss 0.592059\n",
      "batch 3782: loss 0.290544\n",
      "batch 3783: loss 0.629429\n",
      "batch 3784: loss 0.491576\n",
      "batch 3785: loss 0.511277\n",
      "batch 3786: loss 0.264489\n",
      "batch 3787: loss 0.521454\n",
      "batch 3788: loss 0.283043\n",
      "batch 3789: loss 0.431655\n",
      "batch 3790: loss 0.345218\n",
      "batch 3791: loss 0.424164\n",
      "batch 3792: loss 0.430939\n",
      "batch 3793: loss 0.363536\n",
      "batch 3794: loss 0.566718\n",
      "batch 3795: loss 0.523376\n",
      "batch 3796: loss 0.335664\n",
      "batch 3797: loss 0.324706\n",
      "batch 3798: loss 0.367702\n",
      "batch 3799: loss 0.455130\n",
      "batch 3800: loss 0.458405\n",
      "batch 3801: loss 0.393712\n",
      "batch 3802: loss 0.416320\n",
      "batch 3803: loss 0.406143\n",
      "batch 3804: loss 0.337737\n",
      "batch 3805: loss 0.203780\n",
      "batch 3806: loss 0.373941\n",
      "batch 3807: loss 0.411309\n",
      "batch 3808: loss 0.288730\n",
      "batch 3809: loss 0.477293\n",
      "batch 3810: loss 0.445406\n",
      "batch 3811: loss 0.374245\n",
      "batch 3812: loss 0.418058\n",
      "batch 3813: loss 0.379211\n",
      "batch 3814: loss 0.296873\n",
      "batch 3815: loss 0.428920\n",
      "batch 3816: loss 0.451021\n",
      "batch 3817: loss 0.389897\n",
      "batch 3818: loss 0.661041\n",
      "batch 3819: loss 0.426532\n",
      "batch 3820: loss 0.349418\n",
      "batch 3821: loss 0.384925\n",
      "batch 3822: loss 0.408031\n",
      "batch 3823: loss 0.418377\n",
      "batch 3824: loss 0.441876\n",
      "batch 3825: loss 0.388940\n",
      "batch 3826: loss 0.321540\n",
      "batch 3827: loss 0.574250\n",
      "batch 3828: loss 0.321513\n",
      "batch 3829: loss 0.312051\n",
      "batch 3830: loss 0.369703\n",
      "batch 3831: loss 0.505205\n",
      "batch 3832: loss 0.557623\n",
      "batch 3833: loss 0.384692\n",
      "batch 3834: loss 0.346969\n",
      "batch 3835: loss 0.370776\n",
      "batch 3836: loss 0.605651\n",
      "batch 3837: loss 0.464486\n",
      "batch 3838: loss 0.475623\n",
      "batch 3839: loss 0.319610\n",
      "batch 3840: loss 0.391053\n",
      "batch 3841: loss 0.551716\n",
      "batch 3842: loss 0.563986\n",
      "batch 3843: loss 0.720992\n",
      "batch 3844: loss 0.284219\n",
      "batch 3845: loss 0.401448\n",
      "batch 3846: loss 0.416847\n",
      "batch 3847: loss 0.444424\n",
      "batch 3848: loss 0.703008\n",
      "batch 3849: loss 0.337957\n",
      "batch 3850: loss 0.572345\n",
      "batch 3851: loss 0.532538\n",
      "batch 3852: loss 0.267383\n",
      "batch 3853: loss 0.420402\n",
      "batch 3854: loss 0.263240\n",
      "batch 3855: loss 0.346836\n",
      "batch 3856: loss 0.562334\n",
      "batch 3857: loss 0.558339\n",
      "batch 3858: loss 0.472446\n",
      "batch 3859: loss 0.399858\n",
      "batch 3860: loss 0.587674\n",
      "batch 3861: loss 0.419465\n",
      "batch 3862: loss 0.382373\n",
      "batch 3863: loss 0.266562\n",
      "batch 3864: loss 0.201739\n",
      "batch 3865: loss 0.455641\n",
      "batch 3866: loss 0.265073\n",
      "batch 3867: loss 0.520679\n",
      "batch 3868: loss 0.606914\n",
      "batch 3869: loss 0.316294\n",
      "batch 3870: loss 0.311996\n",
      "batch 3871: loss 0.576046\n",
      "batch 3872: loss 0.379722\n",
      "batch 3873: loss 0.283129\n",
      "batch 3874: loss 0.472749\n",
      "batch 3875: loss 0.320536\n",
      "batch 3876: loss 0.344201\n",
      "batch 3877: loss 0.428821\n",
      "batch 3878: loss 0.378571\n",
      "batch 3879: loss 0.322393\n",
      "batch 3880: loss 0.387522\n",
      "batch 3881: loss 0.300781\n",
      "batch 3882: loss 0.414145\n",
      "batch 3883: loss 0.239927\n",
      "batch 3884: loss 0.479668\n",
      "batch 3885: loss 0.429462\n",
      "batch 3886: loss 0.272163\n",
      "batch 3887: loss 0.247459\n",
      "batch 3888: loss 0.262362\n",
      "batch 3889: loss 0.328355\n",
      "batch 3890: loss 0.359686\n",
      "batch 3891: loss 0.389610\n",
      "batch 3892: loss 0.617074\n",
      "batch 3893: loss 0.421928\n",
      "batch 3894: loss 0.186164\n",
      "batch 3895: loss 0.285714\n",
      "batch 3896: loss 0.309061\n",
      "batch 3897: loss 0.425860\n",
      "batch 3898: loss 0.491834\n",
      "batch 3899: loss 0.318493\n",
      "batch 3900: loss 0.389586\n",
      "batch 3901: loss 0.491954\n",
      "batch 3902: loss 0.343283\n",
      "batch 3903: loss 0.279746\n",
      "batch 3904: loss 0.362089\n",
      "batch 3905: loss 0.288272\n",
      "batch 3906: loss 0.560830\n",
      "batch 3907: loss 0.377516\n",
      "batch 3908: loss 0.500444\n",
      "batch 3909: loss 0.363594\n",
      "batch 3910: loss 0.380260\n",
      "batch 3911: loss 0.341885\n",
      "batch 3912: loss 0.384603\n",
      "batch 3913: loss 0.247552\n",
      "batch 3914: loss 0.298119\n",
      "batch 3915: loss 0.206836\n",
      "batch 3916: loss 0.220850\n",
      "batch 3917: loss 0.358206\n",
      "batch 3918: loss 0.244718\n",
      "batch 3919: loss 0.237347\n",
      "batch 3920: loss 0.359778\n",
      "batch 3921: loss 0.618471\n",
      "batch 3922: loss 0.272284\n",
      "batch 3923: loss 0.363495\n",
      "batch 3924: loss 0.432677\n",
      "batch 3925: loss 0.231857\n",
      "batch 3926: loss 0.358914\n",
      "batch 3927: loss 0.513915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3928: loss 0.417981\n",
      "batch 3929: loss 0.323852\n",
      "batch 3930: loss 0.318418\n",
      "batch 3931: loss 0.346079\n",
      "batch 3932: loss 0.480213\n",
      "batch 3933: loss 0.423452\n",
      "batch 3934: loss 0.237804\n",
      "batch 3935: loss 0.189027\n",
      "batch 3936: loss 0.584672\n",
      "batch 3937: loss 0.301954\n",
      "batch 3938: loss 0.319973\n",
      "batch 3939: loss 0.352234\n",
      "batch 3940: loss 0.348416\n",
      "batch 3941: loss 0.461860\n",
      "batch 3942: loss 0.334555\n",
      "batch 3943: loss 0.295372\n",
      "batch 3944: loss 0.359757\n",
      "batch 3945: loss 0.339381\n",
      "batch 3946: loss 0.498045\n",
      "batch 3947: loss 0.505108\n",
      "batch 3948: loss 0.282826\n",
      "batch 3949: loss 0.258680\n",
      "batch 3950: loss 0.336807\n",
      "batch 3951: loss 0.609317\n",
      "batch 3952: loss 0.371570\n",
      "batch 3953: loss 0.603882\n",
      "batch 3954: loss 0.546476\n",
      "batch 3955: loss 0.224182\n",
      "batch 3956: loss 0.347859\n",
      "batch 3957: loss 0.264474\n",
      "batch 3958: loss 0.325716\n",
      "batch 3959: loss 0.358475\n",
      "batch 3960: loss 0.518516\n",
      "batch 3961: loss 0.273193\n",
      "batch 3962: loss 0.533688\n",
      "batch 3963: loss 0.244999\n",
      "batch 3964: loss 0.346748\n",
      "batch 3965: loss 0.406168\n",
      "batch 3966: loss 0.338023\n",
      "batch 3967: loss 0.291900\n",
      "batch 3968: loss 0.208288\n",
      "batch 3969: loss 0.536136\n",
      "batch 3970: loss 0.185455\n",
      "batch 3971: loss 0.371142\n",
      "batch 3972: loss 0.424784\n",
      "batch 3973: loss 0.473892\n",
      "batch 3974: loss 0.417611\n",
      "batch 3975: loss 0.282195\n",
      "batch 3976: loss 0.263905\n",
      "batch 3977: loss 0.377089\n",
      "batch 3978: loss 0.360248\n",
      "batch 3979: loss 0.241713\n",
      "batch 3980: loss 0.609487\n",
      "batch 3981: loss 0.326462\n",
      "batch 3982: loss 0.302217\n",
      "batch 3983: loss 0.376879\n",
      "batch 3984: loss 0.390747\n",
      "batch 3985: loss 0.329656\n",
      "batch 3986: loss 0.453239\n",
      "batch 3987: loss 0.440659\n",
      "batch 3988: loss 0.496456\n",
      "batch 3989: loss 0.390943\n",
      "batch 3990: loss 0.263003\n",
      "batch 3991: loss 0.455504\n",
      "batch 3992: loss 0.294026\n",
      "batch 3993: loss 0.422063\n",
      "batch 3994: loss 0.669018\n",
      "batch 3995: loss 0.325553\n",
      "batch 3996: loss 0.466855\n",
      "batch 3997: loss 0.350456\n",
      "batch 3998: loss 0.491133\n",
      "batch 3999: loss 0.317391\n",
      "batch 4000: loss 0.222411\n",
      "batch 4001: loss 0.290231\n",
      "batch 4002: loss 0.362308\n",
      "batch 4003: loss 0.341119\n",
      "batch 4004: loss 0.351758\n",
      "batch 4005: loss 0.355358\n",
      "batch 4006: loss 0.302852\n",
      "batch 4007: loss 0.325863\n",
      "batch 4008: loss 0.496302\n",
      "batch 4009: loss 0.235519\n",
      "batch 4010: loss 0.432925\n",
      "batch 4011: loss 0.521459\n",
      "batch 4012: loss 0.240102\n",
      "batch 4013: loss 0.651300\n",
      "batch 4014: loss 0.367752\n",
      "batch 4015: loss 0.374388\n",
      "batch 4016: loss 0.418308\n",
      "batch 4017: loss 0.336139\n",
      "batch 4018: loss 0.487104\n",
      "batch 4019: loss 0.305916\n",
      "batch 4020: loss 0.333486\n",
      "batch 4021: loss 0.390085\n",
      "batch 4022: loss 0.356909\n",
      "batch 4023: loss 0.387638\n",
      "batch 4024: loss 0.517138\n",
      "batch 4025: loss 0.307893\n",
      "batch 4026: loss 0.316754\n",
      "batch 4027: loss 0.670667\n",
      "batch 4028: loss 0.481089\n",
      "batch 4029: loss 0.415802\n",
      "batch 4030: loss 0.358743\n",
      "batch 4031: loss 0.463191\n",
      "batch 4032: loss 0.289572\n",
      "batch 4033: loss 0.692388\n",
      "batch 4034: loss 0.298325\n",
      "batch 4035: loss 0.523236\n",
      "batch 4036: loss 0.500351\n",
      "batch 4037: loss 0.537729\n",
      "batch 4038: loss 0.280852\n",
      "batch 4039: loss 0.567804\n",
      "batch 4040: loss 0.270443\n",
      "batch 4041: loss 0.317082\n",
      "batch 4042: loss 0.289395\n",
      "batch 4043: loss 0.358477\n",
      "batch 4044: loss 0.414621\n",
      "batch 4045: loss 0.239241\n",
      "batch 4046: loss 0.380431\n",
      "batch 4047: loss 0.265506\n",
      "batch 4048: loss 0.411845\n",
      "batch 4049: loss 0.365770\n",
      "batch 4050: loss 0.605518\n",
      "batch 4051: loss 0.410507\n",
      "batch 4052: loss 0.228611\n",
      "batch 4053: loss 0.290978\n",
      "batch 4054: loss 0.343789\n",
      "batch 4055: loss 0.543380\n",
      "batch 4056: loss 0.568122\n",
      "batch 4057: loss 0.559467\n",
      "batch 4058: loss 0.296593\n",
      "batch 4059: loss 0.290650\n",
      "batch 4060: loss 0.277482\n",
      "batch 4061: loss 0.399679\n",
      "batch 4062: loss 0.414450\n",
      "batch 4063: loss 0.404519\n",
      "batch 4064: loss 0.356734\n",
      "batch 4065: loss 0.393759\n",
      "batch 4066: loss 0.598761\n",
      "batch 4067: loss 0.399085\n",
      "batch 4068: loss 0.486044\n",
      "batch 4069: loss 0.590928\n",
      "batch 4070: loss 0.256855\n",
      "batch 4071: loss 0.530012\n",
      "batch 4072: loss 0.319538\n",
      "batch 4073: loss 0.473337\n",
      "batch 4074: loss 0.344628\n",
      "batch 4075: loss 0.328464\n",
      "batch 4076: loss 0.327739\n",
      "batch 4077: loss 0.376832\n",
      "batch 4078: loss 0.290858\n",
      "batch 4079: loss 0.292510\n",
      "batch 4080: loss 0.467681\n",
      "batch 4081: loss 0.442343\n",
      "batch 4082: loss 0.318505\n",
      "batch 4083: loss 0.434955\n",
      "batch 4084: loss 0.355308\n",
      "batch 4085: loss 0.504690\n",
      "batch 4086: loss 0.456889\n",
      "batch 4087: loss 0.326809\n",
      "batch 4088: loss 0.379421\n",
      "batch 4089: loss 0.398875\n",
      "batch 4090: loss 0.411252\n",
      "batch 4091: loss 0.391640\n",
      "batch 4092: loss 0.492808\n",
      "batch 4093: loss 0.526592\n",
      "batch 4094: loss 0.490834\n",
      "batch 4095: loss 0.363555\n",
      "batch 4096: loss 0.451244\n",
      "batch 4097: loss 0.352084\n",
      "batch 4098: loss 0.448818\n",
      "batch 4099: loss 0.523456\n",
      "batch 4100: loss 0.486806\n",
      "batch 4101: loss 0.278467\n",
      "batch 4102: loss 0.477072\n",
      "batch 4103: loss 0.310347\n",
      "batch 4104: loss 0.388783\n",
      "batch 4105: loss 0.493748\n",
      "batch 4106: loss 0.378292\n",
      "batch 4107: loss 0.144669\n",
      "batch 4108: loss 0.405112\n",
      "batch 4109: loss 0.405850\n",
      "batch 4110: loss 0.448571\n",
      "batch 4111: loss 0.277104\n",
      "batch 4112: loss 0.314673\n",
      "batch 4113: loss 0.414450\n",
      "batch 4114: loss 0.517115\n",
      "batch 4115: loss 0.252520\n",
      "batch 4116: loss 0.348214\n",
      "batch 4117: loss 0.328940\n",
      "batch 4118: loss 0.272938\n",
      "batch 4119: loss 0.611034\n",
      "batch 4120: loss 0.526620\n",
      "batch 4121: loss 0.352653\n",
      "batch 4122: loss 0.470605\n",
      "batch 4123: loss 0.423159\n",
      "batch 4124: loss 0.495660\n",
      "batch 4125: loss 0.288791\n",
      "batch 4126: loss 0.522192\n",
      "batch 4127: loss 0.633526\n",
      "batch 4128: loss 0.361954\n",
      "batch 4129: loss 0.400446\n",
      "batch 4130: loss 0.393883\n",
      "batch 4131: loss 0.508112\n",
      "batch 4132: loss 0.410907\n",
      "batch 4133: loss 0.448115\n",
      "batch 4134: loss 0.426612\n",
      "batch 4135: loss 0.367013\n",
      "batch 4136: loss 0.349467\n",
      "batch 4137: loss 0.517277\n",
      "batch 4138: loss 0.416949\n",
      "batch 4139: loss 0.618098\n",
      "batch 4140: loss 0.390932\n",
      "batch 4141: loss 0.509434\n",
      "batch 4142: loss 0.314912\n",
      "batch 4143: loss 0.395879\n",
      "batch 4144: loss 0.338643\n",
      "batch 4145: loss 0.322655\n",
      "batch 4146: loss 0.455156\n",
      "batch 4147: loss 0.468265\n",
      "batch 4148: loss 0.473673\n",
      "batch 4149: loss 0.486402\n",
      "batch 4150: loss 0.245641\n",
      "batch 4151: loss 0.350519\n",
      "batch 4152: loss 0.525366\n",
      "batch 4153: loss 0.332169\n",
      "batch 4154: loss 0.408228\n",
      "batch 4155: loss 0.348541\n",
      "batch 4156: loss 0.469301\n",
      "batch 4157: loss 0.435161\n",
      "batch 4158: loss 0.152123\n",
      "batch 4159: loss 0.334817\n",
      "batch 4160: loss 0.290678\n",
      "batch 4161: loss 0.360253\n",
      "batch 4162: loss 0.320724\n",
      "batch 4163: loss 0.540443\n",
      "batch 4164: loss 0.466766\n",
      "batch 4165: loss 0.366688\n",
      "batch 4166: loss 0.423426\n",
      "batch 4167: loss 0.454895\n",
      "batch 4168: loss 0.460968\n",
      "batch 4169: loss 0.479783\n",
      "batch 4170: loss 0.229815\n",
      "batch 4171: loss 0.619196\n",
      "batch 4172: loss 0.392380\n",
      "batch 4173: loss 0.296378\n",
      "batch 4174: loss 0.514652\n",
      "batch 4175: loss 0.332053\n",
      "batch 4176: loss 0.392733\n",
      "batch 4177: loss 0.372376\n",
      "batch 4178: loss 0.284284\n",
      "batch 4179: loss 0.407446\n",
      "batch 4180: loss 0.244020\n",
      "batch 4181: loss 0.378025\n",
      "batch 4182: loss 0.304498\n",
      "batch 4183: loss 0.255389\n",
      "batch 4184: loss 0.412067\n",
      "batch 4185: loss 0.288621\n",
      "batch 4186: loss 0.602619\n",
      "batch 4187: loss 0.695675\n",
      "batch 4188: loss 0.431980\n",
      "batch 4189: loss 0.309105\n",
      "batch 4190: loss 0.325720\n",
      "batch 4191: loss 0.423918\n",
      "batch 4192: loss 0.405116\n",
      "batch 4193: loss 0.431603\n",
      "batch 4194: loss 0.359664\n",
      "batch 4195: loss 0.304733\n",
      "batch 4196: loss 0.317894\n",
      "batch 4197: loss 0.357121\n",
      "batch 4198: loss 0.361766\n",
      "batch 4199: loss 0.289390\n",
      "batch 4200: loss 0.175448\n",
      "batch 4201: loss 0.294929\n",
      "batch 4202: loss 0.302692\n",
      "batch 4203: loss 0.426682\n",
      "batch 4204: loss 0.532707\n",
      "batch 4205: loss 0.382168\n",
      "batch 4206: loss 0.488298\n",
      "batch 4207: loss 0.509061\n",
      "batch 4208: loss 0.393647\n",
      "batch 4209: loss 0.578894\n",
      "batch 4210: loss 0.378170\n",
      "batch 4211: loss 0.355515\n",
      "batch 4212: loss 0.292263\n",
      "batch 4213: loss 0.281027\n",
      "batch 4214: loss 0.384277\n",
      "batch 4215: loss 0.328681\n",
      "batch 4216: loss 0.459532\n",
      "batch 4217: loss 0.470931\n",
      "batch 4218: loss 0.432406\n",
      "batch 4219: loss 0.371259\n",
      "batch 4220: loss 0.251554\n",
      "batch 4221: loss 0.447448\n",
      "batch 4222: loss 0.539822\n",
      "batch 4223: loss 0.404785\n",
      "batch 4224: loss 0.238094\n",
      "batch 4225: loss 0.286789\n",
      "batch 4226: loss 0.200964\n",
      "batch 4227: loss 0.393922\n",
      "batch 4228: loss 0.525605\n",
      "batch 4229: loss 0.353200\n",
      "batch 4230: loss 0.491972\n",
      "batch 4231: loss 0.409603\n",
      "batch 4232: loss 0.322588\n",
      "batch 4233: loss 0.418747\n",
      "batch 4234: loss 0.359866\n",
      "batch 4235: loss 0.658206\n",
      "batch 4236: loss 0.239250\n",
      "batch 4237: loss 0.486070\n",
      "batch 4238: loss 0.454251\n",
      "batch 4239: loss 0.410088\n",
      "batch 4240: loss 0.329195\n",
      "batch 4241: loss 0.256669\n",
      "batch 4242: loss 0.287134\n",
      "batch 4243: loss 0.346375\n",
      "batch 4244: loss 0.307859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4245: loss 0.405179\n",
      "batch 4246: loss 0.245954\n",
      "batch 4247: loss 0.391496\n",
      "batch 4248: loss 0.462544\n",
      "batch 4249: loss 0.480049\n",
      "batch 4250: loss 0.360296\n",
      "batch 4251: loss 0.593154\n",
      "batch 4252: loss 0.290058\n",
      "batch 4253: loss 0.370973\n",
      "batch 4254: loss 0.447295\n",
      "batch 4255: loss 0.220289\n",
      "batch 4256: loss 0.276855\n",
      "batch 4257: loss 0.373578\n",
      "batch 4258: loss 0.473255\n",
      "batch 4259: loss 0.334427\n",
      "batch 4260: loss 0.609165\n",
      "batch 4261: loss 0.443520\n",
      "batch 4262: loss 0.222823\n",
      "batch 4263: loss 0.306586\n",
      "batch 4264: loss 0.524174\n",
      "batch 4265: loss 0.545110\n",
      "batch 4266: loss 0.228805\n",
      "batch 4267: loss 0.403489\n",
      "batch 4268: loss 0.245593\n",
      "batch 4269: loss 0.304942\n",
      "batch 4270: loss 0.496464\n",
      "batch 4271: loss 0.338786\n",
      "batch 4272: loss 0.245557\n",
      "batch 4273: loss 0.204008\n",
      "batch 4274: loss 0.317925\n",
      "batch 4275: loss 0.247081\n",
      "batch 4276: loss 0.501180\n",
      "batch 4277: loss 0.692021\n",
      "batch 4278: loss 0.335666\n",
      "batch 4279: loss 0.383366\n",
      "batch 4280: loss 0.561169\n",
      "batch 4281: loss 0.372173\n",
      "batch 4282: loss 0.260375\n",
      "batch 4283: loss 0.292050\n",
      "batch 4284: loss 0.357611\n",
      "batch 4285: loss 0.271311\n",
      "batch 4286: loss 0.420909\n",
      "batch 4287: loss 0.340014\n",
      "batch 4288: loss 0.410759\n",
      "batch 4289: loss 0.449455\n",
      "batch 4290: loss 0.471041\n",
      "batch 4291: loss 0.479716\n",
      "batch 4292: loss 0.380440\n",
      "batch 4293: loss 0.275727\n",
      "batch 4294: loss 0.329901\n",
      "batch 4295: loss 0.411510\n",
      "batch 4296: loss 0.562098\n",
      "batch 4297: loss 0.200656\n",
      "batch 4298: loss 0.369725\n",
      "batch 4299: loss 0.501605\n",
      "batch 4300: loss 0.470146\n",
      "batch 4301: loss 0.351543\n",
      "batch 4302: loss 0.515544\n",
      "batch 4303: loss 0.381698\n",
      "batch 4304: loss 0.562749\n",
      "batch 4305: loss 0.290482\n",
      "batch 4306: loss 0.465152\n",
      "batch 4307: loss 0.349955\n",
      "batch 4308: loss 0.336014\n",
      "batch 4309: loss 0.481317\n",
      "batch 4310: loss 0.443640\n",
      "batch 4311: loss 0.342730\n",
      "batch 4312: loss 0.357634\n",
      "batch 4313: loss 0.446359\n",
      "batch 4314: loss 0.274109\n",
      "batch 4315: loss 0.391947\n",
      "batch 4316: loss 0.325505\n",
      "batch 4317: loss 0.349198\n",
      "batch 4318: loss 0.379003\n",
      "batch 4319: loss 0.311911\n",
      "batch 4320: loss 0.241504\n",
      "batch 4321: loss 0.317816\n",
      "batch 4322: loss 0.476464\n",
      "batch 4323: loss 0.318037\n",
      "batch 4324: loss 0.456447\n",
      "batch 4325: loss 0.396437\n",
      "batch 4326: loss 0.241347\n",
      "batch 4327: loss 0.464465\n",
      "batch 4328: loss 0.434394\n",
      "batch 4329: loss 0.474788\n",
      "batch 4330: loss 0.317995\n",
      "batch 4331: loss 0.333304\n",
      "batch 4332: loss 0.520340\n",
      "batch 4333: loss 0.320124\n",
      "batch 4334: loss 0.280137\n",
      "batch 4335: loss 0.477031\n",
      "batch 4336: loss 0.405641\n",
      "batch 4337: loss 0.288998\n",
      "batch 4338: loss 0.404046\n",
      "batch 4339: loss 0.362937\n",
      "batch 4340: loss 0.414798\n",
      "batch 4341: loss 0.437229\n",
      "batch 4342: loss 0.323754\n",
      "batch 4343: loss 0.362004\n",
      "batch 4344: loss 0.348923\n",
      "batch 4345: loss 0.291909\n",
      "batch 4346: loss 0.428823\n",
      "batch 4347: loss 0.331545\n",
      "batch 4348: loss 0.306813\n",
      "batch 4349: loss 0.244761\n",
      "batch 4350: loss 0.256466\n",
      "batch 4351: loss 0.530802\n",
      "batch 4352: loss 0.415493\n",
      "batch 4353: loss 0.522377\n",
      "batch 4354: loss 0.331001\n",
      "batch 4355: loss 0.563446\n",
      "batch 4356: loss 0.422309\n",
      "batch 4357: loss 0.404559\n",
      "batch 4358: loss 0.253134\n",
      "batch 4359: loss 0.387158\n",
      "batch 4360: loss 0.387644\n",
      "batch 4361: loss 0.381164\n",
      "batch 4362: loss 0.330807\n",
      "batch 4363: loss 0.572696\n",
      "batch 4364: loss 0.413755\n",
      "batch 4365: loss 0.351270\n",
      "batch 4366: loss 0.342411\n",
      "batch 4367: loss 0.325859\n",
      "batch 4368: loss 0.203172\n",
      "batch 4369: loss 0.265190\n",
      "batch 4370: loss 0.395198\n",
      "batch 4371: loss 0.216494\n",
      "batch 4372: loss 0.516585\n",
      "batch 4373: loss 0.264499\n",
      "batch 4374: loss 0.247526\n",
      "batch 4375: loss 0.284843\n",
      "batch 4376: loss 0.271042\n",
      "batch 4377: loss 0.413335\n",
      "batch 4378: loss 0.362981\n",
      "batch 4379: loss 0.304480\n",
      "batch 4380: loss 0.362941\n",
      "batch 4381: loss 0.244485\n",
      "batch 4382: loss 0.256420\n",
      "batch 4383: loss 0.337463\n",
      "batch 4384: loss 0.482882\n",
      "batch 4385: loss 0.391629\n",
      "batch 4386: loss 0.490924\n",
      "batch 4387: loss 0.388841\n",
      "batch 4388: loss 0.327841\n",
      "batch 4389: loss 0.507089\n",
      "batch 4390: loss 0.388253\n",
      "batch 4391: loss 0.524631\n",
      "batch 4392: loss 0.197803\n",
      "batch 4393: loss 0.440375\n",
      "batch 4394: loss 0.366683\n",
      "batch 4395: loss 0.403057\n",
      "batch 4396: loss 0.392651\n",
      "batch 4397: loss 0.275142\n",
      "batch 4398: loss 0.181399\n",
      "batch 4399: loss 0.451950\n",
      "batch 4400: loss 0.310668\n",
      "batch 4401: loss 0.430826\n",
      "batch 4402: loss 0.336577\n",
      "batch 4403: loss 0.493972\n",
      "batch 4404: loss 0.444712\n",
      "batch 4405: loss 0.341622\n",
      "batch 4406: loss 0.482278\n",
      "batch 4407: loss 0.259500\n",
      "batch 4408: loss 0.528278\n",
      "batch 4409: loss 0.403798\n",
      "batch 4410: loss 0.441412\n",
      "batch 4411: loss 0.324121\n",
      "batch 4412: loss 0.293752\n",
      "batch 4413: loss 0.528803\n",
      "batch 4414: loss 0.426373\n",
      "batch 4415: loss 0.310531\n",
      "batch 4416: loss 0.447294\n",
      "batch 4417: loss 0.315906\n",
      "batch 4418: loss 0.424401\n",
      "batch 4419: loss 0.462850\n",
      "batch 4420: loss 0.290804\n",
      "batch 4421: loss 0.429181\n",
      "batch 4422: loss 0.202147\n",
      "batch 4423: loss 0.442164\n",
      "batch 4424: loss 0.594888\n",
      "batch 4425: loss 0.259705\n",
      "batch 4426: loss 0.368253\n",
      "batch 4427: loss 0.383053\n",
      "batch 4428: loss 0.327716\n",
      "batch 4429: loss 0.306200\n",
      "batch 4430: loss 0.217534\n",
      "batch 4431: loss 0.415929\n",
      "batch 4432: loss 0.303289\n",
      "batch 4433: loss 0.374675\n",
      "batch 4434: loss 0.432953\n",
      "batch 4435: loss 0.334322\n",
      "batch 4436: loss 0.390272\n",
      "batch 4437: loss 0.495484\n",
      "batch 4438: loss 0.197855\n",
      "batch 4439: loss 0.380024\n",
      "batch 4440: loss 0.441562\n",
      "batch 4441: loss 0.345511\n",
      "batch 4442: loss 0.309518\n",
      "batch 4443: loss 0.305180\n",
      "batch 4444: loss 0.543824\n",
      "batch 4445: loss 0.345236\n",
      "batch 4446: loss 0.314494\n",
      "batch 4447: loss 0.334523\n",
      "batch 4448: loss 0.220931\n",
      "batch 4449: loss 0.199480\n",
      "batch 4450: loss 0.207730\n",
      "batch 4451: loss 0.536891\n",
      "batch 4452: loss 0.453456\n",
      "batch 4453: loss 0.344296\n",
      "batch 4454: loss 0.269295\n",
      "batch 4455: loss 0.322611\n",
      "batch 4456: loss 0.384869\n",
      "batch 4457: loss 0.536176\n",
      "batch 4458: loss 0.413570\n",
      "batch 4459: loss 0.327058\n",
      "batch 4460: loss 0.260164\n",
      "batch 4461: loss 0.328799\n",
      "batch 4462: loss 0.321437\n",
      "batch 4463: loss 0.497784\n",
      "batch 4464: loss 0.389263\n",
      "batch 4465: loss 0.200313\n",
      "batch 4466: loss 0.418060\n",
      "batch 4467: loss 0.571620\n",
      "batch 4468: loss 0.353833\n",
      "batch 4469: loss 0.465761\n",
      "batch 4470: loss 0.376780\n",
      "batch 4471: loss 0.533885\n",
      "batch 4472: loss 0.301481\n",
      "batch 4473: loss 0.373663\n",
      "batch 4474: loss 0.208462\n",
      "batch 4475: loss 0.222171\n",
      "batch 4476: loss 0.400512\n",
      "batch 4477: loss 0.566901\n",
      "batch 4478: loss 0.528765\n",
      "batch 4479: loss 0.388378\n",
      "batch 4480: loss 0.287553\n",
      "batch 4481: loss 0.471866\n",
      "batch 4482: loss 0.487981\n",
      "batch 4483: loss 0.397608\n",
      "batch 4484: loss 0.417912\n",
      "batch 4485: loss 0.325858\n",
      "batch 4486: loss 0.289080\n",
      "batch 4487: loss 0.329763\n",
      "batch 4488: loss 0.330857\n",
      "batch 4489: loss 0.318112\n",
      "batch 4490: loss 0.413511\n",
      "batch 4491: loss 0.292795\n",
      "batch 4492: loss 0.272889\n",
      "batch 4493: loss 0.330941\n",
      "batch 4494: loss 0.452367\n",
      "batch 4495: loss 0.439532\n",
      "batch 4496: loss 0.252671\n",
      "batch 4497: loss 0.538029\n",
      "batch 4498: loss 0.361899\n",
      "batch 4499: loss 0.381400\n",
      "batch 4500: loss 0.370566\n",
      "batch 4501: loss 0.331320\n",
      "batch 4502: loss 0.354754\n",
      "batch 4503: loss 0.487282\n",
      "batch 4504: loss 0.292457\n",
      "batch 4505: loss 0.333685\n",
      "batch 4506: loss 0.330545\n",
      "batch 4507: loss 0.312878\n",
      "batch 4508: loss 0.301815\n",
      "batch 4509: loss 0.309129\n",
      "batch 4510: loss 0.461529\n",
      "batch 4511: loss 0.635535\n",
      "batch 4512: loss 0.449113\n",
      "batch 4513: loss 0.392329\n",
      "batch 4514: loss 0.343285\n",
      "batch 4515: loss 0.343927\n",
      "batch 4516: loss 0.459227\n",
      "batch 4517: loss 0.410197\n",
      "batch 4518: loss 0.393991\n",
      "batch 4519: loss 0.456610\n",
      "batch 4520: loss 0.236111\n",
      "batch 4521: loss 0.367484\n",
      "batch 4522: loss 0.517396\n",
      "batch 4523: loss 0.325412\n",
      "batch 4524: loss 0.390318\n",
      "batch 4525: loss 0.460458\n",
      "batch 4526: loss 0.354254\n",
      "batch 4527: loss 0.304268\n",
      "batch 4528: loss 0.239680\n",
      "batch 4529: loss 0.611436\n",
      "batch 4530: loss 0.462982\n",
      "batch 4531: loss 0.294372\n",
      "batch 4532: loss 0.383557\n",
      "batch 4533: loss 0.444793\n",
      "batch 4534: loss 0.430818\n",
      "batch 4535: loss 0.648171\n",
      "batch 4536: loss 0.327902\n",
      "batch 4537: loss 0.453571\n",
      "batch 4538: loss 0.311797\n",
      "batch 4539: loss 0.392115\n",
      "batch 4540: loss 0.369393\n",
      "batch 4541: loss 0.425752\n",
      "batch 4542: loss 0.401114\n",
      "batch 4543: loss 0.338658\n",
      "batch 4544: loss 0.382082\n",
      "batch 4545: loss 0.336876\n",
      "batch 4546: loss 0.259976\n",
      "batch 4547: loss 0.159710\n",
      "batch 4548: loss 0.226085\n",
      "batch 4549: loss 0.468554\n",
      "batch 4550: loss 0.363604\n",
      "batch 4551: loss 0.323927\n",
      "batch 4552: loss 0.200493\n",
      "batch 4553: loss 0.238132\n",
      "batch 4554: loss 0.304204\n",
      "batch 4555: loss 0.329051\n",
      "batch 4556: loss 0.255572\n",
      "batch 4557: loss 0.459035\n",
      "batch 4558: loss 0.384380\n",
      "batch 4559: loss 0.318094\n",
      "batch 4560: loss 0.307661\n",
      "batch 4561: loss 0.366194\n",
      "batch 4562: loss 0.305015\n",
      "batch 4563: loss 0.520050\n",
      "batch 4564: loss 0.486535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4565: loss 0.393465\n",
      "batch 4566: loss 0.458079\n",
      "batch 4567: loss 0.469266\n",
      "batch 4568: loss 0.529657\n",
      "batch 4569: loss 0.340997\n",
      "batch 4570: loss 0.503533\n",
      "batch 4571: loss 0.178522\n",
      "batch 4572: loss 0.226068\n",
      "batch 4573: loss 0.328688\n",
      "batch 4574: loss 0.463463\n",
      "batch 4575: loss 0.375662\n",
      "batch 4576: loss 0.307602\n",
      "batch 4577: loss 0.474629\n",
      "batch 4578: loss 0.278554\n",
      "batch 4579: loss 0.283665\n",
      "batch 4580: loss 0.383428\n",
      "batch 4581: loss 0.333654\n",
      "batch 4582: loss 0.394892\n",
      "batch 4583: loss 0.512433\n",
      "batch 4584: loss 0.295264\n",
      "batch 4585: loss 0.549163\n",
      "batch 4586: loss 0.273746\n",
      "batch 4587: loss 0.474226\n",
      "batch 4588: loss 0.272300\n",
      "batch 4589: loss 0.212039\n",
      "batch 4590: loss 0.260825\n",
      "batch 4591: loss 0.358859\n",
      "batch 4592: loss 0.477550\n",
      "batch 4593: loss 0.339917\n",
      "batch 4594: loss 0.343811\n",
      "batch 4595: loss 0.295315\n",
      "batch 4596: loss 0.518301\n",
      "batch 4597: loss 0.332548\n",
      "batch 4598: loss 0.251485\n",
      "batch 4599: loss 0.288740\n",
      "batch 4600: loss 0.211657\n",
      "batch 4601: loss 0.358484\n",
      "batch 4602: loss 0.373101\n",
      "batch 4603: loss 0.639630\n",
      "batch 4604: loss 0.172727\n",
      "batch 4605: loss 0.409197\n",
      "batch 4606: loss 0.439120\n",
      "batch 4607: loss 0.495433\n",
      "batch 4608: loss 0.265476\n",
      "batch 4609: loss 0.424987\n",
      "batch 4610: loss 0.248797\n",
      "batch 4611: loss 0.208237\n",
      "batch 4612: loss 0.347741\n",
      "batch 4613: loss 0.336646\n",
      "batch 4614: loss 0.317456\n",
      "batch 4615: loss 0.226341\n",
      "batch 4616: loss 0.440098\n",
      "batch 4617: loss 0.331971\n",
      "batch 4618: loss 0.477809\n",
      "batch 4619: loss 0.493259\n",
      "batch 4620: loss 0.303383\n",
      "batch 4621: loss 0.422562\n",
      "batch 4622: loss 0.351953\n",
      "batch 4623: loss 0.442711\n",
      "batch 4624: loss 0.435489\n",
      "batch 4625: loss 0.597413\n",
      "batch 4626: loss 0.385024\n",
      "batch 4627: loss 0.400701\n",
      "batch 4628: loss 0.253810\n",
      "batch 4629: loss 0.371179\n",
      "batch 4630: loss 0.460424\n",
      "batch 4631: loss 0.342506\n",
      "batch 4632: loss 0.388857\n",
      "batch 4633: loss 0.488540\n",
      "batch 4634: loss 0.373466\n",
      "batch 4635: loss 0.377955\n",
      "batch 4636: loss 0.253700\n",
      "batch 4637: loss 0.388804\n",
      "batch 4638: loss 0.353957\n",
      "batch 4639: loss 0.212760\n",
      "batch 4640: loss 0.259557\n",
      "batch 4641: loss 0.312072\n",
      "batch 4642: loss 0.252703\n",
      "batch 4643: loss 0.521019\n",
      "batch 4644: loss 0.568765\n",
      "batch 4645: loss 0.449792\n",
      "batch 4646: loss 0.616874\n",
      "batch 4647: loss 0.291944\n",
      "batch 4648: loss 0.455140\n",
      "batch 4649: loss 0.278245\n",
      "batch 4650: loss 0.242652\n",
      "batch 4651: loss 0.345318\n",
      "batch 4652: loss 0.336885\n",
      "batch 4653: loss 0.385270\n",
      "batch 4654: loss 0.281215\n",
      "batch 4655: loss 0.396111\n",
      "batch 4656: loss 0.455803\n",
      "batch 4657: loss 0.551459\n",
      "batch 4658: loss 0.314693\n",
      "batch 4659: loss 0.270279\n",
      "batch 4660: loss 0.255079\n",
      "batch 4661: loss 0.506201\n",
      "batch 4662: loss 0.465572\n",
      "batch 4663: loss 0.343715\n",
      "batch 4664: loss 0.364304\n",
      "batch 4665: loss 0.373583\n",
      "batch 4666: loss 0.318742\n",
      "batch 4667: loss 0.554482\n",
      "batch 4668: loss 0.200092\n",
      "batch 4669: loss 0.252278\n",
      "batch 4670: loss 0.166761\n",
      "batch 4671: loss 0.388092\n",
      "batch 4672: loss 0.309020\n",
      "batch 4673: loss 0.431477\n",
      "batch 4674: loss 0.225153\n",
      "batch 4675: loss 0.418594\n",
      "batch 4676: loss 0.524777\n",
      "batch 4677: loss 0.424588\n",
      "batch 4678: loss 0.291168\n",
      "batch 4679: loss 0.571023\n",
      "batch 4680: loss 0.468755\n",
      "batch 4681: loss 0.234372\n",
      "batch 4682: loss 0.282753\n",
      "batch 4683: loss 0.363979\n",
      "batch 4684: loss 0.249514\n",
      "batch 4685: loss 0.195707\n",
      "batch 4686: loss 0.330390\n",
      "batch 4687: loss 0.236631\n",
      "batch 4688: loss 0.443484\n",
      "batch 4689: loss 0.567764\n",
      "batch 4690: loss 0.455911\n",
      "batch 4691: loss 0.496895\n",
      "batch 4692: loss 0.145488\n",
      "batch 4693: loss 0.229619\n",
      "batch 4694: loss 0.446531\n",
      "batch 4695: loss 0.344366\n",
      "batch 4696: loss 0.272800\n",
      "batch 4697: loss 0.326626\n",
      "batch 4698: loss 0.473234\n",
      "batch 4699: loss 0.682538\n",
      "batch 4700: loss 0.165339\n",
      "batch 4701: loss 0.349507\n",
      "batch 4702: loss 0.288984\n",
      "batch 4703: loss 0.195303\n",
      "batch 4704: loss 0.336937\n",
      "batch 4705: loss 0.441905\n",
      "batch 4706: loss 0.645280\n",
      "batch 4707: loss 0.307783\n",
      "batch 4708: loss 0.311641\n",
      "batch 4709: loss 0.193044\n",
      "batch 4710: loss 0.376916\n",
      "batch 4711: loss 0.518396\n",
      "batch 4712: loss 0.218688\n",
      "batch 4713: loss 0.360850\n",
      "batch 4714: loss 0.501408\n",
      "batch 4715: loss 0.331937\n",
      "batch 4716: loss 0.369974\n",
      "batch 4717: loss 0.384270\n",
      "batch 4718: loss 0.363099\n",
      "batch 4719: loss 0.391556\n",
      "batch 4720: loss 0.515194\n",
      "batch 4721: loss 0.479677\n",
      "batch 4722: loss 0.348987\n",
      "batch 4723: loss 0.320081\n",
      "batch 4724: loss 0.338806\n",
      "batch 4725: loss 0.302292\n",
      "batch 4726: loss 0.433710\n",
      "batch 4727: loss 0.405799\n",
      "batch 4728: loss 0.223926\n",
      "batch 4729: loss 0.268520\n",
      "batch 4730: loss 0.361859\n",
      "batch 4731: loss 0.183915\n",
      "batch 4732: loss 0.434290\n",
      "batch 4733: loss 0.414730\n",
      "batch 4734: loss 0.321424\n",
      "batch 4735: loss 0.433684\n",
      "batch 4736: loss 0.416127\n",
      "batch 4737: loss 0.317499\n",
      "batch 4738: loss 0.409295\n",
      "batch 4739: loss 0.307902\n",
      "batch 4740: loss 0.520423\n",
      "batch 4741: loss 0.351644\n",
      "batch 4742: loss 0.440646\n",
      "batch 4743: loss 0.337857\n",
      "batch 4744: loss 0.343743\n",
      "batch 4745: loss 0.335738\n",
      "batch 4746: loss 0.297996\n",
      "batch 4747: loss 0.294574\n",
      "batch 4748: loss 0.522141\n",
      "batch 4749: loss 0.318068\n",
      "batch 4750: loss 0.457206\n",
      "batch 4751: loss 0.220361\n",
      "batch 4752: loss 0.403642\n",
      "batch 4753: loss 0.187075\n",
      "batch 4754: loss 0.435109\n",
      "batch 4755: loss 0.416263\n",
      "batch 4756: loss 0.499246\n",
      "batch 4757: loss 0.231604\n",
      "batch 4758: loss 0.211459\n",
      "batch 4759: loss 0.320268\n",
      "batch 4760: loss 0.325554\n",
      "batch 4761: loss 0.397709\n",
      "batch 4762: loss 0.382993\n",
      "batch 4763: loss 0.360963\n",
      "batch 4764: loss 0.434681\n",
      "batch 4765: loss 0.396783\n",
      "batch 4766: loss 0.505722\n",
      "batch 4767: loss 0.326388\n",
      "batch 4768: loss 0.363352\n",
      "batch 4769: loss 0.419706\n",
      "batch 4770: loss 0.404607\n",
      "batch 4771: loss 0.330126\n",
      "batch 4772: loss 0.296288\n",
      "batch 4773: loss 0.448085\n",
      "batch 4774: loss 0.306734\n",
      "batch 4775: loss 0.380949\n",
      "batch 4776: loss 0.420716\n",
      "batch 4777: loss 0.289167\n",
      "batch 4778: loss 0.368777\n",
      "batch 4779: loss 0.245306\n",
      "batch 4780: loss 0.330532\n",
      "batch 4781: loss 0.299145\n",
      "batch 4782: loss 0.177703\n",
      "batch 4783: loss 0.280833\n",
      "batch 4784: loss 0.500398\n",
      "batch 4785: loss 0.420398\n",
      "batch 4786: loss 0.366931\n",
      "batch 4787: loss 0.557563\n",
      "batch 4788: loss 0.305267\n",
      "batch 4789: loss 0.511176\n",
      "batch 4790: loss 0.300044\n",
      "batch 4791: loss 0.378451\n",
      "batch 4792: loss 0.435367\n",
      "batch 4793: loss 0.606598\n",
      "batch 4794: loss 0.393464\n",
      "batch 4795: loss 0.346552\n",
      "batch 4796: loss 0.278370\n",
      "batch 4797: loss 0.468693\n",
      "batch 4798: loss 0.238619\n",
      "batch 4799: loss 0.381009\n",
      "batch 4800: loss 0.280156\n",
      "batch 4801: loss 0.270208\n",
      "batch 4802: loss 0.233712\n",
      "batch 4803: loss 0.202670\n",
      "batch 4804: loss 0.331098\n",
      "batch 4805: loss 0.304535\n",
      "batch 4806: loss 0.318890\n",
      "batch 4807: loss 0.354729\n",
      "batch 4808: loss 0.232025\n",
      "batch 4809: loss 0.302471\n",
      "batch 4810: loss 0.285355\n",
      "batch 4811: loss 0.513713\n",
      "batch 4812: loss 0.541551\n",
      "batch 4813: loss 0.275578\n",
      "batch 4814: loss 0.341605\n",
      "batch 4815: loss 0.401778\n",
      "batch 4816: loss 0.314575\n",
      "batch 4817: loss 0.271521\n",
      "batch 4818: loss 0.457966\n",
      "batch 4819: loss 0.420489\n",
      "batch 4820: loss 0.215265\n",
      "batch 4821: loss 0.401033\n",
      "batch 4822: loss 0.539150\n",
      "batch 4823: loss 0.389886\n",
      "batch 4824: loss 0.206878\n",
      "batch 4825: loss 0.190649\n",
      "batch 4826: loss 0.478704\n",
      "batch 4827: loss 0.457663\n",
      "batch 4828: loss 0.422520\n",
      "batch 4829: loss 0.379899\n",
      "batch 4830: loss 0.523950\n",
      "batch 4831: loss 0.334821\n",
      "batch 4832: loss 0.267104\n",
      "batch 4833: loss 0.358675\n",
      "batch 4834: loss 0.407447\n",
      "batch 4835: loss 0.532038\n",
      "batch 4836: loss 0.224827\n",
      "batch 4837: loss 0.532395\n",
      "batch 4838: loss 0.304583\n",
      "batch 4839: loss 0.324543\n",
      "batch 4840: loss 0.277536\n",
      "batch 4841: loss 0.542951\n",
      "batch 4842: loss 0.287238\n",
      "batch 4843: loss 0.509457\n",
      "batch 4844: loss 0.290274\n",
      "batch 4845: loss 0.582568\n",
      "batch 4846: loss 0.235097\n",
      "batch 4847: loss 0.250936\n",
      "batch 4848: loss 0.495934\n",
      "batch 4849: loss 0.217475\n",
      "batch 4850: loss 0.502390\n",
      "batch 4851: loss 0.294044\n",
      "batch 4852: loss 0.312380\n",
      "batch 4853: loss 0.407906\n",
      "batch 4854: loss 0.371958\n",
      "batch 4855: loss 0.446587\n",
      "batch 4856: loss 0.267334\n",
      "batch 4857: loss 0.457976\n",
      "batch 4858: loss 0.207069\n",
      "batch 4859: loss 0.314481\n",
      "batch 4860: loss 0.447645\n",
      "batch 4861: loss 0.408768\n",
      "batch 4862: loss 0.419301\n",
      "batch 4863: loss 0.315464\n",
      "batch 4864: loss 0.421192\n",
      "batch 4865: loss 0.298221\n",
      "batch 4866: loss 0.212742\n",
      "batch 4867: loss 0.583439\n",
      "batch 4868: loss 0.276868\n",
      "batch 4869: loss 0.265186\n",
      "batch 4870: loss 0.348717\n",
      "batch 4871: loss 0.571626\n",
      "batch 4872: loss 0.253990\n",
      "batch 4873: loss 0.399054\n",
      "batch 4874: loss 0.470669\n",
      "batch 4875: loss 0.437446\n",
      "batch 4876: loss 0.444373\n",
      "batch 4877: loss 0.398454\n",
      "batch 4878: loss 0.384719\n",
      "batch 4879: loss 0.407701\n",
      "batch 4880: loss 0.448594\n",
      "batch 4881: loss 0.358317\n",
      "batch 4882: loss 0.260272\n",
      "batch 4883: loss 0.273122\n",
      "batch 4884: loss 0.235197\n",
      "batch 4885: loss 0.289517\n",
      "batch 4886: loss 0.402383\n",
      "batch 4887: loss 0.359816\n",
      "batch 4888: loss 0.394970\n",
      "batch 4889: loss 0.334237\n",
      "batch 4890: loss 0.225029\n",
      "batch 4891: loss 0.212904\n",
      "batch 4892: loss 0.567759\n",
      "batch 4893: loss 0.382630\n",
      "batch 4894: loss 0.441682\n",
      "batch 4895: loss 0.270939\n",
      "batch 4896: loss 0.306248\n",
      "batch 4897: loss 0.327328\n",
      "batch 4898: loss 0.458008\n",
      "batch 4899: loss 0.248515\n",
      "batch 4900: loss 0.320600\n",
      "batch 4901: loss 0.387841\n",
      "batch 4902: loss 0.559614\n",
      "batch 4903: loss 0.256443\n",
      "batch 4904: loss 0.185342\n",
      "batch 4905: loss 0.276466\n",
      "batch 4906: loss 0.267121\n",
      "batch 4907: loss 0.260283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4908: loss 0.339196\n",
      "batch 4909: loss 0.327297\n",
      "batch 4910: loss 0.703279\n",
      "batch 4911: loss 0.526917\n",
      "batch 4912: loss 0.280244\n",
      "batch 4913: loss 0.403481\n",
      "batch 4914: loss 0.308475\n",
      "batch 4915: loss 0.422574\n",
      "batch 4916: loss 0.402488\n",
      "batch 4917: loss 0.228908\n",
      "batch 4918: loss 0.304811\n",
      "batch 4919: loss 0.384238\n",
      "batch 4920: loss 0.296883\n",
      "batch 4921: loss 0.431715\n",
      "batch 4922: loss 0.370844\n",
      "batch 4923: loss 0.335986\n",
      "batch 4924: loss 0.272550\n",
      "batch 4925: loss 0.297565\n",
      "batch 4926: loss 0.201336\n",
      "batch 4927: loss 0.454298\n",
      "batch 4928: loss 0.445588\n",
      "batch 4929: loss 0.186247\n",
      "batch 4930: loss 0.556872\n",
      "batch 4931: loss 0.727795\n",
      "batch 4932: loss 0.340169\n",
      "batch 4933: loss 0.272626\n",
      "batch 4934: loss 0.527880\n",
      "batch 4935: loss 0.279652\n",
      "batch 4936: loss 0.240741\n",
      "batch 4937: loss 0.380119\n",
      "batch 4938: loss 0.151014\n",
      "batch 4939: loss 0.413697\n",
      "batch 4940: loss 0.361606\n",
      "batch 4941: loss 0.382870\n",
      "batch 4942: loss 0.203020\n",
      "batch 4943: loss 0.479180\n",
      "batch 4944: loss 0.403101\n",
      "batch 4945: loss 0.546179\n",
      "batch 4946: loss 0.202103\n",
      "batch 4947: loss 0.225008\n",
      "batch 4948: loss 0.348242\n",
      "batch 4949: loss 0.271729\n",
      "batch 4950: loss 0.577354\n",
      "batch 4951: loss 0.121022\n",
      "batch 4952: loss 0.234217\n",
      "batch 4953: loss 0.374912\n",
      "batch 4954: loss 0.416064\n",
      "batch 4955: loss 0.369771\n",
      "batch 4956: loss 0.345432\n",
      "batch 4957: loss 0.151800\n",
      "batch 4958: loss 0.251231\n",
      "batch 4959: loss 0.241348\n",
      "batch 4960: loss 0.289013\n",
      "batch 4961: loss 0.351375\n",
      "batch 4962: loss 0.315750\n",
      "batch 4963: loss 0.263359\n",
      "batch 4964: loss 0.353968\n",
      "batch 4965: loss 0.493644\n",
      "batch 4966: loss 0.597598\n",
      "batch 4967: loss 0.361819\n",
      "batch 4968: loss 0.391681\n",
      "batch 4969: loss 0.214410\n",
      "batch 4970: loss 0.587561\n",
      "batch 4971: loss 0.511451\n",
      "batch 4972: loss 0.409703\n",
      "batch 4973: loss 0.311230\n",
      "batch 4974: loss 0.273081\n",
      "batch 4975: loss 0.255096\n",
      "batch 4976: loss 0.254303\n",
      "batch 4977: loss 0.289838\n",
      "batch 4978: loss 0.543950\n",
      "batch 4979: loss 0.541533\n",
      "batch 4980: loss 0.331549\n",
      "batch 4981: loss 0.246893\n",
      "batch 4982: loss 0.409043\n",
      "batch 4983: loss 0.407879\n",
      "batch 4984: loss 0.281724\n",
      "batch 4985: loss 0.458913\n",
      "batch 4986: loss 0.564087\n",
      "batch 4987: loss 0.436380\n",
      "batch 4988: loss 0.402714\n",
      "batch 4989: loss 0.374109\n",
      "batch 4990: loss 0.318196\n",
      "batch 4991: loss 0.417993\n",
      "batch 4992: loss 0.199583\n",
      "batch 4993: loss 0.353160\n",
      "batch 4994: loss 0.286864\n",
      "batch 4995: loss 0.368146\n",
      "batch 4996: loss 0.197923\n",
      "batch 4997: loss 0.276362\n",
      "batch 4998: loss 0.392646\n",
      "batch 4999: loss 0.323190\n",
      "batch 5000: loss 0.241126\n",
      "batch 5001: loss 0.348954\n",
      "batch 5002: loss 0.235027\n",
      "batch 5003: loss 0.485580\n",
      "batch 5004: loss 0.449530\n",
      "batch 5005: loss 0.389593\n",
      "batch 5006: loss 0.283843\n",
      "batch 5007: loss 0.222357\n",
      "batch 5008: loss 0.296128\n",
      "batch 5009: loss 0.407142\n",
      "batch 5010: loss 0.270488\n",
      "batch 5011: loss 0.469249\n",
      "batch 5012: loss 0.294402\n",
      "batch 5013: loss 0.526497\n",
      "batch 5014: loss 0.291765\n",
      "batch 5015: loss 0.259966\n",
      "batch 5016: loss 0.430064\n",
      "batch 5017: loss 0.241433\n",
      "batch 5018: loss 0.386844\n",
      "batch 5019: loss 0.601010\n",
      "batch 5020: loss 0.253400\n",
      "batch 5021: loss 0.443618\n",
      "batch 5022: loss 0.388504\n",
      "batch 5023: loss 0.456975\n",
      "batch 5024: loss 0.475972\n",
      "batch 5025: loss 0.210646\n",
      "batch 5026: loss 0.348207\n",
      "batch 5027: loss 0.269304\n",
      "batch 5028: loss 0.431525\n",
      "batch 5029: loss 0.318453\n",
      "batch 5030: loss 0.426590\n",
      "batch 5031: loss 0.563561\n",
      "batch 5032: loss 0.203691\n",
      "batch 5033: loss 0.230088\n",
      "batch 5034: loss 0.155411\n",
      "batch 5035: loss 0.167838\n",
      "batch 5036: loss 0.169739\n",
      "batch 5037: loss 0.566119\n",
      "batch 5038: loss 0.278796\n",
      "batch 5039: loss 0.552262\n",
      "batch 5040: loss 0.339818\n",
      "batch 5041: loss 0.468798\n",
      "batch 5042: loss 0.338522\n",
      "batch 5043: loss 0.273478\n",
      "batch 5044: loss 0.456754\n",
      "batch 5045: loss 0.277979\n",
      "batch 5046: loss 0.403098\n",
      "batch 5047: loss 0.357882\n",
      "batch 5048: loss 0.230454\n",
      "batch 5049: loss 0.278363\n",
      "batch 5050: loss 0.313696\n",
      "batch 5051: loss 0.309586\n",
      "batch 5052: loss 0.399790\n",
      "batch 5053: loss 0.382508\n",
      "batch 5054: loss 0.353240\n",
      "batch 5055: loss 0.526321\n",
      "batch 5056: loss 0.389178\n",
      "batch 5057: loss 0.467195\n",
      "batch 5058: loss 0.411664\n",
      "batch 5059: loss 0.450290\n",
      "batch 5060: loss 0.245641\n",
      "batch 5061: loss 0.477270\n",
      "batch 5062: loss 0.627751\n",
      "batch 5063: loss 0.265803\n",
      "batch 5064: loss 0.369948\n",
      "batch 5065: loss 0.232355\n",
      "batch 5066: loss 0.238890\n",
      "batch 5067: loss 0.406479\n",
      "batch 5068: loss 0.631220\n",
      "batch 5069: loss 0.224133\n",
      "batch 5070: loss 0.265238\n",
      "batch 5071: loss 0.472400\n",
      "batch 5072: loss 0.304332\n",
      "batch 5073: loss 0.331765\n",
      "batch 5074: loss 0.388052\n",
      "batch 5075: loss 0.376301\n",
      "batch 5076: loss 0.382062\n",
      "batch 5077: loss 0.508782\n",
      "batch 5078: loss 0.685158\n",
      "batch 5079: loss 0.413286\n",
      "batch 5080: loss 0.586967\n",
      "batch 5081: loss 0.275775\n",
      "batch 5082: loss 0.396857\n",
      "batch 5083: loss 0.279385\n",
      "batch 5084: loss 0.227436\n",
      "batch 5085: loss 0.374505\n",
      "batch 5086: loss 0.348367\n",
      "batch 5087: loss 0.361835\n",
      "batch 5088: loss 0.353589\n",
      "batch 5089: loss 0.403297\n",
      "batch 5090: loss 0.424538\n",
      "batch 5091: loss 0.376256\n",
      "batch 5092: loss 0.422057\n",
      "batch 5093: loss 0.315261\n",
      "batch 5094: loss 0.272482\n",
      "batch 5095: loss 0.291873\n",
      "batch 5096: loss 0.197107\n",
      "batch 5097: loss 0.310414\n",
      "batch 5098: loss 0.523624\n",
      "batch 5099: loss 0.309452\n",
      "batch 5100: loss 0.536584\n",
      "batch 5101: loss 0.326530\n",
      "batch 5102: loss 0.173355\n",
      "batch 5103: loss 0.398415\n",
      "batch 5104: loss 0.280136\n",
      "batch 5105: loss 0.248026\n",
      "batch 5106: loss 0.345963\n",
      "batch 5107: loss 0.253530\n",
      "batch 5108: loss 0.227552\n",
      "batch 5109: loss 0.309147\n",
      "batch 5110: loss 0.231624\n",
      "batch 5111: loss 0.431275\n",
      "batch 5112: loss 0.339720\n",
      "batch 5113: loss 0.202466\n",
      "batch 5114: loss 0.523650\n",
      "batch 5115: loss 0.263829\n",
      "batch 5116: loss 0.478975\n",
      "batch 5117: loss 0.285724\n",
      "batch 5118: loss 0.495109\n",
      "batch 5119: loss 0.440104\n",
      "batch 5120: loss 0.240758\n",
      "batch 5121: loss 0.245495\n",
      "batch 5122: loss 0.485823\n",
      "batch 5123: loss 0.217422\n",
      "batch 5124: loss 0.434768\n",
      "batch 5125: loss 0.428783\n",
      "batch 5126: loss 0.260857\n",
      "batch 5127: loss 0.355288\n",
      "batch 5128: loss 0.349720\n",
      "batch 5129: loss 0.242187\n",
      "batch 5130: loss 0.411614\n",
      "batch 5131: loss 0.329308\n",
      "batch 5132: loss 0.693402\n",
      "batch 5133: loss 0.922687\n",
      "batch 5134: loss 0.336867\n",
      "batch 5135: loss 0.382822\n",
      "batch 5136: loss 0.391326\n",
      "batch 5137: loss 0.260081\n",
      "batch 5138: loss 0.269316\n",
      "batch 5139: loss 0.333018\n",
      "batch 5140: loss 0.296154\n",
      "batch 5141: loss 0.385085\n",
      "batch 5142: loss 0.572681\n",
      "batch 5143: loss 0.302142\n",
      "batch 5144: loss 0.181510\n",
      "batch 5145: loss 0.292516\n",
      "batch 5146: loss 0.507859\n",
      "batch 5147: loss 0.344156\n",
      "batch 5148: loss 0.409506\n",
      "batch 5149: loss 0.429723\n",
      "batch 5150: loss 0.303759\n",
      "batch 5151: loss 0.360941\n",
      "batch 5152: loss 0.367352\n",
      "batch 5153: loss 0.422347\n",
      "batch 5154: loss 0.533224\n",
      "batch 5155: loss 0.195663\n",
      "batch 5156: loss 0.255751\n",
      "batch 5157: loss 0.383623\n",
      "batch 5158: loss 0.395531\n",
      "batch 5159: loss 0.438817\n",
      "batch 5160: loss 0.410946\n",
      "batch 5161: loss 0.256282\n",
      "batch 5162: loss 0.337540\n",
      "batch 5163: loss 0.262120\n",
      "batch 5164: loss 0.373289\n",
      "batch 5165: loss 0.306586\n",
      "batch 5166: loss 0.505508\n",
      "batch 5167: loss 0.154236\n",
      "batch 5168: loss 0.301332\n",
      "batch 5169: loss 0.204758\n",
      "batch 5170: loss 0.382387\n",
      "batch 5171: loss 0.657289\n",
      "batch 5172: loss 0.469939\n",
      "batch 5173: loss 0.288251\n",
      "batch 5174: loss 0.254298\n",
      "batch 5175: loss 0.394774\n",
      "batch 5176: loss 0.319688\n",
      "batch 5177: loss 0.391656\n",
      "batch 5178: loss 0.444197\n",
      "batch 5179: loss 0.331358\n",
      "batch 5180: loss 0.340142\n",
      "batch 5181: loss 0.305957\n",
      "batch 5182: loss 0.348523\n",
      "batch 5183: loss 0.284426\n",
      "batch 5184: loss 0.408736\n",
      "batch 5185: loss 0.458757\n",
      "batch 5186: loss 0.295391\n",
      "batch 5187: loss 0.447256\n",
      "batch 5188: loss 0.323234\n",
      "batch 5189: loss 0.301790\n",
      "batch 5190: loss 0.363190\n",
      "batch 5191: loss 0.389844\n",
      "batch 5192: loss 0.282125\n",
      "batch 5193: loss 0.203719\n",
      "batch 5194: loss 0.249785\n",
      "batch 5195: loss 0.300910\n",
      "batch 5196: loss 0.692200\n",
      "batch 5197: loss 0.189642\n",
      "batch 5198: loss 0.392843\n",
      "batch 5199: loss 0.222121\n",
      "batch 5200: loss 0.272362\n",
      "batch 5201: loss 0.215822\n",
      "batch 5202: loss 0.367937\n",
      "batch 5203: loss 0.248409\n",
      "batch 5204: loss 0.459451\n",
      "batch 5205: loss 0.219990\n",
      "batch 5206: loss 0.412223\n",
      "batch 5207: loss 0.227835\n",
      "batch 5208: loss 0.456175\n",
      "batch 5209: loss 0.256247\n",
      "batch 5210: loss 0.502700\n",
      "batch 5211: loss 0.314767\n",
      "batch 5212: loss 0.321750\n",
      "batch 5213: loss 0.143965\n",
      "batch 5214: loss 0.376786\n",
      "batch 5215: loss 0.584073\n",
      "batch 5216: loss 0.377813\n",
      "batch 5217: loss 0.438023\n",
      "batch 5218: loss 0.478748\n",
      "batch 5219: loss 0.341958\n",
      "batch 5220: loss 0.272261\n",
      "batch 5221: loss 0.357689\n",
      "batch 5222: loss 0.552645\n",
      "batch 5223: loss 0.421819\n",
      "batch 5224: loss 0.261527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5225: loss 0.248728\n",
      "batch 5226: loss 0.460969\n",
      "batch 5227: loss 0.206974\n",
      "batch 5228: loss 0.359044\n",
      "batch 5229: loss 0.365082\n",
      "batch 5230: loss 0.583996\n",
      "batch 5231: loss 0.350794\n",
      "batch 5232: loss 0.329026\n",
      "batch 5233: loss 0.353356\n",
      "batch 5234: loss 0.275648\n",
      "batch 5235: loss 0.164922\n",
      "batch 5236: loss 0.431761\n",
      "batch 5237: loss 0.327112\n",
      "batch 5238: loss 0.240511\n",
      "batch 5239: loss 0.307412\n",
      "batch 5240: loss 0.418059\n",
      "batch 5241: loss 0.532717\n",
      "batch 5242: loss 0.408275\n",
      "batch 5243: loss 0.458353\n",
      "batch 5244: loss 0.457882\n",
      "batch 5245: loss 0.241416\n",
      "batch 5246: loss 0.338607\n",
      "batch 5247: loss 0.309174\n",
      "batch 5248: loss 0.360754\n",
      "batch 5249: loss 0.294749\n",
      "batch 5250: loss 0.262626\n",
      "batch 5251: loss 0.146086\n",
      "batch 5252: loss 0.457767\n",
      "batch 5253: loss 0.446854\n",
      "batch 5254: loss 0.224809\n",
      "batch 5255: loss 0.211662\n",
      "batch 5256: loss 0.294999\n",
      "batch 5257: loss 0.145654\n",
      "batch 5258: loss 0.399267\n",
      "batch 5259: loss 0.214471\n",
      "batch 5260: loss 0.361466\n",
      "batch 5261: loss 0.614813\n",
      "batch 5262: loss 0.327603\n",
      "batch 5263: loss 0.172189\n",
      "batch 5264: loss 0.363117\n",
      "batch 5265: loss 0.394923\n",
      "batch 5266: loss 0.419222\n",
      "batch 5267: loss 0.261719\n",
      "batch 5268: loss 0.385730\n",
      "batch 5269: loss 0.444160\n",
      "batch 5270: loss 0.312172\n",
      "batch 5271: loss 0.295243\n",
      "batch 5272: loss 0.223893\n",
      "batch 5273: loss 0.364863\n",
      "batch 5274: loss 0.413211\n",
      "batch 5275: loss 0.423456\n",
      "batch 5276: loss 0.260404\n",
      "batch 5277: loss 0.346274\n",
      "batch 5278: loss 0.289745\n",
      "batch 5279: loss 0.478091\n",
      "batch 5280: loss 0.189516\n",
      "batch 5281: loss 0.313257\n",
      "batch 5282: loss 0.322243\n",
      "batch 5283: loss 0.372303\n",
      "batch 5284: loss 0.340500\n",
      "batch 5285: loss 0.205566\n",
      "batch 5286: loss 0.491537\n",
      "batch 5287: loss 0.475657\n",
      "batch 5288: loss 0.386041\n",
      "batch 5289: loss 0.501176\n",
      "batch 5290: loss 0.320389\n",
      "batch 5291: loss 0.308052\n",
      "batch 5292: loss 0.224888\n",
      "batch 5293: loss 0.320126\n",
      "batch 5294: loss 0.214954\n",
      "batch 5295: loss 0.389433\n",
      "batch 5296: loss 0.516224\n",
      "batch 5297: loss 0.359315\n",
      "batch 5298: loss 0.236509\n",
      "batch 5299: loss 0.423705\n",
      "batch 5300: loss 0.534685\n",
      "batch 5301: loss 0.267563\n",
      "batch 5302: loss 0.409891\n",
      "batch 5303: loss 0.401006\n",
      "batch 5304: loss 0.583309\n",
      "batch 5305: loss 0.248804\n",
      "batch 5306: loss 0.453073\n",
      "batch 5307: loss 0.381887\n",
      "batch 5308: loss 0.379519\n",
      "batch 5309: loss 0.388633\n",
      "batch 5310: loss 0.444850\n",
      "batch 5311: loss 0.462233\n",
      "batch 5312: loss 0.291937\n",
      "batch 5313: loss 0.310560\n",
      "batch 5314: loss 0.334792\n",
      "batch 5315: loss 0.451472\n",
      "batch 5316: loss 0.226129\n",
      "batch 5317: loss 0.212762\n",
      "batch 5318: loss 0.413645\n",
      "batch 5319: loss 0.366445\n",
      "batch 5320: loss 0.348549\n",
      "batch 5321: loss 0.402665\n",
      "batch 5322: loss 0.519272\n",
      "batch 5323: loss 0.238096\n",
      "batch 5324: loss 0.339111\n",
      "batch 5325: loss 0.419914\n",
      "batch 5326: loss 0.254673\n",
      "batch 5327: loss 0.290393\n",
      "batch 5328: loss 0.416865\n",
      "batch 5329: loss 0.534674\n",
      "batch 5330: loss 0.284167\n",
      "batch 5331: loss 0.212475\n",
      "batch 5332: loss 0.192358\n",
      "batch 5333: loss 0.257081\n",
      "batch 5334: loss 0.435699\n",
      "batch 5335: loss 0.222595\n",
      "batch 5336: loss 0.344145\n",
      "batch 5337: loss 0.353795\n",
      "batch 5338: loss 0.187805\n",
      "batch 5339: loss 0.574762\n",
      "batch 5340: loss 0.518572\n",
      "batch 5341: loss 0.245118\n",
      "batch 5342: loss 0.379975\n",
      "batch 5343: loss 0.438023\n",
      "batch 5344: loss 0.522620\n",
      "batch 5345: loss 0.385086\n",
      "batch 5346: loss 0.641788\n",
      "batch 5347: loss 0.267909\n",
      "batch 5348: loss 0.376157\n",
      "batch 5349: loss 0.516831\n",
      "batch 5350: loss 0.322539\n",
      "batch 5351: loss 0.299599\n",
      "batch 5352: loss 0.226833\n",
      "batch 5353: loss 0.147983\n",
      "batch 5354: loss 0.374149\n",
      "batch 5355: loss 0.300371\n",
      "batch 5356: loss 0.297582\n",
      "batch 5357: loss 0.378363\n",
      "batch 5358: loss 0.289796\n",
      "batch 5359: loss 0.349862\n",
      "batch 5360: loss 0.333670\n",
      "batch 5361: loss 0.242776\n",
      "batch 5362: loss 0.399278\n",
      "batch 5363: loss 0.361149\n",
      "batch 5364: loss 0.184887\n",
      "batch 5365: loss 0.244412\n",
      "batch 5366: loss 0.440962\n",
      "batch 5367: loss 0.349763\n",
      "batch 5368: loss 0.485567\n",
      "batch 5369: loss 0.321581\n",
      "batch 5370: loss 0.388241\n",
      "batch 5371: loss 0.202400\n",
      "batch 5372: loss 0.384988\n",
      "batch 5373: loss 0.319280\n",
      "batch 5374: loss 0.400991\n",
      "batch 5375: loss 0.277801\n",
      "batch 5376: loss 0.213494\n",
      "batch 5377: loss 0.299266\n",
      "batch 5378: loss 0.462436\n",
      "batch 5379: loss 0.347787\n",
      "batch 5380: loss 0.490759\n",
      "batch 5381: loss 0.415628\n",
      "batch 5382: loss 0.537133\n",
      "batch 5383: loss 0.545006\n",
      "batch 5384: loss 0.368435\n",
      "batch 5385: loss 0.207345\n",
      "batch 5386: loss 0.264890\n",
      "batch 5387: loss 0.558240\n",
      "batch 5388: loss 0.396207\n",
      "batch 5389: loss 0.541465\n",
      "batch 5390: loss 0.587656\n",
      "batch 5391: loss 0.164211\n",
      "batch 5392: loss 0.273570\n",
      "batch 5393: loss 0.386107\n",
      "batch 5394: loss 0.429152\n",
      "batch 5395: loss 0.301874\n",
      "batch 5396: loss 0.587455\n",
      "batch 5397: loss 0.390311\n",
      "batch 5398: loss 0.165868\n",
      "batch 5399: loss 0.461951\n",
      "batch 5400: loss 0.342715\n",
      "batch 5401: loss 0.237770\n",
      "batch 5402: loss 0.394522\n",
      "batch 5403: loss 0.392397\n",
      "batch 5404: loss 0.660022\n",
      "batch 5405: loss 0.357017\n",
      "batch 5406: loss 0.255836\n",
      "batch 5407: loss 0.254195\n",
      "batch 5408: loss 0.238387\n",
      "batch 5409: loss 0.397391\n",
      "batch 5410: loss 0.546638\n",
      "batch 5411: loss 0.441564\n",
      "batch 5412: loss 0.319345\n",
      "batch 5413: loss 0.203090\n",
      "batch 5414: loss 0.606811\n",
      "batch 5415: loss 0.192315\n",
      "batch 5416: loss 0.255827\n",
      "batch 5417: loss 0.518578\n",
      "batch 5418: loss 0.500119\n",
      "batch 5419: loss 0.246294\n",
      "batch 5420: loss 0.278820\n",
      "batch 5421: loss 0.257840\n",
      "batch 5422: loss 0.403635\n",
      "batch 5423: loss 0.274372\n",
      "batch 5424: loss 0.382787\n",
      "batch 5425: loss 0.487150\n",
      "batch 5426: loss 0.316484\n",
      "batch 5427: loss 0.310437\n",
      "batch 5428: loss 0.407671\n",
      "batch 5429: loss 0.339174\n",
      "batch 5430: loss 0.289912\n",
      "batch 5431: loss 0.249965\n",
      "batch 5432: loss 0.445295\n",
      "batch 5433: loss 0.284364\n",
      "batch 5434: loss 0.429019\n",
      "batch 5435: loss 0.293939\n",
      "batch 5436: loss 0.298002\n",
      "batch 5437: loss 0.405523\n",
      "batch 5438: loss 0.325852\n",
      "batch 5439: loss 0.374431\n",
      "batch 5440: loss 0.243303\n",
      "batch 5441: loss 0.399366\n",
      "batch 5442: loss 0.166492\n",
      "batch 5443: loss 0.315341\n",
      "batch 5444: loss 0.647393\n",
      "batch 5445: loss 0.374576\n",
      "batch 5446: loss 0.444952\n",
      "batch 5447: loss 0.327864\n",
      "batch 5448: loss 0.460864\n",
      "batch 5449: loss 0.490205\n",
      "batch 5450: loss 0.192354\n",
      "batch 5451: loss 0.294713\n",
      "batch 5452: loss 0.230044\n",
      "batch 5453: loss 0.429956\n",
      "batch 5454: loss 0.331015\n",
      "batch 5455: loss 0.279061\n",
      "batch 5456: loss 0.431130\n",
      "batch 5457: loss 0.359006\n",
      "batch 5458: loss 0.204843\n",
      "batch 5459: loss 0.191016\n",
      "batch 5460: loss 0.350849\n",
      "batch 5461: loss 0.378826\n",
      "batch 5462: loss 0.713379\n",
      "batch 5463: loss 0.254286\n",
      "batch 5464: loss 0.379319\n",
      "batch 5465: loss 0.150990\n",
      "batch 5466: loss 0.369310\n",
      "batch 5467: loss 0.195764\n",
      "batch 5468: loss 0.341746\n",
      "batch 5469: loss 0.278868\n",
      "batch 5470: loss 0.416183\n",
      "batch 5471: loss 0.375274\n",
      "batch 5472: loss 0.326037\n",
      "batch 5473: loss 0.327966\n",
      "batch 5474: loss 0.688099\n",
      "batch 5475: loss 0.246151\n",
      "batch 5476: loss 0.329282\n",
      "batch 5477: loss 0.402933\n",
      "batch 5478: loss 0.165251\n",
      "batch 5479: loss 0.355333\n",
      "batch 5480: loss 0.459838\n",
      "batch 5481: loss 0.393940\n",
      "batch 5482: loss 0.213275\n",
      "batch 5483: loss 0.299240\n",
      "batch 5484: loss 0.500469\n",
      "batch 5485: loss 0.411992\n",
      "batch 5486: loss 0.294826\n",
      "batch 5487: loss 0.250024\n",
      "batch 5488: loss 0.285473\n",
      "batch 5489: loss 0.509955\n",
      "batch 5490: loss 0.337201\n",
      "batch 5491: loss 0.310284\n",
      "batch 5492: loss 0.297242\n",
      "batch 5493: loss 0.732673\n",
      "batch 5494: loss 0.324115\n",
      "batch 5495: loss 0.729141\n",
      "batch 5496: loss 0.262731\n",
      "batch 5497: loss 0.446437\n",
      "batch 5498: loss 0.204097\n",
      "batch 5499: loss 0.339594\n"
     ]
    }
   ],
   "source": [
    "# 定义一些模型超参数：\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型和数据读取类，并实例化一个 tf.keras.optimizer 的优化器（这里使用常用的 Adam 优化器）：\n",
    "model = MLP()\n",
    "# data_loader = MNISTLoader() # 导入数据 \n",
    "data_loader = MNISTLoader_my_download()  # 导入数据\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # 更新梯度\n",
    "\n",
    "# num_batches = int(mnist.train.num_examples // batch_size * num_epochs)\n",
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved\\2\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"saved\\\\2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.906900\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "model = tf.saved_model.load(\"saved\\\\2\")\n",
    "\n",
    "categorical_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.call(data_loader.test_data[start_index: end_index])\n",
    "    categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Keras 自有的模型导出格式（Jinpeng）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于历史原因，我们在有些场景也会用到 Keras 的 Sequential 和 Functional 模式的自有模型导出格式（H5）。我们以 keras 模型训练和保存为例进行讲解，如下是 keras 官方的 mnist 模型训练样例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
