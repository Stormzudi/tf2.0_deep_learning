{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_core.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "class MNISTLoader_my_download():\n",
    "    def __init__(self):\n",
    "        # 读取数据，预先已经下载了相应的数据直\n",
    "        mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "        self.train_data = mnist.train.images\n",
    "        self.train_label = mnist.train.labels\n",
    "        self.test_data = mnist.test.images\n",
    "        self.test_label = mnist.test.labels\n",
    "        \n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 784, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 784, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)  # 第一层神经元的个数为100\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)   # 第二层神经元的个数为10,输出一个样本的维度为10\n",
    "\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "batch 0: loss 2.302219\n",
      "batch 1: loss 2.301422\n",
      "batch 2: loss 2.300723\n",
      "batch 3: loss 2.300955\n",
      "batch 4: loss 2.300592\n",
      "batch 5: loss 2.302301\n",
      "batch 6: loss 2.302447\n",
      "batch 7: loss 2.302885\n",
      "batch 8: loss 2.299646\n",
      "batch 9: loss 2.299504\n",
      "batch 10: loss 2.298020\n",
      "batch 11: loss 2.297356\n",
      "batch 12: loss 2.299600\n",
      "batch 13: loss 2.298584\n",
      "batch 14: loss 2.299991\n",
      "batch 15: loss 2.295949\n",
      "batch 16: loss 2.295848\n",
      "batch 17: loss 2.296138\n",
      "batch 18: loss 2.293093\n",
      "batch 19: loss 2.293828\n",
      "batch 20: loss 2.292792\n",
      "batch 21: loss 2.292058\n",
      "batch 22: loss 2.296293\n",
      "batch 23: loss 2.291264\n",
      "batch 24: loss 2.289793\n",
      "batch 25: loss 2.290593\n",
      "batch 26: loss 2.292573\n",
      "batch 27: loss 2.288534\n",
      "batch 28: loss 2.293505\n",
      "batch 29: loss 2.297284\n",
      "batch 30: loss 2.287549\n",
      "batch 31: loss 2.286821\n",
      "batch 32: loss 2.287719\n",
      "batch 33: loss 2.291282\n",
      "batch 34: loss 2.282459\n",
      "batch 35: loss 2.295733\n",
      "batch 36: loss 2.286442\n",
      "batch 37: loss 2.282394\n",
      "batch 38: loss 2.286159\n",
      "batch 39: loss 2.285616\n",
      "batch 40: loss 2.286238\n",
      "batch 41: loss 2.283560\n",
      "batch 42: loss 2.285712\n",
      "batch 43: loss 2.284145\n",
      "batch 44: loss 2.289519\n",
      "batch 45: loss 2.284672\n",
      "batch 46: loss 2.282041\n",
      "batch 47: loss 2.274132\n",
      "batch 48: loss 2.275954\n",
      "batch 49: loss 2.281645\n",
      "batch 50: loss 2.280480\n",
      "batch 51: loss 2.278281\n",
      "batch 52: loss 2.266248\n",
      "batch 53: loss 2.277297\n",
      "batch 54: loss 2.279805\n",
      "batch 55: loss 2.275004\n",
      "batch 56: loss 2.279854\n",
      "batch 57: loss 2.268239\n",
      "batch 58: loss 2.269968\n",
      "batch 59: loss 2.275884\n",
      "batch 60: loss 2.270730\n",
      "batch 61: loss 2.273669\n",
      "batch 62: loss 2.263236\n",
      "batch 63: loss 2.273350\n",
      "batch 64: loss 2.271964\n",
      "batch 65: loss 2.271939\n",
      "batch 66: loss 2.264726\n",
      "batch 67: loss 2.263506\n",
      "batch 68: loss 2.266979\n",
      "batch 69: loss 2.256873\n",
      "batch 70: loss 2.261642\n",
      "batch 71: loss 2.248679\n",
      "batch 72: loss 2.249490\n",
      "batch 73: loss 2.274496\n",
      "batch 74: loss 2.251000\n",
      "batch 75: loss 2.257152\n",
      "batch 76: loss 2.261884\n",
      "batch 77: loss 2.265940\n",
      "batch 78: loss 2.258976\n",
      "batch 79: loss 2.249366\n",
      "batch 80: loss 2.254728\n",
      "batch 81: loss 2.264533\n",
      "batch 82: loss 2.255025\n",
      "batch 83: loss 2.260871\n",
      "batch 84: loss 2.252259\n",
      "batch 85: loss 2.244514\n",
      "batch 86: loss 2.255542\n",
      "batch 87: loss 2.251052\n",
      "batch 88: loss 2.246577\n",
      "batch 89: loss 2.246242\n",
      "batch 90: loss 2.246015\n",
      "batch 91: loss 2.245285\n",
      "batch 92: loss 2.245202\n",
      "batch 93: loss 2.242074\n",
      "batch 94: loss 2.239717\n",
      "batch 95: loss 2.241254\n",
      "batch 96: loss 2.226131\n",
      "batch 97: loss 2.237718\n",
      "batch 98: loss 2.236514\n",
      "batch 99: loss 2.243006\n",
      "batch 100: loss 2.232572\n",
      "batch 101: loss 2.225892\n",
      "batch 102: loss 2.239080\n",
      "batch 103: loss 2.222782\n",
      "batch 104: loss 2.231619\n",
      "batch 105: loss 2.250124\n",
      "batch 106: loss 2.243854\n",
      "batch 107: loss 2.231282\n",
      "batch 108: loss 2.228069\n",
      "batch 109: loss 2.234604\n",
      "batch 110: loss 2.213751\n",
      "batch 111: loss 2.219547\n",
      "batch 112: loss 2.210192\n",
      "batch 113: loss 2.218139\n",
      "batch 114: loss 2.216512\n",
      "batch 115: loss 2.215476\n",
      "batch 116: loss 2.227917\n",
      "batch 117: loss 2.226390\n",
      "batch 118: loss 2.197278\n",
      "batch 119: loss 2.215357\n",
      "batch 120: loss 2.195087\n",
      "batch 121: loss 2.210874\n",
      "batch 122: loss 2.212503\n",
      "batch 123: loss 2.219834\n",
      "batch 124: loss 2.199201\n",
      "batch 125: loss 2.207033\n",
      "batch 126: loss 2.189136\n",
      "batch 127: loss 2.215339\n",
      "batch 128: loss 2.198938\n",
      "batch 129: loss 2.179223\n",
      "batch 130: loss 2.192334\n",
      "batch 131: loss 2.173395\n",
      "batch 132: loss 2.184597\n",
      "batch 133: loss 2.195430\n",
      "batch 134: loss 2.202751\n",
      "batch 135: loss 2.184195\n",
      "batch 136: loss 2.193153\n",
      "batch 137: loss 2.207374\n",
      "batch 138: loss 2.190300\n",
      "batch 139: loss 2.185054\n",
      "batch 140: loss 2.164662\n",
      "batch 141: loss 2.151608\n",
      "batch 142: loss 2.190968\n",
      "batch 143: loss 2.195308\n",
      "batch 144: loss 2.173068\n",
      "batch 145: loss 2.162710\n",
      "batch 146: loss 2.192564\n",
      "batch 147: loss 2.142545\n",
      "batch 148: loss 2.156800\n",
      "batch 149: loss 2.136069\n",
      "batch 150: loss 2.146069\n",
      "batch 151: loss 2.150916\n",
      "batch 152: loss 2.188675\n",
      "batch 153: loss 2.134866\n",
      "batch 154: loss 2.190035\n",
      "batch 155: loss 2.193779\n",
      "batch 156: loss 2.156892\n",
      "batch 157: loss 2.152967\n",
      "batch 158: loss 2.158773\n",
      "batch 159: loss 2.170074\n",
      "batch 160: loss 2.173619\n",
      "batch 161: loss 2.131854\n",
      "batch 162: loss 2.156739\n",
      "batch 163: loss 2.140381\n",
      "batch 164: loss 2.151850\n",
      "batch 165: loss 2.148450\n",
      "batch 166: loss 2.151886\n",
      "batch 167: loss 2.150418\n",
      "batch 168: loss 2.134774\n",
      "batch 169: loss 2.154817\n",
      "batch 170: loss 2.194374\n",
      "batch 171: loss 2.124675\n",
      "batch 172: loss 2.160696\n",
      "batch 173: loss 2.141766\n",
      "batch 174: loss 2.126835\n",
      "batch 175: loss 2.141962\n",
      "batch 176: loss 2.114795\n",
      "batch 177: loss 2.119748\n",
      "batch 178: loss 2.105637\n",
      "batch 179: loss 2.143558\n",
      "batch 180: loss 2.096331\n",
      "batch 181: loss 2.127089\n",
      "batch 182: loss 2.095732\n",
      "batch 183: loss 2.133802\n",
      "batch 184: loss 2.113120\n",
      "batch 185: loss 2.092649\n",
      "batch 186: loss 2.109575\n",
      "batch 187: loss 2.108258\n",
      "batch 188: loss 2.092026\n",
      "batch 189: loss 2.083636\n",
      "batch 190: loss 2.069634\n",
      "batch 191: loss 2.116858\n",
      "batch 192: loss 2.137508\n",
      "batch 193: loss 2.072748\n",
      "batch 194: loss 2.100518\n",
      "batch 195: loss 2.058939\n",
      "batch 196: loss 2.066124\n",
      "batch 197: loss 2.074893\n",
      "batch 198: loss 2.035939\n",
      "batch 199: loss 2.097478\n",
      "batch 200: loss 2.067442\n",
      "batch 201: loss 2.058467\n",
      "batch 202: loss 2.047882\n",
      "batch 203: loss 2.029549\n",
      "batch 204: loss 2.061220\n",
      "batch 205: loss 2.056406\n",
      "batch 206: loss 2.083077\n",
      "batch 207: loss 2.054788\n",
      "batch 208: loss 2.094507\n",
      "batch 209: loss 2.060232\n",
      "batch 210: loss 2.024675\n",
      "batch 211: loss 2.049469\n",
      "batch 212: loss 2.075257\n",
      "batch 213: loss 2.000123\n",
      "batch 214: loss 2.029264\n",
      "batch 215: loss 2.025010\n",
      "batch 216: loss 2.052706\n",
      "batch 217: loss 2.052824\n",
      "batch 218: loss 2.077562\n",
      "batch 219: loss 2.050426\n",
      "batch 220: loss 2.039397\n",
      "batch 221: loss 2.024381\n",
      "batch 222: loss 2.003514\n",
      "batch 223: loss 2.046299\n",
      "batch 224: loss 2.049338\n",
      "batch 225: loss 2.016848\n",
      "batch 226: loss 1.968863\n",
      "batch 227: loss 2.004578\n",
      "batch 228: loss 1.943507\n",
      "batch 229: loss 2.045129\n",
      "batch 230: loss 1.966495\n",
      "batch 231: loss 2.012788\n",
      "batch 232: loss 2.070403\n",
      "batch 233: loss 2.026371\n",
      "batch 234: loss 2.007172\n",
      "batch 235: loss 2.014617\n",
      "batch 236: loss 2.036024\n",
      "batch 237: loss 1.974339\n",
      "batch 238: loss 1.983909\n",
      "batch 239: loss 1.953721\n",
      "batch 240: loss 1.957959\n",
      "batch 241: loss 1.940104\n",
      "batch 242: loss 1.997668\n",
      "batch 243: loss 1.981069\n",
      "batch 244: loss 2.041107\n",
      "batch 245: loss 1.919316\n",
      "batch 246: loss 1.986925\n",
      "batch 247: loss 2.005003\n",
      "batch 248: loss 1.977712\n",
      "batch 249: loss 1.949537\n",
      "batch 250: loss 1.935540\n",
      "batch 251: loss 1.958238\n",
      "batch 252: loss 1.912901\n",
      "batch 253: loss 1.929516\n",
      "batch 254: loss 1.957684\n",
      "batch 255: loss 2.007682\n",
      "batch 256: loss 1.981849\n",
      "batch 257: loss 1.975345\n",
      "batch 258: loss 1.952992\n",
      "batch 259: loss 1.877547\n",
      "batch 260: loss 1.894740\n",
      "batch 261: loss 1.949411\n",
      "batch 262: loss 1.939559\n",
      "batch 263: loss 1.970829\n",
      "batch 264: loss 1.969514\n",
      "batch 265: loss 1.896454\n",
      "batch 266: loss 1.948931\n",
      "batch 267: loss 1.963900\n",
      "batch 268: loss 1.926036\n",
      "batch 269: loss 1.959770\n",
      "batch 270: loss 1.921316\n",
      "batch 271: loss 1.894264\n",
      "batch 272: loss 1.864058\n",
      "batch 273: loss 1.887436\n",
      "batch 274: loss 1.886269\n",
      "batch 275: loss 1.944543\n",
      "batch 276: loss 1.962521\n",
      "batch 277: loss 1.888843\n",
      "batch 278: loss 1.935773\n",
      "batch 279: loss 1.823917\n",
      "batch 280: loss 1.869945\n",
      "batch 281: loss 1.930632\n",
      "batch 282: loss 1.912006\n",
      "batch 283: loss 1.917492\n",
      "batch 284: loss 1.901973\n",
      "batch 285: loss 1.970850\n",
      "batch 286: loss 1.901296\n",
      "batch 287: loss 1.844617\n",
      "batch 288: loss 1.980401\n",
      "batch 289: loss 1.947180\n",
      "batch 290: loss 1.821576\n",
      "batch 291: loss 1.910321\n",
      "batch 292: loss 1.905649\n",
      "batch 293: loss 1.966912\n",
      "batch 294: loss 1.895491\n",
      "batch 295: loss 1.854633\n",
      "batch 296: loss 1.843232\n",
      "batch 297: loss 1.874388\n",
      "batch 298: loss 1.844976\n",
      "batch 299: loss 1.869730\n",
      "batch 300: loss 1.901880\n",
      "batch 301: loss 1.838848\n",
      "batch 302: loss 1.864262\n",
      "batch 303: loss 1.800637\n",
      "batch 304: loss 1.900258\n",
      "batch 305: loss 1.824456\n",
      "batch 306: loss 1.902277\n",
      "batch 307: loss 1.851316\n",
      "batch 308: loss 1.817508\n",
      "batch 309: loss 1.828870\n",
      "batch 310: loss 1.824109\n",
      "batch 311: loss 1.785004\n",
      "batch 312: loss 1.756060\n",
      "batch 313: loss 1.836331\n",
      "batch 314: loss 1.762899\n",
      "batch 315: loss 1.882769\n",
      "batch 316: loss 1.749268\n",
      "batch 317: loss 1.723026\n",
      "batch 318: loss 1.778217\n",
      "batch 319: loss 1.804675\n",
      "batch 320: loss 1.777992\n",
      "batch 321: loss 1.753141\n",
      "batch 322: loss 1.814496\n",
      "batch 323: loss 1.804592\n",
      "batch 324: loss 1.695932\n",
      "batch 325: loss 1.829721\n",
      "batch 326: loss 1.738321\n",
      "batch 327: loss 1.786807\n",
      "batch 328: loss 1.762165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 329: loss 1.725568\n",
      "batch 330: loss 1.765414\n",
      "batch 331: loss 1.690040\n",
      "batch 332: loss 1.720434\n",
      "batch 333: loss 1.753545\n",
      "batch 334: loss 1.775700\n",
      "batch 335: loss 1.823447\n",
      "batch 336: loss 1.836362\n",
      "batch 337: loss 1.819796\n",
      "batch 338: loss 1.753536\n",
      "batch 339: loss 1.724267\n",
      "batch 340: loss 1.748280\n",
      "batch 341: loss 1.644292\n",
      "batch 342: loss 1.805654\n",
      "batch 343: loss 1.616218\n",
      "batch 344: loss 1.670159\n",
      "batch 345: loss 1.778253\n",
      "batch 346: loss 1.597938\n",
      "batch 347: loss 1.742141\n",
      "batch 348: loss 1.674846\n",
      "batch 349: loss 1.682862\n",
      "batch 350: loss 1.679306\n",
      "batch 351: loss 1.667018\n",
      "batch 352: loss 1.700643\n",
      "batch 353: loss 1.761148\n",
      "batch 354: loss 1.779939\n",
      "batch 355: loss 1.671694\n",
      "batch 356: loss 1.796482\n",
      "batch 357: loss 1.716781\n",
      "batch 358: loss 1.702067\n",
      "batch 359: loss 1.693311\n",
      "batch 360: loss 1.661478\n",
      "batch 361: loss 1.632875\n",
      "batch 362: loss 1.617589\n",
      "batch 363: loss 1.667943\n",
      "batch 364: loss 1.717641\n",
      "batch 365: loss 1.699959\n",
      "batch 366: loss 1.684882\n",
      "batch 367: loss 1.706889\n",
      "batch 368: loss 1.762512\n",
      "batch 369: loss 1.515654\n",
      "batch 370: loss 1.720230\n",
      "batch 371: loss 1.699551\n",
      "batch 372: loss 1.683047\n",
      "batch 373: loss 1.668899\n",
      "batch 374: loss 1.614908\n",
      "batch 375: loss 1.711779\n",
      "batch 376: loss 1.678102\n",
      "batch 377: loss 1.678111\n",
      "batch 378: loss 1.687720\n",
      "batch 379: loss 1.635115\n",
      "batch 380: loss 1.657325\n",
      "batch 381: loss 1.684912\n",
      "batch 382: loss 1.680873\n",
      "batch 383: loss 1.628338\n",
      "batch 384: loss 1.620734\n",
      "batch 385: loss 1.600910\n",
      "batch 386: loss 1.664776\n",
      "batch 387: loss 1.608054\n",
      "batch 388: loss 1.680449\n",
      "batch 389: loss 1.711889\n",
      "batch 390: loss 1.706606\n",
      "batch 391: loss 1.665142\n",
      "batch 392: loss 1.642105\n",
      "batch 393: loss 1.637419\n",
      "batch 394: loss 1.596216\n",
      "batch 395: loss 1.662722\n",
      "batch 396: loss 1.573725\n",
      "batch 397: loss 1.509926\n",
      "batch 398: loss 1.580856\n",
      "batch 399: loss 1.570337\n",
      "batch 400: loss 1.691563\n",
      "batch 401: loss 1.512675\n",
      "batch 402: loss 1.685079\n",
      "batch 403: loss 1.474783\n",
      "batch 404: loss 1.624034\n",
      "batch 405: loss 1.603791\n",
      "batch 406: loss 1.562796\n",
      "batch 407: loss 1.574313\n",
      "batch 408: loss 1.594715\n",
      "batch 409: loss 1.571512\n",
      "batch 410: loss 1.664655\n",
      "batch 411: loss 1.578175\n",
      "batch 412: loss 1.562251\n",
      "batch 413: loss 1.605521\n",
      "batch 414: loss 1.610494\n",
      "batch 415: loss 1.449399\n",
      "batch 416: loss 1.570606\n",
      "batch 417: loss 1.541219\n",
      "batch 418: loss 1.670664\n",
      "batch 419: loss 1.551229\n",
      "batch 420: loss 1.620408\n",
      "batch 421: loss 1.606884\n",
      "batch 422: loss 1.589250\n",
      "batch 423: loss 1.604790\n",
      "batch 424: loss 1.591540\n",
      "batch 425: loss 1.655219\n",
      "batch 426: loss 1.530378\n",
      "batch 427: loss 1.470959\n",
      "batch 428: loss 1.572494\n",
      "batch 429: loss 1.494853\n",
      "batch 430: loss 1.472504\n",
      "batch 431: loss 1.533990\n",
      "batch 432: loss 1.669128\n",
      "batch 433: loss 1.524179\n",
      "batch 434: loss 1.531751\n",
      "batch 435: loss 1.522730\n",
      "batch 436: loss 1.495698\n",
      "batch 437: loss 1.437260\n",
      "batch 438: loss 1.477985\n",
      "batch 439: loss 1.539747\n",
      "batch 440: loss 1.445235\n",
      "batch 441: loss 1.457833\n",
      "batch 442: loss 1.643334\n",
      "batch 443: loss 1.452642\n",
      "batch 444: loss 1.642397\n",
      "batch 445: loss 1.463709\n",
      "batch 446: loss 1.407793\n",
      "batch 447: loss 1.420532\n",
      "batch 448: loss 1.484230\n",
      "batch 449: loss 1.521104\n",
      "batch 450: loss 1.569394\n",
      "batch 451: loss 1.432736\n",
      "batch 452: loss 1.467131\n",
      "batch 453: loss 1.614128\n",
      "batch 454: loss 1.493070\n",
      "batch 455: loss 1.534437\n",
      "batch 456: loss 1.619744\n",
      "batch 457: loss 1.390793\n",
      "batch 458: loss 1.488323\n",
      "batch 459: loss 1.494295\n",
      "batch 460: loss 1.491724\n",
      "batch 461: loss 1.451033\n",
      "batch 462: loss 1.514289\n",
      "batch 463: loss 1.478167\n",
      "batch 464: loss 1.327758\n",
      "batch 465: loss 1.428817\n",
      "batch 466: loss 1.413043\n",
      "batch 467: loss 1.521414\n",
      "batch 468: loss 1.518891\n",
      "batch 469: loss 1.437250\n",
      "batch 470: loss 1.659724\n",
      "batch 471: loss 1.396671\n",
      "batch 472: loss 1.467642\n",
      "batch 473: loss 1.356608\n",
      "batch 474: loss 1.443926\n",
      "batch 475: loss 1.455644\n",
      "batch 476: loss 1.460524\n",
      "batch 477: loss 1.417182\n",
      "batch 478: loss 1.548759\n",
      "batch 479: loss 1.417699\n",
      "batch 480: loss 1.582426\n",
      "batch 481: loss 1.488602\n",
      "batch 482: loss 1.381025\n",
      "batch 483: loss 1.391380\n",
      "batch 484: loss 1.319880\n",
      "batch 485: loss 1.529199\n",
      "batch 486: loss 1.297245\n",
      "batch 487: loss 1.457248\n",
      "batch 488: loss 1.357404\n",
      "batch 489: loss 1.358723\n",
      "batch 490: loss 1.341560\n",
      "batch 491: loss 1.512092\n",
      "batch 492: loss 1.453143\n",
      "batch 493: loss 1.330696\n",
      "batch 494: loss 1.355979\n",
      "batch 495: loss 1.423338\n",
      "batch 496: loss 1.362708\n",
      "batch 497: loss 1.365229\n",
      "batch 498: loss 1.459375\n",
      "batch 499: loss 1.496607\n",
      "batch 500: loss 1.551057\n",
      "batch 501: loss 1.413465\n",
      "batch 502: loss 1.369767\n",
      "batch 503: loss 1.461545\n",
      "batch 504: loss 1.585938\n",
      "batch 505: loss 1.348260\n",
      "batch 506: loss 1.472770\n",
      "batch 507: loss 1.551495\n",
      "batch 508: loss 1.396008\n",
      "batch 509: loss 1.326493\n",
      "batch 510: loss 1.287194\n",
      "batch 511: loss 1.427003\n",
      "batch 512: loss 1.422591\n",
      "batch 513: loss 1.308163\n",
      "batch 514: loss 1.320943\n",
      "batch 515: loss 1.307092\n",
      "batch 516: loss 1.292644\n",
      "batch 517: loss 1.494862\n",
      "batch 518: loss 1.376286\n",
      "batch 519: loss 1.431193\n",
      "batch 520: loss 1.441724\n",
      "batch 521: loss 1.354362\n",
      "batch 522: loss 1.374002\n",
      "batch 523: loss 1.346063\n",
      "batch 524: loss 1.324690\n",
      "batch 525: loss 1.307893\n",
      "batch 526: loss 1.411677\n",
      "batch 527: loss 1.178416\n",
      "batch 528: loss 1.371976\n",
      "batch 529: loss 1.315756\n",
      "batch 530: loss 1.362548\n",
      "batch 531: loss 1.350261\n",
      "batch 532: loss 1.420198\n",
      "batch 533: loss 1.404496\n",
      "batch 534: loss 1.410707\n",
      "batch 535: loss 1.371886\n",
      "batch 536: loss 1.493757\n",
      "batch 537: loss 1.344957\n",
      "batch 538: loss 1.333757\n",
      "batch 539: loss 1.354857\n",
      "batch 540: loss 1.384988\n",
      "batch 541: loss 1.260115\n",
      "batch 542: loss 1.341105\n",
      "batch 543: loss 1.242827\n",
      "batch 544: loss 1.275169\n",
      "batch 545: loss 1.417397\n",
      "batch 546: loss 1.264049\n",
      "batch 547: loss 1.275300\n",
      "batch 548: loss 1.285827\n",
      "batch 549: loss 1.312775\n",
      "batch 550: loss 1.354897\n",
      "batch 551: loss 1.187949\n",
      "batch 552: loss 1.314251\n",
      "batch 553: loss 1.347248\n",
      "batch 554: loss 1.281965\n",
      "batch 555: loss 1.377496\n",
      "batch 556: loss 1.216959\n",
      "batch 557: loss 1.366864\n",
      "batch 558: loss 1.311494\n",
      "batch 559: loss 1.196353\n",
      "batch 560: loss 1.267701\n",
      "batch 561: loss 1.279193\n",
      "batch 562: loss 1.201668\n",
      "batch 563: loss 1.287605\n",
      "batch 564: loss 1.349449\n",
      "batch 565: loss 1.303772\n",
      "batch 566: loss 1.209603\n",
      "batch 567: loss 1.256119\n",
      "batch 568: loss 1.306031\n",
      "batch 569: loss 1.278096\n",
      "batch 570: loss 1.209013\n",
      "batch 571: loss 1.433657\n",
      "batch 572: loss 1.242960\n",
      "batch 573: loss 1.473214\n",
      "batch 574: loss 1.166103\n",
      "batch 575: loss 1.263961\n",
      "batch 576: loss 1.282444\n",
      "batch 577: loss 1.280784\n",
      "batch 578: loss 1.429525\n",
      "batch 579: loss 1.193115\n",
      "batch 580: loss 1.222149\n",
      "batch 581: loss 1.261785\n",
      "batch 582: loss 1.294958\n",
      "batch 583: loss 1.397197\n",
      "batch 584: loss 1.392576\n",
      "batch 585: loss 1.231142\n",
      "batch 586: loss 1.367524\n",
      "batch 587: loss 1.337957\n",
      "batch 588: loss 1.126735\n",
      "batch 589: loss 1.207894\n",
      "batch 590: loss 1.389337\n",
      "batch 591: loss 1.390067\n",
      "batch 592: loss 1.239550\n",
      "batch 593: loss 1.274820\n",
      "batch 594: loss 1.206535\n",
      "batch 595: loss 1.160714\n",
      "batch 596: loss 1.240506\n",
      "batch 597: loss 1.254928\n",
      "batch 598: loss 1.219119\n",
      "batch 599: loss 1.265965\n",
      "batch 600: loss 1.171244\n",
      "batch 601: loss 1.306362\n",
      "batch 602: loss 1.272346\n",
      "batch 603: loss 1.159982\n",
      "batch 604: loss 1.258888\n",
      "batch 605: loss 1.356438\n",
      "batch 606: loss 1.335101\n",
      "batch 607: loss 1.180000\n",
      "batch 608: loss 1.290558\n",
      "batch 609: loss 1.195772\n",
      "batch 610: loss 1.200601\n",
      "batch 611: loss 1.192280\n",
      "batch 612: loss 1.228183\n",
      "batch 613: loss 1.101137\n",
      "batch 614: loss 1.116597\n",
      "batch 615: loss 1.311217\n",
      "batch 616: loss 1.290368\n",
      "batch 617: loss 1.270519\n",
      "batch 618: loss 1.356370\n",
      "batch 619: loss 1.272430\n",
      "batch 620: loss 1.187253\n",
      "batch 621: loss 1.275999\n",
      "batch 622: loss 1.154724\n",
      "batch 623: loss 1.245994\n",
      "batch 624: loss 1.180333\n",
      "batch 625: loss 1.227991\n",
      "batch 626: loss 1.289980\n",
      "batch 627: loss 1.336971\n",
      "batch 628: loss 1.175479\n",
      "batch 629: loss 1.033321\n",
      "batch 630: loss 1.120592\n",
      "batch 631: loss 1.113660\n",
      "batch 632: loss 1.209976\n",
      "batch 633: loss 1.194996\n",
      "batch 634: loss 1.215963\n",
      "batch 635: loss 1.192914\n",
      "batch 636: loss 1.192321\n",
      "batch 637: loss 1.263037\n",
      "batch 638: loss 1.064524\n",
      "batch 639: loss 1.200561\n",
      "batch 640: loss 1.237448\n",
      "batch 641: loss 1.253318\n",
      "batch 642: loss 1.278243\n",
      "batch 643: loss 1.036693\n",
      "batch 644: loss 1.174117\n",
      "batch 645: loss 1.159896\n",
      "batch 646: loss 1.264159\n",
      "batch 647: loss 1.242015\n",
      "batch 648: loss 1.168159\n",
      "batch 649: loss 1.130947\n",
      "batch 650: loss 1.142359\n",
      "batch 651: loss 1.109468\n",
      "batch 652: loss 1.257117\n",
      "batch 653: loss 1.123646\n",
      "batch 654: loss 1.187099\n",
      "batch 655: loss 0.995305\n",
      "batch 656: loss 1.180141\n",
      "batch 657: loss 1.118575\n",
      "batch 658: loss 1.258736\n",
      "batch 659: loss 1.101675\n",
      "batch 660: loss 1.160721\n",
      "batch 661: loss 1.175774\n",
      "batch 662: loss 1.042413\n",
      "batch 663: loss 1.161391\n",
      "batch 664: loss 1.234070\n",
      "batch 665: loss 1.208256\n",
      "batch 666: loss 1.182677\n",
      "batch 667: loss 1.280669\n",
      "batch 668: loss 1.094718\n",
      "batch 669: loss 1.127126\n",
      "batch 670: loss 1.196084\n",
      "batch 671: loss 1.212444\n",
      "batch 672: loss 1.068512\n",
      "batch 673: loss 1.128384\n",
      "batch 674: loss 1.067220\n",
      "batch 675: loss 0.999840\n",
      "batch 676: loss 1.040895\n",
      "batch 677: loss 1.173971\n",
      "batch 678: loss 1.130645\n",
      "batch 679: loss 1.259763\n",
      "batch 680: loss 1.224777\n",
      "batch 681: loss 1.164946\n",
      "batch 682: loss 1.262379\n",
      "batch 683: loss 1.117527\n",
      "batch 684: loss 1.201211\n",
      "batch 685: loss 1.026306\n",
      "batch 686: loss 1.204547\n",
      "batch 687: loss 1.077963\n",
      "batch 688: loss 1.013700\n",
      "batch 689: loss 1.136099\n",
      "batch 690: loss 1.210846\n",
      "batch 691: loss 1.168315\n",
      "batch 692: loss 1.045498\n",
      "batch 693: loss 1.134159\n",
      "batch 694: loss 1.069062\n",
      "batch 695: loss 1.102776\n",
      "batch 696: loss 0.976615\n",
      "batch 697: loss 1.208701\n",
      "batch 698: loss 1.079338\n",
      "batch 699: loss 1.121753\n",
      "batch 700: loss 1.070552\n",
      "batch 701: loss 1.144051\n",
      "batch 702: loss 1.042826\n",
      "batch 703: loss 1.157434\n",
      "batch 704: loss 1.176749\n",
      "batch 705: loss 1.051011\n",
      "batch 706: loss 1.104996\n",
      "batch 707: loss 1.138408\n",
      "batch 708: loss 1.136388\n",
      "batch 709: loss 1.023699\n",
      "batch 710: loss 1.073171\n",
      "batch 711: loss 1.039073\n",
      "batch 712: loss 1.300294\n",
      "batch 713: loss 0.945128\n",
      "batch 714: loss 1.243924\n",
      "batch 715: loss 1.297988\n",
      "batch 716: loss 1.020128\n",
      "batch 717: loss 1.136982\n",
      "batch 718: loss 1.068672\n",
      "batch 719: loss 1.125160\n",
      "batch 720: loss 0.984891\n",
      "batch 721: loss 0.997046\n",
      "batch 722: loss 1.220176\n",
      "batch 723: loss 1.106205\n",
      "batch 724: loss 1.130280\n",
      "batch 725: loss 1.085822\n",
      "batch 726: loss 1.223450\n",
      "batch 727: loss 1.047813\n",
      "batch 728: loss 0.951238\n",
      "batch 729: loss 1.018480\n",
      "batch 730: loss 1.092313\n",
      "batch 731: loss 1.092215\n",
      "batch 732: loss 1.084829\n",
      "batch 733: loss 1.021283\n",
      "batch 734: loss 1.068783\n",
      "batch 735: loss 1.109823\n",
      "batch 736: loss 0.869501\n",
      "batch 737: loss 1.084837\n",
      "batch 738: loss 1.122089\n",
      "batch 739: loss 0.830251\n",
      "batch 740: loss 1.168247\n",
      "batch 741: loss 1.047295\n",
      "batch 742: loss 1.216995\n",
      "batch 743: loss 1.162229\n",
      "batch 744: loss 1.132235\n",
      "batch 745: loss 1.112908\n",
      "batch 746: loss 1.195525\n",
      "batch 747: loss 1.035537\n",
      "batch 748: loss 1.186659\n",
      "batch 749: loss 1.108171\n",
      "batch 750: loss 1.201345\n",
      "batch 751: loss 1.102344\n",
      "batch 752: loss 0.954139\n",
      "batch 753: loss 0.962842\n",
      "batch 754: loss 1.091642\n",
      "batch 755: loss 1.042518\n",
      "batch 756: loss 1.001519\n",
      "batch 757: loss 1.133371\n",
      "batch 758: loss 0.919196\n",
      "batch 759: loss 0.944218\n",
      "batch 760: loss 1.087842\n",
      "batch 761: loss 0.963534\n",
      "batch 762: loss 0.992722\n",
      "batch 763: loss 0.926783\n",
      "batch 764: loss 0.980999\n",
      "batch 765: loss 0.978999\n",
      "batch 766: loss 0.842493\n",
      "batch 767: loss 0.941361\n",
      "batch 768: loss 1.011857\n",
      "batch 769: loss 1.110656\n",
      "batch 770: loss 1.026738\n",
      "batch 771: loss 0.988500\n",
      "batch 772: loss 1.026360\n",
      "batch 773: loss 1.035036\n",
      "batch 774: loss 1.070955\n",
      "batch 775: loss 1.081841\n",
      "batch 776: loss 1.101519\n",
      "batch 777: loss 1.061359\n",
      "batch 778: loss 0.960108\n",
      "batch 779: loss 1.110973\n",
      "batch 780: loss 0.973926\n",
      "batch 781: loss 0.981681\n",
      "batch 782: loss 1.234416\n",
      "batch 783: loss 1.088489\n",
      "batch 784: loss 1.061230\n",
      "batch 785: loss 1.065143\n",
      "batch 786: loss 0.982048\n",
      "batch 787: loss 1.124375\n",
      "batch 788: loss 0.962677\n",
      "batch 789: loss 1.112816\n",
      "batch 790: loss 1.020671\n",
      "batch 791: loss 0.902215\n",
      "batch 792: loss 1.102058\n",
      "batch 793: loss 1.160255\n",
      "batch 794: loss 1.061366\n",
      "batch 795: loss 1.036994\n",
      "batch 796: loss 0.929758\n",
      "batch 797: loss 1.036548\n",
      "batch 798: loss 1.058862\n",
      "batch 799: loss 1.029223\n",
      "batch 800: loss 1.231271\n",
      "batch 801: loss 1.063737\n",
      "batch 802: loss 1.010026\n",
      "batch 803: loss 0.879303\n",
      "batch 804: loss 1.105481\n",
      "batch 805: loss 1.008261\n",
      "batch 806: loss 1.044724\n",
      "batch 807: loss 1.102180\n",
      "batch 808: loss 0.883114\n",
      "batch 809: loss 0.966853\n",
      "batch 810: loss 1.140319\n",
      "batch 811: loss 1.231399\n",
      "batch 812: loss 0.952108\n",
      "batch 813: loss 0.980824\n",
      "batch 814: loss 0.947280\n",
      "batch 815: loss 0.998789\n",
      "batch 816: loss 0.985018\n",
      "batch 817: loss 1.134118\n",
      "batch 818: loss 1.143111\n",
      "batch 819: loss 1.092294\n",
      "batch 820: loss 1.205440\n",
      "batch 821: loss 0.847546\n",
      "batch 822: loss 1.081017\n",
      "batch 823: loss 1.024455\n",
      "batch 824: loss 1.155191\n",
      "batch 825: loss 1.034024\n",
      "batch 826: loss 0.955724\n",
      "batch 827: loss 0.923131\n",
      "batch 828: loss 1.127055\n",
      "batch 829: loss 1.001319\n",
      "batch 830: loss 1.076945\n",
      "batch 831: loss 1.051146\n",
      "batch 832: loss 0.960412\n",
      "batch 833: loss 0.979873\n",
      "batch 834: loss 0.862642\n",
      "batch 835: loss 0.988924\n",
      "batch 836: loss 0.884310\n",
      "batch 837: loss 1.062341\n",
      "batch 838: loss 0.821044\n",
      "batch 839: loss 0.948795\n",
      "batch 840: loss 0.929845\n",
      "batch 841: loss 0.971197\n",
      "batch 842: loss 0.887206\n",
      "batch 843: loss 0.886178\n",
      "batch 844: loss 0.971809\n",
      "batch 845: loss 1.166157\n",
      "batch 846: loss 1.050713\n",
      "batch 847: loss 0.981885\n",
      "batch 848: loss 0.998127\n",
      "batch 849: loss 1.158793\n",
      "batch 850: loss 1.066721\n",
      "batch 851: loss 0.995624\n",
      "batch 852: loss 0.879411\n",
      "batch 853: loss 0.946280\n",
      "batch 854: loss 1.147870\n",
      "batch 855: loss 0.962709\n",
      "batch 856: loss 0.984794\n",
      "batch 857: loss 0.905160\n",
      "batch 858: loss 0.980031\n",
      "batch 859: loss 0.907722\n",
      "batch 860: loss 0.875831\n",
      "batch 861: loss 0.956029\n",
      "batch 862: loss 0.895060\n",
      "batch 863: loss 0.777124\n",
      "batch 864: loss 0.863481\n",
      "batch 865: loss 1.065762\n",
      "batch 866: loss 1.095037\n",
      "batch 867: loss 0.854916\n",
      "batch 868: loss 0.871238\n",
      "batch 869: loss 0.976993\n",
      "batch 870: loss 1.067645\n",
      "batch 871: loss 0.891764\n",
      "batch 872: loss 0.980637\n",
      "batch 873: loss 0.903939\n",
      "batch 874: loss 0.957183\n",
      "batch 875: loss 0.865592\n",
      "batch 876: loss 1.000461\n",
      "batch 877: loss 0.919918\n",
      "batch 878: loss 1.004105\n",
      "batch 879: loss 1.003792\n",
      "batch 880: loss 1.114261\n",
      "batch 881: loss 0.945190\n",
      "batch 882: loss 0.890955\n",
      "batch 883: loss 0.849364\n",
      "batch 884: loss 1.152969\n",
      "batch 885: loss 1.051020\n",
      "batch 886: loss 1.082922\n",
      "batch 887: loss 0.932237\n",
      "batch 888: loss 0.860360\n",
      "batch 889: loss 0.859440\n",
      "batch 890: loss 0.874344\n",
      "batch 891: loss 1.164218\n",
      "batch 892: loss 0.881633\n",
      "batch 893: loss 1.008295\n",
      "batch 894: loss 1.003041\n",
      "batch 895: loss 0.962203\n",
      "batch 896: loss 1.051818\n",
      "batch 897: loss 0.832995\n",
      "batch 898: loss 0.888217\n",
      "batch 899: loss 0.952861\n",
      "batch 900: loss 1.042542\n",
      "batch 901: loss 0.940834\n",
      "batch 902: loss 0.891179\n",
      "batch 903: loss 0.845169\n",
      "batch 904: loss 0.931719\n",
      "batch 905: loss 0.823935\n",
      "batch 906: loss 0.958198\n",
      "batch 907: loss 0.864404\n",
      "batch 908: loss 0.857159\n",
      "batch 909: loss 0.853374\n",
      "batch 910: loss 1.057452\n",
      "batch 911: loss 0.897105\n",
      "batch 912: loss 0.920405\n",
      "batch 913: loss 0.907490\n",
      "batch 914: loss 0.777173\n",
      "batch 915: loss 1.077977\n",
      "batch 916: loss 0.892715\n",
      "batch 917: loss 0.992213\n",
      "batch 918: loss 0.860891\n",
      "batch 919: loss 1.048791\n",
      "batch 920: loss 0.957179\n",
      "batch 921: loss 0.798401\n",
      "batch 922: loss 0.893797\n",
      "batch 923: loss 0.949591\n",
      "batch 924: loss 0.812344\n",
      "batch 925: loss 0.971540\n",
      "batch 926: loss 0.926881\n",
      "batch 927: loss 0.984503\n",
      "batch 928: loss 0.851429\n",
      "batch 929: loss 0.918067\n",
      "batch 930: loss 0.826902\n",
      "batch 931: loss 0.863143\n",
      "batch 932: loss 0.861431\n",
      "batch 933: loss 0.913170\n",
      "batch 934: loss 1.059406\n",
      "batch 935: loss 0.814914\n",
      "batch 936: loss 1.002829\n",
      "batch 937: loss 0.847859\n",
      "batch 938: loss 0.955214\n",
      "batch 939: loss 1.015753\n",
      "batch 940: loss 0.889088\n",
      "batch 941: loss 1.040576\n",
      "batch 942: loss 0.843273\n",
      "batch 943: loss 0.957845\n",
      "batch 944: loss 1.149977\n",
      "batch 945: loss 0.803852\n",
      "batch 946: loss 0.950020\n",
      "batch 947: loss 0.982845\n",
      "batch 948: loss 0.983062\n",
      "batch 949: loss 0.915270\n",
      "batch 950: loss 1.006011\n",
      "batch 951: loss 0.851615\n",
      "batch 952: loss 0.816777\n",
      "batch 953: loss 0.932723\n",
      "batch 954: loss 0.947144\n",
      "batch 955: loss 0.791201\n",
      "batch 956: loss 0.876919\n",
      "batch 957: loss 0.908958\n",
      "batch 958: loss 0.762029\n",
      "batch 959: loss 0.833956\n",
      "batch 960: loss 0.965635\n",
      "batch 961: loss 0.937824\n",
      "batch 962: loss 0.838252\n",
      "batch 963: loss 0.914715\n",
      "batch 964: loss 0.922721\n",
      "batch 965: loss 0.906033\n",
      "batch 966: loss 0.864750\n",
      "batch 967: loss 0.929780\n",
      "batch 968: loss 0.838956\n",
      "batch 969: loss 0.949517\n",
      "batch 970: loss 0.734131\n",
      "batch 971: loss 0.864919\n",
      "batch 972: loss 0.813388\n",
      "batch 973: loss 0.846915\n",
      "batch 974: loss 0.974558\n",
      "batch 975: loss 0.871646\n",
      "batch 976: loss 0.915633\n",
      "batch 977: loss 0.809345\n",
      "batch 978: loss 0.860359\n",
      "batch 979: loss 0.812833\n",
      "batch 980: loss 0.821324\n",
      "batch 981: loss 0.699881\n",
      "batch 982: loss 0.986958\n",
      "batch 983: loss 0.846089\n",
      "batch 984: loss 1.058016\n",
      "batch 985: loss 0.849069\n",
      "batch 986: loss 0.826451\n",
      "batch 987: loss 0.869407\n",
      "batch 988: loss 1.045359\n",
      "batch 989: loss 0.754289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 990: loss 0.914851\n",
      "batch 991: loss 0.983410\n",
      "batch 992: loss 0.879827\n",
      "batch 993: loss 0.800982\n",
      "batch 994: loss 0.973723\n",
      "batch 995: loss 0.673251\n",
      "batch 996: loss 0.888513\n",
      "batch 997: loss 0.902901\n",
      "batch 998: loss 0.872275\n",
      "batch 999: loss 0.884556\n",
      "batch 1000: loss 0.963140\n",
      "batch 1001: loss 0.789567\n",
      "batch 1002: loss 0.957051\n",
      "batch 1003: loss 0.822445\n",
      "batch 1004: loss 0.836480\n",
      "batch 1005: loss 0.647777\n",
      "batch 1006: loss 0.947477\n",
      "batch 1007: loss 0.857541\n",
      "batch 1008: loss 0.953716\n",
      "batch 1009: loss 0.735502\n",
      "batch 1010: loss 0.714304\n",
      "batch 1011: loss 0.943559\n",
      "batch 1012: loss 0.840628\n",
      "batch 1013: loss 0.768259\n",
      "batch 1014: loss 0.748090\n",
      "batch 1015: loss 0.703898\n",
      "batch 1016: loss 0.818043\n",
      "batch 1017: loss 0.637366\n",
      "batch 1018: loss 0.722528\n",
      "batch 1019: loss 0.783805\n",
      "batch 1020: loss 0.890520\n",
      "batch 1021: loss 0.855393\n",
      "batch 1022: loss 0.693065\n",
      "batch 1023: loss 0.919418\n",
      "batch 1024: loss 0.926174\n",
      "batch 1025: loss 0.799007\n",
      "batch 1026: loss 0.817318\n",
      "batch 1027: loss 0.721477\n",
      "batch 1028: loss 0.961583\n",
      "batch 1029: loss 0.834521\n",
      "batch 1030: loss 0.888413\n",
      "batch 1031: loss 0.924001\n",
      "batch 1032: loss 1.020731\n",
      "batch 1033: loss 1.100997\n",
      "batch 1034: loss 0.801922\n",
      "batch 1035: loss 0.997464\n",
      "batch 1036: loss 0.850588\n",
      "batch 1037: loss 0.765686\n",
      "batch 1038: loss 0.938605\n",
      "batch 1039: loss 0.873205\n",
      "batch 1040: loss 0.860835\n",
      "batch 1041: loss 0.861109\n",
      "batch 1042: loss 0.839892\n",
      "batch 1043: loss 0.920978\n",
      "batch 1044: loss 0.756065\n",
      "batch 1045: loss 0.796043\n",
      "batch 1046: loss 0.873995\n",
      "batch 1047: loss 0.956013\n",
      "batch 1048: loss 0.729835\n",
      "batch 1049: loss 0.775268\n",
      "batch 1050: loss 0.694126\n",
      "batch 1051: loss 0.830647\n",
      "batch 1052: loss 0.746908\n",
      "batch 1053: loss 0.781490\n",
      "batch 1054: loss 0.808571\n",
      "batch 1055: loss 0.780022\n",
      "batch 1056: loss 0.685363\n",
      "batch 1057: loss 0.849506\n",
      "batch 1058: loss 0.938096\n",
      "batch 1059: loss 0.767624\n",
      "batch 1060: loss 0.693173\n",
      "batch 1061: loss 1.006432\n",
      "batch 1062: loss 0.945023\n",
      "batch 1063: loss 0.684475\n",
      "batch 1064: loss 0.817162\n",
      "batch 1065: loss 0.939549\n",
      "batch 1066: loss 0.646958\n",
      "batch 1067: loss 0.761905\n",
      "batch 1068: loss 0.818739\n",
      "batch 1069: loss 0.908537\n",
      "batch 1070: loss 0.692301\n",
      "batch 1071: loss 0.802443\n",
      "batch 1072: loss 0.884275\n",
      "batch 1073: loss 0.739455\n",
      "batch 1074: loss 0.775775\n",
      "batch 1075: loss 0.752423\n",
      "batch 1076: loss 0.766017\n",
      "batch 1077: loss 0.982286\n",
      "batch 1078: loss 0.887282\n",
      "batch 1079: loss 0.870554\n",
      "batch 1080: loss 0.666445\n",
      "batch 1081: loss 0.886122\n",
      "batch 1082: loss 0.652182\n",
      "batch 1083: loss 0.756925\n",
      "batch 1084: loss 0.930202\n",
      "batch 1085: loss 0.842651\n",
      "batch 1086: loss 0.708793\n",
      "batch 1087: loss 0.796817\n",
      "batch 1088: loss 0.819112\n",
      "batch 1089: loss 0.928701\n",
      "batch 1090: loss 0.925891\n",
      "batch 1091: loss 0.840373\n",
      "batch 1092: loss 0.838392\n",
      "batch 1093: loss 0.718499\n",
      "batch 1094: loss 0.917004\n",
      "batch 1095: loss 0.959612\n",
      "batch 1096: loss 0.805669\n",
      "batch 1097: loss 0.555298\n",
      "batch 1098: loss 0.791702\n",
      "batch 1099: loss 0.713695\n",
      "batch 1100: loss 0.848447\n",
      "batch 1101: loss 0.896938\n",
      "batch 1102: loss 0.886848\n",
      "batch 1103: loss 0.800790\n",
      "batch 1104: loss 0.724562\n",
      "batch 1105: loss 0.759892\n",
      "batch 1106: loss 0.755627\n",
      "batch 1107: loss 0.716412\n",
      "batch 1108: loss 0.705033\n",
      "batch 1109: loss 0.853530\n",
      "batch 1110: loss 0.893512\n",
      "batch 1111: loss 0.896216\n",
      "batch 1112: loss 0.846681\n",
      "batch 1113: loss 0.943910\n",
      "batch 1114: loss 0.723121\n",
      "batch 1115: loss 0.822427\n",
      "batch 1116: loss 0.739137\n",
      "batch 1117: loss 0.815803\n",
      "batch 1118: loss 0.897279\n",
      "batch 1119: loss 0.931190\n",
      "batch 1120: loss 0.818787\n",
      "batch 1121: loss 0.802789\n",
      "batch 1122: loss 0.728406\n",
      "batch 1123: loss 0.938936\n",
      "batch 1124: loss 0.856350\n",
      "batch 1125: loss 0.689968\n",
      "batch 1126: loss 0.800427\n",
      "batch 1127: loss 0.735655\n",
      "batch 1128: loss 0.824985\n",
      "batch 1129: loss 0.938254\n",
      "batch 1130: loss 0.873517\n",
      "batch 1131: loss 0.734557\n",
      "batch 1132: loss 0.730424\n",
      "batch 1133: loss 0.777969\n",
      "batch 1134: loss 0.850075\n",
      "batch 1135: loss 0.786884\n",
      "batch 1136: loss 0.722741\n",
      "batch 1137: loss 0.951463\n",
      "batch 1138: loss 0.726293\n",
      "batch 1139: loss 1.007602\n",
      "batch 1140: loss 0.711881\n",
      "batch 1141: loss 0.666423\n",
      "batch 1142: loss 1.128304\n",
      "batch 1143: loss 0.593687\n",
      "batch 1144: loss 0.751919\n",
      "batch 1145: loss 0.633807\n",
      "batch 1146: loss 0.855526\n",
      "batch 1147: loss 0.842419\n",
      "batch 1148: loss 0.718162\n",
      "batch 1149: loss 0.845519\n",
      "batch 1150: loss 0.745509\n",
      "batch 1151: loss 0.740142\n",
      "batch 1152: loss 0.871566\n",
      "batch 1153: loss 0.810351\n",
      "batch 1154: loss 0.817849\n",
      "batch 1155: loss 0.660556\n",
      "batch 1156: loss 0.811859\n",
      "batch 1157: loss 0.701595\n",
      "batch 1158: loss 0.655705\n",
      "batch 1159: loss 0.848090\n",
      "batch 1160: loss 0.792786\n",
      "batch 1161: loss 0.727710\n",
      "batch 1162: loss 0.860691\n",
      "batch 1163: loss 0.891917\n",
      "batch 1164: loss 0.773921\n",
      "batch 1165: loss 0.618918\n",
      "batch 1166: loss 0.886278\n",
      "batch 1167: loss 0.721876\n",
      "batch 1168: loss 0.834871\n",
      "batch 1169: loss 0.748337\n",
      "batch 1170: loss 0.864547\n",
      "batch 1171: loss 0.679822\n",
      "batch 1172: loss 0.747116\n",
      "batch 1173: loss 0.860580\n",
      "batch 1174: loss 0.849732\n",
      "batch 1175: loss 0.998824\n",
      "batch 1176: loss 0.805936\n",
      "batch 1177: loss 0.772242\n",
      "batch 1178: loss 0.862654\n",
      "batch 1179: loss 0.670494\n",
      "batch 1180: loss 0.684053\n",
      "batch 1181: loss 0.800571\n",
      "batch 1182: loss 0.584025\n",
      "batch 1183: loss 0.754012\n",
      "batch 1184: loss 0.806785\n",
      "batch 1185: loss 0.960980\n",
      "batch 1186: loss 0.695007\n",
      "batch 1187: loss 0.716182\n",
      "batch 1188: loss 0.859729\n",
      "batch 1189: loss 0.746037\n",
      "batch 1190: loss 0.804995\n",
      "batch 1191: loss 0.801768\n",
      "batch 1192: loss 0.738664\n",
      "batch 1193: loss 0.712334\n",
      "batch 1194: loss 0.719388\n",
      "batch 1195: loss 0.692339\n",
      "batch 1196: loss 0.786988\n",
      "batch 1197: loss 0.781037\n",
      "batch 1198: loss 0.776008\n",
      "batch 1199: loss 0.806978\n",
      "batch 1200: loss 0.703578\n",
      "batch 1201: loss 0.724886\n",
      "batch 1202: loss 0.872071\n",
      "batch 1203: loss 0.763377\n",
      "batch 1204: loss 0.718725\n",
      "batch 1205: loss 0.879488\n",
      "batch 1206: loss 0.786792\n",
      "batch 1207: loss 0.753328\n",
      "batch 1208: loss 0.839580\n",
      "batch 1209: loss 0.785772\n",
      "batch 1210: loss 0.669538\n",
      "batch 1211: loss 0.726973\n",
      "batch 1212: loss 0.681013\n",
      "batch 1213: loss 0.774645\n",
      "batch 1214: loss 0.799629\n",
      "batch 1215: loss 0.781476\n",
      "batch 1216: loss 0.758583\n",
      "batch 1217: loss 0.829538\n",
      "batch 1218: loss 0.564894\n",
      "batch 1219: loss 0.701365\n",
      "batch 1220: loss 0.646313\n",
      "batch 1221: loss 0.700196\n",
      "batch 1222: loss 0.759646\n",
      "batch 1223: loss 0.751005\n",
      "batch 1224: loss 0.815549\n",
      "batch 1225: loss 0.869940\n",
      "batch 1226: loss 0.766279\n",
      "batch 1227: loss 0.676793\n",
      "batch 1228: loss 0.867471\n",
      "batch 1229: loss 0.656106\n",
      "batch 1230: loss 0.661060\n",
      "batch 1231: loss 0.758473\n",
      "batch 1232: loss 0.827654\n",
      "batch 1233: loss 0.775487\n",
      "batch 1234: loss 0.531425\n",
      "batch 1235: loss 0.552521\n",
      "batch 1236: loss 0.769106\n",
      "batch 1237: loss 0.817971\n",
      "batch 1238: loss 0.593390\n",
      "batch 1239: loss 0.577942\n",
      "batch 1240: loss 0.904109\n",
      "batch 1241: loss 0.843961\n",
      "batch 1242: loss 0.570252\n",
      "batch 1243: loss 0.940818\n",
      "batch 1244: loss 0.789210\n",
      "batch 1245: loss 0.836915\n",
      "batch 1246: loss 0.838164\n",
      "batch 1247: loss 0.727850\n",
      "batch 1248: loss 0.637156\n",
      "batch 1249: loss 0.697080\n",
      "batch 1250: loss 0.756016\n",
      "batch 1251: loss 0.614133\n",
      "batch 1252: loss 0.694224\n",
      "batch 1253: loss 0.806089\n",
      "batch 1254: loss 0.807715\n",
      "batch 1255: loss 0.741854\n",
      "batch 1256: loss 0.687391\n",
      "batch 1257: loss 0.965198\n",
      "batch 1258: loss 0.624819\n",
      "batch 1259: loss 0.648183\n",
      "batch 1260: loss 0.643341\n",
      "batch 1261: loss 0.721102\n",
      "batch 1262: loss 0.736804\n",
      "batch 1263: loss 0.663026\n",
      "batch 1264: loss 0.777651\n",
      "batch 1265: loss 0.712250\n",
      "batch 1266: loss 0.730020\n",
      "batch 1267: loss 0.671831\n",
      "batch 1268: loss 0.743113\n",
      "batch 1269: loss 0.805738\n",
      "batch 1270: loss 0.746958\n",
      "batch 1271: loss 0.693343\n",
      "batch 1272: loss 0.726871\n",
      "batch 1273: loss 0.564852\n",
      "batch 1274: loss 0.793525\n",
      "batch 1275: loss 0.883410\n",
      "batch 1276: loss 0.758084\n",
      "batch 1277: loss 0.649567\n",
      "batch 1278: loss 0.758805\n",
      "batch 1279: loss 0.697915\n",
      "batch 1280: loss 0.614323\n",
      "batch 1281: loss 0.782564\n",
      "batch 1282: loss 0.786357\n",
      "batch 1283: loss 0.761510\n",
      "batch 1284: loss 0.625837\n",
      "batch 1285: loss 0.813909\n",
      "batch 1286: loss 0.653194\n",
      "batch 1287: loss 0.706239\n",
      "batch 1288: loss 0.788890\n",
      "batch 1289: loss 0.712155\n",
      "batch 1290: loss 0.756355\n",
      "batch 1291: loss 0.810469\n",
      "batch 1292: loss 0.807567\n",
      "batch 1293: loss 0.715935\n",
      "batch 1294: loss 0.727607\n",
      "batch 1295: loss 0.815402\n",
      "batch 1296: loss 0.784443\n",
      "batch 1297: loss 0.735007\n",
      "batch 1298: loss 0.857727\n",
      "batch 1299: loss 0.547968\n",
      "batch 1300: loss 0.658552\n",
      "batch 1301: loss 0.655117\n",
      "batch 1302: loss 0.748767\n",
      "batch 1303: loss 0.829778\n",
      "batch 1304: loss 0.797958\n",
      "batch 1305: loss 0.779292\n",
      "batch 1306: loss 0.738540\n",
      "batch 1307: loss 0.956269\n",
      "batch 1308: loss 0.720178\n",
      "batch 1309: loss 0.791987\n",
      "batch 1310: loss 0.696370\n",
      "batch 1311: loss 0.640594\n",
      "batch 1312: loss 0.830034\n",
      "batch 1313: loss 0.710854\n",
      "batch 1314: loss 0.879249\n",
      "batch 1315: loss 0.860085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1316: loss 0.658525\n",
      "batch 1317: loss 0.671394\n",
      "batch 1318: loss 0.727253\n",
      "batch 1319: loss 0.665925\n",
      "batch 1320: loss 0.646469\n",
      "batch 1321: loss 0.615763\n",
      "batch 1322: loss 0.648285\n",
      "batch 1323: loss 0.601521\n",
      "batch 1324: loss 0.690069\n",
      "batch 1325: loss 0.808954\n",
      "batch 1326: loss 0.760732\n",
      "batch 1327: loss 0.638628\n",
      "batch 1328: loss 0.727024\n",
      "batch 1329: loss 0.780128\n",
      "batch 1330: loss 0.720718\n",
      "batch 1331: loss 0.661415\n",
      "batch 1332: loss 0.636843\n",
      "batch 1333: loss 0.686686\n",
      "batch 1334: loss 0.747302\n",
      "batch 1335: loss 0.648433\n",
      "batch 1336: loss 1.074362\n",
      "batch 1337: loss 0.621543\n",
      "batch 1338: loss 0.696614\n",
      "batch 1339: loss 0.942074\n",
      "batch 1340: loss 0.523304\n",
      "batch 1341: loss 0.685202\n",
      "batch 1342: loss 0.753509\n",
      "batch 1343: loss 0.753131\n",
      "batch 1344: loss 0.859449\n",
      "batch 1345: loss 0.644387\n",
      "batch 1346: loss 0.842469\n",
      "batch 1347: loss 0.614612\n",
      "batch 1348: loss 0.823629\n",
      "batch 1349: loss 0.638849\n",
      "batch 1350: loss 0.565703\n",
      "batch 1351: loss 0.774390\n",
      "batch 1352: loss 0.759620\n",
      "batch 1353: loss 0.635825\n",
      "batch 1354: loss 0.656912\n",
      "batch 1355: loss 0.785729\n",
      "batch 1356: loss 0.624623\n",
      "batch 1357: loss 0.765844\n",
      "batch 1358: loss 0.692798\n",
      "batch 1359: loss 0.848037\n",
      "batch 1360: loss 0.631958\n",
      "batch 1361: loss 0.580937\n",
      "batch 1362: loss 0.860769\n",
      "batch 1363: loss 0.744789\n",
      "batch 1364: loss 0.674712\n",
      "batch 1365: loss 0.776721\n",
      "batch 1366: loss 0.615738\n",
      "batch 1367: loss 0.828875\n",
      "batch 1368: loss 0.755856\n",
      "batch 1369: loss 0.607580\n",
      "batch 1370: loss 0.701601\n",
      "batch 1371: loss 0.773568\n",
      "batch 1372: loss 0.596885\n",
      "batch 1373: loss 0.737396\n",
      "batch 1374: loss 0.861376\n",
      "batch 1375: loss 0.536916\n",
      "batch 1376: loss 0.622733\n",
      "batch 1377: loss 0.617763\n",
      "batch 1378: loss 0.751337\n",
      "batch 1379: loss 0.792020\n",
      "batch 1380: loss 0.724661\n",
      "batch 1381: loss 0.829561\n",
      "batch 1382: loss 0.562052\n",
      "batch 1383: loss 0.680836\n",
      "batch 1384: loss 0.636776\n",
      "batch 1385: loss 0.750636\n",
      "batch 1386: loss 0.631477\n",
      "batch 1387: loss 0.768908\n",
      "batch 1388: loss 0.711467\n",
      "batch 1389: loss 0.669398\n",
      "batch 1390: loss 0.905664\n",
      "batch 1391: loss 0.648151\n",
      "batch 1392: loss 0.628942\n",
      "batch 1393: loss 0.570871\n",
      "batch 1394: loss 0.709901\n",
      "batch 1395: loss 0.505567\n",
      "batch 1396: loss 0.658448\n",
      "batch 1397: loss 0.603041\n",
      "batch 1398: loss 0.596987\n",
      "batch 1399: loss 0.807772\n",
      "batch 1400: loss 0.708404\n",
      "batch 1401: loss 0.722408\n",
      "batch 1402: loss 0.715018\n",
      "batch 1403: loss 0.750087\n",
      "batch 1404: loss 0.610354\n",
      "batch 1405: loss 0.708737\n",
      "batch 1406: loss 0.621242\n",
      "batch 1407: loss 0.751375\n",
      "batch 1408: loss 0.649589\n",
      "batch 1409: loss 0.694995\n",
      "batch 1410: loss 0.626773\n",
      "batch 1411: loss 0.549735\n",
      "batch 1412: loss 0.643172\n",
      "batch 1413: loss 0.604069\n",
      "batch 1414: loss 0.694523\n",
      "batch 1415: loss 0.676685\n",
      "batch 1416: loss 0.646771\n",
      "batch 1417: loss 0.576926\n",
      "batch 1418: loss 0.678835\n",
      "batch 1419: loss 0.718382\n",
      "batch 1420: loss 0.578656\n",
      "batch 1421: loss 0.783735\n",
      "batch 1422: loss 0.716195\n",
      "batch 1423: loss 0.678064\n",
      "batch 1424: loss 0.460300\n",
      "batch 1425: loss 0.591280\n",
      "batch 1426: loss 0.587419\n",
      "batch 1427: loss 0.842271\n",
      "batch 1428: loss 0.787220\n",
      "batch 1429: loss 0.717595\n",
      "batch 1430: loss 0.788498\n",
      "batch 1431: loss 0.686509\n",
      "batch 1432: loss 0.633404\n",
      "batch 1433: loss 0.562348\n",
      "batch 1434: loss 0.705247\n",
      "batch 1435: loss 0.770162\n",
      "batch 1436: loss 0.521972\n",
      "batch 1437: loss 0.839990\n",
      "batch 1438: loss 0.713633\n",
      "batch 1439: loss 0.668149\n",
      "batch 1440: loss 0.499108\n",
      "batch 1441: loss 0.796942\n",
      "batch 1442: loss 0.689572\n",
      "batch 1443: loss 0.644051\n",
      "batch 1444: loss 0.603992\n",
      "batch 1445: loss 0.497722\n",
      "batch 1446: loss 0.706422\n",
      "batch 1447: loss 0.656156\n",
      "batch 1448: loss 0.698122\n",
      "batch 1449: loss 0.780631\n",
      "batch 1450: loss 0.842305\n",
      "batch 1451: loss 0.557468\n",
      "batch 1452: loss 0.721729\n",
      "batch 1453: loss 0.873823\n",
      "batch 1454: loss 0.762432\n",
      "batch 1455: loss 0.717107\n",
      "batch 1456: loss 0.696015\n",
      "batch 1457: loss 0.542731\n",
      "batch 1458: loss 0.464448\n",
      "batch 1459: loss 0.756829\n",
      "batch 1460: loss 0.814249\n",
      "batch 1461: loss 0.703564\n",
      "batch 1462: loss 0.651567\n",
      "batch 1463: loss 0.754785\n",
      "batch 1464: loss 0.517369\n",
      "batch 1465: loss 0.599077\n",
      "batch 1466: loss 0.754306\n",
      "batch 1467: loss 0.579015\n",
      "batch 1468: loss 0.501020\n",
      "batch 1469: loss 0.752266\n",
      "batch 1470: loss 0.683799\n",
      "batch 1471: loss 0.600969\n",
      "batch 1472: loss 0.815451\n",
      "batch 1473: loss 0.796533\n",
      "batch 1474: loss 0.525600\n",
      "batch 1475: loss 0.619533\n",
      "batch 1476: loss 0.621706\n",
      "batch 1477: loss 0.755960\n",
      "batch 1478: loss 0.705989\n",
      "batch 1479: loss 0.526035\n",
      "batch 1480: loss 0.747409\n",
      "batch 1481: loss 0.786468\n",
      "batch 1482: loss 0.879694\n",
      "batch 1483: loss 0.623449\n",
      "batch 1484: loss 0.665485\n",
      "batch 1485: loss 0.590906\n",
      "batch 1486: loss 0.725483\n",
      "batch 1487: loss 0.480724\n",
      "batch 1488: loss 0.762142\n",
      "batch 1489: loss 0.800840\n",
      "batch 1490: loss 0.756332\n",
      "batch 1491: loss 0.646634\n",
      "batch 1492: loss 0.890889\n",
      "batch 1493: loss 0.700245\n",
      "batch 1494: loss 0.660683\n",
      "batch 1495: loss 0.822557\n",
      "batch 1496: loss 0.657443\n",
      "batch 1497: loss 0.615113\n",
      "batch 1498: loss 0.731348\n",
      "batch 1499: loss 0.531307\n",
      "batch 1500: loss 0.623032\n",
      "batch 1501: loss 0.624316\n",
      "batch 1502: loss 0.694338\n",
      "batch 1503: loss 0.548320\n",
      "batch 1504: loss 0.472512\n",
      "batch 1505: loss 0.656278\n",
      "batch 1506: loss 0.676137\n",
      "batch 1507: loss 0.628584\n",
      "batch 1508: loss 0.609434\n",
      "batch 1509: loss 0.624037\n",
      "batch 1510: loss 0.650860\n",
      "batch 1511: loss 0.658386\n",
      "batch 1512: loss 0.736712\n",
      "batch 1513: loss 0.666970\n",
      "batch 1514: loss 0.658593\n",
      "batch 1515: loss 0.629372\n",
      "batch 1516: loss 0.675273\n",
      "batch 1517: loss 0.714700\n",
      "batch 1518: loss 0.583515\n",
      "batch 1519: loss 0.729484\n",
      "batch 1520: loss 0.595770\n",
      "batch 1521: loss 0.511831\n",
      "batch 1522: loss 0.569828\n",
      "batch 1523: loss 0.442253\n",
      "batch 1524: loss 0.658145\n",
      "batch 1525: loss 0.647644\n",
      "batch 1526: loss 0.598667\n",
      "batch 1527: loss 0.441101\n",
      "batch 1528: loss 0.580074\n",
      "batch 1529: loss 0.751445\n",
      "batch 1530: loss 0.778014\n",
      "batch 1531: loss 0.587501\n",
      "batch 1532: loss 0.588349\n",
      "batch 1533: loss 0.611313\n",
      "batch 1534: loss 0.570956\n",
      "batch 1535: loss 0.621044\n",
      "batch 1536: loss 0.696066\n",
      "batch 1537: loss 0.591774\n",
      "batch 1538: loss 0.672767\n",
      "batch 1539: loss 0.761481\n",
      "batch 1540: loss 0.644344\n",
      "batch 1541: loss 0.570004\n",
      "batch 1542: loss 0.635054\n",
      "batch 1543: loss 0.645925\n",
      "batch 1544: loss 0.663395\n",
      "batch 1545: loss 0.841303\n",
      "batch 1546: loss 0.717959\n",
      "batch 1547: loss 0.678591\n",
      "batch 1548: loss 0.599871\n",
      "batch 1549: loss 0.703979\n",
      "batch 1550: loss 0.749055\n",
      "batch 1551: loss 0.642505\n",
      "batch 1552: loss 0.513218\n",
      "batch 1553: loss 0.656672\n",
      "batch 1554: loss 0.545912\n",
      "batch 1555: loss 0.574352\n",
      "batch 1556: loss 0.678791\n",
      "batch 1557: loss 0.580948\n",
      "batch 1558: loss 0.627053\n",
      "batch 1559: loss 0.608963\n",
      "batch 1560: loss 0.566672\n",
      "batch 1561: loss 0.627267\n",
      "batch 1562: loss 0.837000\n",
      "batch 1563: loss 0.681563\n",
      "batch 1564: loss 0.725827\n",
      "batch 1565: loss 0.578611\n",
      "batch 1566: loss 0.970266\n",
      "batch 1567: loss 0.597697\n",
      "batch 1568: loss 0.635449\n",
      "batch 1569: loss 0.502991\n",
      "batch 1570: loss 0.732719\n",
      "batch 1571: loss 0.638790\n",
      "batch 1572: loss 0.562153\n",
      "batch 1573: loss 0.577189\n",
      "batch 1574: loss 0.541098\n",
      "batch 1575: loss 0.622832\n",
      "batch 1576: loss 0.687200\n",
      "batch 1577: loss 0.625368\n",
      "batch 1578: loss 0.486964\n",
      "batch 1579: loss 0.684518\n",
      "batch 1580: loss 0.617913\n",
      "batch 1581: loss 0.569799\n",
      "batch 1582: loss 0.568716\n",
      "batch 1583: loss 0.703378\n",
      "batch 1584: loss 0.458850\n",
      "batch 1585: loss 0.844496\n",
      "batch 1586: loss 0.647644\n",
      "batch 1587: loss 0.769927\n",
      "batch 1588: loss 0.630552\n",
      "batch 1589: loss 0.760597\n",
      "batch 1590: loss 0.763352\n",
      "batch 1591: loss 0.769891\n",
      "batch 1592: loss 0.715289\n",
      "batch 1593: loss 0.711430\n",
      "batch 1594: loss 0.600944\n",
      "batch 1595: loss 0.663244\n",
      "batch 1596: loss 0.599438\n",
      "batch 1597: loss 0.636758\n",
      "batch 1598: loss 0.628215\n",
      "batch 1599: loss 0.669351\n",
      "batch 1600: loss 0.502254\n",
      "batch 1601: loss 0.546330\n",
      "batch 1602: loss 0.808271\n",
      "batch 1603: loss 0.662753\n",
      "batch 1604: loss 0.654759\n",
      "batch 1605: loss 0.581655\n",
      "batch 1606: loss 0.615290\n",
      "batch 1607: loss 0.649403\n",
      "batch 1608: loss 0.696508\n",
      "batch 1609: loss 0.599983\n",
      "batch 1610: loss 0.620200\n",
      "batch 1611: loss 0.471715\n",
      "batch 1612: loss 0.556386\n",
      "batch 1613: loss 0.622232\n",
      "batch 1614: loss 0.711071\n",
      "batch 1615: loss 0.558944\n",
      "batch 1616: loss 0.714186\n",
      "batch 1617: loss 0.597988\n",
      "batch 1618: loss 0.521839\n",
      "batch 1619: loss 0.550909\n",
      "batch 1620: loss 0.662380\n",
      "batch 1621: loss 0.528786\n",
      "batch 1622: loss 0.582356\n",
      "batch 1623: loss 0.644804\n",
      "batch 1624: loss 0.648225\n",
      "batch 1625: loss 0.652386\n",
      "batch 1626: loss 0.699257\n",
      "batch 1627: loss 0.734339\n",
      "batch 1628: loss 0.570358\n",
      "batch 1629: loss 0.559813\n",
      "batch 1630: loss 0.522395\n",
      "batch 1631: loss 0.633250\n",
      "batch 1632: loss 0.715715\n",
      "batch 1633: loss 0.704918\n",
      "batch 1634: loss 0.619567\n",
      "batch 1635: loss 0.726294\n",
      "batch 1636: loss 0.620645\n",
      "batch 1637: loss 0.682774\n",
      "batch 1638: loss 0.640745\n",
      "batch 1639: loss 0.775123\n",
      "batch 1640: loss 0.628724\n",
      "batch 1641: loss 0.649133\n",
      "batch 1642: loss 0.691881\n",
      "batch 1643: loss 0.611707\n",
      "batch 1644: loss 0.755426\n",
      "batch 1645: loss 0.678164\n",
      "batch 1646: loss 0.564952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1647: loss 0.575888\n",
      "batch 1648: loss 0.566537\n",
      "batch 1649: loss 0.852583\n",
      "batch 1650: loss 0.509603\n",
      "batch 1651: loss 0.515211\n",
      "batch 1652: loss 0.616841\n",
      "batch 1653: loss 0.808108\n",
      "batch 1654: loss 0.688520\n",
      "batch 1655: loss 0.421160\n",
      "batch 1656: loss 0.564218\n",
      "batch 1657: loss 0.505799\n",
      "batch 1658: loss 0.482542\n",
      "batch 1659: loss 0.615862\n",
      "batch 1660: loss 0.582146\n",
      "batch 1661: loss 0.726576\n",
      "batch 1662: loss 0.584119\n",
      "batch 1663: loss 0.650148\n",
      "batch 1664: loss 0.838927\n",
      "batch 1665: loss 0.644927\n",
      "batch 1666: loss 0.740786\n",
      "batch 1667: loss 0.589867\n",
      "batch 1668: loss 0.644680\n",
      "batch 1669: loss 0.757301\n",
      "batch 1670: loss 0.507625\n",
      "batch 1671: loss 0.545814\n",
      "batch 1672: loss 0.590056\n",
      "batch 1673: loss 0.498751\n",
      "batch 1674: loss 0.653624\n",
      "batch 1675: loss 0.527967\n",
      "batch 1676: loss 0.542075\n",
      "batch 1677: loss 0.592759\n",
      "batch 1678: loss 0.513007\n",
      "batch 1679: loss 0.735367\n",
      "batch 1680: loss 0.599252\n",
      "batch 1681: loss 0.549289\n",
      "batch 1682: loss 0.762347\n",
      "batch 1683: loss 0.750583\n",
      "batch 1684: loss 0.776802\n",
      "batch 1685: loss 0.726856\n",
      "batch 1686: loss 0.544828\n",
      "batch 1687: loss 0.615063\n",
      "batch 1688: loss 0.515835\n",
      "batch 1689: loss 0.644186\n",
      "batch 1690: loss 0.633340\n",
      "batch 1691: loss 0.579554\n",
      "batch 1692: loss 0.728807\n",
      "batch 1693: loss 0.569988\n",
      "batch 1694: loss 0.627669\n",
      "batch 1695: loss 0.669993\n",
      "batch 1696: loss 0.679692\n",
      "batch 1697: loss 0.502384\n",
      "batch 1698: loss 0.712716\n",
      "batch 1699: loss 0.581165\n",
      "batch 1700: loss 0.622077\n",
      "batch 1701: loss 0.767448\n",
      "batch 1702: loss 0.526321\n",
      "batch 1703: loss 0.759426\n",
      "batch 1704: loss 0.700301\n",
      "batch 1705: loss 0.694617\n",
      "batch 1706: loss 0.793826\n",
      "batch 1707: loss 0.694334\n",
      "batch 1708: loss 0.467031\n",
      "batch 1709: loss 0.654804\n",
      "batch 1710: loss 0.520199\n",
      "batch 1711: loss 0.481309\n",
      "batch 1712: loss 0.664015\n",
      "batch 1713: loss 0.467063\n",
      "batch 1714: loss 0.606035\n",
      "batch 1715: loss 0.562001\n",
      "batch 1716: loss 0.464325\n",
      "batch 1717: loss 0.580367\n",
      "batch 1718: loss 0.571243\n",
      "batch 1719: loss 0.919046\n",
      "batch 1720: loss 0.667366\n",
      "batch 1721: loss 0.565888\n",
      "batch 1722: loss 0.575768\n",
      "batch 1723: loss 0.537399\n",
      "batch 1724: loss 0.436845\n",
      "batch 1725: loss 0.563116\n",
      "batch 1726: loss 0.720334\n",
      "batch 1727: loss 0.498062\n",
      "batch 1728: loss 0.628123\n",
      "batch 1729: loss 0.703831\n",
      "batch 1730: loss 0.694661\n",
      "batch 1731: loss 0.513872\n",
      "batch 1732: loss 0.608312\n",
      "batch 1733: loss 0.734817\n",
      "batch 1734: loss 0.608017\n",
      "batch 1735: loss 0.546625\n",
      "batch 1736: loss 0.659200\n",
      "batch 1737: loss 0.607265\n",
      "batch 1738: loss 0.531302\n",
      "batch 1739: loss 0.496454\n",
      "batch 1740: loss 0.596814\n",
      "batch 1741: loss 0.475288\n",
      "batch 1742: loss 0.567858\n",
      "batch 1743: loss 0.532354\n",
      "batch 1744: loss 0.545312\n",
      "batch 1745: loss 0.686685\n",
      "batch 1746: loss 0.481082\n",
      "batch 1747: loss 0.451046\n",
      "batch 1748: loss 0.552381\n",
      "batch 1749: loss 0.476502\n",
      "batch 1750: loss 0.507019\n",
      "batch 1751: loss 0.626632\n",
      "batch 1752: loss 0.529721\n",
      "batch 1753: loss 0.623603\n",
      "batch 1754: loss 0.592020\n",
      "batch 1755: loss 0.729679\n",
      "batch 1756: loss 0.415656\n",
      "batch 1757: loss 0.653157\n",
      "batch 1758: loss 0.579259\n",
      "batch 1759: loss 0.782119\n",
      "batch 1760: loss 0.592144\n",
      "batch 1761: loss 0.432356\n",
      "batch 1762: loss 0.690083\n",
      "batch 1763: loss 0.583007\n",
      "batch 1764: loss 0.519000\n",
      "batch 1765: loss 0.446739\n",
      "batch 1766: loss 0.595007\n",
      "batch 1767: loss 0.723540\n",
      "batch 1768: loss 0.614854\n",
      "batch 1769: loss 0.649887\n",
      "batch 1770: loss 0.498271\n",
      "batch 1771: loss 0.532456\n",
      "batch 1772: loss 0.667822\n",
      "batch 1773: loss 0.502627\n",
      "batch 1774: loss 0.446054\n",
      "batch 1775: loss 0.526401\n",
      "batch 1776: loss 0.797091\n",
      "batch 1777: loss 0.687419\n",
      "batch 1778: loss 0.601284\n",
      "batch 1779: loss 0.437162\n",
      "batch 1780: loss 0.531689\n",
      "batch 1781: loss 0.669482\n",
      "batch 1782: loss 0.660690\n",
      "batch 1783: loss 0.491361\n",
      "batch 1784: loss 0.539328\n",
      "batch 1785: loss 0.496572\n",
      "batch 1786: loss 0.736612\n",
      "batch 1787: loss 0.582314\n",
      "batch 1788: loss 0.552601\n",
      "batch 1789: loss 0.543485\n",
      "batch 1790: loss 0.644851\n",
      "batch 1791: loss 0.587916\n",
      "batch 1792: loss 0.632319\n",
      "batch 1793: loss 0.490749\n",
      "batch 1794: loss 0.537020\n",
      "batch 1795: loss 0.661979\n",
      "batch 1796: loss 0.517655\n",
      "batch 1797: loss 0.458940\n",
      "batch 1798: loss 0.596970\n",
      "batch 1799: loss 0.513654\n",
      "batch 1800: loss 0.500892\n",
      "batch 1801: loss 0.529956\n",
      "batch 1802: loss 0.496635\n",
      "batch 1803: loss 0.667751\n",
      "batch 1804: loss 0.514054\n",
      "batch 1805: loss 0.691175\n",
      "batch 1806: loss 0.513799\n",
      "batch 1807: loss 0.665382\n",
      "batch 1808: loss 0.693734\n",
      "batch 1809: loss 0.518650\n",
      "batch 1810: loss 0.600493\n",
      "batch 1811: loss 0.710972\n",
      "batch 1812: loss 0.610134\n",
      "batch 1813: loss 0.703983\n",
      "batch 1814: loss 0.571299\n",
      "batch 1815: loss 0.691945\n",
      "batch 1816: loss 0.423378\n",
      "batch 1817: loss 0.557197\n",
      "batch 1818: loss 0.638005\n",
      "batch 1819: loss 0.546993\n",
      "batch 1820: loss 0.447241\n",
      "batch 1821: loss 0.679917\n",
      "batch 1822: loss 0.432514\n",
      "batch 1823: loss 0.474471\n",
      "batch 1824: loss 0.656246\n",
      "batch 1825: loss 0.457837\n",
      "batch 1826: loss 0.629412\n",
      "batch 1827: loss 0.568631\n",
      "batch 1828: loss 0.600581\n",
      "batch 1829: loss 0.638429\n",
      "batch 1830: loss 0.557708\n",
      "batch 1831: loss 0.555363\n",
      "batch 1832: loss 0.483839\n",
      "batch 1833: loss 0.563823\n",
      "batch 1834: loss 0.558506\n",
      "batch 1835: loss 0.582365\n",
      "batch 1836: loss 0.739039\n",
      "batch 1837: loss 0.511160\n",
      "batch 1838: loss 0.520118\n",
      "batch 1839: loss 0.590091\n",
      "batch 1840: loss 0.661523\n",
      "batch 1841: loss 0.871841\n",
      "batch 1842: loss 0.566404\n",
      "batch 1843: loss 0.480674\n",
      "batch 1844: loss 0.565678\n",
      "batch 1845: loss 0.746597\n",
      "batch 1846: loss 0.484007\n",
      "batch 1847: loss 0.365334\n",
      "batch 1848: loss 0.762616\n",
      "batch 1849: loss 0.513880\n",
      "batch 1850: loss 0.485173\n",
      "batch 1851: loss 0.528503\n",
      "batch 1852: loss 0.542680\n",
      "batch 1853: loss 0.444735\n",
      "batch 1854: loss 0.706156\n",
      "batch 1855: loss 0.683546\n",
      "batch 1856: loss 0.615943\n",
      "batch 1857: loss 0.422208\n",
      "batch 1858: loss 0.501743\n",
      "batch 1859: loss 0.507936\n",
      "batch 1860: loss 0.531062\n",
      "batch 1861: loss 0.499000\n",
      "batch 1862: loss 0.410688\n",
      "batch 1863: loss 0.771211\n",
      "batch 1864: loss 0.706154\n",
      "batch 1865: loss 0.709988\n",
      "batch 1866: loss 0.428246\n",
      "batch 1867: loss 0.463028\n",
      "batch 1868: loss 0.375699\n",
      "batch 1869: loss 0.545305\n",
      "batch 1870: loss 0.474478\n",
      "batch 1871: loss 0.691676\n",
      "batch 1872: loss 0.454203\n",
      "batch 1873: loss 0.484289\n",
      "batch 1874: loss 0.547834\n",
      "batch 1875: loss 0.467016\n",
      "batch 1876: loss 0.639102\n",
      "batch 1877: loss 0.714387\n",
      "batch 1878: loss 0.702761\n",
      "batch 1879: loss 0.608862\n",
      "batch 1880: loss 0.514277\n",
      "batch 1881: loss 0.413850\n",
      "batch 1882: loss 0.765721\n",
      "batch 1883: loss 0.683495\n",
      "batch 1884: loss 0.585397\n",
      "batch 1885: loss 0.597999\n",
      "batch 1886: loss 0.643937\n",
      "batch 1887: loss 0.482676\n",
      "batch 1888: loss 0.421776\n",
      "batch 1889: loss 0.513423\n",
      "batch 1890: loss 0.455512\n",
      "batch 1891: loss 0.556018\n",
      "batch 1892: loss 0.428976\n",
      "batch 1893: loss 0.505432\n",
      "batch 1894: loss 0.674456\n",
      "batch 1895: loss 0.482803\n",
      "batch 1896: loss 0.599801\n",
      "batch 1897: loss 0.781589\n",
      "batch 1898: loss 0.352262\n",
      "batch 1899: loss 0.457299\n",
      "batch 1900: loss 0.593368\n",
      "batch 1901: loss 0.479803\n",
      "batch 1902: loss 0.627084\n",
      "batch 1903: loss 0.526689\n",
      "batch 1904: loss 0.477756\n",
      "batch 1905: loss 0.646364\n",
      "batch 1906: loss 0.605921\n",
      "batch 1907: loss 0.606872\n",
      "batch 1908: loss 0.524728\n",
      "batch 1909: loss 0.507075\n",
      "batch 1910: loss 0.470550\n",
      "batch 1911: loss 0.783222\n",
      "batch 1912: loss 0.648308\n",
      "batch 1913: loss 0.543060\n",
      "batch 1914: loss 0.475366\n",
      "batch 1915: loss 0.571529\n",
      "batch 1916: loss 0.575126\n",
      "batch 1917: loss 0.611083\n",
      "batch 1918: loss 0.501136\n",
      "batch 1919: loss 0.554368\n",
      "batch 1920: loss 0.495511\n",
      "batch 1921: loss 0.524381\n",
      "batch 1922: loss 0.635557\n",
      "batch 1923: loss 0.530622\n",
      "batch 1924: loss 0.499929\n",
      "batch 1925: loss 0.404496\n",
      "batch 1926: loss 0.423199\n",
      "batch 1927: loss 0.490731\n",
      "batch 1928: loss 0.432979\n",
      "batch 1929: loss 0.532783\n",
      "batch 1930: loss 0.470396\n",
      "batch 1931: loss 0.706331\n",
      "batch 1932: loss 0.549665\n",
      "batch 1933: loss 0.607561\n",
      "batch 1934: loss 0.653730\n",
      "batch 1935: loss 0.699736\n",
      "batch 1936: loss 0.480241\n",
      "batch 1937: loss 0.671391\n",
      "batch 1938: loss 0.683515\n",
      "batch 1939: loss 0.805350\n",
      "batch 1940: loss 0.489787\n",
      "batch 1941: loss 0.637266\n",
      "batch 1942: loss 0.471195\n",
      "batch 1943: loss 0.613217\n",
      "batch 1944: loss 0.456765\n",
      "batch 1945: loss 0.530985\n",
      "batch 1946: loss 0.517902\n",
      "batch 1947: loss 0.580635\n",
      "batch 1948: loss 0.546292\n",
      "batch 1949: loss 0.612391\n",
      "batch 1950: loss 0.501412\n",
      "batch 1951: loss 0.408663\n",
      "batch 1952: loss 0.594961\n",
      "batch 1953: loss 0.545789\n",
      "batch 1954: loss 0.494202\n",
      "batch 1955: loss 0.609769\n",
      "batch 1956: loss 0.593048\n",
      "batch 1957: loss 0.436607\n",
      "batch 1958: loss 0.632355\n",
      "batch 1959: loss 0.507058\n",
      "batch 1960: loss 0.738699\n",
      "batch 1961: loss 0.514277\n",
      "batch 1962: loss 0.384992\n",
      "batch 1963: loss 0.525100\n",
      "batch 1964: loss 0.573949\n",
      "batch 1965: loss 0.372317\n",
      "batch 1966: loss 0.588729\n",
      "batch 1967: loss 0.332701\n",
      "batch 1968: loss 0.523207\n",
      "batch 1969: loss 0.501622\n",
      "batch 1970: loss 0.509701\n",
      "batch 1971: loss 0.599839\n",
      "batch 1972: loss 0.549223\n",
      "batch 1973: loss 0.574701\n",
      "batch 1974: loss 0.686581\n",
      "batch 1975: loss 0.546050\n",
      "batch 1976: loss 0.652032\n",
      "batch 1977: loss 0.496060\n",
      "batch 1978: loss 0.706425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1979: loss 0.749557\n",
      "batch 1980: loss 0.490687\n",
      "batch 1981: loss 0.510103\n",
      "batch 1982: loss 0.536599\n",
      "batch 1983: loss 0.469121\n",
      "batch 1984: loss 0.497206\n",
      "batch 1985: loss 0.472424\n",
      "batch 1986: loss 0.389275\n",
      "batch 1987: loss 0.501917\n",
      "batch 1988: loss 0.352632\n",
      "batch 1989: loss 0.564049\n",
      "batch 1990: loss 0.527379\n",
      "batch 1991: loss 0.500119\n",
      "batch 1992: loss 0.480271\n",
      "batch 1993: loss 0.627980\n",
      "batch 1994: loss 0.480041\n",
      "batch 1995: loss 0.565999\n",
      "batch 1996: loss 0.641105\n",
      "batch 1997: loss 0.508551\n",
      "batch 1998: loss 0.481240\n",
      "batch 1999: loss 0.481201\n",
      "batch 2000: loss 0.495671\n",
      "batch 2001: loss 0.544312\n",
      "batch 2002: loss 0.345390\n",
      "batch 2003: loss 0.375512\n",
      "batch 2004: loss 0.654940\n",
      "batch 2005: loss 0.370940\n",
      "batch 2006: loss 0.592065\n",
      "batch 2007: loss 0.617299\n",
      "batch 2008: loss 0.435508\n",
      "batch 2009: loss 0.593200\n",
      "batch 2010: loss 0.597404\n",
      "batch 2011: loss 0.689003\n",
      "batch 2012: loss 0.523281\n",
      "batch 2013: loss 0.481638\n",
      "batch 2014: loss 0.456115\n",
      "batch 2015: loss 0.491198\n",
      "batch 2016: loss 0.747737\n",
      "batch 2017: loss 0.603222\n",
      "batch 2018: loss 0.681029\n",
      "batch 2019: loss 0.411907\n",
      "batch 2020: loss 0.530711\n",
      "batch 2021: loss 0.507561\n",
      "batch 2022: loss 0.708214\n",
      "batch 2023: loss 0.660733\n",
      "batch 2024: loss 0.772038\n",
      "batch 2025: loss 0.540779\n",
      "batch 2026: loss 0.444505\n",
      "batch 2027: loss 0.554787\n",
      "batch 2028: loss 0.708633\n",
      "batch 2029: loss 0.601139\n",
      "batch 2030: loss 0.537831\n",
      "batch 2031: loss 0.716718\n",
      "batch 2032: loss 0.448114\n",
      "batch 2033: loss 0.807445\n",
      "batch 2034: loss 0.613215\n",
      "batch 2035: loss 0.609434\n",
      "batch 2036: loss 0.494927\n",
      "batch 2037: loss 0.467468\n",
      "batch 2038: loss 0.507315\n",
      "batch 2039: loss 0.491150\n",
      "batch 2040: loss 0.408236\n",
      "batch 2041: loss 0.510449\n",
      "batch 2042: loss 0.610542\n",
      "batch 2043: loss 0.638513\n",
      "batch 2044: loss 0.604101\n",
      "batch 2045: loss 0.598951\n",
      "batch 2046: loss 0.705558\n",
      "batch 2047: loss 0.418867\n",
      "batch 2048: loss 0.603086\n",
      "batch 2049: loss 0.547930\n",
      "batch 2050: loss 0.474832\n",
      "batch 2051: loss 0.713609\n",
      "batch 2052: loss 0.523555\n",
      "batch 2053: loss 0.549029\n",
      "batch 2054: loss 0.756207\n",
      "batch 2055: loss 0.503949\n",
      "batch 2056: loss 0.627422\n",
      "batch 2057: loss 0.563340\n",
      "batch 2058: loss 0.539096\n",
      "batch 2059: loss 0.533102\n",
      "batch 2060: loss 0.435039\n",
      "batch 2061: loss 0.466443\n",
      "batch 2062: loss 0.547460\n",
      "batch 2063: loss 0.422053\n",
      "batch 2064: loss 0.608648\n",
      "batch 2065: loss 0.540021\n",
      "batch 2066: loss 0.571486\n",
      "batch 2067: loss 0.499778\n",
      "batch 2068: loss 0.575723\n",
      "batch 2069: loss 0.437699\n",
      "batch 2070: loss 0.606581\n",
      "batch 2071: loss 0.558036\n",
      "batch 2072: loss 0.469616\n",
      "batch 2073: loss 0.765011\n",
      "batch 2074: loss 0.370450\n",
      "batch 2075: loss 0.395276\n",
      "batch 2076: loss 0.572410\n",
      "batch 2077: loss 0.492800\n",
      "batch 2078: loss 0.743026\n",
      "batch 2079: loss 0.725625\n",
      "batch 2080: loss 0.397681\n",
      "batch 2081: loss 0.478567\n",
      "batch 2082: loss 0.462957\n",
      "batch 2083: loss 0.527462\n",
      "batch 2084: loss 0.491943\n",
      "batch 2085: loss 0.602338\n",
      "batch 2086: loss 0.485821\n",
      "batch 2087: loss 0.807859\n",
      "batch 2088: loss 0.632490\n",
      "batch 2089: loss 0.458812\n",
      "batch 2090: loss 0.655311\n",
      "batch 2091: loss 0.451785\n",
      "batch 2092: loss 0.645091\n",
      "batch 2093: loss 0.489542\n",
      "batch 2094: loss 0.534497\n",
      "batch 2095: loss 0.531109\n",
      "batch 2096: loss 0.547357\n",
      "batch 2097: loss 0.634916\n",
      "batch 2098: loss 0.497241\n",
      "batch 2099: loss 0.479569\n",
      "batch 2100: loss 0.627282\n",
      "batch 2101: loss 0.407286\n",
      "batch 2102: loss 0.477272\n",
      "batch 2103: loss 0.547614\n",
      "batch 2104: loss 0.534184\n",
      "batch 2105: loss 0.532312\n",
      "batch 2106: loss 0.588803\n",
      "batch 2107: loss 0.630658\n",
      "batch 2108: loss 0.311815\n",
      "batch 2109: loss 0.406109\n",
      "batch 2110: loss 0.611868\n",
      "batch 2111: loss 0.514455\n",
      "batch 2112: loss 0.462618\n",
      "batch 2113: loss 0.659959\n",
      "batch 2114: loss 0.434408\n",
      "batch 2115: loss 0.546372\n",
      "batch 2116: loss 0.330193\n",
      "batch 2117: loss 0.592931\n",
      "batch 2118: loss 0.471827\n",
      "batch 2119: loss 0.558676\n",
      "batch 2120: loss 0.436214\n",
      "batch 2121: loss 0.779782\n",
      "batch 2122: loss 0.482311\n",
      "batch 2123: loss 0.369660\n",
      "batch 2124: loss 0.627745\n",
      "batch 2125: loss 0.371633\n",
      "batch 2126: loss 0.567719\n",
      "batch 2127: loss 0.587993\n",
      "batch 2128: loss 0.524125\n",
      "batch 2129: loss 0.707692\n",
      "batch 2130: loss 0.450464\n",
      "batch 2131: loss 0.515528\n",
      "batch 2132: loss 0.472073\n",
      "batch 2133: loss 0.637212\n",
      "batch 2134: loss 0.596404\n",
      "batch 2135: loss 0.536300\n",
      "batch 2136: loss 0.629777\n",
      "batch 2137: loss 0.400935\n",
      "batch 2138: loss 0.452839\n",
      "batch 2139: loss 0.644355\n",
      "batch 2140: loss 0.606700\n",
      "batch 2141: loss 0.424272\n",
      "batch 2142: loss 0.608286\n",
      "batch 2143: loss 0.501521\n",
      "batch 2144: loss 0.490300\n",
      "batch 2145: loss 0.531317\n",
      "batch 2146: loss 0.395964\n",
      "batch 2147: loss 0.749183\n",
      "batch 2148: loss 0.553654\n",
      "batch 2149: loss 0.593985\n",
      "batch 2150: loss 0.489989\n",
      "batch 2151: loss 0.559651\n",
      "batch 2152: loss 0.491839\n",
      "batch 2153: loss 0.528173\n",
      "batch 2154: loss 0.507506\n",
      "batch 2155: loss 0.548002\n",
      "batch 2156: loss 0.485770\n",
      "batch 2157: loss 0.481641\n",
      "batch 2158: loss 0.609295\n",
      "batch 2159: loss 0.454789\n",
      "batch 2160: loss 0.363172\n",
      "batch 2161: loss 0.467477\n",
      "batch 2162: loss 0.544844\n",
      "batch 2163: loss 0.522167\n",
      "batch 2164: loss 0.579584\n",
      "batch 2165: loss 0.526001\n",
      "batch 2166: loss 0.447432\n",
      "batch 2167: loss 0.529682\n",
      "batch 2168: loss 0.437784\n",
      "batch 2169: loss 0.375747\n",
      "batch 2170: loss 0.582454\n",
      "batch 2171: loss 0.571560\n",
      "batch 2172: loss 0.742208\n",
      "batch 2173: loss 0.586839\n",
      "batch 2174: loss 0.599341\n",
      "batch 2175: loss 0.388096\n",
      "batch 2176: loss 0.656161\n",
      "batch 2177: loss 0.503089\n",
      "batch 2178: loss 0.415428\n",
      "batch 2179: loss 0.445023\n",
      "batch 2180: loss 0.435283\n",
      "batch 2181: loss 0.440573\n",
      "batch 2182: loss 0.377801\n",
      "batch 2183: loss 0.497091\n",
      "batch 2184: loss 0.575221\n",
      "batch 2185: loss 0.452388\n",
      "batch 2186: loss 0.500107\n",
      "batch 2187: loss 0.566848\n",
      "batch 2188: loss 0.812253\n",
      "batch 2189: loss 0.434490\n",
      "batch 2190: loss 0.631728\n",
      "batch 2191: loss 0.448664\n",
      "batch 2192: loss 0.641395\n",
      "batch 2193: loss 0.492867\n",
      "batch 2194: loss 0.606202\n",
      "batch 2195: loss 0.458072\n",
      "batch 2196: loss 0.508400\n",
      "batch 2197: loss 0.459311\n",
      "batch 2198: loss 0.571169\n",
      "batch 2199: loss 0.488049\n",
      "batch 2200: loss 0.530173\n",
      "batch 2201: loss 0.637366\n",
      "batch 2202: loss 0.504293\n",
      "batch 2203: loss 0.473367\n",
      "batch 2204: loss 0.521979\n",
      "batch 2205: loss 0.472053\n",
      "batch 2206: loss 0.623175\n",
      "batch 2207: loss 0.449219\n",
      "batch 2208: loss 0.435800\n",
      "batch 2209: loss 0.509614\n",
      "batch 2210: loss 0.822854\n",
      "batch 2211: loss 0.664593\n",
      "batch 2212: loss 0.492935\n",
      "batch 2213: loss 0.400487\n",
      "batch 2214: loss 0.385326\n",
      "batch 2215: loss 0.507059\n",
      "batch 2216: loss 0.445850\n",
      "batch 2217: loss 0.553668\n",
      "batch 2218: loss 0.567433\n",
      "batch 2219: loss 0.576080\n",
      "batch 2220: loss 0.445994\n",
      "batch 2221: loss 0.396503\n",
      "batch 2222: loss 0.607349\n",
      "batch 2223: loss 0.446597\n",
      "batch 2224: loss 0.523156\n",
      "batch 2225: loss 0.472916\n",
      "batch 2226: loss 0.667375\n",
      "batch 2227: loss 0.366839\n",
      "batch 2228: loss 0.431498\n",
      "batch 2229: loss 0.546371\n",
      "batch 2230: loss 0.657504\n",
      "batch 2231: loss 0.479313\n",
      "batch 2232: loss 0.498976\n",
      "batch 2233: loss 0.649539\n",
      "batch 2234: loss 0.599238\n",
      "batch 2235: loss 0.441298\n",
      "batch 2236: loss 0.445415\n",
      "batch 2237: loss 0.493220\n",
      "batch 2238: loss 0.570084\n",
      "batch 2239: loss 0.543769\n",
      "batch 2240: loss 0.352798\n",
      "batch 2241: loss 0.617730\n",
      "batch 2242: loss 0.518401\n",
      "batch 2243: loss 0.486868\n",
      "batch 2244: loss 0.634831\n",
      "batch 2245: loss 0.567291\n",
      "batch 2246: loss 0.468032\n",
      "batch 2247: loss 0.563767\n",
      "batch 2248: loss 0.517551\n",
      "batch 2249: loss 0.468913\n",
      "batch 2250: loss 0.401489\n",
      "batch 2251: loss 0.639738\n",
      "batch 2252: loss 0.470654\n",
      "batch 2253: loss 0.384452\n",
      "batch 2254: loss 0.576129\n",
      "batch 2255: loss 0.644523\n",
      "batch 2256: loss 0.542845\n",
      "batch 2257: loss 0.387451\n",
      "batch 2258: loss 0.461750\n",
      "batch 2259: loss 0.550431\n",
      "batch 2260: loss 0.490084\n",
      "batch 2261: loss 0.539074\n",
      "batch 2262: loss 0.424087\n",
      "batch 2263: loss 0.422329\n",
      "batch 2264: loss 0.610769\n",
      "batch 2265: loss 0.589461\n",
      "batch 2266: loss 0.516261\n",
      "batch 2267: loss 0.881356\n",
      "batch 2268: loss 0.407404\n",
      "batch 2269: loss 0.465663\n",
      "batch 2270: loss 0.711298\n",
      "batch 2271: loss 0.445076\n",
      "batch 2272: loss 0.610139\n",
      "batch 2273: loss 0.530736\n",
      "batch 2274: loss 0.416642\n",
      "batch 2275: loss 0.521226\n",
      "batch 2276: loss 0.455048\n",
      "batch 2277: loss 0.468827\n",
      "batch 2278: loss 0.321044\n",
      "batch 2279: loss 0.530516\n",
      "batch 2280: loss 0.569077\n",
      "batch 2281: loss 0.352978\n",
      "batch 2282: loss 0.516683\n",
      "batch 2283: loss 0.501262\n",
      "batch 2284: loss 0.448370\n",
      "batch 2285: loss 0.512568\n",
      "batch 2286: loss 0.391979\n",
      "batch 2287: loss 0.472519\n",
      "batch 2288: loss 0.641440\n",
      "batch 2289: loss 0.433367\n",
      "batch 2290: loss 0.470443\n",
      "batch 2291: loss 0.501753\n",
      "batch 2292: loss 0.484469\n",
      "batch 2293: loss 0.387085\n",
      "batch 2294: loss 0.538145\n",
      "batch 2295: loss 0.784069\n",
      "batch 2296: loss 0.548295\n",
      "batch 2297: loss 0.724287\n",
      "batch 2298: loss 0.449365\n",
      "batch 2299: loss 0.413208\n",
      "batch 2300: loss 0.465062\n",
      "batch 2301: loss 0.480218\n",
      "batch 2302: loss 0.560227\n",
      "batch 2303: loss 0.506488\n",
      "batch 2304: loss 0.559531\n",
      "batch 2305: loss 0.720807\n",
      "batch 2306: loss 0.505264\n",
      "batch 2307: loss 0.536769\n",
      "batch 2308: loss 0.551935\n",
      "batch 2309: loss 0.687543\n",
      "batch 2310: loss 0.381837\n",
      "batch 2311: loss 0.475467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2312: loss 0.423153\n",
      "batch 2313: loss 0.530026\n",
      "batch 2314: loss 0.382237\n",
      "batch 2315: loss 0.684850\n",
      "batch 2316: loss 0.473524\n",
      "batch 2317: loss 0.558720\n",
      "batch 2318: loss 0.479632\n",
      "batch 2319: loss 0.659803\n",
      "batch 2320: loss 0.378776\n",
      "batch 2321: loss 0.606426\n",
      "batch 2322: loss 0.619408\n",
      "batch 2323: loss 0.417759\n",
      "batch 2324: loss 0.473819\n",
      "batch 2325: loss 0.397069\n",
      "batch 2326: loss 0.589830\n",
      "batch 2327: loss 0.643786\n",
      "batch 2328: loss 0.563173\n",
      "batch 2329: loss 0.546069\n",
      "batch 2330: loss 0.481209\n",
      "batch 2331: loss 0.673139\n",
      "batch 2332: loss 0.606036\n",
      "batch 2333: loss 0.752144\n",
      "batch 2334: loss 0.355222\n",
      "batch 2335: loss 0.565494\n",
      "batch 2336: loss 0.614276\n",
      "batch 2337: loss 0.547794\n",
      "batch 2338: loss 0.742819\n",
      "batch 2339: loss 0.493450\n",
      "batch 2340: loss 0.574988\n",
      "batch 2341: loss 0.631656\n",
      "batch 2342: loss 0.440691\n",
      "batch 2343: loss 0.480379\n",
      "batch 2344: loss 0.423455\n",
      "batch 2345: loss 0.469851\n",
      "batch 2346: loss 0.498084\n",
      "batch 2347: loss 0.478952\n",
      "batch 2348: loss 0.389382\n",
      "batch 2349: loss 0.474937\n",
      "batch 2350: loss 0.431220\n",
      "batch 2351: loss 0.667134\n",
      "batch 2352: loss 0.459846\n",
      "batch 2353: loss 0.462286\n",
      "batch 2354: loss 0.592386\n",
      "batch 2355: loss 0.537487\n",
      "batch 2356: loss 0.404540\n",
      "batch 2357: loss 0.382269\n",
      "batch 2358: loss 0.562834\n",
      "batch 2359: loss 0.574653\n",
      "batch 2360: loss 0.367748\n",
      "batch 2361: loss 0.429408\n",
      "batch 2362: loss 0.609445\n",
      "batch 2363: loss 0.580931\n",
      "batch 2364: loss 0.422737\n",
      "batch 2365: loss 0.556857\n",
      "batch 2366: loss 0.428863\n",
      "batch 2367: loss 0.493255\n",
      "batch 2368: loss 0.555867\n",
      "batch 2369: loss 0.395428\n",
      "batch 2370: loss 0.435470\n",
      "batch 2371: loss 0.538438\n",
      "batch 2372: loss 0.446318\n",
      "batch 2373: loss 0.698514\n",
      "batch 2374: loss 0.480247\n",
      "batch 2375: loss 0.508101\n",
      "batch 2376: loss 0.472911\n",
      "batch 2377: loss 0.257889\n",
      "batch 2378: loss 0.484601\n",
      "batch 2379: loss 0.696773\n",
      "batch 2380: loss 0.484704\n",
      "batch 2381: loss 0.550287\n",
      "batch 2382: loss 0.377449\n",
      "batch 2383: loss 0.621713\n",
      "batch 2384: loss 0.679160\n",
      "batch 2385: loss 0.454150\n",
      "batch 2386: loss 0.524418\n",
      "batch 2387: loss 0.527558\n",
      "batch 2388: loss 0.380699\n",
      "batch 2389: loss 0.322046\n",
      "batch 2390: loss 0.704667\n",
      "batch 2391: loss 0.534175\n",
      "batch 2392: loss 0.574438\n",
      "batch 2393: loss 0.444007\n",
      "batch 2394: loss 0.370851\n",
      "batch 2395: loss 0.440763\n",
      "batch 2396: loss 0.544391\n",
      "batch 2397: loss 0.356148\n",
      "batch 2398: loss 0.437007\n",
      "batch 2399: loss 0.629916\n",
      "batch 2400: loss 0.467925\n",
      "batch 2401: loss 0.514854\n",
      "batch 2402: loss 0.561448\n",
      "batch 2403: loss 0.668451\n",
      "batch 2404: loss 0.934160\n",
      "batch 2405: loss 0.807931\n",
      "batch 2406: loss 0.460898\n",
      "batch 2407: loss 0.409263\n",
      "batch 2408: loss 0.421317\n",
      "batch 2409: loss 0.604060\n",
      "batch 2410: loss 0.401747\n",
      "batch 2411: loss 0.397592\n",
      "batch 2412: loss 0.466286\n",
      "batch 2413: loss 0.621745\n",
      "batch 2414: loss 0.456206\n",
      "batch 2415: loss 0.346137\n",
      "batch 2416: loss 0.520016\n",
      "batch 2417: loss 0.483155\n",
      "batch 2418: loss 0.446036\n",
      "batch 2419: loss 0.554887\n",
      "batch 2420: loss 0.485202\n",
      "batch 2421: loss 0.485326\n",
      "batch 2422: loss 0.396361\n",
      "batch 2423: loss 0.616632\n",
      "batch 2424: loss 0.404684\n",
      "batch 2425: loss 0.721604\n",
      "batch 2426: loss 0.571485\n",
      "batch 2427: loss 0.426734\n",
      "batch 2428: loss 0.481049\n",
      "batch 2429: loss 0.431181\n",
      "batch 2430: loss 0.583187\n",
      "batch 2431: loss 0.468558\n",
      "batch 2432: loss 0.444909\n",
      "batch 2433: loss 0.339987\n",
      "batch 2434: loss 0.676861\n",
      "batch 2435: loss 0.565652\n",
      "batch 2436: loss 0.401629\n",
      "batch 2437: loss 0.701478\n",
      "batch 2438: loss 0.421213\n",
      "batch 2439: loss 0.368649\n",
      "batch 2440: loss 0.597023\n",
      "batch 2441: loss 0.622155\n",
      "batch 2442: loss 0.471792\n",
      "batch 2443: loss 0.700182\n",
      "batch 2444: loss 0.722540\n",
      "batch 2445: loss 0.428035\n",
      "batch 2446: loss 0.476861\n",
      "batch 2447: loss 0.517918\n",
      "batch 2448: loss 0.647121\n",
      "batch 2449: loss 0.417259\n",
      "batch 2450: loss 0.500154\n",
      "batch 2451: loss 0.509591\n",
      "batch 2452: loss 0.364276\n",
      "batch 2453: loss 0.413733\n",
      "batch 2454: loss 0.559316\n",
      "batch 2455: loss 0.495356\n",
      "batch 2456: loss 0.407208\n",
      "batch 2457: loss 0.457833\n",
      "batch 2458: loss 0.534872\n",
      "batch 2459: loss 0.418418\n",
      "batch 2460: loss 0.549796\n",
      "batch 2461: loss 0.509437\n",
      "batch 2462: loss 0.368456\n",
      "batch 2463: loss 0.539952\n",
      "batch 2464: loss 0.460648\n",
      "batch 2465: loss 0.609479\n",
      "batch 2466: loss 0.513793\n",
      "batch 2467: loss 0.409983\n",
      "batch 2468: loss 0.569693\n",
      "batch 2469: loss 0.727372\n",
      "batch 2470: loss 0.635589\n",
      "batch 2471: loss 0.473714\n",
      "batch 2472: loss 0.615080\n",
      "batch 2473: loss 0.351495\n",
      "batch 2474: loss 0.557774\n",
      "batch 2475: loss 0.468242\n",
      "batch 2476: loss 0.406158\n",
      "batch 2477: loss 0.497635\n",
      "batch 2478: loss 0.534318\n",
      "batch 2479: loss 0.595338\n",
      "batch 2480: loss 0.469688\n",
      "batch 2481: loss 0.414003\n",
      "batch 2482: loss 0.652860\n",
      "batch 2483: loss 0.460718\n",
      "batch 2484: loss 0.455018\n",
      "batch 2485: loss 0.575542\n",
      "batch 2486: loss 0.418143\n",
      "batch 2487: loss 0.402974\n",
      "batch 2488: loss 0.749382\n",
      "batch 2489: loss 0.538141\n",
      "batch 2490: loss 0.654671\n",
      "batch 2491: loss 0.539910\n",
      "batch 2492: loss 0.629518\n",
      "batch 2493: loss 0.561567\n",
      "batch 2494: loss 0.531522\n",
      "batch 2495: loss 0.668853\n",
      "batch 2496: loss 0.582886\n",
      "batch 2497: loss 0.451657\n",
      "batch 2498: loss 0.461770\n",
      "batch 2499: loss 0.374099\n",
      "batch 2500: loss 0.592462\n",
      "batch 2501: loss 0.484725\n",
      "batch 2502: loss 0.570034\n",
      "batch 2503: loss 0.370334\n",
      "batch 2504: loss 0.385656\n",
      "batch 2505: loss 0.290573\n",
      "batch 2506: loss 0.573198\n",
      "batch 2507: loss 0.348251\n",
      "batch 2508: loss 0.559622\n",
      "batch 2509: loss 0.532024\n",
      "batch 2510: loss 0.515102\n",
      "batch 2511: loss 0.492757\n",
      "batch 2512: loss 0.534834\n",
      "batch 2513: loss 0.567974\n",
      "batch 2514: loss 0.334202\n",
      "batch 2515: loss 0.350703\n",
      "batch 2516: loss 0.527705\n",
      "batch 2517: loss 0.414821\n",
      "batch 2518: loss 0.480162\n",
      "batch 2519: loss 0.501813\n",
      "batch 2520: loss 0.412971\n",
      "batch 2521: loss 0.615854\n",
      "batch 2522: loss 0.720783\n",
      "batch 2523: loss 0.404724\n",
      "batch 2524: loss 0.463212\n",
      "batch 2525: loss 0.393782\n",
      "batch 2526: loss 0.675187\n",
      "batch 2527: loss 0.347669\n",
      "batch 2528: loss 0.274260\n",
      "batch 2529: loss 0.466363\n",
      "batch 2530: loss 0.399845\n",
      "batch 2531: loss 0.510185\n",
      "batch 2532: loss 0.432976\n",
      "batch 2533: loss 0.501284\n",
      "batch 2534: loss 0.454571\n",
      "batch 2535: loss 0.547193\n",
      "batch 2536: loss 0.651302\n",
      "batch 2537: loss 0.543209\n",
      "batch 2538: loss 0.415665\n",
      "batch 2539: loss 0.361009\n",
      "batch 2540: loss 0.544608\n",
      "batch 2541: loss 0.561519\n",
      "batch 2542: loss 0.488231\n",
      "batch 2543: loss 0.478729\n",
      "batch 2544: loss 0.457039\n",
      "batch 2545: loss 0.478668\n",
      "batch 2546: loss 0.399748\n",
      "batch 2547: loss 0.401806\n",
      "batch 2548: loss 0.469266\n",
      "batch 2549: loss 0.350501\n",
      "batch 2550: loss 0.429305\n",
      "batch 2551: loss 0.605701\n",
      "batch 2552: loss 0.397310\n",
      "batch 2553: loss 0.479472\n",
      "batch 2554: loss 0.407454\n",
      "batch 2555: loss 0.346075\n",
      "batch 2556: loss 0.399331\n",
      "batch 2557: loss 0.435794\n",
      "batch 2558: loss 0.647181\n",
      "batch 2559: loss 0.418955\n",
      "batch 2560: loss 0.400802\n",
      "batch 2561: loss 0.375803\n",
      "batch 2562: loss 0.361250\n",
      "batch 2563: loss 0.505411\n",
      "batch 2564: loss 0.508238\n",
      "batch 2565: loss 0.363202\n",
      "batch 2566: loss 0.581286\n",
      "batch 2567: loss 0.581484\n",
      "batch 2568: loss 0.382666\n",
      "batch 2569: loss 0.482888\n",
      "batch 2570: loss 0.573428\n",
      "batch 2571: loss 0.480743\n",
      "batch 2572: loss 0.459968\n",
      "batch 2573: loss 0.524368\n",
      "batch 2574: loss 0.614643\n",
      "batch 2575: loss 0.528837\n",
      "batch 2576: loss 0.484760\n",
      "batch 2577: loss 0.419141\n",
      "batch 2578: loss 0.481153\n",
      "batch 2579: loss 0.473491\n",
      "batch 2580: loss 0.531650\n",
      "batch 2581: loss 0.429326\n",
      "batch 2582: loss 0.421525\n",
      "batch 2583: loss 0.454996\n",
      "batch 2584: loss 0.481109\n",
      "batch 2585: loss 0.583133\n",
      "batch 2586: loss 0.452398\n",
      "batch 2587: loss 0.748073\n",
      "batch 2588: loss 0.329114\n",
      "batch 2589: loss 0.474132\n",
      "batch 2590: loss 0.684204\n",
      "batch 2591: loss 0.454110\n",
      "batch 2592: loss 0.483209\n",
      "batch 2593: loss 0.466562\n",
      "batch 2594: loss 0.495502\n",
      "batch 2595: loss 0.700804\n",
      "batch 2596: loss 0.365248\n",
      "batch 2597: loss 0.443088\n",
      "batch 2598: loss 0.265002\n",
      "batch 2599: loss 0.482552\n",
      "batch 2600: loss 0.447035\n",
      "batch 2601: loss 0.404920\n",
      "batch 2602: loss 0.470627\n",
      "batch 2603: loss 0.434121\n",
      "batch 2604: loss 0.465665\n",
      "batch 2605: loss 0.416006\n",
      "batch 2606: loss 0.563401\n",
      "batch 2607: loss 0.479851\n",
      "batch 2608: loss 0.515657\n",
      "batch 2609: loss 0.642210\n",
      "batch 2610: loss 0.635087\n",
      "batch 2611: loss 0.514943\n",
      "batch 2612: loss 0.364101\n",
      "batch 2613: loss 0.569755\n",
      "batch 2614: loss 0.857077\n",
      "batch 2615: loss 0.537637\n",
      "batch 2616: loss 0.403323\n",
      "batch 2617: loss 0.353518\n",
      "batch 2618: loss 0.612586\n",
      "batch 2619: loss 0.489348\n",
      "batch 2620: loss 0.511981\n",
      "batch 2621: loss 0.466435\n",
      "batch 2622: loss 0.402926\n",
      "batch 2623: loss 0.647584\n",
      "batch 2624: loss 0.356155\n",
      "batch 2625: loss 0.391400\n",
      "batch 2626: loss 0.608786\n",
      "batch 2627: loss 0.532160\n",
      "batch 2628: loss 0.752107\n",
      "batch 2629: loss 0.481817\n",
      "batch 2630: loss 0.387972\n",
      "batch 2631: loss 0.453400\n",
      "batch 2632: loss 0.650220\n",
      "batch 2633: loss 0.437024\n",
      "batch 2634: loss 0.523546\n",
      "batch 2635: loss 0.459425\n",
      "batch 2636: loss 0.458632\n",
      "batch 2637: loss 0.352414\n",
      "batch 2638: loss 0.480599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2639: loss 0.482717\n",
      "batch 2640: loss 0.432695\n",
      "batch 2641: loss 0.662827\n",
      "batch 2642: loss 0.445412\n",
      "batch 2643: loss 0.460272\n",
      "batch 2644: loss 0.402905\n",
      "batch 2645: loss 0.453567\n",
      "batch 2646: loss 0.492583\n",
      "batch 2647: loss 0.385350\n",
      "batch 2648: loss 0.344275\n",
      "batch 2649: loss 0.607630\n",
      "batch 2650: loss 0.453704\n",
      "batch 2651: loss 0.624153\n",
      "batch 2652: loss 0.363900\n",
      "batch 2653: loss 0.473910\n",
      "batch 2654: loss 0.540908\n",
      "batch 2655: loss 0.385924\n",
      "batch 2656: loss 0.339264\n",
      "batch 2657: loss 0.582204\n",
      "batch 2658: loss 0.520542\n",
      "batch 2659: loss 0.475700\n",
      "batch 2660: loss 0.363865\n",
      "batch 2661: loss 0.326507\n",
      "batch 2662: loss 0.605712\n",
      "batch 2663: loss 0.641088\n",
      "batch 2664: loss 0.336313\n",
      "batch 2665: loss 0.368913\n",
      "batch 2666: loss 0.367411\n",
      "batch 2667: loss 0.349145\n",
      "batch 2668: loss 0.608670\n",
      "batch 2669: loss 0.602477\n",
      "batch 2670: loss 0.523100\n",
      "batch 2671: loss 0.538784\n",
      "batch 2672: loss 0.556191\n",
      "batch 2673: loss 0.363321\n",
      "batch 2674: loss 0.586998\n",
      "batch 2675: loss 0.480675\n",
      "batch 2676: loss 0.377284\n",
      "batch 2677: loss 0.507148\n",
      "batch 2678: loss 0.432669\n",
      "batch 2679: loss 0.506899\n",
      "batch 2680: loss 0.489085\n",
      "batch 2681: loss 0.470567\n",
      "batch 2682: loss 0.373531\n",
      "batch 2683: loss 0.290948\n",
      "batch 2684: loss 0.423655\n",
      "batch 2685: loss 0.409332\n",
      "batch 2686: loss 0.431594\n",
      "batch 2687: loss 0.373774\n",
      "batch 2688: loss 0.342645\n",
      "batch 2689: loss 0.519285\n",
      "batch 2690: loss 0.393851\n",
      "batch 2691: loss 0.274958\n",
      "batch 2692: loss 0.533135\n",
      "batch 2693: loss 0.388341\n",
      "batch 2694: loss 0.378083\n",
      "batch 2695: loss 0.415873\n",
      "batch 2696: loss 0.567111\n",
      "batch 2697: loss 0.446490\n",
      "batch 2698: loss 0.647413\n",
      "batch 2699: loss 0.721957\n",
      "batch 2700: loss 0.444170\n",
      "batch 2701: loss 0.372205\n",
      "batch 2702: loss 0.373406\n",
      "batch 2703: loss 0.367794\n",
      "batch 2704: loss 0.538297\n",
      "batch 2705: loss 0.573951\n",
      "batch 2706: loss 0.389972\n",
      "batch 2707: loss 0.357401\n",
      "batch 2708: loss 0.507617\n",
      "batch 2709: loss 0.305752\n",
      "batch 2710: loss 0.335061\n",
      "batch 2711: loss 0.404957\n",
      "batch 2712: loss 0.297113\n",
      "batch 2713: loss 0.523225\n",
      "batch 2714: loss 0.549099\n",
      "batch 2715: loss 0.466011\n",
      "batch 2716: loss 0.446683\n",
      "batch 2717: loss 0.490869\n",
      "batch 2718: loss 0.427521\n",
      "batch 2719: loss 0.367836\n",
      "batch 2720: loss 0.302353\n",
      "batch 2721: loss 0.505518\n",
      "batch 2722: loss 0.536172\n",
      "batch 2723: loss 0.442009\n",
      "batch 2724: loss 0.585689\n",
      "batch 2725: loss 0.474558\n",
      "batch 2726: loss 0.454202\n",
      "batch 2727: loss 0.282986\n",
      "batch 2728: loss 0.338327\n",
      "batch 2729: loss 0.449180\n",
      "batch 2730: loss 0.414544\n",
      "batch 2731: loss 0.396776\n",
      "batch 2732: loss 0.560804\n",
      "batch 2733: loss 0.426304\n",
      "batch 2734: loss 0.419583\n",
      "batch 2735: loss 0.336835\n",
      "batch 2736: loss 0.288683\n",
      "batch 2737: loss 0.460763\n",
      "batch 2738: loss 0.324146\n",
      "batch 2739: loss 0.450396\n",
      "batch 2740: loss 0.317199\n",
      "batch 2741: loss 0.356965\n",
      "batch 2742: loss 0.459460\n",
      "batch 2743: loss 0.602852\n",
      "batch 2744: loss 0.347737\n",
      "batch 2745: loss 0.499786\n",
      "batch 2746: loss 0.455626\n",
      "batch 2747: loss 0.544551\n",
      "batch 2748: loss 0.613228\n",
      "batch 2749: loss 0.512370\n",
      "batch 2750: loss 0.357252\n",
      "batch 2751: loss 0.451535\n",
      "batch 2752: loss 0.352466\n",
      "batch 2753: loss 0.476283\n",
      "batch 2754: loss 0.350568\n",
      "batch 2755: loss 0.433005\n",
      "batch 2756: loss 0.368761\n",
      "batch 2757: loss 0.415069\n",
      "batch 2758: loss 0.410253\n",
      "batch 2759: loss 0.382416\n",
      "batch 2760: loss 0.504358\n",
      "batch 2761: loss 0.409685\n",
      "batch 2762: loss 0.476305\n",
      "batch 2763: loss 0.515547\n",
      "batch 2764: loss 0.503763\n",
      "batch 2765: loss 0.399024\n",
      "batch 2766: loss 0.601459\n",
      "batch 2767: loss 0.567983\n",
      "batch 2768: loss 0.390118\n",
      "batch 2769: loss 0.437953\n",
      "batch 2770: loss 0.453944\n",
      "batch 2771: loss 0.487165\n",
      "batch 2772: loss 0.509468\n",
      "batch 2773: loss 0.365455\n",
      "batch 2774: loss 0.558183\n",
      "batch 2775: loss 0.396536\n",
      "batch 2776: loss 0.451388\n",
      "batch 2777: loss 0.455807\n",
      "batch 2778: loss 0.469050\n",
      "batch 2779: loss 0.671314\n",
      "batch 2780: loss 0.569859\n",
      "batch 2781: loss 0.419188\n",
      "batch 2782: loss 0.464656\n",
      "batch 2783: loss 0.463116\n",
      "batch 2784: loss 0.365318\n",
      "batch 2785: loss 0.645684\n",
      "batch 2786: loss 0.437929\n",
      "batch 2787: loss 0.468167\n",
      "batch 2788: loss 0.375479\n",
      "batch 2789: loss 0.627958\n",
      "batch 2790: loss 0.443763\n",
      "batch 2791: loss 0.439852\n",
      "batch 2792: loss 0.338129\n",
      "batch 2793: loss 0.480703\n",
      "batch 2794: loss 0.458121\n",
      "batch 2795: loss 0.255938\n",
      "batch 2796: loss 0.471395\n",
      "batch 2797: loss 0.499192\n",
      "batch 2798: loss 0.577101\n",
      "batch 2799: loss 0.574597\n",
      "batch 2800: loss 0.549096\n",
      "batch 2801: loss 0.622086\n",
      "batch 2802: loss 0.325088\n",
      "batch 2803: loss 0.507388\n",
      "batch 2804: loss 0.289725\n",
      "batch 2805: loss 0.377802\n",
      "batch 2806: loss 0.410515\n",
      "batch 2807: loss 0.518467\n",
      "batch 2808: loss 0.524679\n",
      "batch 2809: loss 0.396514\n",
      "batch 2810: loss 0.527415\n",
      "batch 2811: loss 0.412785\n",
      "batch 2812: loss 0.504908\n",
      "batch 2813: loss 0.201633\n",
      "batch 2814: loss 0.512487\n",
      "batch 2815: loss 0.459253\n",
      "batch 2816: loss 0.345551\n",
      "batch 2817: loss 0.439232\n",
      "batch 2818: loss 0.302165\n",
      "batch 2819: loss 0.526903\n",
      "batch 2820: loss 0.586818\n",
      "batch 2821: loss 0.585503\n",
      "batch 2822: loss 0.510850\n",
      "batch 2823: loss 0.413810\n",
      "batch 2824: loss 0.485380\n",
      "batch 2825: loss 0.388449\n",
      "batch 2826: loss 0.356692\n",
      "batch 2827: loss 0.304296\n",
      "batch 2828: loss 0.608041\n",
      "batch 2829: loss 0.431496\n",
      "batch 2830: loss 0.429258\n",
      "batch 2831: loss 0.372006\n",
      "batch 2832: loss 0.407769\n",
      "batch 2833: loss 0.616814\n",
      "batch 2834: loss 0.583127\n",
      "batch 2835: loss 0.519689\n",
      "batch 2836: loss 0.396764\n",
      "batch 2837: loss 0.602433\n",
      "batch 2838: loss 0.451371\n",
      "batch 2839: loss 0.383623\n",
      "batch 2840: loss 0.597884\n",
      "batch 2841: loss 0.567850\n",
      "batch 2842: loss 0.386356\n",
      "batch 2843: loss 0.356316\n",
      "batch 2844: loss 0.533509\n",
      "batch 2845: loss 0.573076\n",
      "batch 2846: loss 0.595798\n",
      "batch 2847: loss 0.400066\n",
      "batch 2848: loss 0.598932\n",
      "batch 2849: loss 0.419806\n",
      "batch 2850: loss 0.536288\n",
      "batch 2851: loss 0.584218\n",
      "batch 2852: loss 0.268882\n",
      "batch 2853: loss 0.572545\n",
      "batch 2854: loss 0.284896\n",
      "batch 2855: loss 0.496969\n",
      "batch 2856: loss 0.378821\n",
      "batch 2857: loss 0.312730\n",
      "batch 2858: loss 0.564232\n",
      "batch 2859: loss 0.301062\n",
      "batch 2860: loss 0.502957\n",
      "batch 2861: loss 0.488530\n",
      "batch 2862: loss 0.578320\n",
      "batch 2863: loss 0.434629\n",
      "batch 2864: loss 0.437566\n",
      "batch 2865: loss 0.610186\n",
      "batch 2866: loss 0.444292\n",
      "batch 2867: loss 0.316249\n",
      "batch 2868: loss 0.359080\n",
      "batch 2869: loss 0.261199\n",
      "batch 2870: loss 0.502776\n",
      "batch 2871: loss 0.379487\n",
      "batch 2872: loss 0.300698\n",
      "batch 2873: loss 0.436513\n",
      "batch 2874: loss 0.566942\n",
      "batch 2875: loss 0.381959\n",
      "batch 2876: loss 0.506445\n",
      "batch 2877: loss 0.519822\n",
      "batch 2878: loss 0.573299\n",
      "batch 2879: loss 0.368476\n",
      "batch 2880: loss 0.499011\n",
      "batch 2881: loss 0.553118\n",
      "batch 2882: loss 0.759276\n",
      "batch 2883: loss 0.596429\n",
      "batch 2884: loss 0.521770\n",
      "batch 2885: loss 0.252345\n",
      "batch 2886: loss 0.339069\n",
      "batch 2887: loss 0.449753\n",
      "batch 2888: loss 0.540603\n",
      "batch 2889: loss 0.398464\n",
      "batch 2890: loss 0.510039\n",
      "batch 2891: loss 0.690948\n",
      "batch 2892: loss 0.533162\n",
      "batch 2893: loss 0.509578\n",
      "batch 2894: loss 0.431443\n",
      "batch 2895: loss 0.483143\n",
      "batch 2896: loss 0.600584\n",
      "batch 2897: loss 0.298624\n",
      "batch 2898: loss 0.444571\n",
      "batch 2899: loss 0.537619\n",
      "batch 2900: loss 0.531348\n",
      "batch 2901: loss 0.378398\n",
      "batch 2902: loss 0.380148\n",
      "batch 2903: loss 0.509567\n",
      "batch 2904: loss 0.469353\n",
      "batch 2905: loss 0.461676\n",
      "batch 2906: loss 0.354496\n",
      "batch 2907: loss 0.407150\n",
      "batch 2908: loss 0.279950\n",
      "batch 2909: loss 0.468885\n",
      "batch 2910: loss 0.573954\n",
      "batch 2911: loss 0.516916\n",
      "batch 2912: loss 0.455326\n",
      "batch 2913: loss 0.450162\n",
      "batch 2914: loss 0.376633\n",
      "batch 2915: loss 0.428752\n",
      "batch 2916: loss 0.328674\n",
      "batch 2917: loss 0.366286\n",
      "batch 2918: loss 0.500223\n",
      "batch 2919: loss 0.671198\n",
      "batch 2920: loss 0.434430\n",
      "batch 2921: loss 0.367376\n",
      "batch 2922: loss 0.344556\n",
      "batch 2923: loss 0.604861\n",
      "batch 2924: loss 0.427078\n",
      "batch 2925: loss 0.303379\n",
      "batch 2926: loss 0.467998\n",
      "batch 2927: loss 0.789251\n",
      "batch 2928: loss 0.441275\n",
      "batch 2929: loss 0.452989\n",
      "batch 2930: loss 0.446779\n",
      "batch 2931: loss 0.333007\n",
      "batch 2932: loss 0.458267\n",
      "batch 2933: loss 0.320550\n",
      "batch 2934: loss 0.346568\n",
      "batch 2935: loss 0.490364\n",
      "batch 2936: loss 0.442694\n",
      "batch 2937: loss 0.360266\n",
      "batch 2938: loss 0.528119\n",
      "batch 2939: loss 0.578192\n",
      "batch 2940: loss 0.451402\n",
      "batch 2941: loss 0.363277\n",
      "batch 2942: loss 0.648210\n",
      "batch 2943: loss 0.740585\n",
      "batch 2944: loss 0.470031\n",
      "batch 2945: loss 0.484190\n",
      "batch 2946: loss 0.507645\n",
      "batch 2947: loss 0.517204\n",
      "batch 2948: loss 0.615799\n",
      "batch 2949: loss 0.460207\n",
      "batch 2950: loss 0.414641\n",
      "batch 2951: loss 0.332876\n",
      "batch 2952: loss 0.525176\n",
      "batch 2953: loss 0.560931\n",
      "batch 2954: loss 0.441051\n",
      "batch 2955: loss 0.396320\n",
      "batch 2956: loss 0.507036\n",
      "batch 2957: loss 0.555679\n",
      "batch 2958: loss 0.327920\n",
      "batch 2959: loss 0.315574\n",
      "batch 2960: loss 0.715962\n",
      "batch 2961: loss 0.410387\n",
      "batch 2962: loss 0.271928\n",
      "batch 2963: loss 0.342776\n",
      "batch 2964: loss 0.539516\n",
      "batch 2965: loss 0.271994\n",
      "batch 2966: loss 0.344689\n",
      "batch 2967: loss 0.357291\n",
      "batch 2968: loss 0.264922\n",
      "batch 2969: loss 0.477506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2970: loss 0.281784\n",
      "batch 2971: loss 0.430651\n",
      "batch 2972: loss 0.289647\n",
      "batch 2973: loss 0.555661\n",
      "batch 2974: loss 0.444470\n",
      "batch 2975: loss 0.505618\n",
      "batch 2976: loss 0.469611\n",
      "batch 2977: loss 0.296204\n",
      "batch 2978: loss 0.528664\n",
      "batch 2979: loss 0.778321\n",
      "batch 2980: loss 0.247367\n",
      "batch 2981: loss 0.500571\n",
      "batch 2982: loss 0.375129\n",
      "batch 2983: loss 0.606787\n",
      "batch 2984: loss 0.396143\n",
      "batch 2985: loss 0.527923\n",
      "batch 2986: loss 0.674322\n",
      "batch 2987: loss 0.410016\n",
      "batch 2988: loss 0.411899\n",
      "batch 2989: loss 0.381646\n",
      "batch 2990: loss 0.416068\n",
      "batch 2991: loss 0.464380\n",
      "batch 2992: loss 0.508538\n",
      "batch 2993: loss 0.320713\n",
      "batch 2994: loss 0.477883\n",
      "batch 2995: loss 0.374011\n",
      "batch 2996: loss 0.227590\n",
      "batch 2997: loss 0.390063\n",
      "batch 2998: loss 0.588759\n",
      "batch 2999: loss 0.289316\n",
      "batch 3000: loss 0.576974\n",
      "batch 3001: loss 0.273091\n",
      "batch 3002: loss 0.454285\n",
      "batch 3003: loss 0.401500\n",
      "batch 3004: loss 0.439024\n",
      "batch 3005: loss 0.573588\n",
      "batch 3006: loss 0.375842\n",
      "batch 3007: loss 0.355414\n",
      "batch 3008: loss 0.419864\n",
      "batch 3009: loss 0.555075\n",
      "batch 3010: loss 0.478104\n",
      "batch 3011: loss 0.368858\n",
      "batch 3012: loss 0.366638\n",
      "batch 3013: loss 0.377260\n",
      "batch 3014: loss 0.417983\n",
      "batch 3015: loss 0.573619\n",
      "batch 3016: loss 0.555571\n",
      "batch 3017: loss 0.403226\n",
      "batch 3018: loss 0.462288\n",
      "batch 3019: loss 0.315077\n",
      "batch 3020: loss 0.435684\n",
      "batch 3021: loss 0.616660\n",
      "batch 3022: loss 0.345862\n",
      "batch 3023: loss 0.630644\n",
      "batch 3024: loss 0.399452\n",
      "batch 3025: loss 0.423044\n",
      "batch 3026: loss 0.525950\n",
      "batch 3027: loss 0.518991\n",
      "batch 3028: loss 0.503397\n",
      "batch 3029: loss 0.462352\n",
      "batch 3030: loss 0.411687\n",
      "batch 3031: loss 0.394717\n",
      "batch 3032: loss 0.366960\n",
      "batch 3033: loss 0.570618\n",
      "batch 3034: loss 0.354463\n",
      "batch 3035: loss 0.469624\n",
      "batch 3036: loss 0.477790\n",
      "batch 3037: loss 0.511919\n",
      "batch 3038: loss 0.470991\n",
      "batch 3039: loss 0.398618\n",
      "batch 3040: loss 0.520801\n",
      "batch 3041: loss 0.501005\n",
      "batch 3042: loss 0.435957\n",
      "batch 3043: loss 0.355395\n",
      "batch 3044: loss 0.499125\n",
      "batch 3045: loss 0.458450\n",
      "batch 3046: loss 0.506238\n",
      "batch 3047: loss 0.314489\n",
      "batch 3048: loss 0.431154\n",
      "batch 3049: loss 0.319400\n",
      "batch 3050: loss 0.331291\n",
      "batch 3051: loss 0.486633\n",
      "batch 3052: loss 0.359468\n",
      "batch 3053: loss 0.655774\n",
      "batch 3054: loss 0.335873\n",
      "batch 3055: loss 0.663505\n",
      "batch 3056: loss 0.427485\n",
      "batch 3057: loss 0.417383\n",
      "batch 3058: loss 0.248187\n",
      "batch 3059: loss 0.454672\n",
      "batch 3060: loss 0.344459\n",
      "batch 3061: loss 0.524518\n",
      "batch 3062: loss 0.484943\n",
      "batch 3063: loss 0.331234\n",
      "batch 3064: loss 0.386196\n",
      "batch 3065: loss 0.430232\n",
      "batch 3066: loss 0.377369\n",
      "batch 3067: loss 0.324147\n",
      "batch 3068: loss 0.429085\n",
      "batch 3069: loss 0.494715\n",
      "batch 3070: loss 0.322672\n",
      "batch 3071: loss 0.449306\n",
      "batch 3072: loss 0.447054\n",
      "batch 3073: loss 0.292817\n",
      "batch 3074: loss 0.478685\n",
      "batch 3075: loss 0.427099\n",
      "batch 3076: loss 0.445899\n",
      "batch 3077: loss 0.387118\n",
      "batch 3078: loss 0.394487\n",
      "batch 3079: loss 0.526680\n",
      "batch 3080: loss 0.307996\n",
      "batch 3081: loss 0.650580\n",
      "batch 3082: loss 0.364610\n",
      "batch 3083: loss 0.458549\n",
      "batch 3084: loss 0.497307\n",
      "batch 3085: loss 0.384771\n",
      "batch 3086: loss 0.484584\n",
      "batch 3087: loss 0.389009\n",
      "batch 3088: loss 0.285511\n",
      "batch 3089: loss 0.410059\n",
      "batch 3090: loss 0.389479\n",
      "batch 3091: loss 0.454414\n",
      "batch 3092: loss 0.478047\n",
      "batch 3093: loss 0.288849\n",
      "batch 3094: loss 0.464008\n",
      "batch 3095: loss 0.398680\n",
      "batch 3096: loss 0.460451\n",
      "batch 3097: loss 0.183633\n",
      "batch 3098: loss 0.431267\n",
      "batch 3099: loss 0.551996\n",
      "batch 3100: loss 0.510743\n",
      "batch 3101: loss 0.436176\n",
      "batch 3102: loss 0.359779\n",
      "batch 3103: loss 0.317528\n",
      "batch 3104: loss 0.310045\n",
      "batch 3105: loss 0.707341\n",
      "batch 3106: loss 0.503835\n",
      "batch 3107: loss 0.268546\n",
      "batch 3108: loss 0.570384\n",
      "batch 3109: loss 0.507018\n",
      "batch 3110: loss 0.412898\n",
      "batch 3111: loss 0.645946\n",
      "batch 3112: loss 0.334118\n",
      "batch 3113: loss 0.400564\n",
      "batch 3114: loss 0.318586\n",
      "batch 3115: loss 0.300729\n",
      "batch 3116: loss 0.390016\n",
      "batch 3117: loss 0.374300\n",
      "batch 3118: loss 0.507429\n",
      "batch 3119: loss 0.419233\n",
      "batch 3120: loss 0.327963\n",
      "batch 3121: loss 0.392292\n",
      "batch 3122: loss 0.440353\n",
      "batch 3123: loss 0.523737\n",
      "batch 3124: loss 0.505603\n",
      "batch 3125: loss 0.350828\n",
      "batch 3126: loss 0.362513\n",
      "batch 3127: loss 0.369455\n",
      "batch 3128: loss 0.385685\n",
      "batch 3129: loss 0.451924\n",
      "batch 3130: loss 0.507168\n",
      "batch 3131: loss 0.401258\n",
      "batch 3132: loss 0.481091\n",
      "batch 3133: loss 0.516814\n",
      "batch 3134: loss 0.484838\n",
      "batch 3135: loss 0.441291\n",
      "batch 3136: loss 0.316084\n",
      "batch 3137: loss 0.419037\n",
      "batch 3138: loss 0.310352\n",
      "batch 3139: loss 0.483111\n",
      "batch 3140: loss 0.425366\n",
      "batch 3141: loss 0.579956\n",
      "batch 3142: loss 0.458971\n",
      "batch 3143: loss 0.461792\n",
      "batch 3144: loss 0.530554\n",
      "batch 3145: loss 0.296721\n",
      "batch 3146: loss 0.387186\n",
      "batch 3147: loss 0.496872\n",
      "batch 3148: loss 0.678543\n",
      "batch 3149: loss 0.505787\n",
      "batch 3150: loss 0.195602\n",
      "batch 3151: loss 0.456536\n",
      "batch 3152: loss 0.431699\n",
      "batch 3153: loss 0.414894\n",
      "batch 3154: loss 0.460304\n",
      "batch 3155: loss 0.891271\n",
      "batch 3156: loss 0.323761\n",
      "batch 3157: loss 0.334574\n",
      "batch 3158: loss 0.588864\n",
      "batch 3159: loss 0.329362\n",
      "batch 3160: loss 0.342949\n",
      "batch 3161: loss 0.500544\n",
      "batch 3162: loss 0.360280\n",
      "batch 3163: loss 0.439465\n",
      "batch 3164: loss 0.538669\n",
      "batch 3165: loss 0.630257\n",
      "batch 3166: loss 0.208878\n",
      "batch 3167: loss 0.418011\n",
      "batch 3168: loss 0.447572\n",
      "batch 3169: loss 0.378298\n",
      "batch 3170: loss 0.352467\n",
      "batch 3171: loss 0.374123\n",
      "batch 3172: loss 0.584219\n",
      "batch 3173: loss 0.289398\n",
      "batch 3174: loss 0.350066\n",
      "batch 3175: loss 0.536914\n",
      "batch 3176: loss 0.632436\n",
      "batch 3177: loss 0.464960\n",
      "batch 3178: loss 0.323721\n",
      "batch 3179: loss 0.520887\n",
      "batch 3180: loss 0.362627\n",
      "batch 3181: loss 0.414957\n",
      "batch 3182: loss 0.409629\n",
      "batch 3183: loss 0.490907\n",
      "batch 3184: loss 0.394981\n",
      "batch 3185: loss 0.342605\n",
      "batch 3186: loss 0.519298\n",
      "batch 3187: loss 0.309555\n",
      "batch 3188: loss 0.315243\n",
      "batch 3189: loss 0.460663\n",
      "batch 3190: loss 0.655774\n",
      "batch 3191: loss 0.429903\n",
      "batch 3192: loss 0.317142\n",
      "batch 3193: loss 0.337964\n",
      "batch 3194: loss 0.440070\n",
      "batch 3195: loss 0.453151\n",
      "batch 3196: loss 0.292147\n",
      "batch 3197: loss 0.420223\n",
      "batch 3198: loss 0.513515\n",
      "batch 3199: loss 0.361748\n",
      "batch 3200: loss 0.267804\n",
      "batch 3201: loss 0.486015\n",
      "batch 3202: loss 0.414934\n",
      "batch 3203: loss 0.459365\n",
      "batch 3204: loss 0.502944\n",
      "batch 3205: loss 0.218156\n",
      "batch 3206: loss 0.380240\n",
      "batch 3207: loss 0.459495\n",
      "batch 3208: loss 0.431211\n",
      "batch 3209: loss 0.701030\n",
      "batch 3210: loss 0.463953\n",
      "batch 3211: loss 0.360687\n",
      "batch 3212: loss 0.409570\n",
      "batch 3213: loss 0.608687\n",
      "batch 3214: loss 0.515898\n",
      "batch 3215: loss 0.472329\n",
      "batch 3216: loss 0.373692\n",
      "batch 3217: loss 0.673523\n",
      "batch 3218: loss 0.654298\n",
      "batch 3219: loss 0.385139\n",
      "batch 3220: loss 0.525304\n",
      "batch 3221: loss 0.268832\n",
      "batch 3222: loss 0.390401\n",
      "batch 3223: loss 0.479703\n",
      "batch 3224: loss 0.563528\n",
      "batch 3225: loss 0.369041\n",
      "batch 3226: loss 0.543981\n",
      "batch 3227: loss 0.332206\n",
      "batch 3228: loss 0.492808\n",
      "batch 3229: loss 0.519180\n",
      "batch 3230: loss 0.428634\n",
      "batch 3231: loss 0.248679\n",
      "batch 3232: loss 0.483705\n",
      "batch 3233: loss 0.359965\n",
      "batch 3234: loss 0.404839\n",
      "batch 3235: loss 0.442248\n",
      "batch 3236: loss 0.356948\n",
      "batch 3237: loss 0.426118\n",
      "batch 3238: loss 0.375801\n",
      "batch 3239: loss 0.433545\n",
      "batch 3240: loss 0.324520\n",
      "batch 3241: loss 0.551391\n",
      "batch 3242: loss 0.366961\n",
      "batch 3243: loss 0.456071\n",
      "batch 3244: loss 0.319982\n",
      "batch 3245: loss 0.239899\n",
      "batch 3246: loss 0.422770\n",
      "batch 3247: loss 0.354790\n",
      "batch 3248: loss 0.478133\n",
      "batch 3249: loss 0.410658\n",
      "batch 3250: loss 0.286083\n",
      "batch 3251: loss 0.428539\n",
      "batch 3252: loss 0.721648\n",
      "batch 3253: loss 0.416956\n",
      "batch 3254: loss 0.607996\n",
      "batch 3255: loss 0.507381\n",
      "batch 3256: loss 0.403419\n",
      "batch 3257: loss 0.547821\n",
      "batch 3258: loss 0.320200\n",
      "batch 3259: loss 0.557489\n",
      "batch 3260: loss 0.572972\n",
      "batch 3261: loss 0.233990\n",
      "batch 3262: loss 0.349484\n",
      "batch 3263: loss 0.527565\n",
      "batch 3264: loss 0.625977\n",
      "batch 3265: loss 0.451486\n",
      "batch 3266: loss 0.437096\n",
      "batch 3267: loss 0.397683\n",
      "batch 3268: loss 0.605266\n",
      "batch 3269: loss 0.316128\n",
      "batch 3270: loss 0.312757\n",
      "batch 3271: loss 0.435198\n",
      "batch 3272: loss 0.335644\n",
      "batch 3273: loss 0.432549\n",
      "batch 3274: loss 0.492584\n",
      "batch 3275: loss 0.577390\n",
      "batch 3276: loss 0.537505\n",
      "batch 3277: loss 0.390566\n",
      "batch 3278: loss 0.575308\n",
      "batch 3279: loss 0.573298\n",
      "batch 3280: loss 0.501650\n",
      "batch 3281: loss 0.308290\n",
      "batch 3282: loss 0.554485\n",
      "batch 3283: loss 0.452350\n",
      "batch 3284: loss 0.337646\n",
      "batch 3285: loss 0.387638\n",
      "batch 3286: loss 0.314814\n",
      "batch 3287: loss 0.445032\n",
      "batch 3288: loss 0.414575\n",
      "batch 3289: loss 0.336197\n",
      "batch 3290: loss 0.285240\n",
      "batch 3291: loss 0.330522\n",
      "batch 3292: loss 0.278906\n",
      "batch 3293: loss 0.384360\n",
      "batch 3294: loss 0.464797\n",
      "batch 3295: loss 0.289826\n",
      "batch 3296: loss 0.435108\n",
      "batch 3297: loss 0.311764\n",
      "batch 3298: loss 0.519698\n",
      "batch 3299: loss 0.490204\n",
      "batch 3300: loss 0.457367\n",
      "batch 3301: loss 0.315631\n",
      "batch 3302: loss 0.594336\n",
      "batch 3303: loss 0.429984\n",
      "batch 3304: loss 0.480343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3305: loss 0.412538\n",
      "batch 3306: loss 0.338086\n",
      "batch 3307: loss 0.547395\n",
      "batch 3308: loss 0.590162\n",
      "batch 3309: loss 0.244342\n",
      "batch 3310: loss 0.431840\n",
      "batch 3311: loss 0.363955\n",
      "batch 3312: loss 0.322640\n",
      "batch 3313: loss 0.554611\n",
      "batch 3314: loss 0.369382\n",
      "batch 3315: loss 0.314319\n",
      "batch 3316: loss 0.719661\n",
      "batch 3317: loss 0.459410\n",
      "batch 3318: loss 0.391389\n",
      "batch 3319: loss 0.718531\n",
      "batch 3320: loss 0.455417\n",
      "batch 3321: loss 0.310999\n",
      "batch 3322: loss 0.337593\n",
      "batch 3323: loss 0.348585\n",
      "batch 3324: loss 0.376282\n",
      "batch 3325: loss 0.519015\n",
      "batch 3326: loss 0.487672\n",
      "batch 3327: loss 0.399542\n",
      "batch 3328: loss 0.419411\n",
      "batch 3329: loss 0.651986\n",
      "batch 3330: loss 0.527283\n",
      "batch 3331: loss 0.459104\n",
      "batch 3332: loss 0.519444\n",
      "batch 3333: loss 0.416387\n",
      "batch 3334: loss 0.370711\n",
      "batch 3335: loss 0.444055\n",
      "batch 3336: loss 0.382469\n",
      "batch 3337: loss 0.427856\n",
      "batch 3338: loss 0.558194\n",
      "batch 3339: loss 0.343968\n",
      "batch 3340: loss 0.273463\n",
      "batch 3341: loss 0.523900\n",
      "batch 3342: loss 0.317139\n",
      "batch 3343: loss 0.448748\n",
      "batch 3344: loss 0.418507\n",
      "batch 3345: loss 0.494292\n",
      "batch 3346: loss 0.455034\n",
      "batch 3347: loss 0.449529\n",
      "batch 3348: loss 0.449913\n",
      "batch 3349: loss 0.394243\n",
      "batch 3350: loss 0.322801\n",
      "batch 3351: loss 0.346558\n",
      "batch 3352: loss 0.402023\n",
      "batch 3353: loss 0.377844\n",
      "batch 3354: loss 0.345854\n",
      "batch 3355: loss 0.412148\n",
      "batch 3356: loss 0.389937\n",
      "batch 3357: loss 0.569178\n",
      "batch 3358: loss 0.625947\n",
      "batch 3359: loss 0.348179\n",
      "batch 3360: loss 0.505524\n",
      "batch 3361: loss 0.383105\n",
      "batch 3362: loss 0.408652\n",
      "batch 3363: loss 0.590808\n",
      "batch 3364: loss 0.268402\n",
      "batch 3365: loss 0.597636\n",
      "batch 3366: loss 0.289342\n",
      "batch 3367: loss 0.395979\n",
      "batch 3368: loss 0.595797\n",
      "batch 3369: loss 0.349841\n",
      "batch 3370: loss 0.430981\n",
      "batch 3371: loss 0.341151\n",
      "batch 3372: loss 0.417849\n",
      "batch 3373: loss 0.478627\n",
      "batch 3374: loss 0.326029\n",
      "batch 3375: loss 0.423474\n",
      "batch 3376: loss 0.377159\n",
      "batch 3377: loss 0.483431\n",
      "batch 3378: loss 0.380017\n",
      "batch 3379: loss 0.406834\n",
      "batch 3380: loss 0.524898\n",
      "batch 3381: loss 0.510417\n",
      "batch 3382: loss 0.472778\n",
      "batch 3383: loss 0.550547\n",
      "batch 3384: loss 0.336057\n",
      "batch 3385: loss 0.531716\n",
      "batch 3386: loss 0.341814\n",
      "batch 3387: loss 0.533191\n",
      "batch 3388: loss 0.381219\n",
      "batch 3389: loss 0.498258\n",
      "batch 3390: loss 0.471493\n",
      "batch 3391: loss 0.558540\n",
      "batch 3392: loss 0.440705\n",
      "batch 3393: loss 0.588347\n",
      "batch 3394: loss 0.316019\n",
      "batch 3395: loss 0.677728\n",
      "batch 3396: loss 0.412944\n",
      "batch 3397: loss 0.422645\n",
      "batch 3398: loss 0.455716\n",
      "batch 3399: loss 0.462511\n",
      "batch 3400: loss 0.454109\n",
      "batch 3401: loss 0.511951\n",
      "batch 3402: loss 0.552869\n",
      "batch 3403: loss 0.425106\n",
      "batch 3404: loss 0.245625\n",
      "batch 3405: loss 0.585951\n",
      "batch 3406: loss 0.477325\n",
      "batch 3407: loss 0.620427\n",
      "batch 3408: loss 0.187166\n",
      "batch 3409: loss 0.482822\n",
      "batch 3410: loss 0.410788\n",
      "batch 3411: loss 0.362439\n",
      "batch 3412: loss 0.429865\n",
      "batch 3413: loss 0.394079\n",
      "batch 3414: loss 0.503975\n",
      "batch 3415: loss 0.350542\n",
      "batch 3416: loss 0.346396\n",
      "batch 3417: loss 0.368394\n",
      "batch 3418: loss 0.394451\n",
      "batch 3419: loss 0.233315\n",
      "batch 3420: loss 0.326577\n",
      "batch 3421: loss 0.473921\n",
      "batch 3422: loss 0.513470\n",
      "batch 3423: loss 0.361720\n",
      "batch 3424: loss 0.432227\n",
      "batch 3425: loss 0.309636\n",
      "batch 3426: loss 0.405666\n",
      "batch 3427: loss 0.376630\n",
      "batch 3428: loss 0.497057\n",
      "batch 3429: loss 0.280781\n",
      "batch 3430: loss 0.472290\n",
      "batch 3431: loss 0.437394\n",
      "batch 3432: loss 0.257778\n",
      "batch 3433: loss 0.360645\n",
      "batch 3434: loss 0.374598\n",
      "batch 3435: loss 0.300653\n",
      "batch 3436: loss 0.433395\n",
      "batch 3437: loss 0.339988\n",
      "batch 3438: loss 0.599313\n",
      "batch 3439: loss 0.671049\n",
      "batch 3440: loss 0.501741\n",
      "batch 3441: loss 0.352831\n",
      "batch 3442: loss 0.396934\n",
      "batch 3443: loss 0.554851\n",
      "batch 3444: loss 0.458498\n",
      "batch 3445: loss 0.372019\n",
      "batch 3446: loss 0.350575\n",
      "batch 3447: loss 0.306586\n",
      "batch 3448: loss 0.340245\n",
      "batch 3449: loss 0.275684\n",
      "batch 3450: loss 0.261487\n",
      "batch 3451: loss 0.452430\n",
      "batch 3452: loss 0.502491\n",
      "batch 3453: loss 0.385552\n",
      "batch 3454: loss 0.514223\n",
      "batch 3455: loss 0.479701\n",
      "batch 3456: loss 0.458859\n",
      "batch 3457: loss 0.341281\n",
      "batch 3458: loss 0.433822\n",
      "batch 3459: loss 0.254294\n",
      "batch 3460: loss 0.497970\n",
      "batch 3461: loss 0.387443\n",
      "batch 3462: loss 0.506200\n",
      "batch 3463: loss 0.427836\n",
      "batch 3464: loss 0.254993\n",
      "batch 3465: loss 0.367027\n",
      "batch 3466: loss 0.354215\n",
      "batch 3467: loss 0.423597\n",
      "batch 3468: loss 0.540622\n",
      "batch 3469: loss 0.674959\n",
      "batch 3470: loss 0.318893\n",
      "batch 3471: loss 0.411866\n",
      "batch 3472: loss 0.468424\n",
      "batch 3473: loss 0.373845\n",
      "batch 3474: loss 0.230266\n",
      "batch 3475: loss 0.463620\n",
      "batch 3476: loss 0.315398\n",
      "batch 3477: loss 0.471775\n",
      "batch 3478: loss 0.511108\n",
      "batch 3479: loss 0.487095\n",
      "batch 3480: loss 0.577572\n",
      "batch 3481: loss 0.362220\n",
      "batch 3482: loss 0.475703\n",
      "batch 3483: loss 0.407424\n",
      "batch 3484: loss 0.370125\n",
      "batch 3485: loss 0.461945\n",
      "batch 3486: loss 0.383300\n",
      "batch 3487: loss 0.403682\n",
      "batch 3488: loss 0.619437\n",
      "batch 3489: loss 0.269537\n",
      "batch 3490: loss 0.317282\n",
      "batch 3491: loss 0.202853\n",
      "batch 3492: loss 0.290162\n",
      "batch 3493: loss 0.491627\n",
      "batch 3494: loss 0.406106\n",
      "batch 3495: loss 0.343002\n",
      "batch 3496: loss 0.422458\n",
      "batch 3497: loss 0.552087\n",
      "batch 3498: loss 0.638568\n",
      "batch 3499: loss 0.372684\n",
      "batch 3500: loss 0.318189\n",
      "batch 3501: loss 0.526847\n",
      "batch 3502: loss 0.297026\n",
      "batch 3503: loss 0.292249\n",
      "batch 3504: loss 0.476041\n",
      "batch 3505: loss 0.414354\n",
      "batch 3506: loss 0.352090\n",
      "batch 3507: loss 0.600905\n",
      "batch 3508: loss 0.451712\n",
      "batch 3509: loss 0.263209\n",
      "batch 3510: loss 0.557084\n",
      "batch 3511: loss 0.310918\n",
      "batch 3512: loss 0.599906\n",
      "batch 3513: loss 0.450493\n",
      "batch 3514: loss 0.379814\n",
      "batch 3515: loss 0.489776\n",
      "batch 3516: loss 0.386806\n",
      "batch 3517: loss 0.362702\n",
      "batch 3518: loss 0.311545\n",
      "batch 3519: loss 0.382151\n",
      "batch 3520: loss 0.512748\n",
      "batch 3521: loss 0.533871\n",
      "batch 3522: loss 0.304319\n",
      "batch 3523: loss 0.328507\n",
      "batch 3524: loss 0.356723\n",
      "batch 3525: loss 0.362493\n",
      "batch 3526: loss 0.476680\n",
      "batch 3527: loss 0.307285\n",
      "batch 3528: loss 0.515410\n",
      "batch 3529: loss 0.571756\n",
      "batch 3530: loss 0.340626\n",
      "batch 3531: loss 0.238399\n",
      "batch 3532: loss 0.356624\n",
      "batch 3533: loss 0.354549\n",
      "batch 3534: loss 0.524677\n",
      "batch 3535: loss 0.367414\n",
      "batch 3536: loss 0.257976\n",
      "batch 3537: loss 0.310479\n",
      "batch 3538: loss 0.487453\n",
      "batch 3539: loss 0.208350\n",
      "batch 3540: loss 0.418642\n",
      "batch 3541: loss 0.366795\n",
      "batch 3542: loss 0.214050\n",
      "batch 3543: loss 0.214810\n",
      "batch 3544: loss 0.445293\n",
      "batch 3545: loss 0.300046\n",
      "batch 3546: loss 0.461391\n",
      "batch 3547: loss 0.342293\n",
      "batch 3548: loss 0.447491\n",
      "batch 3549: loss 0.642068\n",
      "batch 3550: loss 0.487851\n",
      "batch 3551: loss 0.408950\n",
      "batch 3552: loss 0.361302\n",
      "batch 3553: loss 0.485078\n",
      "batch 3554: loss 0.422775\n",
      "batch 3555: loss 0.424250\n",
      "batch 3556: loss 0.351564\n",
      "batch 3557: loss 0.432573\n",
      "batch 3558: loss 0.396847\n",
      "batch 3559: loss 0.395877\n",
      "batch 3560: loss 0.630105\n",
      "batch 3561: loss 0.342221\n",
      "batch 3562: loss 0.429539\n",
      "batch 3563: loss 0.384955\n",
      "batch 3564: loss 0.434732\n",
      "batch 3565: loss 0.418068\n",
      "batch 3566: loss 0.553955\n",
      "batch 3567: loss 0.509344\n",
      "batch 3568: loss 0.508612\n",
      "batch 3569: loss 0.348162\n",
      "batch 3570: loss 0.338776\n",
      "batch 3571: loss 0.528997\n",
      "batch 3572: loss 0.417619\n",
      "batch 3573: loss 0.331528\n",
      "batch 3574: loss 0.535108\n",
      "batch 3575: loss 0.436075\n",
      "batch 3576: loss 0.381251\n",
      "batch 3577: loss 0.307682\n",
      "batch 3578: loss 0.411325\n",
      "batch 3579: loss 0.397259\n",
      "batch 3580: loss 0.300790\n",
      "batch 3581: loss 0.661737\n",
      "batch 3582: loss 0.337931\n",
      "batch 3583: loss 0.731726\n",
      "batch 3584: loss 0.326954\n",
      "batch 3585: loss 0.417087\n",
      "batch 3586: loss 0.356031\n",
      "batch 3587: loss 0.274910\n",
      "batch 3588: loss 0.439098\n",
      "batch 3589: loss 0.350790\n",
      "batch 3590: loss 0.412588\n",
      "batch 3591: loss 0.542109\n",
      "batch 3592: loss 0.640840\n",
      "batch 3593: loss 0.500377\n",
      "batch 3594: loss 0.462078\n",
      "batch 3595: loss 0.471653\n",
      "batch 3596: loss 0.601099\n",
      "batch 3597: loss 0.421598\n",
      "batch 3598: loss 0.304364\n",
      "batch 3599: loss 0.443699\n",
      "batch 3600: loss 0.418069\n",
      "batch 3601: loss 0.356826\n",
      "batch 3602: loss 0.361014\n",
      "batch 3603: loss 0.340658\n",
      "batch 3604: loss 0.188498\n",
      "batch 3605: loss 0.371920\n",
      "batch 3606: loss 0.423978\n",
      "batch 3607: loss 0.575538\n",
      "batch 3608: loss 0.382578\n",
      "batch 3609: loss 0.561486\n",
      "batch 3610: loss 0.329289\n",
      "batch 3611: loss 0.345847\n",
      "batch 3612: loss 0.474623\n",
      "batch 3613: loss 0.396686\n",
      "batch 3614: loss 0.239698\n",
      "batch 3615: loss 0.282680\n",
      "batch 3616: loss 0.301707\n",
      "batch 3617: loss 0.387327\n",
      "batch 3618: loss 0.304079\n",
      "batch 3619: loss 0.392771\n",
      "batch 3620: loss 0.486075\n",
      "batch 3621: loss 0.395174\n",
      "batch 3622: loss 0.303690\n",
      "batch 3623: loss 0.466194\n",
      "batch 3624: loss 0.367067\n",
      "batch 3625: loss 0.298415\n",
      "batch 3626: loss 0.547209\n",
      "batch 3627: loss 0.462335\n",
      "batch 3628: loss 0.320169\n",
      "batch 3629: loss 0.517471\n",
      "batch 3630: loss 0.443967\n",
      "batch 3631: loss 0.569572\n",
      "batch 3632: loss 0.542608\n",
      "batch 3633: loss 0.371372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3634: loss 0.315041\n",
      "batch 3635: loss 0.428744\n",
      "batch 3636: loss 0.295056\n",
      "batch 3637: loss 0.482995\n",
      "batch 3638: loss 0.381560\n",
      "batch 3639: loss 0.285773\n",
      "batch 3640: loss 0.346374\n",
      "batch 3641: loss 0.491439\n",
      "batch 3642: loss 0.436141\n",
      "batch 3643: loss 0.218787\n",
      "batch 3644: loss 0.419180\n",
      "batch 3645: loss 0.231663\n",
      "batch 3646: loss 0.280087\n",
      "batch 3647: loss 0.340209\n",
      "batch 3648: loss 0.545818\n",
      "batch 3649: loss 0.375387\n",
      "batch 3650: loss 0.461132\n",
      "batch 3651: loss 0.397539\n",
      "batch 3652: loss 0.349121\n",
      "batch 3653: loss 0.411919\n",
      "batch 3654: loss 0.282165\n",
      "batch 3655: loss 0.453682\n",
      "batch 3656: loss 0.347188\n",
      "batch 3657: loss 0.429344\n",
      "batch 3658: loss 0.401562\n",
      "batch 3659: loss 0.348232\n",
      "batch 3660: loss 0.539543\n",
      "batch 3661: loss 0.343375\n",
      "batch 3662: loss 0.325386\n",
      "batch 3663: loss 0.406274\n",
      "batch 3664: loss 0.471190\n",
      "batch 3665: loss 0.330080\n",
      "batch 3666: loss 0.382547\n",
      "batch 3667: loss 0.446478\n",
      "batch 3668: loss 0.474614\n",
      "batch 3669: loss 0.315799\n",
      "batch 3670: loss 0.452830\n",
      "batch 3671: loss 0.383004\n",
      "batch 3672: loss 0.327307\n",
      "batch 3673: loss 0.456447\n",
      "batch 3674: loss 0.492423\n",
      "batch 3675: loss 0.334446\n",
      "batch 3676: loss 0.481180\n",
      "batch 3677: loss 0.312956\n",
      "batch 3678: loss 0.430230\n",
      "batch 3679: loss 0.372214\n",
      "batch 3680: loss 0.247249\n",
      "batch 3681: loss 0.229303\n",
      "batch 3682: loss 0.627277\n",
      "batch 3683: loss 0.354677\n",
      "batch 3684: loss 0.522433\n",
      "batch 3685: loss 0.392511\n",
      "batch 3686: loss 0.355148\n",
      "batch 3687: loss 0.461319\n",
      "batch 3688: loss 0.458250\n",
      "batch 3689: loss 0.356891\n",
      "batch 3690: loss 0.408178\n",
      "batch 3691: loss 0.380080\n",
      "batch 3692: loss 0.384686\n",
      "batch 3693: loss 0.502849\n",
      "batch 3694: loss 0.351330\n",
      "batch 3695: loss 0.274242\n",
      "batch 3696: loss 0.268023\n",
      "batch 3697: loss 0.609610\n",
      "batch 3698: loss 0.407163\n",
      "batch 3699: loss 0.366168\n",
      "batch 3700: loss 0.199301\n",
      "batch 3701: loss 0.392236\n",
      "batch 3702: loss 0.330014\n",
      "batch 3703: loss 0.239586\n",
      "batch 3704: loss 0.334568\n",
      "batch 3705: loss 0.558867\n",
      "batch 3706: loss 0.317043\n",
      "batch 3707: loss 0.361850\n",
      "batch 3708: loss 0.367369\n",
      "batch 3709: loss 0.454882\n",
      "batch 3710: loss 0.316612\n",
      "batch 3711: loss 0.470436\n",
      "batch 3712: loss 0.408799\n",
      "batch 3713: loss 0.632458\n",
      "batch 3714: loss 0.389095\n",
      "batch 3715: loss 0.428428\n",
      "batch 3716: loss 0.421913\n",
      "batch 3717: loss 0.396229\n",
      "batch 3718: loss 0.477688\n",
      "batch 3719: loss 0.364458\n",
      "batch 3720: loss 0.293260\n",
      "batch 3721: loss 0.422318\n",
      "batch 3722: loss 0.317494\n",
      "batch 3723: loss 0.473563\n",
      "batch 3724: loss 0.369658\n",
      "batch 3725: loss 0.476175\n",
      "batch 3726: loss 0.357461\n",
      "batch 3727: loss 0.581127\n",
      "batch 3728: loss 0.395389\n",
      "batch 3729: loss 0.293144\n",
      "batch 3730: loss 0.400704\n",
      "batch 3731: loss 0.624639\n",
      "batch 3732: loss 0.364459\n",
      "batch 3733: loss 0.294407\n",
      "batch 3734: loss 0.630093\n",
      "batch 3735: loss 0.370373\n",
      "batch 3736: loss 0.300137\n",
      "batch 3737: loss 0.366716\n",
      "batch 3738: loss 0.384150\n",
      "batch 3739: loss 0.447203\n",
      "batch 3740: loss 0.403404\n",
      "batch 3741: loss 0.400392\n",
      "batch 3742: loss 0.486941\n",
      "batch 3743: loss 0.376398\n",
      "batch 3744: loss 0.402110\n",
      "batch 3745: loss 0.407667\n",
      "batch 3746: loss 0.235022\n",
      "batch 3747: loss 0.479272\n",
      "batch 3748: loss 0.414061\n",
      "batch 3749: loss 0.449489\n",
      "batch 3750: loss 0.371859\n",
      "batch 3751: loss 0.593669\n",
      "batch 3752: loss 0.406359\n",
      "batch 3753: loss 0.286946\n",
      "batch 3754: loss 0.397481\n",
      "batch 3755: loss 0.626215\n",
      "batch 3756: loss 0.504720\n",
      "batch 3757: loss 0.358714\n",
      "batch 3758: loss 0.332885\n",
      "batch 3759: loss 0.422996\n",
      "batch 3760: loss 0.328862\n",
      "batch 3761: loss 0.422750\n",
      "batch 3762: loss 0.403054\n",
      "batch 3763: loss 0.444081\n",
      "batch 3764: loss 0.359598\n",
      "batch 3765: loss 0.264387\n",
      "batch 3766: loss 0.321099\n",
      "batch 3767: loss 0.562827\n",
      "batch 3768: loss 0.554067\n",
      "batch 3769: loss 0.468001\n",
      "batch 3770: loss 0.328317\n",
      "batch 3771: loss 0.705124\n",
      "batch 3772: loss 0.355473\n",
      "batch 3773: loss 0.310132\n",
      "batch 3774: loss 0.304344\n",
      "batch 3775: loss 0.312313\n",
      "batch 3776: loss 0.298769\n",
      "batch 3777: loss 0.436666\n",
      "batch 3778: loss 0.704311\n",
      "batch 3779: loss 0.319574\n",
      "batch 3780: loss 0.313291\n",
      "batch 3781: loss 0.315947\n",
      "batch 3782: loss 0.417342\n",
      "batch 3783: loss 0.292776\n",
      "batch 3784: loss 0.649713\n",
      "batch 3785: loss 0.425256\n",
      "batch 3786: loss 0.269618\n",
      "batch 3787: loss 0.447809\n",
      "batch 3788: loss 0.295241\n",
      "batch 3789: loss 0.499667\n",
      "batch 3790: loss 0.388036\n",
      "batch 3791: loss 0.259136\n",
      "batch 3792: loss 0.326939\n",
      "batch 3793: loss 0.531847\n",
      "batch 3794: loss 0.427095\n",
      "batch 3795: loss 0.340695\n",
      "batch 3796: loss 0.404971\n",
      "batch 3797: loss 0.448725\n",
      "batch 3798: loss 0.422649\n",
      "batch 3799: loss 0.388120\n",
      "batch 3800: loss 0.226436\n",
      "batch 3801: loss 0.326231\n",
      "batch 3802: loss 0.457169\n",
      "batch 3803: loss 0.412679\n",
      "batch 3804: loss 0.387676\n",
      "batch 3805: loss 0.429024\n",
      "batch 3806: loss 0.419707\n",
      "batch 3807: loss 0.416179\n",
      "batch 3808: loss 0.501658\n",
      "batch 3809: loss 0.310802\n",
      "batch 3810: loss 0.303862\n",
      "batch 3811: loss 0.393023\n",
      "batch 3812: loss 0.281849\n",
      "batch 3813: loss 0.488791\n",
      "batch 3814: loss 0.275793\n",
      "batch 3815: loss 0.442430\n",
      "batch 3816: loss 0.667285\n",
      "batch 3817: loss 0.375620\n",
      "batch 3818: loss 0.298048\n",
      "batch 3819: loss 0.314033\n",
      "batch 3820: loss 0.398235\n",
      "batch 3821: loss 0.376042\n",
      "batch 3822: loss 0.464124\n",
      "batch 3823: loss 0.530787\n",
      "batch 3824: loss 0.267648\n",
      "batch 3825: loss 0.430891\n",
      "batch 3826: loss 0.561623\n",
      "batch 3827: loss 0.400411\n",
      "batch 3828: loss 0.272006\n",
      "batch 3829: loss 0.323577\n",
      "batch 3830: loss 0.264762\n",
      "batch 3831: loss 0.354580\n",
      "batch 3832: loss 0.475523\n",
      "batch 3833: loss 0.374075\n",
      "batch 3834: loss 0.387873\n",
      "batch 3835: loss 0.342779\n",
      "batch 3836: loss 0.280602\n",
      "batch 3837: loss 0.321447\n",
      "batch 3838: loss 0.321238\n",
      "batch 3839: loss 0.406255\n",
      "batch 3840: loss 0.462881\n",
      "batch 3841: loss 0.283691\n",
      "batch 3842: loss 0.399419\n",
      "batch 3843: loss 0.380024\n",
      "batch 3844: loss 0.310433\n",
      "batch 3845: loss 0.263487\n",
      "batch 3846: loss 0.555686\n",
      "batch 3847: loss 0.380707\n",
      "batch 3848: loss 0.256001\n",
      "batch 3849: loss 0.276927\n",
      "batch 3850: loss 0.290271\n",
      "batch 3851: loss 0.457507\n",
      "batch 3852: loss 0.333367\n",
      "batch 3853: loss 0.254338\n",
      "batch 3854: loss 0.430900\n",
      "batch 3855: loss 0.341437\n",
      "batch 3856: loss 0.472236\n",
      "batch 3857: loss 0.265940\n",
      "batch 3858: loss 0.365484\n",
      "batch 3859: loss 0.446368\n",
      "batch 3860: loss 0.358904\n",
      "batch 3861: loss 0.370392\n",
      "batch 3862: loss 0.326259\n",
      "batch 3863: loss 0.299070\n",
      "batch 3864: loss 0.361727\n",
      "batch 3865: loss 0.511721\n",
      "batch 3866: loss 0.468721\n",
      "batch 3867: loss 0.431488\n",
      "batch 3868: loss 0.305387\n",
      "batch 3869: loss 0.258446\n",
      "batch 3870: loss 0.458239\n",
      "batch 3871: loss 0.330512\n",
      "batch 3872: loss 0.411353\n",
      "batch 3873: loss 0.493588\n",
      "batch 3874: loss 0.408458\n",
      "batch 3875: loss 0.471816\n",
      "batch 3876: loss 0.505134\n",
      "batch 3877: loss 0.404253\n",
      "batch 3878: loss 0.345239\n",
      "batch 3879: loss 0.322133\n",
      "batch 3880: loss 0.310742\n",
      "batch 3881: loss 0.350730\n",
      "batch 3882: loss 0.358538\n",
      "batch 3883: loss 0.269064\n",
      "batch 3884: loss 0.400138\n",
      "batch 3885: loss 0.314838\n",
      "batch 3886: loss 0.554912\n",
      "batch 3887: loss 0.570921\n",
      "batch 3888: loss 0.610157\n",
      "batch 3889: loss 0.401605\n",
      "batch 3890: loss 0.351429\n",
      "batch 3891: loss 0.318347\n",
      "batch 3892: loss 0.622770\n",
      "batch 3893: loss 0.524698\n",
      "batch 3894: loss 0.383028\n",
      "batch 3895: loss 0.471530\n",
      "batch 3896: loss 0.494820\n",
      "batch 3897: loss 0.385705\n",
      "batch 3898: loss 0.357159\n",
      "batch 3899: loss 0.190192\n",
      "batch 3900: loss 0.555715\n",
      "batch 3901: loss 0.349424\n",
      "batch 3902: loss 0.443266\n",
      "batch 3903: loss 0.272272\n",
      "batch 3904: loss 0.398324\n",
      "batch 3905: loss 0.411081\n",
      "batch 3906: loss 0.316189\n",
      "batch 3907: loss 0.261033\n",
      "batch 3908: loss 0.334174\n",
      "batch 3909: loss 0.391915\n",
      "batch 3910: loss 0.412876\n",
      "batch 3911: loss 0.321980\n",
      "batch 3912: loss 0.542966\n",
      "batch 3913: loss 0.572621\n",
      "batch 3914: loss 0.260957\n",
      "batch 3915: loss 0.382257\n",
      "batch 3916: loss 0.286078\n",
      "batch 3917: loss 0.334034\n",
      "batch 3918: loss 0.278894\n",
      "batch 3919: loss 0.382827\n",
      "batch 3920: loss 0.355628\n",
      "batch 3921: loss 0.285357\n",
      "batch 3922: loss 0.455790\n",
      "batch 3923: loss 0.446775\n",
      "batch 3924: loss 0.381446\n",
      "batch 3925: loss 0.427992\n",
      "batch 3926: loss 0.355735\n",
      "batch 3927: loss 0.338275\n",
      "batch 3928: loss 0.461417\n",
      "batch 3929: loss 0.572076\n",
      "batch 3930: loss 0.464195\n",
      "batch 3931: loss 0.471773\n",
      "batch 3932: loss 0.544165\n",
      "batch 3933: loss 0.445990\n",
      "batch 3934: loss 0.335696\n",
      "batch 3935: loss 0.423051\n",
      "batch 3936: loss 0.370239\n",
      "batch 3937: loss 0.401264\n",
      "batch 3938: loss 0.269656\n",
      "batch 3939: loss 0.476983\n",
      "batch 3940: loss 0.161276\n",
      "batch 3941: loss 0.347105\n",
      "batch 3942: loss 0.472978\n",
      "batch 3943: loss 0.499165\n",
      "batch 3944: loss 0.380838\n",
      "batch 3945: loss 0.366235\n",
      "batch 3946: loss 0.263591\n",
      "batch 3947: loss 0.523145\n",
      "batch 3948: loss 0.360583\n",
      "batch 3949: loss 0.360273\n",
      "batch 3950: loss 0.449689\n",
      "batch 3951: loss 0.389178\n",
      "batch 3952: loss 0.267884\n",
      "batch 3953: loss 0.736576\n",
      "batch 3954: loss 0.404061\n",
      "batch 3955: loss 0.452392\n",
      "batch 3956: loss 0.514362\n",
      "batch 3957: loss 0.381903\n",
      "batch 3958: loss 0.562198\n",
      "batch 3959: loss 0.387803\n",
      "batch 3960: loss 0.266268\n",
      "batch 3961: loss 0.376464\n",
      "batch 3962: loss 0.379328\n",
      "batch 3963: loss 0.391731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3964: loss 0.386218\n",
      "batch 3965: loss 0.424322\n",
      "batch 3966: loss 0.524059\n",
      "batch 3967: loss 0.302708\n",
      "batch 3968: loss 0.487854\n",
      "batch 3969: loss 0.327433\n",
      "batch 3970: loss 0.409593\n",
      "batch 3971: loss 0.365979\n",
      "batch 3972: loss 0.287426\n",
      "batch 3973: loss 0.318753\n",
      "batch 3974: loss 0.369342\n",
      "batch 3975: loss 0.271539\n",
      "batch 3976: loss 0.275945\n",
      "batch 3977: loss 0.542150\n",
      "batch 3978: loss 0.344318\n",
      "batch 3979: loss 0.405079\n",
      "batch 3980: loss 0.442062\n",
      "batch 3981: loss 0.195965\n",
      "batch 3982: loss 0.273658\n",
      "batch 3983: loss 0.333468\n",
      "batch 3984: loss 0.428682\n",
      "batch 3985: loss 0.267171\n",
      "batch 3986: loss 0.329988\n",
      "batch 3987: loss 0.451824\n",
      "batch 3988: loss 0.270979\n",
      "batch 3989: loss 0.297140\n",
      "batch 3990: loss 0.427469\n",
      "batch 3991: loss 0.239448\n",
      "batch 3992: loss 0.450628\n",
      "batch 3993: loss 0.306219\n",
      "batch 3994: loss 0.351463\n",
      "batch 3995: loss 0.607751\n",
      "batch 3996: loss 0.653694\n",
      "batch 3997: loss 0.470637\n",
      "batch 3998: loss 0.544904\n",
      "batch 3999: loss 0.193482\n",
      "batch 4000: loss 0.449796\n",
      "batch 4001: loss 0.339613\n",
      "batch 4002: loss 0.350269\n",
      "batch 4003: loss 0.362514\n",
      "batch 4004: loss 0.351191\n",
      "batch 4005: loss 0.376915\n",
      "batch 4006: loss 0.516137\n",
      "batch 4007: loss 0.346269\n",
      "batch 4008: loss 0.377273\n",
      "batch 4009: loss 0.274861\n",
      "batch 4010: loss 0.325977\n",
      "batch 4011: loss 0.314526\n",
      "batch 4012: loss 0.503099\n",
      "batch 4013: loss 0.381707\n",
      "batch 4014: loss 0.256144\n",
      "batch 4015: loss 0.440518\n",
      "batch 4016: loss 0.346892\n",
      "batch 4017: loss 0.286564\n",
      "batch 4018: loss 0.292361\n",
      "batch 4019: loss 0.479881\n",
      "batch 4020: loss 0.336789\n",
      "batch 4021: loss 0.356285\n",
      "batch 4022: loss 0.323782\n",
      "batch 4023: loss 0.364811\n",
      "batch 4024: loss 0.360919\n",
      "batch 4025: loss 0.230326\n",
      "batch 4026: loss 0.482169\n",
      "batch 4027: loss 0.281790\n",
      "batch 4028: loss 0.386337\n",
      "batch 4029: loss 0.301640\n",
      "batch 4030: loss 0.491895\n",
      "batch 4031: loss 0.347774\n",
      "batch 4032: loss 0.549054\n",
      "batch 4033: loss 0.400005\n",
      "batch 4034: loss 0.333443\n",
      "batch 4035: loss 0.302277\n",
      "batch 4036: loss 0.356962\n",
      "batch 4037: loss 0.371872\n",
      "batch 4038: loss 0.370534\n",
      "batch 4039: loss 0.235082\n",
      "batch 4040: loss 0.339579\n",
      "batch 4041: loss 0.403185\n",
      "batch 4042: loss 0.357417\n",
      "batch 4043: loss 0.607388\n",
      "batch 4044: loss 0.320721\n",
      "batch 4045: loss 0.612717\n",
      "batch 4046: loss 0.436591\n",
      "batch 4047: loss 0.205856\n",
      "batch 4048: loss 0.422996\n",
      "batch 4049: loss 0.273181\n",
      "batch 4050: loss 0.372684\n",
      "batch 4051: loss 0.378335\n",
      "batch 4052: loss 0.406220\n",
      "batch 4053: loss 0.421153\n",
      "batch 4054: loss 0.347235\n",
      "batch 4055: loss 0.253569\n",
      "batch 4056: loss 0.283691\n",
      "batch 4057: loss 0.383959\n",
      "batch 4058: loss 0.343308\n",
      "batch 4059: loss 0.262378\n",
      "batch 4060: loss 0.231495\n",
      "batch 4061: loss 0.389445\n",
      "batch 4062: loss 0.478468\n",
      "batch 4063: loss 0.357936\n",
      "batch 4064: loss 0.373278\n",
      "batch 4065: loss 0.428749\n",
      "batch 4066: loss 0.318607\n",
      "batch 4067: loss 0.635176\n",
      "batch 4068: loss 0.367152\n",
      "batch 4069: loss 0.347671\n",
      "batch 4070: loss 0.471675\n",
      "batch 4071: loss 0.573958\n",
      "batch 4072: loss 0.252304\n",
      "batch 4073: loss 0.284692\n",
      "batch 4074: loss 0.339801\n",
      "batch 4075: loss 0.445147\n",
      "batch 4076: loss 0.461520\n",
      "batch 4077: loss 0.268316\n",
      "batch 4078: loss 0.241920\n",
      "batch 4079: loss 0.548408\n",
      "batch 4080: loss 0.360685\n",
      "batch 4081: loss 0.401111\n",
      "batch 4082: loss 0.280833\n",
      "batch 4083: loss 0.432693\n",
      "batch 4084: loss 0.418359\n",
      "batch 4085: loss 0.394970\n",
      "batch 4086: loss 0.333031\n",
      "batch 4087: loss 0.396198\n",
      "batch 4088: loss 0.406933\n",
      "batch 4089: loss 0.295375\n",
      "batch 4090: loss 0.384727\n",
      "batch 4091: loss 0.281010\n",
      "batch 4092: loss 0.294528\n",
      "batch 4093: loss 0.452210\n",
      "batch 4094: loss 0.423055\n",
      "batch 4095: loss 0.440576\n",
      "batch 4096: loss 0.307152\n",
      "batch 4097: loss 0.541928\n",
      "batch 4098: loss 0.363946\n",
      "batch 4099: loss 0.218187\n",
      "batch 4100: loss 0.451769\n",
      "batch 4101: loss 0.368320\n",
      "batch 4102: loss 0.536343\n",
      "batch 4103: loss 0.369230\n",
      "batch 4104: loss 0.457001\n",
      "batch 4105: loss 0.388909\n",
      "batch 4106: loss 0.421152\n",
      "batch 4107: loss 0.509946\n",
      "batch 4108: loss 0.404309\n",
      "batch 4109: loss 0.511795\n",
      "batch 4110: loss 0.416365\n",
      "batch 4111: loss 0.272343\n",
      "batch 4112: loss 0.422416\n",
      "batch 4113: loss 0.259481\n",
      "batch 4114: loss 0.278852\n",
      "batch 4115: loss 0.302529\n",
      "batch 4116: loss 0.444455\n",
      "batch 4117: loss 0.514918\n",
      "batch 4118: loss 0.337797\n",
      "batch 4119: loss 0.264123\n",
      "batch 4120: loss 0.438516\n",
      "batch 4121: loss 0.268005\n",
      "batch 4122: loss 0.355065\n",
      "batch 4123: loss 0.420106\n",
      "batch 4124: loss 0.454991\n",
      "batch 4125: loss 0.308251\n",
      "batch 4126: loss 0.307874\n",
      "batch 4127: loss 0.322561\n",
      "batch 4128: loss 0.380041\n",
      "batch 4129: loss 0.338222\n",
      "batch 4130: loss 0.317689\n",
      "batch 4131: loss 0.387457\n",
      "batch 4132: loss 0.470474\n",
      "batch 4133: loss 0.451496\n",
      "batch 4134: loss 0.476971\n",
      "batch 4135: loss 0.415267\n",
      "batch 4136: loss 0.384782\n",
      "batch 4137: loss 0.211637\n",
      "batch 4138: loss 0.400619\n",
      "batch 4139: loss 0.264019\n",
      "batch 4140: loss 0.368395\n",
      "batch 4141: loss 0.550674\n",
      "batch 4142: loss 0.369972\n",
      "batch 4143: loss 0.513912\n",
      "batch 4144: loss 0.402622\n",
      "batch 4145: loss 0.316818\n",
      "batch 4146: loss 0.604838\n",
      "batch 4147: loss 0.337189\n",
      "batch 4148: loss 0.534465\n",
      "batch 4149: loss 0.272848\n",
      "batch 4150: loss 0.356478\n",
      "batch 4151: loss 0.255711\n",
      "batch 4152: loss 0.278483\n",
      "batch 4153: loss 0.444682\n",
      "batch 4154: loss 0.321599\n",
      "batch 4155: loss 0.491718\n",
      "batch 4156: loss 0.378172\n",
      "batch 4157: loss 0.361829\n",
      "batch 4158: loss 0.339599\n",
      "batch 4159: loss 0.652452\n",
      "batch 4160: loss 0.340163\n",
      "batch 4161: loss 0.435587\n",
      "batch 4162: loss 0.501111\n",
      "batch 4163: loss 0.441474\n",
      "batch 4164: loss 0.353628\n",
      "batch 4165: loss 0.299743\n",
      "batch 4166: loss 0.388882\n",
      "batch 4167: loss 0.399286\n",
      "batch 4168: loss 0.310055\n",
      "batch 4169: loss 0.279518\n",
      "batch 4170: loss 0.304675\n",
      "batch 4171: loss 0.252402\n",
      "batch 4172: loss 0.443440\n",
      "batch 4173: loss 0.609729\n",
      "batch 4174: loss 0.394474\n",
      "batch 4175: loss 0.358766\n",
      "batch 4176: loss 0.437304\n",
      "batch 4177: loss 0.384061\n",
      "batch 4178: loss 0.490044\n",
      "batch 4179: loss 0.509421\n",
      "batch 4180: loss 0.431072\n",
      "batch 4181: loss 0.357442\n",
      "batch 4182: loss 0.360080\n",
      "batch 4183: loss 0.314119\n",
      "batch 4184: loss 0.312714\n",
      "batch 4185: loss 0.324516\n",
      "batch 4186: loss 0.264173\n",
      "batch 4187: loss 0.459400\n",
      "batch 4188: loss 0.275357\n",
      "batch 4189: loss 0.357872\n",
      "batch 4190: loss 0.474717\n",
      "batch 4191: loss 0.391108\n",
      "batch 4192: loss 0.421666\n",
      "batch 4193: loss 0.360918\n",
      "batch 4194: loss 0.425155\n",
      "batch 4195: loss 0.213321\n",
      "batch 4196: loss 0.344919\n",
      "batch 4197: loss 0.474107\n",
      "batch 4198: loss 0.447916\n",
      "batch 4199: loss 0.274427\n",
      "batch 4200: loss 0.355962\n",
      "batch 4201: loss 0.532693\n",
      "batch 4202: loss 0.430472\n",
      "batch 4203: loss 0.251910\n",
      "batch 4204: loss 0.368179\n",
      "batch 4205: loss 0.482764\n",
      "batch 4206: loss 0.251055\n",
      "batch 4207: loss 0.543851\n",
      "batch 4208: loss 0.411336\n",
      "batch 4209: loss 0.438071\n",
      "batch 4210: loss 0.323229\n",
      "batch 4211: loss 0.348776\n",
      "batch 4212: loss 0.271774\n",
      "batch 4213: loss 0.337108\n",
      "batch 4214: loss 0.289544\n",
      "batch 4215: loss 0.248661\n",
      "batch 4216: loss 0.575759\n",
      "batch 4217: loss 0.287926\n",
      "batch 4218: loss 0.348025\n",
      "batch 4219: loss 0.407201\n",
      "batch 4220: loss 0.188075\n",
      "batch 4221: loss 0.364803\n",
      "batch 4222: loss 0.438107\n",
      "batch 4223: loss 0.280258\n",
      "batch 4224: loss 0.548560\n",
      "batch 4225: loss 0.290376\n",
      "batch 4226: loss 0.409367\n",
      "batch 4227: loss 0.375099\n",
      "batch 4228: loss 0.361537\n",
      "batch 4229: loss 0.422338\n",
      "batch 4230: loss 0.532387\n",
      "batch 4231: loss 0.489162\n",
      "batch 4232: loss 0.257439\n",
      "batch 4233: loss 0.498495\n",
      "batch 4234: loss 0.412428\n",
      "batch 4235: loss 0.419655\n",
      "batch 4236: loss 0.352914\n",
      "batch 4237: loss 0.272356\n",
      "batch 4238: loss 0.460516\n",
      "batch 4239: loss 0.424725\n",
      "batch 4240: loss 0.392901\n",
      "batch 4241: loss 0.186714\n",
      "batch 4242: loss 0.485347\n",
      "batch 4243: loss 0.307908\n",
      "batch 4244: loss 0.397140\n",
      "batch 4245: loss 0.466979\n",
      "batch 4246: loss 0.416577\n",
      "batch 4247: loss 0.437964\n",
      "batch 4248: loss 0.525579\n",
      "batch 4249: loss 0.341911\n",
      "batch 4250: loss 0.400743\n",
      "batch 4251: loss 0.644441\n",
      "batch 4252: loss 0.252171\n",
      "batch 4253: loss 0.426954\n",
      "batch 4254: loss 0.306356\n",
      "batch 4255: loss 0.430278\n",
      "batch 4256: loss 0.336247\n",
      "batch 4257: loss 0.593946\n",
      "batch 4258: loss 0.384728\n",
      "batch 4259: loss 0.255552\n",
      "batch 4260: loss 0.347147\n",
      "batch 4261: loss 0.615053\n",
      "batch 4262: loss 0.385660\n",
      "batch 4263: loss 0.365812\n",
      "batch 4264: loss 0.700737\n",
      "batch 4265: loss 0.382546\n",
      "batch 4266: loss 0.282907\n",
      "batch 4267: loss 0.342005\n",
      "batch 4268: loss 0.189471\n",
      "batch 4269: loss 0.501517\n",
      "batch 4270: loss 0.401322\n",
      "batch 4271: loss 0.352150\n",
      "batch 4272: loss 0.477094\n",
      "batch 4273: loss 0.281790\n",
      "batch 4274: loss 0.339200\n",
      "batch 4275: loss 0.210848\n",
      "batch 4276: loss 0.304035\n",
      "batch 4277: loss 0.674338\n",
      "batch 4278: loss 0.429369\n",
      "batch 4279: loss 0.294435\n",
      "batch 4280: loss 0.226255\n",
      "batch 4281: loss 0.334763\n",
      "batch 4282: loss 0.376155\n",
      "batch 4283: loss 0.437255\n",
      "batch 4284: loss 0.306621\n",
      "batch 4285: loss 0.504322\n",
      "batch 4286: loss 0.461383\n",
      "batch 4287: loss 0.573139\n",
      "batch 4288: loss 0.297825\n",
      "batch 4289: loss 0.334699\n",
      "batch 4290: loss 0.234632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4291: loss 0.309474\n",
      "batch 4292: loss 0.378057\n",
      "batch 4293: loss 0.307088\n",
      "batch 4294: loss 0.489785\n",
      "batch 4295: loss 0.278384\n",
      "batch 4296: loss 0.410208\n",
      "batch 4297: loss 0.549360\n",
      "batch 4298: loss 0.522572\n",
      "batch 4299: loss 0.419292\n",
      "batch 4300: loss 0.402801\n",
      "batch 4301: loss 0.380424\n",
      "batch 4302: loss 0.410837\n",
      "batch 4303: loss 0.414971\n",
      "batch 4304: loss 0.431970\n",
      "batch 4305: loss 0.405408\n",
      "batch 4306: loss 0.569391\n",
      "batch 4307: loss 0.435038\n",
      "batch 4308: loss 0.413860\n",
      "batch 4309: loss 0.271008\n",
      "batch 4310: loss 0.358764\n",
      "batch 4311: loss 0.293947\n",
      "batch 4312: loss 0.270990\n",
      "batch 4313: loss 0.357443\n",
      "batch 4314: loss 0.492562\n",
      "batch 4315: loss 0.389309\n",
      "batch 4316: loss 0.443402\n",
      "batch 4317: loss 0.492626\n",
      "batch 4318: loss 0.229525\n",
      "batch 4319: loss 0.321333\n",
      "batch 4320: loss 0.435126\n",
      "batch 4321: loss 0.402847\n",
      "batch 4322: loss 0.315383\n",
      "batch 4323: loss 0.422726\n",
      "batch 4324: loss 0.482013\n",
      "batch 4325: loss 0.485354\n",
      "batch 4326: loss 0.609487\n",
      "batch 4327: loss 0.231309\n",
      "batch 4328: loss 0.459526\n",
      "batch 4329: loss 0.348570\n",
      "batch 4330: loss 0.367861\n",
      "batch 4331: loss 0.235058\n",
      "batch 4332: loss 0.398631\n",
      "batch 4333: loss 0.382713\n",
      "batch 4334: loss 0.305441\n",
      "batch 4335: loss 0.576381\n",
      "batch 4336: loss 0.430611\n",
      "batch 4337: loss 0.300254\n",
      "batch 4338: loss 0.469602\n",
      "batch 4339: loss 0.261875\n",
      "batch 4340: loss 0.330011\n",
      "batch 4341: loss 0.512270\n",
      "batch 4342: loss 0.364057\n",
      "batch 4343: loss 0.231697\n",
      "batch 4344: loss 0.275719\n",
      "batch 4345: loss 0.359640\n",
      "batch 4346: loss 0.324695\n",
      "batch 4347: loss 0.358651\n",
      "batch 4348: loss 0.331376\n",
      "batch 4349: loss 0.221464\n",
      "batch 4350: loss 0.366754\n",
      "batch 4351: loss 0.579096\n",
      "batch 4352: loss 0.553169\n",
      "batch 4353: loss 0.452020\n",
      "batch 4354: loss 0.359641\n",
      "batch 4355: loss 0.409559\n",
      "batch 4356: loss 0.470299\n",
      "batch 4357: loss 0.457623\n",
      "batch 4358: loss 0.419488\n",
      "batch 4359: loss 0.352297\n",
      "batch 4360: loss 0.400301\n",
      "batch 4361: loss 0.476742\n",
      "batch 4362: loss 0.337334\n",
      "batch 4363: loss 0.623049\n",
      "batch 4364: loss 0.318708\n",
      "batch 4365: loss 0.536621\n",
      "batch 4366: loss 0.235913\n",
      "batch 4367: loss 0.398718\n",
      "batch 4368: loss 0.329827\n",
      "batch 4369: loss 0.518579\n",
      "batch 4370: loss 0.342728\n",
      "batch 4371: loss 0.341886\n",
      "batch 4372: loss 0.435476\n",
      "batch 4373: loss 0.339467\n",
      "batch 4374: loss 0.283350\n",
      "batch 4375: loss 0.384650\n",
      "batch 4376: loss 0.371269\n",
      "batch 4377: loss 0.341097\n",
      "batch 4378: loss 0.345249\n",
      "batch 4379: loss 0.380173\n",
      "batch 4380: loss 0.367503\n",
      "batch 4381: loss 0.473911\n",
      "batch 4382: loss 0.191446\n",
      "batch 4383: loss 0.376060\n",
      "batch 4384: loss 0.431860\n",
      "batch 4385: loss 0.611373\n",
      "batch 4386: loss 0.266264\n",
      "batch 4387: loss 0.232891\n",
      "batch 4388: loss 0.435415\n",
      "batch 4389: loss 0.257813\n",
      "batch 4390: loss 0.393445\n",
      "batch 4391: loss 0.292457\n",
      "batch 4392: loss 0.462850\n",
      "batch 4393: loss 0.554477\n",
      "batch 4394: loss 0.340192\n",
      "batch 4395: loss 0.352195\n",
      "batch 4396: loss 0.628443\n",
      "batch 4397: loss 0.476026\n",
      "batch 4398: loss 0.364223\n",
      "batch 4399: loss 0.535278\n",
      "batch 4400: loss 0.321666\n",
      "batch 4401: loss 0.459943\n",
      "batch 4402: loss 0.402386\n",
      "batch 4403: loss 0.386980\n",
      "batch 4404: loss 0.351914\n",
      "batch 4405: loss 0.279807\n",
      "batch 4406: loss 0.330577\n",
      "batch 4407: loss 0.500091\n",
      "batch 4408: loss 0.434301\n",
      "batch 4409: loss 0.275082\n",
      "batch 4410: loss 0.635169\n",
      "batch 4411: loss 0.216772\n",
      "batch 4412: loss 0.431285\n",
      "batch 4413: loss 0.297362\n",
      "batch 4414: loss 0.426668\n",
      "batch 4415: loss 0.347473\n",
      "batch 4416: loss 0.296880\n",
      "batch 4417: loss 0.556142\n",
      "batch 4418: loss 0.487710\n",
      "batch 4419: loss 0.389345\n",
      "batch 4420: loss 0.400466\n",
      "batch 4421: loss 0.237945\n",
      "batch 4422: loss 0.514493\n",
      "batch 4423: loss 0.501377\n",
      "batch 4424: loss 0.159435\n",
      "batch 4425: loss 0.346559\n",
      "batch 4426: loss 0.734311\n",
      "batch 4427: loss 0.604056\n",
      "batch 4428: loss 0.376860\n",
      "batch 4429: loss 0.302247\n",
      "batch 4430: loss 0.467137\n",
      "batch 4431: loss 0.368489\n",
      "batch 4432: loss 0.329241\n",
      "batch 4433: loss 0.310076\n",
      "batch 4434: loss 0.573675\n",
      "batch 4435: loss 0.330434\n",
      "batch 4436: loss 0.314046\n",
      "batch 4437: loss 0.381401\n",
      "batch 4438: loss 0.232875\n",
      "batch 4439: loss 0.515403\n",
      "batch 4440: loss 0.706425\n",
      "batch 4441: loss 0.397491\n",
      "batch 4442: loss 0.443355\n",
      "batch 4443: loss 0.332092\n",
      "batch 4444: loss 0.284038\n",
      "batch 4445: loss 0.389667\n",
      "batch 4446: loss 0.346763\n",
      "batch 4447: loss 0.182989\n",
      "batch 4448: loss 0.528412\n",
      "batch 4449: loss 0.279867\n",
      "batch 4450: loss 0.433187\n",
      "batch 4451: loss 0.652846\n",
      "batch 4452: loss 0.231916\n",
      "batch 4453: loss 0.284610\n",
      "batch 4454: loss 0.353076\n",
      "batch 4455: loss 0.479477\n",
      "batch 4456: loss 0.272492\n",
      "batch 4457: loss 0.284672\n",
      "batch 4458: loss 0.280749\n",
      "batch 4459: loss 0.286887\n",
      "batch 4460: loss 0.530906\n",
      "batch 4461: loss 0.458478\n",
      "batch 4462: loss 0.582009\n",
      "batch 4463: loss 0.376306\n",
      "batch 4464: loss 0.299210\n",
      "batch 4465: loss 0.426295\n",
      "batch 4466: loss 0.286385\n",
      "batch 4467: loss 0.382144\n",
      "batch 4468: loss 0.424248\n",
      "batch 4469: loss 0.738404\n",
      "batch 4470: loss 0.478910\n",
      "batch 4471: loss 0.646769\n",
      "batch 4472: loss 0.285538\n",
      "batch 4473: loss 0.547720\n",
      "batch 4474: loss 0.422001\n",
      "batch 4475: loss 0.399012\n",
      "batch 4476: loss 0.346734\n",
      "batch 4477: loss 0.312281\n",
      "batch 4478: loss 0.398164\n",
      "batch 4479: loss 0.418678\n",
      "batch 4480: loss 0.231595\n",
      "batch 4481: loss 0.610606\n",
      "batch 4482: loss 0.344244\n",
      "batch 4483: loss 0.434801\n",
      "batch 4484: loss 0.484865\n",
      "batch 4485: loss 0.438442\n",
      "batch 4486: loss 0.584368\n",
      "batch 4487: loss 0.388974\n",
      "batch 4488: loss 0.284514\n",
      "batch 4489: loss 0.380452\n",
      "batch 4490: loss 0.364370\n",
      "batch 4491: loss 0.514883\n",
      "batch 4492: loss 0.313328\n",
      "batch 4493: loss 0.465796\n",
      "batch 4494: loss 0.398610\n",
      "batch 4495: loss 0.276530\n",
      "batch 4496: loss 0.396302\n",
      "batch 4497: loss 0.308586\n",
      "batch 4498: loss 0.357854\n",
      "batch 4499: loss 0.221677\n",
      "batch 4500: loss 0.295067\n",
      "batch 4501: loss 0.343474\n",
      "batch 4502: loss 0.580857\n",
      "batch 4503: loss 0.335686\n",
      "batch 4504: loss 0.333884\n",
      "batch 4505: loss 0.309648\n",
      "batch 4506: loss 0.587186\n",
      "batch 4507: loss 0.552270\n",
      "batch 4508: loss 0.291609\n",
      "batch 4509: loss 0.324157\n",
      "batch 4510: loss 0.678228\n",
      "batch 4511: loss 0.340080\n",
      "batch 4512: loss 0.278986\n",
      "batch 4513: loss 0.494534\n",
      "batch 4514: loss 0.242637\n",
      "batch 4515: loss 0.509260\n",
      "batch 4516: loss 0.358159\n",
      "batch 4517: loss 0.485245\n",
      "batch 4518: loss 0.353788\n",
      "batch 4519: loss 0.347525\n",
      "batch 4520: loss 0.226427\n",
      "batch 4521: loss 0.442855\n",
      "batch 4522: loss 0.392564\n",
      "batch 4523: loss 0.291513\n",
      "batch 4524: loss 0.267663\n",
      "batch 4525: loss 0.329520\n",
      "batch 4526: loss 0.350204\n",
      "batch 4527: loss 0.267471\n",
      "batch 4528: loss 0.318584\n",
      "batch 4529: loss 0.516714\n",
      "batch 4530: loss 0.391801\n",
      "batch 4531: loss 0.371989\n",
      "batch 4532: loss 0.209465\n",
      "batch 4533: loss 0.337999\n",
      "batch 4534: loss 0.357082\n",
      "batch 4535: loss 0.313359\n",
      "batch 4536: loss 0.543053\n",
      "batch 4537: loss 0.319195\n",
      "batch 4538: loss 0.220050\n",
      "batch 4539: loss 0.296312\n",
      "batch 4540: loss 0.407778\n",
      "batch 4541: loss 0.192639\n",
      "batch 4542: loss 0.242412\n",
      "batch 4543: loss 0.200599\n",
      "batch 4544: loss 0.362160\n",
      "batch 4545: loss 0.312790\n",
      "batch 4546: loss 0.369828\n",
      "batch 4547: loss 0.321987\n",
      "batch 4548: loss 0.320401\n",
      "batch 4549: loss 0.573736\n",
      "batch 4550: loss 0.307104\n",
      "batch 4551: loss 0.396053\n",
      "batch 4552: loss 0.397290\n",
      "batch 4553: loss 0.719352\n",
      "batch 4554: loss 0.220469\n",
      "batch 4555: loss 0.588626\n",
      "batch 4556: loss 0.301539\n",
      "batch 4557: loss 0.359909\n",
      "batch 4558: loss 0.492772\n",
      "batch 4559: loss 0.292449\n",
      "batch 4560: loss 0.252433\n",
      "batch 4561: loss 0.350126\n",
      "batch 4562: loss 0.363068\n",
      "batch 4563: loss 0.545328\n",
      "batch 4564: loss 0.315477\n",
      "batch 4565: loss 0.438001\n",
      "batch 4566: loss 0.278698\n",
      "batch 4567: loss 0.200244\n",
      "batch 4568: loss 0.225421\n",
      "batch 4569: loss 0.305337\n",
      "batch 4570: loss 0.402313\n",
      "batch 4571: loss 0.331126\n",
      "batch 4572: loss 0.322737\n",
      "batch 4573: loss 0.297850\n",
      "batch 4574: loss 0.270006\n",
      "batch 4575: loss 0.398718\n",
      "batch 4576: loss 0.438566\n",
      "batch 4577: loss 0.436221\n",
      "batch 4578: loss 0.239860\n",
      "batch 4579: loss 0.384237\n",
      "batch 4580: loss 0.232711\n",
      "batch 4581: loss 0.352872\n",
      "batch 4582: loss 0.213075\n",
      "batch 4583: loss 0.251250\n",
      "batch 4584: loss 0.341213\n",
      "batch 4585: loss 0.316880\n",
      "batch 4586: loss 0.292873\n",
      "batch 4587: loss 0.537684\n",
      "batch 4588: loss 0.449154\n",
      "batch 4589: loss 0.264907\n",
      "batch 4590: loss 0.341259\n",
      "batch 4591: loss 0.458267\n",
      "batch 4592: loss 0.350706\n",
      "batch 4593: loss 0.446449\n",
      "batch 4594: loss 0.310532\n",
      "batch 4595: loss 0.503974\n",
      "batch 4596: loss 0.364557\n",
      "batch 4597: loss 0.247044\n",
      "batch 4598: loss 0.506271\n",
      "batch 4599: loss 0.228794\n",
      "batch 4600: loss 0.363415\n",
      "batch 4601: loss 0.195246\n",
      "batch 4602: loss 0.722028\n",
      "batch 4603: loss 0.279846\n",
      "batch 4604: loss 0.338586\n",
      "batch 4605: loss 0.538225\n",
      "batch 4606: loss 0.205818\n",
      "batch 4607: loss 0.297942\n",
      "batch 4608: loss 0.320717\n",
      "batch 4609: loss 0.516014\n",
      "batch 4610: loss 0.522818\n",
      "batch 4611: loss 0.458682\n",
      "batch 4612: loss 0.290906\n",
      "batch 4613: loss 0.291830\n",
      "batch 4614: loss 0.167721\n",
      "batch 4615: loss 0.169245\n",
      "batch 4616: loss 0.368480\n",
      "batch 4617: loss 0.330694\n",
      "batch 4618: loss 0.165926\n",
      "batch 4619: loss 0.247096\n",
      "batch 4620: loss 0.312580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4621: loss 0.299835\n",
      "batch 4622: loss 0.375484\n",
      "batch 4623: loss 0.400967\n",
      "batch 4624: loss 0.214634\n",
      "batch 4625: loss 0.369022\n",
      "batch 4626: loss 0.286843\n",
      "batch 4627: loss 0.309143\n",
      "batch 4628: loss 0.403598\n",
      "batch 4629: loss 0.394657\n",
      "batch 4630: loss 0.416860\n",
      "batch 4631: loss 0.372907\n",
      "batch 4632: loss 0.330731\n",
      "batch 4633: loss 0.276249\n",
      "batch 4634: loss 0.380058\n",
      "batch 4635: loss 0.351811\n",
      "batch 4636: loss 0.428431\n",
      "batch 4637: loss 0.386466\n",
      "batch 4638: loss 0.351659\n",
      "batch 4639: loss 0.354523\n",
      "batch 4640: loss 0.494377\n",
      "batch 4641: loss 0.450769\n",
      "batch 4642: loss 0.323137\n",
      "batch 4643: loss 0.624979\n",
      "batch 4644: loss 0.211322\n",
      "batch 4645: loss 0.321506\n",
      "batch 4646: loss 0.408596\n",
      "batch 4647: loss 0.310691\n",
      "batch 4648: loss 0.840021\n",
      "batch 4649: loss 0.408998\n",
      "batch 4650: loss 0.119663\n",
      "batch 4651: loss 0.380339\n",
      "batch 4652: loss 0.636624\n",
      "batch 4653: loss 0.316965\n",
      "batch 4654: loss 0.327380\n",
      "batch 4655: loss 0.158354\n",
      "batch 4656: loss 0.347643\n",
      "batch 4657: loss 0.230026\n",
      "batch 4658: loss 0.515220\n",
      "batch 4659: loss 0.482710\n",
      "batch 4660: loss 0.511201\n",
      "batch 4661: loss 0.430883\n",
      "batch 4662: loss 0.292080\n",
      "batch 4663: loss 0.321701\n",
      "batch 4664: loss 0.323775\n",
      "batch 4665: loss 0.648880\n",
      "batch 4666: loss 0.364685\n",
      "batch 4667: loss 0.386146\n",
      "batch 4668: loss 0.386217\n",
      "batch 4669: loss 0.588490\n",
      "batch 4670: loss 0.303727\n",
      "batch 4671: loss 0.234020\n",
      "batch 4672: loss 0.245596\n",
      "batch 4673: loss 0.241537\n",
      "batch 4674: loss 0.328123\n",
      "batch 4675: loss 0.542415\n",
      "batch 4676: loss 0.238690\n",
      "batch 4677: loss 0.683516\n",
      "batch 4678: loss 0.247744\n",
      "batch 4679: loss 0.331975\n",
      "batch 4680: loss 0.404860\n",
      "batch 4681: loss 0.382908\n",
      "batch 4682: loss 0.178940\n",
      "batch 4683: loss 0.398329\n",
      "batch 4684: loss 0.309760\n",
      "batch 4685: loss 0.307835\n",
      "batch 4686: loss 0.190148\n",
      "batch 4687: loss 0.331483\n",
      "batch 4688: loss 0.458778\n",
      "batch 4689: loss 0.327132\n",
      "batch 4690: loss 0.640216\n",
      "batch 4691: loss 0.380082\n",
      "batch 4692: loss 0.506996\n",
      "batch 4693: loss 0.421465\n",
      "batch 4694: loss 0.540378\n",
      "batch 4695: loss 0.458418\n",
      "batch 4696: loss 0.227523\n",
      "batch 4697: loss 0.321929\n",
      "batch 4698: loss 0.286896\n",
      "batch 4699: loss 0.429658\n",
      "batch 4700: loss 0.335671\n",
      "batch 4701: loss 0.308216\n",
      "batch 4702: loss 0.436757\n",
      "batch 4703: loss 0.406542\n",
      "batch 4704: loss 0.403830\n",
      "batch 4705: loss 0.317300\n",
      "batch 4706: loss 0.781532\n",
      "batch 4707: loss 0.342399\n",
      "batch 4708: loss 0.564746\n",
      "batch 4709: loss 0.503757\n",
      "batch 4710: loss 0.373612\n",
      "batch 4711: loss 0.363072\n",
      "batch 4712: loss 0.343994\n",
      "batch 4713: loss 0.272676\n",
      "batch 4714: loss 0.339315\n",
      "batch 4715: loss 0.182776\n",
      "batch 4716: loss 0.303398\n",
      "batch 4717: loss 0.496616\n",
      "batch 4718: loss 0.305804\n",
      "batch 4719: loss 0.586549\n",
      "batch 4720: loss 0.496988\n",
      "batch 4721: loss 0.389427\n",
      "batch 4722: loss 0.318299\n",
      "batch 4723: loss 0.249101\n",
      "batch 4724: loss 0.356436\n",
      "batch 4725: loss 0.520971\n",
      "batch 4726: loss 0.459142\n",
      "batch 4727: loss 0.354660\n",
      "batch 4728: loss 0.467753\n",
      "batch 4729: loss 0.267066\n",
      "batch 4730: loss 0.340121\n",
      "batch 4731: loss 0.291257\n",
      "batch 4732: loss 0.201609\n",
      "batch 4733: loss 0.329605\n",
      "batch 4734: loss 0.343963\n",
      "batch 4735: loss 0.354604\n",
      "batch 4736: loss 0.267077\n",
      "batch 4737: loss 0.316358\n",
      "batch 4738: loss 0.409448\n",
      "batch 4739: loss 0.567020\n",
      "batch 4740: loss 0.510723\n",
      "batch 4741: loss 0.498128\n",
      "batch 4742: loss 0.332302\n",
      "batch 4743: loss 0.394676\n",
      "batch 4744: loss 0.514126\n",
      "batch 4745: loss 0.247349\n",
      "batch 4746: loss 0.401318\n",
      "batch 4747: loss 0.616881\n",
      "batch 4748: loss 0.391912\n",
      "batch 4749: loss 0.492115\n",
      "batch 4750: loss 0.424337\n",
      "batch 4751: loss 0.214763\n",
      "batch 4752: loss 0.259804\n",
      "batch 4753: loss 0.204404\n",
      "batch 4754: loss 0.630884\n",
      "batch 4755: loss 0.315467\n",
      "batch 4756: loss 0.471438\n",
      "batch 4757: loss 0.369611\n",
      "batch 4758: loss 0.424791\n",
      "batch 4759: loss 0.389938\n",
      "batch 4760: loss 0.400650\n",
      "batch 4761: loss 0.244135\n",
      "batch 4762: loss 0.204396\n",
      "batch 4763: loss 0.399969\n",
      "batch 4764: loss 0.346493\n",
      "batch 4765: loss 0.444675\n",
      "batch 4766: loss 0.427868\n",
      "batch 4767: loss 0.313913\n",
      "batch 4768: loss 0.604496\n",
      "batch 4769: loss 0.227900\n",
      "batch 4770: loss 0.508292\n",
      "batch 4771: loss 0.429597\n",
      "batch 4772: loss 0.236278\n",
      "batch 4773: loss 0.199156\n",
      "batch 4774: loss 0.251755\n",
      "batch 4775: loss 0.418137\n",
      "batch 4776: loss 0.327719\n",
      "batch 4777: loss 0.582151\n",
      "batch 4778: loss 0.477633\n",
      "batch 4779: loss 0.387035\n",
      "batch 4780: loss 0.169951\n",
      "batch 4781: loss 0.369808\n",
      "batch 4782: loss 0.218465\n",
      "batch 4783: loss 0.588650\n",
      "batch 4784: loss 0.323754\n",
      "batch 4785: loss 0.375631\n",
      "batch 4786: loss 0.304741\n",
      "batch 4787: loss 0.466902\n",
      "batch 4788: loss 0.345136\n",
      "batch 4789: loss 0.370828\n",
      "batch 4790: loss 0.348087\n",
      "batch 4791: loss 0.389605\n",
      "batch 4792: loss 0.395065\n",
      "batch 4793: loss 0.370356\n",
      "batch 4794: loss 0.351077\n",
      "batch 4795: loss 0.376590\n",
      "batch 4796: loss 0.383542\n",
      "batch 4797: loss 0.514547\n",
      "batch 4798: loss 0.410521\n",
      "batch 4799: loss 0.355602\n",
      "batch 4800: loss 0.354325\n",
      "batch 4801: loss 0.396902\n",
      "batch 4802: loss 0.709708\n",
      "batch 4803: loss 0.252806\n",
      "batch 4804: loss 0.304281\n",
      "batch 4805: loss 0.229416\n",
      "batch 4806: loss 0.511224\n",
      "batch 4807: loss 0.473460\n",
      "batch 4808: loss 0.540993\n",
      "batch 4809: loss 0.571833\n",
      "batch 4810: loss 0.262469\n",
      "batch 4811: loss 0.319227\n",
      "batch 4812: loss 0.322688\n",
      "batch 4813: loss 0.399264\n",
      "batch 4814: loss 0.499575\n",
      "batch 4815: loss 0.496731\n",
      "batch 4816: loss 0.210116\n",
      "batch 4817: loss 0.570630\n",
      "batch 4818: loss 0.319023\n",
      "batch 4819: loss 0.439438\n",
      "batch 4820: loss 0.390751\n",
      "batch 4821: loss 0.401294\n",
      "batch 4822: loss 0.532570\n",
      "batch 4823: loss 0.289665\n",
      "batch 4824: loss 0.583894\n",
      "batch 4825: loss 0.415847\n",
      "batch 4826: loss 0.264979\n",
      "batch 4827: loss 0.440137\n",
      "batch 4828: loss 0.391162\n",
      "batch 4829: loss 0.450600\n",
      "batch 4830: loss 0.324104\n",
      "batch 4831: loss 0.176379\n",
      "batch 4832: loss 0.584663\n",
      "batch 4833: loss 0.269630\n",
      "batch 4834: loss 0.152720\n",
      "batch 4835: loss 0.305396\n",
      "batch 4836: loss 0.371446\n",
      "batch 4837: loss 0.354411\n",
      "batch 4838: loss 0.456604\n",
      "batch 4839: loss 0.385759\n",
      "batch 4840: loss 0.451549\n",
      "batch 4841: loss 0.366187\n",
      "batch 4842: loss 0.447201\n",
      "batch 4843: loss 0.306285\n",
      "batch 4844: loss 0.238611\n",
      "batch 4845: loss 0.180549\n",
      "batch 4846: loss 0.545824\n",
      "batch 4847: loss 0.256392\n",
      "batch 4848: loss 0.303798\n",
      "batch 4849: loss 0.434519\n",
      "batch 4850: loss 0.277068\n",
      "batch 4851: loss 0.230213\n",
      "batch 4852: loss 0.559585\n",
      "batch 4853: loss 0.410458\n",
      "batch 4854: loss 0.418658\n",
      "batch 4855: loss 0.580879\n",
      "batch 4856: loss 0.239781\n",
      "batch 4857: loss 0.364350\n",
      "batch 4858: loss 0.302024\n",
      "batch 4859: loss 0.475560\n",
      "batch 4860: loss 0.368386\n",
      "batch 4861: loss 0.259232\n",
      "batch 4862: loss 0.312396\n",
      "batch 4863: loss 0.246609\n",
      "batch 4864: loss 0.339902\n",
      "batch 4865: loss 0.451136\n",
      "batch 4866: loss 0.177519\n",
      "batch 4867: loss 0.169735\n",
      "batch 4868: loss 0.378823\n",
      "batch 4869: loss 0.291432\n",
      "batch 4870: loss 0.336445\n",
      "batch 4871: loss 0.496421\n",
      "batch 4872: loss 0.434240\n",
      "batch 4873: loss 0.557789\n",
      "batch 4874: loss 0.400254\n",
      "batch 4875: loss 0.276605\n",
      "batch 4876: loss 0.165259\n",
      "batch 4877: loss 0.261173\n",
      "batch 4878: loss 0.187666\n",
      "batch 4879: loss 0.250811\n",
      "batch 4880: loss 0.274431\n",
      "batch 4881: loss 0.426098\n",
      "batch 4882: loss 0.357628\n",
      "batch 4883: loss 0.439247\n",
      "batch 4884: loss 0.301748\n",
      "batch 4885: loss 0.334426\n",
      "batch 4886: loss 0.614640\n",
      "batch 4887: loss 0.299968\n",
      "batch 4888: loss 0.253802\n",
      "batch 4889: loss 0.475136\n",
      "batch 4890: loss 0.391001\n",
      "batch 4891: loss 0.410969\n",
      "batch 4892: loss 0.322396\n",
      "batch 4893: loss 0.622138\n",
      "batch 4894: loss 0.520482\n",
      "batch 4895: loss 0.425518\n",
      "batch 4896: loss 0.532663\n",
      "batch 4897: loss 0.367791\n",
      "batch 4898: loss 0.499501\n",
      "batch 4899: loss 0.671065\n",
      "batch 4900: loss 0.556938\n",
      "batch 4901: loss 0.385898\n",
      "batch 4902: loss 0.536222\n",
      "batch 4903: loss 0.359031\n",
      "batch 4904: loss 0.469022\n",
      "batch 4905: loss 0.404199\n",
      "batch 4906: loss 0.323776\n",
      "batch 4907: loss 0.441819\n",
      "batch 4908: loss 0.201033\n",
      "batch 4909: loss 0.241895\n",
      "batch 4910: loss 0.391759\n",
      "batch 4911: loss 0.423909\n",
      "batch 4912: loss 0.364768\n",
      "batch 4913: loss 0.204612\n",
      "batch 4914: loss 0.589829\n",
      "batch 4915: loss 0.518426\n",
      "batch 4916: loss 0.432800\n",
      "batch 4917: loss 0.357281\n",
      "batch 4918: loss 0.315141\n",
      "batch 4919: loss 0.216068\n",
      "batch 4920: loss 0.382406\n",
      "batch 4921: loss 0.339718\n",
      "batch 4922: loss 0.350704\n",
      "batch 4923: loss 0.642720\n",
      "batch 4924: loss 0.171390\n",
      "batch 4925: loss 0.300437\n",
      "batch 4926: loss 0.137397\n",
      "batch 4927: loss 0.297532\n",
      "batch 4928: loss 0.244184\n",
      "batch 4929: loss 0.233548\n",
      "batch 4930: loss 0.385988\n",
      "batch 4931: loss 0.284633\n",
      "batch 4932: loss 0.290345\n",
      "batch 4933: loss 0.430352\n",
      "batch 4934: loss 0.319163\n",
      "batch 4935: loss 0.304186\n",
      "batch 4936: loss 0.242392\n",
      "batch 4937: loss 0.266660\n",
      "batch 4938: loss 0.296206\n",
      "batch 4939: loss 0.390529\n",
      "batch 4940: loss 0.306400\n",
      "batch 4941: loss 0.295972\n",
      "batch 4942: loss 0.324831\n",
      "batch 4943: loss 0.342862\n",
      "batch 4944: loss 0.502069\n",
      "batch 4945: loss 0.343804\n",
      "batch 4946: loss 0.439144\n",
      "batch 4947: loss 0.425536\n",
      "batch 4948: loss 0.570175\n",
      "batch 4949: loss 0.285972\n",
      "batch 4950: loss 0.212283\n",
      "batch 4951: loss 0.282650\n",
      "batch 4952: loss 0.188206\n",
      "batch 4953: loss 0.413969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4954: loss 0.426022\n",
      "batch 4955: loss 0.357043\n",
      "batch 4956: loss 0.239253\n",
      "batch 4957: loss 0.280199\n",
      "batch 4958: loss 0.317207\n",
      "batch 4959: loss 0.357459\n",
      "batch 4960: loss 0.362327\n",
      "batch 4961: loss 0.250988\n",
      "batch 4962: loss 0.368882\n",
      "batch 4963: loss 0.283142\n",
      "batch 4964: loss 0.278075\n",
      "batch 4965: loss 0.374975\n",
      "batch 4966: loss 0.551075\n",
      "batch 4967: loss 0.361621\n",
      "batch 4968: loss 0.231932\n",
      "batch 4969: loss 0.337216\n",
      "batch 4970: loss 0.367625\n",
      "batch 4971: loss 0.321157\n",
      "batch 4972: loss 0.301117\n",
      "batch 4973: loss 0.429934\n",
      "batch 4974: loss 0.533546\n",
      "batch 4975: loss 0.296307\n",
      "batch 4976: loss 0.490444\n",
      "batch 4977: loss 0.520848\n",
      "batch 4978: loss 0.490120\n",
      "batch 4979: loss 0.293328\n",
      "batch 4980: loss 0.401180\n",
      "batch 4981: loss 0.293670\n",
      "batch 4982: loss 0.419897\n",
      "batch 4983: loss 0.373288\n",
      "batch 4984: loss 0.261106\n",
      "batch 4985: loss 0.257050\n",
      "batch 4986: loss 0.300601\n",
      "batch 4987: loss 0.379706\n",
      "batch 4988: loss 0.691899\n",
      "batch 4989: loss 0.576500\n",
      "batch 4990: loss 0.612205\n",
      "batch 4991: loss 0.441731\n",
      "batch 4992: loss 0.277202\n",
      "batch 4993: loss 0.206920\n",
      "batch 4994: loss 0.410431\n",
      "batch 4995: loss 0.217944\n",
      "batch 4996: loss 0.327110\n",
      "batch 4997: loss 0.447217\n",
      "batch 4998: loss 0.384341\n",
      "batch 4999: loss 0.399286\n",
      "batch 5000: loss 0.279986\n",
      "batch 5001: loss 0.287607\n",
      "batch 5002: loss 0.378345\n",
      "batch 5003: loss 0.334928\n",
      "batch 5004: loss 0.525398\n",
      "batch 5005: loss 0.369883\n",
      "batch 5006: loss 0.294502\n",
      "batch 5007: loss 0.152092\n",
      "batch 5008: loss 0.425712\n",
      "batch 5009: loss 0.331627\n",
      "batch 5010: loss 0.332328\n",
      "batch 5011: loss 0.212859\n",
      "batch 5012: loss 0.251188\n",
      "batch 5013: loss 0.284611\n",
      "batch 5014: loss 0.292672\n",
      "batch 5015: loss 0.334641\n",
      "batch 5016: loss 0.482753\n",
      "batch 5017: loss 0.562754\n",
      "batch 5018: loss 0.339199\n",
      "batch 5019: loss 0.362908\n",
      "batch 5020: loss 0.244580\n",
      "batch 5021: loss 0.646872\n",
      "batch 5022: loss 0.337985\n",
      "batch 5023: loss 0.284309\n",
      "batch 5024: loss 0.319630\n",
      "batch 5025: loss 0.220264\n",
      "batch 5026: loss 0.353847\n",
      "batch 5027: loss 0.467741\n",
      "batch 5028: loss 0.312352\n",
      "batch 5029: loss 0.342964\n",
      "batch 5030: loss 0.205026\n",
      "batch 5031: loss 0.566820\n",
      "batch 5032: loss 0.185147\n",
      "batch 5033: loss 0.401168\n",
      "batch 5034: loss 0.238166\n",
      "batch 5035: loss 0.449642\n",
      "batch 5036: loss 0.394420\n",
      "batch 5037: loss 0.404438\n",
      "batch 5038: loss 0.181584\n",
      "batch 5039: loss 0.352574\n",
      "batch 5040: loss 0.297232\n",
      "batch 5041: loss 0.480791\n",
      "batch 5042: loss 0.307432\n",
      "batch 5043: loss 0.462220\n",
      "batch 5044: loss 0.345394\n",
      "batch 5045: loss 0.227377\n",
      "batch 5046: loss 0.316773\n",
      "batch 5047: loss 0.367306\n",
      "batch 5048: loss 0.210909\n",
      "batch 5049: loss 0.250672\n",
      "batch 5050: loss 0.260270\n",
      "batch 5051: loss 0.459640\n",
      "batch 5052: loss 0.341413\n",
      "batch 5053: loss 0.408735\n",
      "batch 5054: loss 0.349167\n",
      "batch 5055: loss 0.632824\n",
      "batch 5056: loss 0.349803\n",
      "batch 5057: loss 0.510926\n",
      "batch 5058: loss 0.389850\n",
      "batch 5059: loss 0.423271\n",
      "batch 5060: loss 0.557152\n",
      "batch 5061: loss 0.359307\n",
      "batch 5062: loss 0.453207\n",
      "batch 5063: loss 0.233887\n",
      "batch 5064: loss 0.451217\n",
      "batch 5065: loss 0.267438\n",
      "batch 5066: loss 0.380516\n",
      "batch 5067: loss 0.454385\n",
      "batch 5068: loss 0.424647\n",
      "batch 5069: loss 0.353338\n",
      "batch 5070: loss 0.298889\n",
      "batch 5071: loss 0.266756\n",
      "batch 5072: loss 0.374956\n",
      "batch 5073: loss 0.311056\n",
      "batch 5074: loss 0.370406\n",
      "batch 5075: loss 0.368188\n",
      "batch 5076: loss 0.298001\n",
      "batch 5077: loss 0.333393\n",
      "batch 5078: loss 0.419337\n",
      "batch 5079: loss 0.283793\n",
      "batch 5080: loss 0.267251\n",
      "batch 5081: loss 0.289159\n",
      "batch 5082: loss 0.367805\n",
      "batch 5083: loss 0.506770\n",
      "batch 5084: loss 0.231988\n",
      "batch 5085: loss 0.293303\n",
      "batch 5086: loss 0.344827\n",
      "batch 5087: loss 0.500397\n",
      "batch 5088: loss 0.302107\n",
      "batch 5089: loss 0.417639\n",
      "batch 5090: loss 0.298987\n",
      "batch 5091: loss 0.329573\n",
      "batch 5092: loss 0.417447\n",
      "batch 5093: loss 0.184942\n",
      "batch 5094: loss 0.302645\n",
      "batch 5095: loss 0.331737\n",
      "batch 5096: loss 0.408031\n",
      "batch 5097: loss 0.349214\n",
      "batch 5098: loss 0.339442\n",
      "batch 5099: loss 0.196950\n",
      "batch 5100: loss 0.271237\n",
      "batch 5101: loss 0.389004\n",
      "batch 5102: loss 0.385691\n",
      "batch 5103: loss 0.524863\n",
      "batch 5104: loss 0.443924\n",
      "batch 5105: loss 0.346117\n",
      "batch 5106: loss 0.422028\n",
      "batch 5107: loss 0.359111\n",
      "batch 5108: loss 0.406640\n",
      "batch 5109: loss 0.372798\n",
      "batch 5110: loss 0.276075\n",
      "batch 5111: loss 0.373702\n",
      "batch 5112: loss 0.295009\n",
      "batch 5113: loss 0.313022\n",
      "batch 5114: loss 0.542607\n",
      "batch 5115: loss 0.437402\n",
      "batch 5116: loss 0.180520\n",
      "batch 5117: loss 0.438424\n",
      "batch 5118: loss 0.340302\n",
      "batch 5119: loss 0.530941\n",
      "batch 5120: loss 0.347726\n",
      "batch 5121: loss 0.393630\n",
      "batch 5122: loss 0.478163\n",
      "batch 5123: loss 0.389348\n",
      "batch 5124: loss 0.341749\n",
      "batch 5125: loss 0.191861\n",
      "batch 5126: loss 0.256329\n",
      "batch 5127: loss 0.414949\n",
      "batch 5128: loss 0.277844\n",
      "batch 5129: loss 0.284424\n",
      "batch 5130: loss 0.232283\n",
      "batch 5131: loss 0.370068\n",
      "batch 5132: loss 0.523619\n",
      "batch 5133: loss 0.251426\n",
      "batch 5134: loss 0.461428\n",
      "batch 5135: loss 0.257518\n",
      "batch 5136: loss 0.178444\n",
      "batch 5137: loss 0.499661\n",
      "batch 5138: loss 0.353418\n",
      "batch 5139: loss 0.410392\n",
      "batch 5140: loss 0.386838\n",
      "batch 5141: loss 0.406468\n",
      "batch 5142: loss 0.419361\n",
      "batch 5143: loss 0.385076\n",
      "batch 5144: loss 0.397335\n",
      "batch 5145: loss 0.322017\n",
      "batch 5146: loss 0.461134\n",
      "batch 5147: loss 0.348385\n",
      "batch 5148: loss 0.442761\n",
      "batch 5149: loss 0.422922\n",
      "batch 5150: loss 0.328914\n",
      "batch 5151: loss 0.190135\n",
      "batch 5152: loss 0.458104\n",
      "batch 5153: loss 0.361917\n",
      "batch 5154: loss 0.451361\n",
      "batch 5155: loss 0.275525\n",
      "batch 5156: loss 0.222634\n",
      "batch 5157: loss 0.420783\n",
      "batch 5158: loss 0.299580\n",
      "batch 5159: loss 0.440273\n",
      "batch 5160: loss 0.320871\n",
      "batch 5161: loss 0.292881\n",
      "batch 5162: loss 0.260869\n",
      "batch 5163: loss 0.314011\n",
      "batch 5164: loss 0.499025\n",
      "batch 5165: loss 0.182842\n",
      "batch 5166: loss 0.451297\n",
      "batch 5167: loss 0.225610\n",
      "batch 5168: loss 0.423870\n",
      "batch 5169: loss 0.408647\n",
      "batch 5170: loss 0.394598\n",
      "batch 5171: loss 0.300695\n",
      "batch 5172: loss 0.535206\n",
      "batch 5173: loss 0.347177\n",
      "batch 5174: loss 0.293210\n",
      "batch 5175: loss 0.248881\n",
      "batch 5176: loss 0.272563\n",
      "batch 5177: loss 0.324208\n",
      "batch 5178: loss 0.299512\n",
      "batch 5179: loss 0.328016\n",
      "batch 5180: loss 0.350979\n",
      "batch 5181: loss 0.382772\n",
      "batch 5182: loss 0.530839\n",
      "batch 5183: loss 0.401713\n",
      "batch 5184: loss 0.240270\n",
      "batch 5185: loss 0.520118\n",
      "batch 5186: loss 0.573264\n",
      "batch 5187: loss 0.327167\n",
      "batch 5188: loss 0.647515\n",
      "batch 5189: loss 0.318750\n",
      "batch 5190: loss 0.311237\n",
      "batch 5191: loss 0.218937\n",
      "batch 5192: loss 0.244369\n",
      "batch 5193: loss 0.321130\n",
      "batch 5194: loss 0.193668\n",
      "batch 5195: loss 0.256621\n",
      "batch 5196: loss 0.414539\n",
      "batch 5197: loss 0.255076\n",
      "batch 5198: loss 0.405808\n",
      "batch 5199: loss 0.298449\n",
      "batch 5200: loss 0.353240\n",
      "batch 5201: loss 0.358253\n",
      "batch 5202: loss 0.330313\n",
      "batch 5203: loss 0.398971\n",
      "batch 5204: loss 0.452444\n",
      "batch 5205: loss 0.195158\n",
      "batch 5206: loss 0.174389\n",
      "batch 5207: loss 0.267331\n",
      "batch 5208: loss 0.253533\n",
      "batch 5209: loss 0.161367\n",
      "batch 5210: loss 0.281708\n",
      "batch 5211: loss 0.397887\n",
      "batch 5212: loss 0.356122\n",
      "batch 5213: loss 0.490292\n",
      "batch 5214: loss 0.485958\n",
      "batch 5215: loss 0.319635\n",
      "batch 5216: loss 0.256996\n",
      "batch 5217: loss 0.300128\n",
      "batch 5218: loss 0.269618\n",
      "batch 5219: loss 0.364257\n",
      "batch 5220: loss 0.470862\n",
      "batch 5221: loss 0.291768\n",
      "batch 5222: loss 0.453234\n",
      "batch 5223: loss 0.206871\n",
      "batch 5224: loss 0.264730\n",
      "batch 5225: loss 0.584531\n",
      "batch 5226: loss 0.289038\n",
      "batch 5227: loss 0.289299\n",
      "batch 5228: loss 0.397744\n",
      "batch 5229: loss 0.307653\n",
      "batch 5230: loss 0.424926\n",
      "batch 5231: loss 0.311435\n",
      "batch 5232: loss 0.199006\n",
      "batch 5233: loss 0.368184\n",
      "batch 5234: loss 0.166398\n",
      "batch 5235: loss 0.554015\n",
      "batch 5236: loss 0.225683\n",
      "batch 5237: loss 0.632268\n",
      "batch 5238: loss 0.291626\n",
      "batch 5239: loss 0.548390\n",
      "batch 5240: loss 0.136310\n",
      "batch 5241: loss 0.418354\n",
      "batch 5242: loss 0.387974\n",
      "batch 5243: loss 0.231100\n",
      "batch 5244: loss 0.282097\n",
      "batch 5245: loss 0.361144\n",
      "batch 5246: loss 0.272512\n",
      "batch 5247: loss 0.374707\n",
      "batch 5248: loss 0.206173\n",
      "batch 5249: loss 0.258202\n",
      "batch 5250: loss 0.574946\n",
      "batch 5251: loss 0.323440\n",
      "batch 5252: loss 0.293395\n",
      "batch 5253: loss 0.213170\n",
      "batch 5254: loss 0.316339\n",
      "batch 5255: loss 0.419221\n",
      "batch 5256: loss 0.268322\n",
      "batch 5257: loss 0.193573\n",
      "batch 5258: loss 0.294021\n",
      "batch 5259: loss 0.255249\n",
      "batch 5260: loss 0.426856\n",
      "batch 5261: loss 0.342832\n",
      "batch 5262: loss 0.551004\n",
      "batch 5263: loss 0.198944\n",
      "batch 5264: loss 0.591065\n",
      "batch 5265: loss 0.344675\n",
      "batch 5266: loss 0.323779\n",
      "batch 5267: loss 0.300453\n",
      "batch 5268: loss 0.270792\n",
      "batch 5269: loss 0.557337\n",
      "batch 5270: loss 0.300120\n",
      "batch 5271: loss 0.299710\n",
      "batch 5272: loss 0.258185\n",
      "batch 5273: loss 0.207673\n",
      "batch 5274: loss 0.224973\n",
      "batch 5275: loss 0.399448\n",
      "batch 5276: loss 0.543782\n",
      "batch 5277: loss 0.326284\n",
      "batch 5278: loss 0.262991\n",
      "batch 5279: loss 0.369946\n",
      "batch 5280: loss 0.342283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5281: loss 0.464448\n",
      "batch 5282: loss 0.333797\n",
      "batch 5283: loss 0.266728\n",
      "batch 5284: loss 0.331454\n",
      "batch 5285: loss 0.238499\n",
      "batch 5286: loss 0.530285\n",
      "batch 5287: loss 0.281276\n",
      "batch 5288: loss 0.267661\n",
      "batch 5289: loss 0.438047\n",
      "batch 5290: loss 0.180621\n",
      "batch 5291: loss 0.508271\n",
      "batch 5292: loss 0.307319\n",
      "batch 5293: loss 0.287689\n",
      "batch 5294: loss 0.428738\n",
      "batch 5295: loss 0.293536\n",
      "batch 5296: loss 0.400318\n",
      "batch 5297: loss 0.267971\n",
      "batch 5298: loss 0.378808\n",
      "batch 5299: loss 0.297762\n",
      "batch 5300: loss 0.542674\n",
      "batch 5301: loss 0.308477\n",
      "batch 5302: loss 0.424807\n",
      "batch 5303: loss 0.362610\n",
      "batch 5304: loss 0.483146\n",
      "batch 5305: loss 0.223527\n",
      "batch 5306: loss 0.331224\n",
      "batch 5307: loss 0.488449\n",
      "batch 5308: loss 0.244557\n",
      "batch 5309: loss 0.408495\n",
      "batch 5310: loss 0.258482\n",
      "batch 5311: loss 0.247604\n",
      "batch 5312: loss 0.608301\n",
      "batch 5313: loss 0.395165\n",
      "batch 5314: loss 0.377494\n",
      "batch 5315: loss 0.318112\n",
      "batch 5316: loss 0.447782\n",
      "batch 5317: loss 0.348895\n",
      "batch 5318: loss 0.277059\n",
      "batch 5319: loss 0.407478\n",
      "batch 5320: loss 0.120538\n",
      "batch 5321: loss 0.225016\n",
      "batch 5322: loss 0.427973\n",
      "batch 5323: loss 0.433703\n",
      "batch 5324: loss 0.663008\n",
      "batch 5325: loss 0.245929\n",
      "batch 5326: loss 0.187405\n",
      "batch 5327: loss 0.329200\n",
      "batch 5328: loss 0.333307\n",
      "batch 5329: loss 0.479921\n",
      "batch 5330: loss 0.456075\n",
      "batch 5331: loss 0.348940\n",
      "batch 5332: loss 0.260617\n",
      "batch 5333: loss 0.314942\n",
      "batch 5334: loss 0.248474\n",
      "batch 5335: loss 0.267513\n",
      "batch 5336: loss 0.379634\n",
      "batch 5337: loss 0.376586\n",
      "batch 5338: loss 0.497897\n",
      "batch 5339: loss 0.218625\n",
      "batch 5340: loss 0.345834\n",
      "batch 5341: loss 0.254227\n",
      "batch 5342: loss 0.356508\n",
      "batch 5343: loss 0.172448\n",
      "batch 5344: loss 0.355370\n",
      "batch 5345: loss 0.288366\n",
      "batch 5346: loss 0.275126\n",
      "batch 5347: loss 0.325377\n",
      "batch 5348: loss 0.382043\n",
      "batch 5349: loss 0.303495\n",
      "batch 5350: loss 0.238599\n",
      "batch 5351: loss 0.396386\n",
      "batch 5352: loss 0.225509\n",
      "batch 5353: loss 0.216817\n",
      "batch 5354: loss 0.388648\n",
      "batch 5355: loss 0.201455\n",
      "batch 5356: loss 0.242348\n",
      "batch 5357: loss 0.300432\n",
      "batch 5358: loss 0.327020\n",
      "batch 5359: loss 0.314587\n",
      "batch 5360: loss 0.471569\n",
      "batch 5361: loss 0.364775\n",
      "batch 5362: loss 0.498918\n",
      "batch 5363: loss 0.293007\n",
      "batch 5364: loss 0.258009\n",
      "batch 5365: loss 0.277014\n",
      "batch 5366: loss 0.284609\n",
      "batch 5367: loss 0.247920\n",
      "batch 5368: loss 0.349489\n",
      "batch 5369: loss 0.603951\n",
      "batch 5370: loss 0.284178\n",
      "batch 5371: loss 0.359875\n",
      "batch 5372: loss 0.364716\n",
      "batch 5373: loss 0.359298\n",
      "batch 5374: loss 0.290821\n",
      "batch 5375: loss 0.418073\n",
      "batch 5376: loss 0.270478\n",
      "batch 5377: loss 0.553177\n",
      "batch 5378: loss 0.439210\n",
      "batch 5379: loss 0.401724\n",
      "batch 5380: loss 0.246814\n",
      "batch 5381: loss 0.429392\n",
      "batch 5382: loss 0.387659\n",
      "batch 5383: loss 0.540346\n",
      "batch 5384: loss 0.312148\n",
      "batch 5385: loss 0.371086\n",
      "batch 5386: loss 0.219904\n",
      "batch 5387: loss 0.409458\n",
      "batch 5388: loss 0.228432\n",
      "batch 5389: loss 0.293520\n",
      "batch 5390: loss 0.467530\n",
      "batch 5391: loss 0.315365\n",
      "batch 5392: loss 0.210535\n",
      "batch 5393: loss 0.133073\n",
      "batch 5394: loss 0.399872\n",
      "batch 5395: loss 0.146166\n",
      "batch 5396: loss 0.428142\n",
      "batch 5397: loss 0.505490\n",
      "batch 5398: loss 0.284080\n",
      "batch 5399: loss 0.371615\n",
      "batch 5400: loss 0.472698\n",
      "batch 5401: loss 0.336065\n",
      "batch 5402: loss 0.310326\n",
      "batch 5403: loss 0.287202\n",
      "batch 5404: loss 0.288374\n",
      "batch 5405: loss 0.264208\n",
      "batch 5406: loss 0.324004\n",
      "batch 5407: loss 0.493420\n",
      "batch 5408: loss 0.348275\n",
      "batch 5409: loss 0.288645\n",
      "batch 5410: loss 0.337220\n",
      "batch 5411: loss 0.462601\n",
      "batch 5412: loss 0.419230\n",
      "batch 5413: loss 0.245755\n",
      "batch 5414: loss 0.402540\n",
      "batch 5415: loss 0.313641\n",
      "batch 5416: loss 0.220943\n",
      "batch 5417: loss 0.331138\n",
      "batch 5418: loss 0.204171\n",
      "batch 5419: loss 0.225183\n",
      "batch 5420: loss 0.626116\n",
      "batch 5421: loss 0.606363\n",
      "batch 5422: loss 0.459394\n",
      "batch 5423: loss 0.476392\n",
      "batch 5424: loss 0.236418\n",
      "batch 5425: loss 0.383583\n",
      "batch 5426: loss 0.315788\n",
      "batch 5427: loss 0.385516\n",
      "batch 5428: loss 0.307173\n",
      "batch 5429: loss 0.226392\n",
      "batch 5430: loss 0.386481\n",
      "batch 5431: loss 0.209404\n",
      "batch 5432: loss 0.582607\n",
      "batch 5433: loss 0.302329\n",
      "batch 5434: loss 0.543896\n",
      "batch 5435: loss 0.370905\n",
      "batch 5436: loss 0.217326\n",
      "batch 5437: loss 0.639982\n",
      "batch 5438: loss 0.272031\n",
      "batch 5439: loss 0.247650\n",
      "batch 5440: loss 0.337901\n",
      "batch 5441: loss 0.321764\n",
      "batch 5442: loss 0.308337\n",
      "batch 5443: loss 0.269848\n",
      "batch 5444: loss 0.380483\n",
      "batch 5445: loss 0.574972\n",
      "batch 5446: loss 0.336311\n",
      "batch 5447: loss 0.297164\n",
      "batch 5448: loss 0.219707\n",
      "batch 5449: loss 0.272274\n",
      "batch 5450: loss 0.226536\n",
      "batch 5451: loss 0.290746\n",
      "batch 5452: loss 0.382210\n",
      "batch 5453: loss 0.524596\n",
      "batch 5454: loss 0.465913\n",
      "batch 5455: loss 0.267760\n",
      "batch 5456: loss 0.404369\n",
      "batch 5457: loss 0.359669\n",
      "batch 5458: loss 0.228158\n",
      "batch 5459: loss 0.483382\n",
      "batch 5460: loss 0.226083\n",
      "batch 5461: loss 0.332077\n",
      "batch 5462: loss 0.441861\n",
      "batch 5463: loss 0.170875\n",
      "batch 5464: loss 0.353925\n",
      "batch 5465: loss 0.420850\n",
      "batch 5466: loss 0.308484\n",
      "batch 5467: loss 0.322854\n",
      "batch 5468: loss 0.301085\n",
      "batch 5469: loss 0.443879\n",
      "batch 5470: loss 0.298109\n",
      "batch 5471: loss 0.333411\n",
      "batch 5472: loss 0.294453\n",
      "batch 5473: loss 0.236870\n",
      "batch 5474: loss 0.320990\n",
      "batch 5475: loss 0.395396\n",
      "batch 5476: loss 0.351418\n",
      "batch 5477: loss 0.307700\n",
      "batch 5478: loss 0.579791\n",
      "batch 5479: loss 0.223378\n",
      "batch 5480: loss 0.321248\n",
      "batch 5481: loss 0.377613\n",
      "batch 5482: loss 0.362235\n",
      "batch 5483: loss 0.322661\n",
      "batch 5484: loss 0.479193\n",
      "batch 5485: loss 0.374039\n",
      "batch 5486: loss 0.450995\n",
      "batch 5487: loss 0.194164\n",
      "batch 5488: loss 0.555139\n",
      "batch 5489: loss 0.368662\n",
      "batch 5490: loss 0.251950\n",
      "batch 5491: loss 0.230330\n",
      "batch 5492: loss 0.272326\n",
      "batch 5493: loss 0.162912\n",
      "batch 5494: loss 0.354998\n",
      "batch 5495: loss 0.318321\n",
      "batch 5496: loss 0.403679\n",
      "batch 5497: loss 0.409636\n",
      "batch 5498: loss 0.357927\n",
      "batch 5499: loss 0.356003\n"
     ]
    }
   ],
   "source": [
    "# 定义一些模型超参数：\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 实例化模型和数据读取类，并实例化一个 tf.keras.optimizer 的优化器（这里使用常用的 Adam 优化器）：\n",
    "model = MLP()\n",
    "# data_loader = MNISTLoader() # 导入数据 \n",
    "data_loader = MNISTLoader_my_download()  # 导入数据\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # 更新梯度\n",
    "\n",
    "# num_batches = int(mnist.train.num_examples // batch_size * num_epochs)\n",
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a39275f13501>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcategorical_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_test_data\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstart_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "categorical_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "    categorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
